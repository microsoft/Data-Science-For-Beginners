# à¤¡à¥‡à¤Ÿà¤¾ à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾ à¤•à¤¾ à¤ªà¤°à¤¿à¤šà¤¯

|![[(@sketchthedocs) à¤¦à¥à¤µà¤¾à¤°à¤¾ à¤¸à¥à¤•à¥‡à¤šà¤¨à¥‹à¤Ÿ](https://sketchthedocs.dev) ](../../../sketchnotes/02-Ethics.png)|
|:---:|
| à¤¡à¥‡à¤Ÿà¤¾ à¤µà¤¿à¤œà¥à¤žà¤¾à¤¨ à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾ - _[@nitya](https://twitter.com/nitya) à¤¦à¥à¤µà¤¾à¤°à¤¾ à¤¸à¥à¤•à¥‡à¤šà¤¨à¥‹à¤Ÿ_ |

---

à¤¹à¤® à¤¸à¤¬ à¤‡à¤¸ à¤¡à¤¾à¤Ÿà¤¾-à¤«à¤¾à¤‡à¤¡ à¤¦à¥à¤¨à¤¿à¤¯à¤¾ à¤®à¥‡à¤‚ à¤°à¤¹à¤¨à¥‡ à¤µà¤¾à¤²à¥‡ à¤¡à¤¾à¤Ÿà¤¾-à¤¨à¤¾à¤—à¤°à¤¿à¤• à¤¹à¥ˆ | 

à¤¬à¤¾à¤œà¤¾à¤° à¤•à¥‡ à¤°à¥à¤à¤¾à¤¨ à¤¯à¤¹ à¤¦à¤°à¥à¤¶à¤¾à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¤•à¤¿ à¥¨à¥¦à¥¨à¥¨ à¤¤à¤•, à¤¤à¥€à¤¨ à¤®à¥‡à¤‚ à¤¸à¥‡ à¤à¤• à¤¬à¥œà¥€ à¤¸à¤‚à¤¸à¥à¤¥à¤¾ à¤…à¤ªà¤¨à¤¾ à¤¡à¤¾à¤Ÿà¤¾ à¤•à¤¿ à¤–à¤°à¥€à¤¦ à¤”à¤° à¤¬à¥‡à¤šà¤¨à¤¾ à¤‘à¤¨à¤²à¤¾à¤‡à¤¨ [à¤¦à¥à¤•à¤¾à¤¨à¥‹à¤‚](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/) à¤¦à¥à¤µà¤¾à¤°à¤¾ à¤•à¤°à¥‡à¤‚à¤—à¥€ | **à¤à¤ª à¤¡à¥‡à¤µà¤²à¤ªà¤°** à¤•à¥‡ à¤°à¥‚à¤ª à¤®à¥‡à¤‚, à¤¹à¤® à¤¡à¥‡à¤Ÿà¤¾-à¤¸à¤‚à¤šà¤¾à¤²à¤¿à¤¤ à¤…à¤‚à¤¤à¤°à¥à¤¦à¥ƒà¤·à¥à¤Ÿà¤¿ à¤”à¤° à¤à¤²à¥à¤—à¥‹à¤°à¤¿à¤¥à¤®-à¤šà¤¾à¤²à¤¿à¤¤ à¤¸à¥à¤µà¤šà¤¾à¤²à¤¨ à¤•à¥‹ à¤¦à¥ˆà¤¨à¤¿à¤• à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾ à¤…à¤¨à¥à¤­à¤µà¥‹à¤‚ à¤®à¥‡à¤‚ à¤à¤•à¥€à¤•à¥ƒà¤¤ à¤•à¤°à¤¨à¤¾ à¤†à¤¸à¤¾à¤¨ à¤”à¤° à¤¸à¤¸à¥à¤¤à¤¾ à¤ªà¤¾à¤à¤‚à¤—à¥‡à¥¤ à¤²à¥‡à¤•à¤¿à¤¨ à¤œà¥ˆà¤¸à¥‡-à¤œà¥ˆà¤¸à¥‡ AI à¤µà¥à¤¯à¤¾à¤ªà¤• à¤¹à¥‹à¤¤à¤¾ à¤œà¤¾à¤à¤—à¤¾, à¤¹à¤®à¥‡à¤‚ à¤‡à¤¸ à¤¤à¤°à¤¹ à¤•à¥‡ à¤à¤²à¥à¤—à¥‹à¤°à¤¿à¤¦à¤® à¤•à¥‡ [à¤¹à¤¥à¤¿à¤¯à¤¾à¤°à¥€à¤•à¤°à¤£](https://www.youtube.com/watch?v=TQHs8SA1qpk) à¤¸à¥‡ à¤¹à¥‹à¤¨à¥‡ à¤µà¤¾à¤²à¥‡ à¤¸à¤‚à¤­à¤¾à¤µà¤¿à¤¤ à¤¨à¥à¤•à¤¸à¤¾à¤¨ à¤•à¥‹ à¤­à¥€ à¤¸à¤®à¤à¤¨à¤¾ à¤¹à¥‹à¤—à¤¾ à¥¤

à¤°à¥à¤à¤¾à¤¨ à¤¯à¤¹ à¤­à¥€ à¤¸à¤‚à¤•à¥‡à¤¤ à¤¦à¥‡à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¤•à¤¿ à¤¹à¤® à¥¨à¥¦à¥¨à¥« à¤¤à¤• [180 zettabytes](https://www.statista.com/statistics/871513/worldwide-data-created/) à¤¡à¥‡à¤Ÿà¤¾ à¤•à¤¾ à¤¨à¤¿à¤°à¥à¤®à¤¾à¤£ à¤”à¤° à¤‰à¤ªà¤­à¥‹à¤— à¤•à¤°à¥‡à¤‚à¤—à¥‡ à¥¤ **à¤¡à¥‡à¤Ÿà¤¾ à¤µà¥ˆà¤œà¥à¤žà¤¾à¤¨à¤¿à¤•** à¤•à¥‡ à¤°à¥‚à¤ª à¤®à¥‡à¤‚, à¤¯à¤¹ à¤¹à¤®à¥‡à¤‚ à¤µà¥à¤¯à¤•à¥à¤¤à¤¿à¤—à¤¤ à¤¡à¥‡à¤Ÿà¤¾ à¤¤à¤• à¤ªà¤¹à¥à¤‚à¤šà¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤¯à¥‡ à¤…à¤­à¥‚à¤¤à¤ªà¥‚à¤°à¥à¤µ à¤¸à¥à¤¤à¤° à¤ªà¥à¤°à¤¦à¤¾à¤¨ à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆ à¥¤ à¤‡à¤¸à¤•à¤¾ à¤®à¤¤à¤²à¤¬ à¤¹à¥ˆ à¤•à¤¿ à¤¹à¤® à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾à¤“à¤‚ à¤•à¥‡ à¤µà¥à¤¯à¤µà¤¹à¤¾à¤° à¤¸à¤‚à¤¬à¤‚à¤§à¥€ à¤ªà¥à¤°à¥‹à¤«à¤¾à¤‡à¤² à¤¬à¤¨à¤¾ à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¤”à¤° à¤¨à¤¿à¤°à¥à¤£à¤¯ à¤²à¥‡à¤¨à¥‡ à¤•à¥‹ à¤‡à¤¸ à¤¤à¤°à¤¹ à¤¸à¥‡ à¤ªà¥à¤°à¤­à¤¾à¤µà¤¿à¤¤ à¤•à¤° à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¤œà¥‹ à¤¸à¤‚à¤­à¤¾à¤µà¤¿à¤¤ à¤°à¥‚à¤ª à¤¸à¥‡ à¤à¤• [à¤®à¥à¤•à¥à¤¤ à¤‡à¤šà¥à¤›à¤¾ à¤•à¤¾ à¤­à¥à¤°à¤®](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) à¤ªà¥ˆà¤¦à¤¾ à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆ à¤œà¤¬à¥à¤•à¤¿ à¤µà¤¹ à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾à¤“à¤‚ à¤•à¥‹ à¤¹à¤®à¤¾à¤°à¥‡ à¤¦à¥à¤µà¤¾à¤°à¤¾ à¤ªà¤¸à¤‚à¤¦ à¤•à¤¿à¤ à¤œà¤¾à¤¨à¥‡ à¤µà¤¾à¤²à¥‡ à¤ªà¤°à¤¿à¤£à¤¾à¤®à¥‹à¤‚ à¤•à¥€ à¤“à¤° à¤†à¤•à¤°à¥à¤·à¤¿à¤¤ à¤•à¤°à¤¨à¤¾ à¥¤ à¤¯à¤¹ à¤¡à¥‡à¤Ÿà¤¾ à¤—à¥‹à¤ªà¤¨à¥€à¤¯à¤¤à¤¾ à¤”à¤° à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾ à¤•à¥€ à¤¸à¥à¤°à¤•à¥à¤·à¤¾ à¤ªà¤° à¤­à¥€ à¤µà¥à¤¯à¤¾à¤ªà¤• à¤ªà¥à¤°à¤¶à¥à¤¨ à¤‰à¤ à¤¾à¤¤à¤¾ à¤¹à¥ˆ à¥¤

à¤¡à¥‡à¤Ÿà¤¾ à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾ à¤…à¤¬ à¤¡à¥‡à¤Ÿà¤¾ à¤µà¤¿à¤œà¥à¤žà¤¾à¤¨ à¤”à¤° à¤‡à¤‚à¤œà¥€à¤¨à¤¿à¤¯à¤°à¤¿à¤‚à¤— à¤•à¤¾  _à¤†à¤µà¤¶à¥à¤¯à¤• à¤°à¤•à¥à¤·à¤•_ à¤¹à¥ˆà¤‚, à¤œà¤¿à¤¸à¤¸à¥‡ à¤¹à¤®à¥‡à¤‚ à¤…à¤ªà¤¨à¥‡ à¤¡à¥‡à¤Ÿà¤¾-à¤¸à¤‚à¤šà¤¾à¤²à¤¿à¤¤ à¤•à¤¾à¤°à¥à¤¯à¥‹à¤‚ à¤¸à¥‡ à¤¸à¤‚à¤­à¤¾à¤µà¤¿à¤¤ à¤¨à¥à¤•à¤¸à¤¾à¤¨ à¤”à¤° à¤…à¤¨à¤ªà¥‡à¤•à¥à¤·à¤¿à¤¤ à¤ªà¤°à¤¿à¤£à¤¾à¤®à¥‹à¤‚ à¤•à¥‹ à¤¨à¥€à¤šà¥‡ à¤°à¤–à¤¨à¥‡ à¤®à¥‡à¤‚ à¤®à¤¦à¤¦ à¤®à¤¿à¤²à¤¤à¥€ à¤¹à¥ˆ à¥¤ [AI à¤•à¥‡ à¤²à¤¿à¤ à¤—à¤¾à¤°à¥à¤Ÿà¤¨à¤° à¤¹à¤¾à¤‡à¤ª à¤¸à¤¾à¤‡à¤•à¤¿à¤²](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) à¤¡à¤¿à¤œà¤¿à¤Ÿà¤² à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾ à¤®à¥‡à¤‚ à¤‰à¤šà¤¿à¤¤ à¤°à¥à¤à¤¾à¤¨à¥‹à¤‚ à¤•à¥€ à¤ªà¤¹à¤šà¤¾à¤¨ à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆ AI à¤•à¥‡ _democratization_ à¤”à¤° _industrialization_ à¤•à¥‡ à¤†à¤¸à¤ªà¤¾à¤¸ à¤¬à¤¡à¤¼à¥‡ à¤®à¥‡à¤—à¤¾à¤Ÿà¥à¤°à¥‡à¤‚à¤¡ à¤•à¥‡ à¤²à¤¿à¤ à¤ªà¥à¤°à¤®à¥à¤– à¤¡à¥à¤°à¤¾à¤‡à¤µà¤° à¤•à¥‡ à¤°à¥‚à¤ª à¤®à¥‡à¤‚ à¤œà¤¿à¤®à¥à¤®à¥‡à¤¦à¤¾à¤° AI à¤•à¥€ à¥›à¤¿à¤®à¥à¤®à¥‡à¤¦à¤¾à¤°à¥€ à¤”à¤° AI à¤¶à¤¾à¤¸à¤¨ à¥¤


![AI à¤•à¥‡ à¤²à¤¿à¤ à¤—à¤¾à¤°à¥à¤Ÿà¤¨à¤° à¤•à¤¾ à¤ªà¥à¤°à¤šà¤¾à¤° à¤šà¤•à¥à¤° - à¥¨à¥¦à¥¨à¥¦](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

à¤‡à¤¸ à¤ªà¤¾à¤  à¤®à¥‡à¤‚, à¤¹à¤® à¤¡à¥‡à¤Ÿà¤¾ à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾ à¤•à¥‡ à¤†à¤•à¤°à¥à¤·à¤• à¤•à¥à¤·à¥‡à¤¤à¥à¤° à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¸à¥€à¤–à¥‡à¤‚à¤—à¥‡  - à¤®à¥‚à¤² à¤…à¤µà¤§à¤¾à¤°à¤£à¤¾à¤“à¤‚ à¤”à¤° à¤šà¥à¤¨à¥Œà¤¤à¤¿à¤¯à¥‹à¤‚ à¤¸à¥‡ à¤²à¥‡à¤•à¤° à¤•à¥‡à¤¸-à¤¸à¥à¤Ÿà¤¡à¥€ à¤”à¤° à¤¶à¤¾à¤¸à¤¨ à¤œà¥ˆà¤¸à¥€ à¤à¤ªà¥à¤²à¤¾à¤‡à¤¡ AI à¤…à¤µà¤§à¤¾à¤°à¤£à¤¾à¤“à¤‚ à¤¤à¤• - à¤œà¥‹ à¤¡à¥‡à¤Ÿà¤¾ à¤”à¤° AI à¤•à¥‡ à¤¸à¤¾à¤¥ à¤•à¤¾à¤® à¤•à¤°à¤¨à¥‡ à¤µà¤¾à¤²à¥€ à¤¸à¤®à¥‚à¤¹ à¤”à¤° à¤¸à¤‚à¤—à¤ à¤¨à¥‹à¤‚ à¤®à¥‡à¤‚ à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾ à¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤¿ à¤¸à¥à¤¥à¤¾à¤ªà¤¿à¤¤ à¤•à¤°à¤¨à¥‡ à¤®à¥‡à¤‚ à¤®à¤¦à¤¦ à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¥¤

## [à¤ªà¤¾à¤  à¤¸à¥‡ à¤ªà¤¹à¤²à¥‡ à¤•à¥€ à¤ªà¥à¤°à¤¶à¥à¤¨à¥‹à¤¤à¥à¤¤à¤°à¥€](https://red-water-0103e7a0f.azurestaticapps.net/quiz/2) ðŸŽ¯

## à¤®à¥‚à¤² à¤ªà¤°à¤¿à¤­à¤¾à¤·à¤¾à¤à¤‚

à¤†à¤‡à¤ à¤¬à¥à¤¨à¤¿à¤¯à¤¾à¤¦à¥€ à¤¶à¤¬à¥à¤¦à¤¾à¤µà¤²à¥€ à¤•à¥‹ à¤¸à¤®à¤à¤¨à¤¾ à¤¶à¥à¤°à¥‚ à¤•à¤°à¥‡à¤‚ à¥¤

"à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾" [à¤—à¥à¤°à¥€à¤• à¤¶à¤¬à¥à¤¦ "à¤à¤¥à¤¿à¤•à¥‹à¤¸"](https://en.wikipedia.org/wiki/Ethics) (à¤”à¤° à¤‡à¤¸à¤•à¥€ à¤œà¤¡à¤¼ "à¤à¤¥à¥‹à¤¸") à¤¸à¥‡ à¤†à¤¯à¤¾ à¤¹à¥ˆ à¤œà¤¿à¤¸à¤•à¤¾ à¤…à¤°à¥à¤¥ _à¤šà¤°à¤¿à¤¤à¥à¤° à¤¯à¤¾ à¤¨à¥ˆà¤¤à¤¿à¤• à¤ªà¥à¤°à¤•à¥ƒà¤¤à¤¿_ à¤¹à¥‹à¤¤à¤¾ à¤¹à¥ˆ à¥¤

**à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾** à¤‰à¤¨ à¤¸à¤¾à¤à¤¾ à¤®à¥‚à¤²à¥à¤¯à¥‹à¤‚ à¤”à¤° à¤¨à¥ˆà¤¤à¤¿à¤• à¤¸à¤¿à¤¦à¥à¤§à¤¾à¤‚à¤¤à¥‹à¤‚ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¹à¥ˆ à¤œà¥‹ à¤¸à¤®à¤¾à¤œ à¤®à¥‡à¤‚ à¤¹à¤®à¤¾à¤°à¥‡ à¤µà¥à¤¯à¤µà¤¹à¤¾à¤° à¤•à¥‹ à¤¨à¤¿à¤¯à¤‚à¤¤à¥à¤°à¤¿à¤¤ à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¥¤ à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾ à¤•à¤¾à¤¨à¥‚à¤¨à¥‹à¤‚ à¤ªà¤° à¤¨à¤¹à¥€à¤‚ à¤¬à¤²à¥à¤•à¤¿ "à¤¸à¤¹à¥€ à¤¬à¤¨à¤¾à¤® à¤—à¤²à¤¤" à¤•à¥‡ à¤µà¥à¤¯à¤¾à¤ªà¤• à¤°à¥‚à¤ª à¤¸à¥‡ à¤¸à¥à¤µà¥€à¤•à¥ƒà¤¤ à¤®à¤¾à¤¨à¤¦à¤‚à¤¡ à¤ªà¤° à¤†à¤§à¤¾à¤°à¤¿à¤¤ à¤¹à¥ˆ à¥¤ à¤²à¥‡à¤•à¤¿à¤¨ , à¤¨à¥ˆà¤¤à¤¿à¤• à¤µà¤¿à¤šà¤¾à¤° à¤•à¥‰à¤°à¥à¤ªà¥‹à¤°à¥‡à¤Ÿ à¤ªà¥à¤°à¤¶à¤¾à¤¸à¤¨ à¤•à¥€ à¤ªà¤¹à¤² à¤”à¤° à¤…à¤¨à¥à¤ªà¤¾à¤²à¤¨ à¤•à¥‡ à¤²à¤¿à¤ à¤…à¤§à¤¿à¤• à¤ªà¥à¤°à¥‹à¤¤à¥à¤¸à¤¾à¤¹à¤¨ à¤ªà¥ˆà¤¦à¤¾ à¤•à¤°à¤¨à¥‡ à¤µà¤¾à¤²à¥‡ à¤¸à¤°à¤•à¤¾à¤°à¥€ à¤¨à¤¿à¤¯à¤®à¥‹à¤‚ à¤•à¥‹ à¤ªà¥à¤°à¤­à¤¾à¤µà¤¿à¤¤ à¤•à¤° à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¥¤

**à¤¡à¥‡à¤Ÿà¤¾ à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾** à¤à¤• [à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾ à¤•à¥€ à¤¨à¤ˆ à¤¶à¤¾à¤–à¤¾](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1) à¤¹à¥ˆ à¤œà¥‹ "_à¤¡à¥‡à¤Ÿà¤¾, à¤à¤²à¥à¤—à¥‹à¤°à¤¿à¤¦à¤® à¤”à¤° à¤¸à¥‡ à¤¸à¤‚à¤¬à¤‚à¤§à¤¿à¤¤ à¤¨à¥ˆà¤¤à¤¿à¤• à¤¸à¤®à¤¸à¥à¤¯à¤¾à¤“à¤‚ à¤•à¤¾ à¤…à¤§à¥à¤¯à¤¯à¤¨ à¤”à¤° à¤®à¥‚à¤²à¥à¤¯à¤¾à¤‚à¤•à¤¨ à¤•à¤°à¤¤à¥€ à¤¹à¥ˆ_" à¥¤ à¤¯à¤¹à¤¾à¤‚, **"à¤¡à¥‡à¤Ÿà¤¾"** - à¤¨à¤¿à¤°à¥à¤®à¤¾à¤£, à¤°à¤¿à¤•à¥‰à¤°à¥à¤¡à¤¿à¤‚à¤—, à¤…à¤µà¤§à¤¿, à¤ªà¥à¤°à¤¸à¤‚à¤¸à¥à¤•à¤°à¤£ à¤ªà¥à¤°à¤¸à¤¾à¤°, à¤¸à¤¾à¤à¤¾à¤•à¤°à¤£ à¤”à¤° à¤‰à¤ªà¤¯à¥‹à¤— à¤¸à¥‡ à¤¸à¤‚à¤¬à¤‚à¤§à¤¿à¤¤ à¤•à¤¾à¤°à¥à¤¯à¥‹à¤‚ à¤ªà¤° à¤•à¥‡à¤‚à¤¦à¥à¤°à¤¿à¤¤ à¤¹à¥ˆ, **"à¤à¤²à¥à¤—à¥‹à¤°à¤¿à¤¦à¤®"** AI , à¤à¤œà¥‡à¤‚à¤Ÿà¥‹à¤‚, à¤®à¤¶à¥€à¤¨ à¤²à¤°à¥à¤¨à¤¿à¤‚à¤— à¤”à¤° à¤°à¥‹à¤¬à¥‹à¤Ÿà¥‹ à¤ªà¤° à¤•à¥‡à¤‚à¤¦à¥à¤°à¤¿à¤¤ à¤¹à¥ˆ, à¤”à¤° ** "à¤…à¤­à¥à¤¯à¤¾à¤¸"** à¤œà¤¿à¤®à¥à¤®à¥‡à¤¦à¤¾à¤° à¤¨à¤µà¤¾à¤šà¤¾à¤°, à¤ªà¥à¤°à¥‹à¤—à¥à¤°à¤¾à¤®à¤¿à¤‚à¤—, à¤¹à¥ˆà¤•à¤¿à¤‚à¤— à¤”à¤° à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾ à¤•à¥‹à¤¡ à¤œà¥ˆà¤¸à¥‡ à¤µà¤¿à¤·à¤¯à¥‹à¤‚ à¤ªà¤° à¤•à¥‡à¤‚à¤¦à¥à¤°à¤¿à¤¤ à¤¹à¥ˆ à¥¤

**à¤à¤ªà¥à¤²à¤¾à¤‡à¤¡ à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾** [à¤¨à¥ˆà¤¤à¤¿à¤• à¤µà¤¿à¤šà¤¾à¤°à¥‹à¤‚ à¤•à¤¾ à¤µà¥à¤¯à¤¾à¤µà¤¹à¤¾à¤°à¤¿à¤• à¤…à¤¨à¥à¤ªà¥à¤°à¤¯à¥‹à¤—](https://en.wikipedia.org/wiki/Applied_ethics) à¤¹à¥ˆ à¥¤ à¤¯à¤¹ _à¤µà¤¾à¤¸à¥à¤¤à¤µà¤¿à¤• à¤¦à¥à¤¨à¤¿à¤¯à¤¾ à¤•à¥€ à¤•à¤¾à¤°à¥à¤°à¤µà¤¾à¤‡à¤¯à¥‹à¤‚, à¤‰à¤¤à¥à¤ªà¤¾à¤¦à¥‹à¤‚ à¤”à¤° à¤ªà¥à¤°à¤•à¥à¤°à¤¿à¤¯à¤¾à¤“à¤‚_ à¤•à¥‡ à¤¸à¤‚à¤¦à¤°à¥à¤­ à¤®à¥‡à¤‚ à¤¨à¥ˆà¤¤à¤¿à¤• à¤®à¥à¤¦à¥à¤¦à¥‹à¤‚ à¤•à¥€ à¤¸à¤•à¥à¤°à¤¿à¤¯ à¤°à¥‚à¤ª à¤¸à¥‡ à¤œà¤¾à¤‚à¤š à¤•à¤°à¤¨à¥‡ à¤”à¤° à¤¸à¥à¤§à¤¾à¤°à¤¾à¤¤à¥à¤®à¤• à¤‰à¤ªà¤¾à¤¯ à¤•à¤°à¤¨à¥‡ à¤•à¥€ à¤ªà¥à¤°à¤•à¥à¤°à¤¿à¤¯à¤¾ à¤¹à¥ˆ à¤¤à¤¾à¤•à¤¿ à¤¯à¥‡ à¤¹à¤®à¤¾à¤°à¥‡ à¤ªà¤°à¤¿à¤­à¤¾à¤·à¤¿à¤¤ à¤¨à¥ˆà¤¤à¤¿à¤• à¤®à¥‚à¤²à¥à¤¯à¥‹à¤‚ à¤•à¥‡ à¤¸à¤¾à¤¥ à¤¸à¤‚à¤°à¥‡à¤–à¤¿à¤¤ à¤°à¤¹à¥‡à¤‚ à¥¤

**à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾ à¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤¿** à¤¯à¤¹ à¤¸à¥à¤¨à¤¿à¤¶à¥à¤šà¤¿à¤¤ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ [_operationalizing_ à¤à¤ªà¥à¤²à¤¾à¤‡à¤¡ à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾](https://hbr.org/2019/05/how-to-design-an-ethical-organization) à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¹à¥ˆ à¤•à¤¿ à¤¹à¤®à¤¾à¤°à¥‡ à¤¨à¥ˆà¤¤à¤¿à¤• à¤¸à¤¿à¤¦à¥à¤§à¤¾à¤‚à¤¤à¥‹à¤‚ à¤”à¤° à¤ªà¥à¤°à¤¥à¤¾à¤“à¤‚ à¤•à¥‹ à¤ªà¥‚à¤°à¥‡ à¤¸à¤‚à¤—à¤ à¤¨ à¤®à¥‡à¤‚ à¤à¤• à¤¸à¥à¤¸à¤‚à¤—à¤¤ à¤”à¤° à¤®à¤¾à¤ªà¤¨à¥€à¤¯ à¤¤à¤°à¥€à¤•à¥‡ à¤¸à¥‡ à¤…à¤ªà¤¨à¤¾à¤¯à¤¾ à¤œà¤¾à¤ à¥¤ à¤¸à¤«à¤² à¤¨à¥ˆà¤¤à¤¿à¤• à¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤¿à¤¯à¤¾à¤ à¤¸à¤‚à¤—à¤ à¤¨-à¤µà¥à¤¯à¤¾à¤ªà¥€ à¤¨à¥ˆà¤¤à¤¿à¤• à¤¸à¤¿à¤¦à¥à¤§à¤¾à¤‚à¤¤à¥‹à¤‚ à¤•à¥‹ à¤ªà¤°à¤¿à¤­à¤¾à¤·à¤¿à¤¤ à¤•à¤°à¤¤à¥€ à¤¹à¥ˆà¤‚, à¤…à¤¨à¥à¤ªà¤¾à¤²à¤¨ à¤•à¥‡ à¤²à¤¿à¤ à¤¸à¤¾à¤°à¥à¤¥à¤• à¤ªà¥à¤°à¥‹à¤¤à¥à¤¸à¤¾à¤¹à¤¨ à¤ªà¥à¤°à¤¦à¤¾à¤¨ à¤•à¤°à¤¤à¥€ à¤¹à¥ˆà¤‚, à¤”à¤° à¤¸à¤‚à¤—à¤ à¤¨ à¤•à¥‡ à¤¹à¤° à¤¸à¥à¤¤à¤° à¤ªà¤° à¤µà¤¾à¤‚à¤›à¤¿à¤¤ à¤µà¥à¤¯à¤µà¤¹à¤¾à¤°à¥‹à¤‚ à¤•à¥‹ à¤ªà¥à¤°à¥‹à¤¤à¥à¤¸à¤¾à¤¹à¤¿à¤¤ à¤”à¤° à¤ªà¥à¤°à¤µà¤°à¥à¤§à¤¿à¤¤ à¤•à¤°à¤•à¥‡ à¤¨à¥ˆà¤¤à¤¿à¤• à¤®à¤¾à¤¨à¤¦à¤‚à¤¡à¥‹à¤‚ à¤•à¥‹ à¤¸à¥à¤¦à¥ƒà¤¢à¤¼ à¤•à¤°à¤¤à¥€ à¤¹à¥ˆà¤‚ à¥¤


## à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾ à¤•à¥€ à¤…à¤µà¤§à¤¾à¤°à¤£à¤¾à¤à¤‚

à¤‡à¤¸ à¤–à¤‚à¤¡ à¤®à¥‡à¤‚, à¤¹à¤® à¤¡à¥‡à¤Ÿà¤¾ à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾ à¤•à¥‡ à¤²à¤¿à¤ à¤¸à¤¾à¤à¤¾ à¤®à¥‚à¤²à¥à¤¯à¥‹à¤‚ (à¤¸à¤¿à¤¦à¥à¤§à¤¾à¤‚à¤¤à¥‹à¤‚) à¤”à¤° à¤¨à¥ˆà¤¤à¤¿à¤• à¤šà¥à¤¨à¥Œà¤¤à¤¿à¤¯à¥‹à¤‚ (à¤¸à¤®à¤¸à¥à¤¯à¤¾à¤“à¤‚) à¤œà¥ˆà¤¸à¥€ à¤…à¤µà¤§à¤¾à¤°à¤£à¤¾à¤“à¤‚ à¤ªà¤° à¤šà¤°à¥à¤šà¤¾ à¤•à¤°à¥‡à¤‚à¤—à¥‡ - à¤”à¤° à¤®à¤¾à¤®à¤²à¥‡ à¤•à¥‡ à¤…à¤§à¥à¤¯à¤¯à¤¨ à¤•à¤¾ à¤ªà¤¤à¤¾ à¤²à¤—à¤¾à¤à¤‚à¤—à¥‡ à¤œà¥‹ à¤†à¤ªà¤•à¥‹ à¤µà¤¾à¤¸à¥à¤¤à¤µà¤¿à¤• à¤¦à¥à¤¨à¤¿à¤¯à¤¾ à¤•à¥‡ à¤¸à¤‚à¤¦à¤°à¥à¤­à¥‹à¤‚ à¤®à¥‡à¤‚ à¤‡à¤¨ à¤…à¤µà¤§à¤¾à¤°à¤£à¤¾à¤“à¤‚ à¤•à¥‹ à¤¸à¤®à¤à¤¨à¥‡ à¤®à¥‡à¤‚ à¤®à¤¦à¤¦ à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¥¤

### 1. à¤¨à¥ˆà¤¤à¤¿à¤• à¤¸à¤¿à¤¦à¥à¤§à¤¾à¤‚à¤¤

à¤ªà¥à¤°à¤¤à¥à¤¯à¥‡à¤• à¤¡à¥‡à¤Ÿà¤¾ à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾ à¤°à¤£à¤¨à¥€à¤¤à¤¿ _à¤¨à¥ˆà¤¤à¤¿à¤• à¤¸à¤¿à¤¦à¥à¤§à¤¾à¤‚à¤¤à¥‹à¤‚_ à¤•à¥‹ à¤ªà¤°à¤¿à¤­à¤¾à¤·à¤¿à¤¤ à¤•à¤°à¤•à¥‡ à¤¶à¥à¤°à¥‚ à¤¹à¥‹à¤¤à¥€ à¤¹à¥ˆ - "à¤¸à¤¾à¤à¤¾ à¤®à¥‚à¤²à¥à¤¯" à¤œà¥‹ à¤¸à¥à¤µà¥€à¤•à¤¾à¤°à¥à¤¯ à¤µà¥à¤¯à¤µà¤¹à¤¾à¤°à¥‹à¤‚ à¤•à¤¾ à¤µà¤°à¥à¤£à¤¨ à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚, à¤”à¤° à¤¹à¤®à¤¾à¤°à¥‡ à¤¡à¥‡à¤Ÿà¤¾ à¤”à¤° AI à¤ªà¤°à¤¿à¤¯à¥‹à¤œà¤¨à¤¾à¤“à¤‚ à¤®à¥‡à¤‚ à¤…à¤¨à¥à¤ªà¤¾à¤²à¤¨ à¤•à¤¾à¤°à¥à¤¯à¥‹à¤‚ à¤•à¤¾ à¤®à¤¾à¤°à¥à¤—à¤¦à¤°à¥à¤¶à¤¨ à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¥¤ à¤²à¥‡à¤•à¤¿à¤¨, à¤…à¤§à¤¿à¤•à¤¾à¤‚à¤¶ à¤¬à¤¡à¤¼à¥‡ à¤¸à¤‚à¤—à¤ à¤¨ à¤‡à¤¨à¥à¤¹à¥‡à¤‚ à¤à¤• _à¤¨à¥ˆà¤¤à¤¿à¤• AI_ à¤®à¤¿à¤¶à¤¨ à¤¸à¥à¤Ÿà¥‡à¤Ÿà¤®à¥‡à¤‚à¤Ÿ à¤¯à¤¾ à¤«à¥à¤°à¥‡à¤®à¤µà¤°à¥à¤• à¤®à¥‡à¤‚ à¤°à¥‡à¤–à¤¾à¤‚à¤•à¤¿à¤¤ à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¤œà¥‹ à¤•à¥‰à¤°à¥à¤ªà¥‹à¤°à¥‡à¤Ÿ à¤¸à¥à¤¤à¤° à¤ªà¤° à¤ªà¤°à¤¿à¤­à¤¾à¤·à¤¿à¤¤ à¤¹à¥‹à¤¤à¤¾ à¤¹à¥ˆ à¤”à¤° à¤¸à¤­à¥€ à¤Ÿà¥€à¤®à¥‹à¤‚ à¤®à¥‡à¤‚ à¤²à¤—à¤¾à¤¤à¤¾à¤° à¤²à¤¾à¤—à¥‚ à¤¹à¥‹à¤¤à¤¾ à¤¹à¥ˆ à¥¤

**à¤‰à¤¦à¤¾à¤¹à¤°à¤£:** à¤®à¤¾à¤‡à¤•à¥à¤°à¥‹à¤¸à¥‰à¤«à¥à¤Ÿ à¤•à¥€ [Responsible AI](https://www.microsoft.com/en-us/ai/responsible-ai) à¤®à¤¿à¤¶à¤¨ à¤¸à¥à¤Ÿà¥‡à¤Ÿà¤®à¥‡à¤‚à¤Ÿ à¤•à¤¹à¤¤à¥€ à¤¹à¥ˆ : _"à¤¹à¤® à¤¨à¥ˆà¤¤à¤¿à¤• à¤¸à¤¿à¤¦à¥à¤§à¤¾à¤‚à¤¤à¥‹à¤‚ à¤¦à¥à¤µà¤¾à¤°à¤¾ à¤¸à¤‚à¤šà¤¾à¤²à¤¿à¤¤ AI à¤•à¥€ à¤‰à¤¨à¥à¤¨à¤¤à¤¿ à¤•à¥‡ à¤²à¤¿à¤ à¤ªà¥à¤°à¤¤à¤¿à¤¬à¤¦à¥à¤§ à¤¹à¥ˆà¤‚ à¤œà¥‹ à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‹ à¤¸à¤¬à¤¸à¥‡ à¤ªà¤¹à¤²à¥‡ à¤°à¤–à¤¤à¥‡ à¤¹à¥ˆà¤‚ |"_ - à¤¨à¥€à¤šà¥‡ à¤¦à¤¿à¤ à¤—à¤ à¤¢à¤¾à¤‚à¤šà¥‡ à¤®à¥‡à¤‚ 6 à¤¨à¥ˆà¤¤à¤¿à¤• à¤¸à¤¿à¤¦à¥à¤§à¤¾à¤‚à¤¤à¥‹à¤‚ à¤•à¥€ à¤µà¤¾à¤°à¥à¤¨à¤¾ à¤•à¥€ à¤—à¤¯à¥€ à¤¹à¥ˆ :

![à¤®à¤¾à¤‡à¤•à¥à¤°à¥‹à¤¸à¥‰à¤«à¥à¤Ÿ à¤•à¥€ Responsible AI](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

à¤†à¤‡à¤ à¤¸à¤‚à¤•à¥à¤·à¥‡à¤ª à¤®à¥‡à¤‚ à¤‡à¤¨ à¤¸à¤¿à¤¦à¥à¤§à¤¾à¤‚à¤¤à¥‹à¤‚ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¸à¥€à¤–à¥‡ | _à¤ªà¤¾à¤°à¤¦à¤°à¥à¤¶à¤¿à¤¤à¤¾_ à¤”à¤° _à¤œà¤µà¤¾à¤¬à¤¦à¥‡à¤¹à¥€_ à¤µà¤¹ à¤®à¥‚à¤²à¤­à¥‚à¤¤ à¤®à¥‚à¤²à¥à¤¯ à¤¹à¥ˆà¤‚ à¤œà¤¿à¤¨ à¤ªà¤° à¤…à¤¨à¥à¤¯ à¤¸à¤¿à¤¦à¥à¤§à¤¾à¤‚à¤¤à¥‹à¤‚ à¤•à¤¾ à¤¨à¤¿à¤°à¥à¤®à¤¾à¤£ à¤•à¤¿à¤¯à¤¾ à¤—à¤¯à¤¾ à¤¹à¥ˆ - à¤¤à¥‹ à¤šà¤²à¤¿à¤ à¤µà¤¹à¤¾à¤‚ à¤¶à¥à¤°à¥ à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚ :

* [**à¤œà¤µà¤¾à¤¬à¤¦à¥‡à¤¹à¥€**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾à¤“à¤‚ à¤•à¥‹ à¤‰à¤¨à¤•à¥‡ à¤¡à¥‡à¤Ÿà¤¾ à¤”à¤° AI à¤¸à¤‚à¤šà¤¾à¤²à¤¨, à¤”à¤° à¤‡à¤¨ à¤¨à¥ˆà¤¤à¤¿à¤• à¤¸à¤¿à¤¦à¥à¤§à¤¾à¤‚à¤¤à¥‹à¤‚ à¤•à¥‡ à¤…à¤¨à¥à¤ªà¤¾à¤²à¤¨ à¤•à¥‡ à¤²à¤¿à¤ _à¤œà¤¿à¤®à¥à¤®à¥‡à¤¦à¤¾à¤°_ à¤¬à¤¨à¤¾à¤¤à¥€ à¤¹à¥ˆ à¥¤
* [**à¤ªà¤¾à¤°à¤¦à¤°à¥à¤¶à¤¿à¤¤à¤¾**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) à¤¸à¥à¤¨à¤¿à¤¶à¥à¤šà¤¿à¤¤ à¤•à¤°à¤¤à¥€ à¤¹à¥ˆ à¤•à¤¿ à¤¡à¥‡à¤Ÿà¤¾ à¤”à¤° AI à¤•à¥à¤°à¤¿à¤¯à¤¾à¤à¤‚ à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾à¤“à¤‚ à¤•à¥‡ à¤²à¤¿à¤ _à¤¸à¤®à¤à¤¨à¥‡ à¤¯à¥‹à¤—à¥à¤¯_ (à¤µà¥à¤¯à¤¾à¤–à¥à¤¯à¤¾ à¤¯à¥‹à¤—à¥à¤¯) à¤¹à¥ˆà¤‚, à¤¯à¤¹ à¤¬à¤¤à¤¾à¤¤à¥‡ à¤¹à¥à¤ à¤•à¤¿ à¤¨à¤¿à¤°à¥à¤£à¤¯à¥‹à¤‚ à¤•à¥‡ à¤ªà¥€à¤›à¥‡ à¤•à¥à¤¯à¤¾ à¤”à¤° à¤•à¥à¤¯à¥‹à¤‚ à¤¹à¥ˆ à¥¤
* [**à¤¨à¤¿à¤·à¥à¤ªà¤•à¥à¤·à¤¤à¤¾**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - à¤¯à¤¹ à¤¸à¥à¤¨à¤¿à¤¶à¥à¤šà¤¿à¤¤ à¤•à¤°à¤¨à¥‡ à¤ªà¤° à¤§à¥à¤¯à¤¾à¤¨ à¤•à¥‡à¤‚à¤¦à¥à¤°à¤¿à¤¤ à¤•à¤°à¤¤à¥€ à¤¹à¥ˆ à¤•à¤¿ AI à¤¡à¥‡à¤Ÿà¤¾ à¤”à¤° à¤¸à¤¿à¤¸à¥à¤Ÿà¤® à¤®à¥‡à¤‚ à¤•à¤¿à¤¸à¥€ à¤­à¥€ à¤ªà¥à¤°à¤£à¤¾à¤²à¥€à¤—à¤¤ à¤¯à¤¾ à¤¨à¤¿à¤¹à¤¿à¤¤ à¤¸à¤¾à¤®à¤¾à¤œà¤¿à¤•-à¤¤à¤•à¤¨à¥€à¤•à¥€ à¤ªà¥‚à¤°à¥à¤µà¤¾à¤—à¥à¤°à¤¹à¥‹à¤‚ à¤•à¥‹ à¤¸à¤‚à¤¬à¥‹à¤§à¤¿à¤¤ à¤•à¤°à¤¤à¥‡ à¤¹à¥à¤ _à¤¸à¤­à¥€ à¤²à¥‹à¤—à¥‹à¤‚_ à¤•à¥‡ à¤¸à¤¾à¤¥ à¤‰à¤šà¤¿à¤¤ à¤µà¥à¤¯à¤µà¤¹à¤¾à¤° à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆ à¥¤
* [**à¤µà¤¿à¤¶à¥à¤µà¤¸à¤¨à¥€à¤¯à¤¤à¤¾ à¤”à¤° à¤…à¤¹à¤¨à¤¿à¤•à¤¾à¤°à¤•à¤¤à¤¾**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - à¤¸à¥à¤¨à¤¿à¤¶à¥à¤šà¤¿à¤¤ à¤•à¤°à¤¤à¥€ à¤¹à¥ˆ à¤•à¤¿ AI- à¤¸à¤‚à¤­à¤¾à¤µà¤¿à¤¤ à¤¨à¥à¤•à¤¸à¤¾à¤¨ à¤¯à¤¾ à¤…à¤¨à¤ªà¥‡à¤•à¥à¤·à¤¿à¤¤ à¤ªà¤°à¤¿à¤£à¤¾à¤®à¥‹à¤‚ à¤•à¥‹ à¤•à¤® à¤•à¤°à¤¤à¥‡ à¤¹à¥à¤ à¤ªà¤°à¤¿à¤­à¤¾à¤·à¤¿à¤¤ à¤®à¥‚à¤²à¥à¤¯à¥‹à¤‚ à¤•à¥‡ à¤¸à¤¾à¤¥ _à¤²à¤—à¤¾à¤¤à¤¾à¤°_ à¤•à¤¾à¤® à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆ à¥¤
* [**à¤¨à¤¿à¤œà¤¤à¤¾ à¤à¤µà¤‚ à¤¸à¥à¤°à¤•à¥à¤·à¤¾**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - à¤¡à¥‡à¤Ÿà¤¾ à¤µà¤‚à¤¶ à¤•à¥‹ à¤¸à¤®à¤à¤¨à¥‡, à¤”à¤° à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾à¤“à¤‚ à¤•à¥‹ _à¤¡à¥‡à¤Ÿà¤¾ à¤—à¥‹à¤ªà¤¨à¥€à¤¯à¤¤à¤¾ à¤”à¤° à¤¸à¤‚à¤¬à¤‚à¤§à¤¿à¤¤ à¤¸à¥à¤°à¤•à¥à¤·à¤¾_ à¤ªà¥à¤°à¤¦à¤¾à¤¨ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¹à¥ˆ à¥¤
* [**à¤¸à¤®à¤—à¥à¤°à¤¤à¤¾**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - AI à¤¸à¤®à¤¾à¤§à¤¾à¤¨à¥‹à¤‚ à¤•à¥‹ à¤‡à¤°à¤¾à¤¦à¥‡ à¤¸à¥‡ à¤¡à¤¿à¤œà¤¾à¤‡à¤¨ à¤•à¤°à¤¨à¤¾ à¤à¤µà¤‚ à¤‰à¤¨à¥à¤¹à¥‡à¤‚ _à¤®à¤¾à¤¨à¤µà¥€à¤¯ à¤†à¤µà¤¶à¥à¤¯à¤•à¤¤à¤¾à¤“à¤‚ à¤•à¥€ à¤à¤• à¤µà¤¿à¤¸à¥à¤¤à¥ƒà¤¤ à¤¶à¥à¤°à¥ƒà¤‚à¤–à¤²à¤¾_ à¤”à¤° à¤•à¥à¤·à¤®à¤¤à¤¾à¤“à¤‚ à¤•à¥‹ à¤ªà¥‚à¤°à¤¾ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤…à¤¨à¥à¤•à¥‚à¤²à¤¿à¤¤ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¹à¥ˆ à¥¤

> ðŸš¨ à¤…à¤ªà¤¨à¥‡ à¤¡à¥‡à¤Ÿà¤¾ à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾ à¤®à¤¿à¤¶à¤¨ à¤µà¤•à¥à¤¤à¤µà¥à¤¯ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¸à¥‹à¤šà¥‡à¤‚ | à¤…à¤¨à¥à¤¯ à¤¸à¤‚à¤—à¤ à¤¨à¥‹à¤‚ à¤¸à¥‡ à¤¨à¥ˆà¤¤à¤¿à¤• AI à¤¢à¤¾à¤‚à¤šà¥‹à¤‚ à¤•à¤¾ à¤…à¤¨à¥à¤µà¥‡à¤·à¤£ à¤•à¤°à¥‡à¤‚ - à¤¯à¥‡ à¤¹à¥ˆà¤‚ à¤•à¥à¤› à¤‰à¤¦à¤¾à¤¹à¤°à¤£ [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles) ,à¤à¤µà¤‚ [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/) | à¤‡à¤¨à¤•à¥‡ à¤¬à¥€à¤š à¤•à¥à¤¯à¤¾ à¤¸à¤¾à¤à¤¾ à¤®à¥‚à¤²à¥à¤¯ à¤¹à¥ˆà¤‚? à¤¯à¥‡ à¤¸à¤¿à¤¦à¥à¤§à¤¾à¤‚à¤¤ à¤‰à¤¨à¤•à¥‡ à¤¦à¥à¤µà¤¾à¤°à¤¾ à¤¸à¤‚à¤šà¤¾à¤²à¤¿à¤¤ AI à¤‰à¤¤à¥à¤ªà¤¾à¤¦ à¤¯à¤¾ à¤‰à¤¦à¥à¤¯à¥‹à¤— à¤¸à¥‡ à¤•à¥ˆà¤¸à¥‡ à¤¸à¤‚à¤¬à¤‚à¤§à¤¿à¤¤ à¤¹à¥ˆà¤‚ ?

### 2. à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾ à¤¸à¥‡ à¤œà¥à¤¡à¥€ à¤šà¥à¤¨à¥Œà¤¤à¤¿à¤¯à¤¾à¤‚

à¤à¤• à¤¬à¤¾à¤° à¤œà¤¬ à¤¹à¤®à¤¾à¤°à¥‡ à¤ªà¤¾à¤¸ à¤¨à¥ˆà¤¤à¤¿à¤• à¤¸à¤¿à¤¦à¥à¤§à¤¾à¤‚à¤¤ à¤ªà¤°à¤¿à¤­à¤¾à¤·à¤¿à¤¤ à¤¹à¥‹ à¤œà¤¾à¤¤à¥‡ à¤¹à¥ˆà¤‚, à¤¤à¥‹ à¤…à¤—à¤²à¤¾ à¤•à¤¦à¤® à¤¯à¤¹ à¤¦à¥‡à¤–à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤¹à¤®à¤¾à¤°à¥‡ à¤¡à¥‡à¤Ÿà¤¾ à¤”à¤° à¤à¤†à¤ˆ à¤•à¤¾à¤°à¥à¤¯à¥‹à¤‚ à¤•à¤¾ à¤®à¥‚à¤²à¥à¤¯à¤¾à¤‚à¤•à¤¨ à¤•à¤°à¤¨à¤¾ à¤¹à¥ˆ à¤•à¤¿ à¤•à¥à¤¯à¤¾ à¤µà¥‡ à¤‰à¤¨ à¤¸à¤¾à¤à¤¾ à¤®à¥‚à¤²à¥à¤¯à¥‹à¤‚ à¤•à¥‡ à¤¸à¤¾à¤¥ à¤¸à¤‚à¤°à¥‡à¤–à¤¿à¤¤ à¤¹à¥ˆà¤‚ à¥¤ à¤…à¤ªà¤¨à¥‡ à¤•à¤¾à¤°à¥à¤¯à¥‹à¤‚ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¦à¥‹ à¤¶à¥à¤°à¥‡à¤£à¤¿à¤¯à¥‹à¤‚ à¤®à¥‡à¤‚ à¤¸à¥‹à¤šà¥‡à¤‚: _à¤¡à¥‡à¤Ÿà¤¾ à¤¸à¤‚à¤—à¥à¤°à¤¹_ à¤”à¤° _à¤à¤²à¥à¤—à¥‹à¤°à¤¿à¤¦à¤® à¤¡à¤¿à¤œà¤¼à¤¾à¤‡à¤¨_ | 

à¤¡à¥‡à¤Ÿà¤¾ à¤¸à¤‚à¤—à¥à¤°à¤¹ à¤•à¥‡ à¤¸à¤¾à¤¥, à¤•à¤¾à¤°à¥à¤°à¤µà¤¾à¤‡à¤¯à¥‹à¤‚ à¤®à¥‡à¤‚ à¤¸à¤‚à¤­à¤µà¤¤à¤ƒ à¤ªà¤¹à¤šà¤¾à¤¨ à¤¯à¥‹à¤—à¥à¤¯ à¤œà¥€à¤µà¤¿à¤¤ à¤µà¥à¤¯à¤•à¥à¤¤à¤¿à¤¯à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ **à¤µà¥à¤¯à¤•à¥à¤¤à¤¿à¤—à¤¤ à¤¡à¥‡à¤Ÿà¤¾** à¤¯à¤¾ à¤µà¥à¤¯à¤•à¥à¤¤à¤¿à¤—à¤¤ à¤°à¥‚à¤ª à¤¸à¥‡ à¤ªà¤¹à¤šà¤¾à¤¨ à¤¯à¥‹à¤—à¥à¤¯ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤¶à¤¾à¤®à¤¿à¤² à¤¹à¥‹à¤—à¥€ à¥¤ à¤‡à¤¸à¤®à¥‡à¤‚ [à¤—à¥ˆà¤°-à¤µà¥à¤¯à¤•à¥à¤¤à¤¿à¤—à¤¤ à¤¡à¥‡à¤Ÿà¤¾ à¤•à¥‡ à¤µà¤¿à¤µà¤¿à¤§ à¤†à¤‡à¤Ÿà¤®] (https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) à¤¶à¤¾à¤®à¤¿à¤² à¤¹à¥ˆà¤‚, à¤œà¥‹ _collectively_ à¤•à¤¿à¤¸à¥€ à¤µà¥à¤¯à¤•à¥à¤¤à¤¿ à¤•à¥€ à¤ªà¤¹à¤šà¤¾à¤¨ à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¥¤ à¤¨à¥ˆà¤¤à¤¿à¤• à¤šà¥à¤¨à¥Œà¤¤à¤¿à¤¯à¤¾à¤‚ _à¤¡à¥‡à¤Ÿà¤¾ à¤—à¥‹à¤ªà¤¨à¥€à¤¯à¤¤à¤¾_, _à¤¡à¥‡à¤Ÿà¤¾ à¤¸à¥à¤µà¤¾à¤®à¤¿à¤¤à¥à¤µ_, à¤”à¤° à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾à¤“à¤‚ à¤•à¥‡ à¤²à¤¿à¤ _à¤¸à¥‚à¤šà¤¿à¤¤ à¤¸à¤¹à¤®à¤¤à¤¿_ à¤”à¤° _à¤¬à¥Œà¤¦à¥à¤§à¤¿à¤• à¤¸à¤‚à¤ªà¤¦à¤¾ à¤…à¤§à¤¿à¤•à¤¾à¤°_ à¤œà¥ˆà¤¸à¥‡ à¤¸à¤‚à¤¬à¤‚à¤§à¤¿à¤¤ à¤µà¤¿à¤·à¤¯à¥‹à¤‚ à¤¸à¥‡ à¤¸à¤‚à¤¬à¤‚à¤§à¤¿à¤¤ à¤¹à¥‹ à¤¸à¤•à¤¤à¥€ à¤¹à¥ˆà¤‚ à¥¤

à¤à¤²à¥à¤—à¥‹à¤°à¤¿à¤¥à¤® à¤¡à¤¿à¤œà¤¼à¤¾à¤‡à¤¨ à¤•à¥‡ à¤¸à¤¾à¤¥, à¤•à¥à¤°à¤¿à¤¯à¤¾à¤“à¤‚ à¤®à¥‡à¤‚ **à¤¡à¥‡à¤Ÿà¤¾à¤¸à¥‡à¤Ÿ** à¤à¤•à¤¤à¥à¤° à¤•à¤°à¤¨à¤¾ à¤”à¤° à¤•à¥à¤¯à¥‚à¤°à¥‡à¤Ÿ à¤•à¤°à¤¨à¤¾ à¤¶à¤¾à¤®à¤¿à¤² à¤¹à¥‹à¤—à¤¾, à¤«à¤¿à¤° à¤‰à¤¨à¤•à¤¾ à¤‰à¤ªà¤¯à¥‹à¤— **à¤¡à¥‡à¤Ÿà¤¾ à¤®à¥‰à¤¡à¤²** à¤•à¥‹ à¤ªà¥à¤°à¤¶à¤¿à¤•à¥à¤·à¤¿à¤¤ à¤”à¤° à¤¤à¥ˆà¤¨à¤¾à¤¤ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤•à¤¿à¤¯à¤¾ à¤œà¤¾à¤à¤—à¤¾ à¤œà¥‹ à¤µà¤¾à¤¸à¥à¤¤à¤µà¤¿à¤• à¤¦à¥à¤¨à¤¿à¤¯à¤¾ à¤•à¥‡ à¤¸à¤‚à¤¦à¤°à¥à¤­à¥‹à¤‚ à¤®à¥‡à¤‚ à¤ªà¤°à¤¿à¤£à¤¾à¤®à¥‹à¤‚ à¤•à¥€ à¤­à¤µà¤¿à¤·à¥à¤¯à¤µà¤¾à¤£à¥€ à¤¯à¤¾ à¤¸à¥à¤µà¤šà¤¾à¤²à¤¿à¤¤ à¤¨à¤¿à¤°à¥à¤£à¤¯ à¤²à¥‡à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¥¤ à¤à¤²à¥à¤—à¥‹à¤°à¤¿à¤¥à¤® à¤¡à¤¿à¤œà¤¼à¤¾à¤‡à¤¨ à¤•à¥‡ à¤¸à¤¾à¤¥, à¤•à¥à¤°à¤¿à¤¯à¤¾à¤“à¤‚ à¤®à¥‡à¤‚ **à¤¡à¥‡à¤Ÿà¤¾à¤¸à¥‡à¤Ÿ** à¤à¤•à¤¤à¥à¤° à¤•à¤°à¤¨à¤¾ à¤”à¤° à¤•à¥à¤¯à¥‚à¤°à¥‡à¤Ÿ à¤•à¤°à¤¨à¤¾ à¤¶à¤¾à¤®à¤¿à¤² à¤¹à¥‹à¤—à¤¾, à¤«à¤¿à¤° à¤‰à¤¨à¤•à¤¾ à¤‰à¤ªà¤¯à¥‹à¤— **à¤¡à¥‡à¤Ÿà¤¾ à¤®à¥‰à¤¡à¤²** à¤•à¥‹ à¤ªà¥à¤°à¤¶à¤¿à¤•à¥à¤·à¤¿à¤¤ à¤”à¤° à¤¤à¥ˆà¤¨à¤¾à¤¤ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤•à¤¿à¤¯à¤¾ à¤œà¤¾à¤à¤—à¤¾ à¤œà¥‹ à¤µà¤¾à¤¸à¥à¤¤à¤µà¤¿à¤• à¤¦à¥à¤¨à¤¿à¤¯à¤¾ à¤•à¥‡ à¤¸à¤‚à¤¦à¤°à¥à¤­à¥‹à¤‚ à¤®à¥‡à¤‚ à¤ªà¤°à¤¿à¤£à¤¾à¤®à¥‹à¤‚ à¤•à¥€ à¤­à¤µà¤¿à¤·à¥à¤¯à¤µà¤¾à¤£à¥€ à¤¯à¤¾ à¤¸à¥à¤µà¤šà¤¾à¤²à¤¿à¤¤ à¤¨à¤¿à¤°à¥à¤£à¤¯ à¤²à¥‡à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¥¤

à¤¦à¥‹à¤¨à¥‹à¤‚ à¤¹à¥€ à¤®à¤¾à¤®à¤²à¥‹à¤‚ à¤®à¥‡à¤‚, à¤¨à¥ˆà¤¤à¤¿à¤•à¤¤à¤¾ à¤•à¥€ à¤šà¥à¤¨à¥Œà¤¤à¤¿à¤¯à¤¾à¤ à¤‰à¤¨ à¤•à¥à¤·à¥‡à¤¤à¥à¤°à¥‹à¤‚ à¤•à¥‹ à¤‰à¤œà¤¾à¤—à¤° à¤•à¤°à¤¤à¥€ à¤¹à¥ˆà¤‚ à¤œà¤¹à¤¾à¤ à¤¹à¤®à¤¾à¤°à¥‡ à¤•à¤¾à¤°à¥à¤¯à¥‹à¤‚ à¤•à¤¾ à¤¹à¤®à¤¾à¤°à¥‡ à¤¸à¤¾à¤à¤¾ à¤®à¥‚à¤²à¥à¤¯à¥‹à¤‚ à¤•à¥‡ à¤¸à¤¾à¤¥ à¤Ÿà¤•à¤°à¤¾à¤µ à¤¹à¥‹ à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆ à¥¤ à¤‡à¤¨ à¤šà¤¿à¤‚à¤¤à¤¾à¤“à¤‚ à¤•à¤¾ à¤ªà¤¤à¤¾ à¤²à¤—à¤¾à¤¨à¥‡, à¤¸à¤¾à¤®à¤¨à¤¾ à¤•à¤°à¤¨à¥‡, à¤•à¤® à¤•à¤°à¤¨à¥‡ à¤¯à¤¾ à¤¸à¤®à¤¾à¤ªà¥à¤¤ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ - à¤¹à¤®à¥‡à¤‚ à¤…à¤ªà¤¨à¥‡ à¤•à¤¾à¤°à¥à¤¯à¥‹à¤‚ à¤¸à¥‡ à¤¸à¤‚à¤¬à¤‚à¤§à¤¿à¤¤ à¤¨à¥ˆà¤¤à¤¿à¤• "à¤¹à¤¾à¤‚ à¤¯à¤¾ à¤¨à¤¹à¥€à¤‚" à¤ªà¥à¤°à¤¶à¥à¤¨ à¤ªà¥‚à¤›à¤¨à¥‡ à¤•à¥€ à¤œà¤°à¥‚à¤°à¤¤ à¤¹à¥ˆ, à¤«à¤¿à¤° à¤†à¤µà¤¶à¥à¤¯à¤•à¤¤à¤¾à¤¨à¥à¤¸à¤¾à¤° à¤¸à¥à¤§à¤¾à¤°à¤¾à¤¤à¥à¤®à¤• à¤•à¤¾à¤°à¥à¤°à¤µà¤¾à¤ˆ à¤•à¤°à¥‡à¤‚ à¥¤ à¤†à¤‡à¤ à¤•à¥à¤› à¤¨à¥ˆà¤¤à¤¿à¤• à¤šà¥à¤¨à¥Œà¤¤à¤¿à¤¯à¥‹à¤‚ à¤”à¤° à¤‰à¤¨à¤•à¥‡ à¤¦à¥à¤µà¤¾à¤°à¤¾ à¤‰à¤ à¤¾à¤ à¤—à¤ à¤¨à¥ˆà¤¤à¤¿à¤• à¤ªà¥à¤°à¤¶à¥à¤¨à¥‹à¤‚ à¤ªà¤° à¤à¤• à¤¨à¤œà¤¼à¤° à¤¡à¤¾à¤²à¥‡à¤‚ :


#### 2.1 à¤¡à¥‡à¤Ÿà¤¾ à¤¸à¥à¤µà¤¾à¤®à¤¿à¤¤à¥à¤µ

à¤¡à¥‡à¤Ÿà¤¾ à¤¸à¤‚à¤—à¥à¤°à¤¹ à¤®à¥‡à¤‚ à¤…à¤•à¥à¤¸à¤° à¤µà¥à¤¯à¤•à¥à¤¤à¤¿à¤—à¤¤ à¤¡à¥‡à¤Ÿà¤¾ à¤¶à¤¾à¤®à¤¿à¤² à¤¹à¥‹à¤¤à¤¾ à¤¹à¥ˆ à¤œà¥‹ à¤¡à¥‡à¤Ÿà¤¾ à¤µà¤¿à¤·à¤¯à¥‹à¤‚ à¤•à¥€ à¤ªà¤¹à¤šà¤¾à¤¨ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆ à¥¤ [à¤¡à¥‡à¤Ÿà¤¾ à¤¸à¥à¤µà¤¾à¤®à¤¿à¤¤à¥à¤µ](https://permission.io/blog/data-ownership) _à¤¨à¤¿à¤¯à¤‚à¤¤à¥à¤°à¤£_ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤”à¤° à¤‰à¤¨ [_à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾ à¤…à¤§à¤¿à¤•à¤¾à¤°à¥‹_](https://permission.io/blog/data-ownership)à¤•à¥‡ à¤¸à¤®à¥à¤­à¤‚à¤¦à¤¿à¤¤ à¤¹à¥ˆ à¤œà¥‹ à¤¨à¤¿à¤°à¥à¤®à¤¾à¤£ , à¤ªà¥à¤°à¤¸à¤‚à¤¸à¥à¤•à¤°à¤£ à¤”à¤° à¤¸à¥‡ à¤¸à¤‚à¤¬à¤‚à¤§à¤¿à¤¤ à¤¹à¥ˆ à¥¤ 

à¤¹à¤®à¥‡à¤‚ à¤œà¥‹ à¤¨à¥ˆà¤¤à¤¿à¤• à¤ªà¥à¤°à¤¶à¥à¤¨ à¤ªà¥‚à¤›à¤¨à¥‡ à¤šà¤¾à¤¹à¤¿à¤, à¤µà¥‡ à¤¹à¥ˆà¤‚ : 
 * à¤¡à¥‡à¤Ÿà¤¾ à¤•à¤¾ à¤®à¤¾à¤²à¤¿à¤• à¤•à¥Œà¤¨ à¤¹à¥ˆ ? (à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾ à¤¯à¤¾ à¤¸à¤‚à¤—à¤ à¤¨)
 * à¤¡à¥‡à¤Ÿà¤¾ à¤µà¤¿à¤·à¤¯à¥‹à¤‚ à¤•à¥‡ à¤ªà¤¾à¤¸ à¤•à¥à¤¯à¤¾ à¤…à¤§à¤¿à¤•à¤¾à¤° à¤¹à¥ˆà¤‚ ? (à¤‰à¤¦à¤¾: à¤ªà¤¹à¥à¤‚à¤š, à¤®à¤¿à¤Ÿà¤¾à¤¨à¤¾, à¤¸à¥à¤µà¤¾à¤¹à¥à¤¯à¤¤à¤¾)
 * à¤¸à¤‚à¤—à¤ à¤¨à¥‹à¤‚ à¤•à¥‡ à¤ªà¤¾à¤¸ à¤•à¥à¤¯à¤¾ à¤…à¤§à¤¿à¤•à¤¾à¤° à¤¹à¥ˆà¤‚ ? (à¤‰à¤¦à¤¾: à¤¦à¥à¤°à¥à¤­à¤¾à¤µà¤¨à¤¾à¤ªà¥‚à¤°à¥à¤£ à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾ à¤¸à¤®à¥€à¤•à¥à¤·à¤¾à¤“à¤‚ à¤•à¤¾ à¤¸à¥à¤§à¤¾à¤°)

#### 2.2 à¤¸à¥‚à¤šà¤¿à¤¤ à¤¸à¤¹à¤®à¤¤à¤¿

[à¤¸à¥‚à¤šà¤¿à¤¤ à¤¸à¤¹à¤®à¤¤à¤¿](https://legaldictionary.net/informed-consent/) à¤‰à¤¦à¥à¤¦à¥‡à¤¶à¥à¤¯, à¤¸à¤‚à¤­à¤¾à¤µà¤¿à¤¤ à¤œà¥‹à¤–à¤¿à¤®à¥‹à¤‚ à¤”à¤° à¤µà¤¿à¤•à¤²à¥à¤ªà¥‹à¤‚ à¤¸à¤¹à¤¿à¤¤ à¤ªà¥à¤°à¤¾à¤¸à¤‚à¤—à¤¿à¤• à¤¤à¤¥à¥à¤¯à¥‹à¤‚ à¤•à¥€ _à¤ªà¥‚à¤°à¥à¤£ à¤¸à¤®à¤_ à¤•à¥‡ à¤¸à¤¾à¤¥ à¤•à¤¾à¤°à¥à¤°à¤µà¤¾à¤ˆ (à¤œà¥ˆà¤¸à¥‡ à¤¡à¥‡à¤Ÿà¤¾ à¤¸à¤‚à¤—à¥à¤°à¤¹) à¤•à¥‡ à¤²à¤¿à¤ à¤¸à¤¹à¤®à¤¤ à¤¹à¥‹à¤¨à¥‡ à¤µà¤¾à¤²à¥‡ à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾à¤“à¤‚ à¤•à¥‡ à¤•à¤¾à¤°à¥à¤¯ à¤•à¥‹ à¤ªà¤°à¤¿à¤­à¤¾à¤·à¤¿à¤¤ à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆ à¥¤ 

à¤¯à¤¹à¤¾à¤‚ à¤¦à¥‡à¤–à¤¨à¥‡ à¤²à¤¾à¤¯à¤• à¤ªà¥à¤°à¤¶à¥à¤¨ à¤¹à¥ˆà¤‚ :
 * à¤•à¥à¤¯à¤¾ à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾ (à¤¡à¥‡à¤Ÿà¤¾ à¤µà¤¿à¤·à¤¯) à¤¨à¥‡ à¤¡à¥‡à¤Ÿà¤¾ à¤•à¥ˆà¤ªà¥à¤šà¤° à¤”à¤° à¤‰à¤ªà¤¯à¥‹à¤— à¤•à¥‡ à¤²à¤¿à¤ à¤…à¤¨à¥à¤®à¤¤à¤¿ à¤¦à¥€ à¤¥à¥€ ?
 * à¤•à¥à¤¯à¤¾ à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾ à¤•à¥‹ à¤µà¤¹ à¤‰à¤¦à¥à¤¦à¥‡à¤¶à¥à¤¯ à¤¸à¤®à¤ à¤®à¥‡à¤‚ à¤†à¤¯à¤¾ à¤œà¤¿à¤¸à¤•à¥‡ à¤²à¤¿à¤ à¤‰à¤¸ à¤¡à¥‡à¤Ÿà¤¾ à¤•à¥‹ à¤•à¥ˆà¤ªà¥à¤šà¤° à¤•à¤¿à¤¯à¤¾ à¤—à¤¯à¤¾ à¤¥à¤¾ ?
 * à¤•à¥à¤¯à¤¾ à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾ à¤¨à¥‡ à¤‰à¤¨à¤•à¥€ à¤­à¤¾à¤—à¥€à¤¦à¤¾à¤°à¥€ à¤¸à¥‡ à¤¸à¤‚à¤­à¤¾à¤µà¤¿à¤¤ à¤œà¥‹à¤–à¤¿à¤®à¥‹à¤‚ à¤•à¥‹ à¤¸à¤®à¤à¤¾ ?

#### 2.3 à¤¬à¥Œà¤¦à¥à¤§à¤¿à¤• à¤¸à¤‚à¤ªà¤¦à¤¾

[à¤¬à¥Œà¤¦à¥à¤§à¤¿à¤• à¤¸à¤‚à¤ªà¤¦à¤¾](https://en.wikipedia.org/wiki/Intellectual_property) à¤®à¤¾à¤¨à¤µ à¤ªà¤¹à¤² à¤¸à¥‡ à¤‰à¤¤à¥à¤ªà¤¨à¥à¤¨ à¤…à¤®à¥‚à¤°à¥à¤¤ à¤•à¥ƒà¤¤à¤¿à¤¯à¥‹à¤‚ à¤•à¥‹ à¤¸à¤‚à¤¦à¤°à¥à¤­à¤¿à¤¤ à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆ, à¤œà¤¿à¤¨à¤•à¤¾ à¤µà¥à¤¯à¤•à¥à¤¤à¤¿à¤¯à¥‹à¤‚ à¤¯à¤¾ à¤µà¥à¤¯à¤µà¤¸à¤¾à¤¯à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ _à¤†à¤°à¥à¤¥à¤¿à¤•_ à¤®à¤¹à¤¤à¥à¤µ à¤¹à¥‹ à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆ à¥¤

à¤¯à¤¹à¤¾à¤‚ à¤¦à¥‡à¤–à¤¨à¥‡ à¤²à¤¾à¤¯à¤• à¤ªà¥à¤°à¤¶à¥à¤¨ à¤¹à¥ˆà¤‚ :
 * à¤•à¥à¤¯à¤¾ à¤œà¤®à¤¾ à¤•à¤¿à¤ à¤—à¤ à¤¡à¥‡à¤Ÿà¤¾ à¤•à¤¾ à¤•à¤¿à¤¸à¥€ à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾ à¤¯à¤¾ à¤µà¥à¤¯à¤µà¤¸à¤¾à¤¯ à¤•à¥‡ à¤²à¤¿à¤ à¤†à¤°à¥à¤¥à¤¿à¤• à¤®à¤¹à¤¤à¥à¤µ à¤¹à¥ˆ ?
 * à¤•à¥à¤¯à¤¾ **à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾** à¤•à¥‡ à¤ªà¤¾à¤¸ à¤¯à¤¹à¤¾à¤‚ à¤¬à¥Œà¤¦à¥à¤§à¤¿à¤• à¤¸à¤‚à¤ªà¤¦à¤¾ à¤¹à¥ˆ ?
 * à¤•à¥à¤¯à¤¾ **à¤¸à¤‚à¤—à¤ à¤¨** à¤•à¥‡ à¤ªà¤¾à¤¸ à¤¯à¤¹à¤¾à¤‚ à¤¬à¥Œà¤¦à¥à¤§à¤¿à¤• à¤¸à¤‚à¤ªà¤¦à¤¾ à¤¹à¥ˆ ?
 * à¤…à¤—à¤° à¤¯à¥‡ à¤…à¤§à¤¿à¤•à¤¾à¤° à¤®à¥Œà¤œà¥‚à¤¦ à¤¹à¥ˆà¤‚, à¤¤à¥‹ à¤¹à¤® à¤‰à¤¨à¤•à¥€ à¤°à¤•à¥à¤·à¤¾ à¤•à¥ˆà¤¸à¥‡ à¤•à¤° à¤°à¤¹à¥‡ à¤¹à¥ˆà¤‚ ?

#### 2.4 à¤¡à¤¾à¤Ÿà¤¾ à¤—à¥‹à¤ªà¤¨à¥€à¤¯à¤¤à¤¾

[à¤¡à¥‡à¤Ÿà¤¾ à¤—à¥‹à¤ªà¤¨à¥€à¤¯à¤¤à¤¾](https://www.northeaster.edu/graduate/blog/what-is-data-privacy/) à¤¯à¤¾ à¤¸à¥‚à¤šà¤¨à¤¾ à¤—à¥‹à¤ªà¤¨à¥€à¤¯à¤¤à¤¾ à¤µà¥à¤¯à¤•à¥à¤¤à¤¿à¤—à¤¤ à¤°à¥‚à¤ª à¤¸à¥‡ à¤ªà¤¹à¤šà¤¾à¤¨ à¤¯à¥‹à¤—à¥à¤¯ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤•à¥‡ à¤¸à¤‚à¤¬à¤‚à¤§ à¤®à¥‡à¤‚ à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾ à¤•à¥€ à¤—à¥‹à¤ªà¤¨à¥€à¤¯à¤¤à¤¾ à¤•à¥‡ à¤¸à¤‚à¤°à¤•à¥à¤·à¤£ à¤”à¤° à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾ à¤•à¥€ à¤ªà¤¹à¤šà¤¾à¤¨ à¤•à¥€ à¤¸à¥à¤°à¤•à¥à¤·à¤¾ à¤•à¥‹ à¤¸à¤‚à¤¦à¤°à¥à¤­à¤¿à¤¤ à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆ à¥¤

à¤¯à¤¹à¤¾à¤‚ à¤¦à¥‡à¤–à¤¨à¥‡ à¤²à¤¾à¤¯à¤• à¤ªà¥à¤°à¤¶à¥à¤¨ à¤¹à¥ˆà¤‚ :
 * à¤•à¥à¤¯à¤¾ à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾à¤“à¤‚ à¤•à¤¾ (à¤µà¥à¤¯à¤•à¥à¤¤à¤¿à¤—à¤¤) à¤¡à¥‡à¤Ÿà¤¾ à¤¹à¥ˆà¤• à¤”à¤° à¤²à¥€à¤• à¤¸à¥‡ à¤¸à¥à¤°à¤•à¥à¤·à¤¿à¤¤ à¤¹à¥ˆ ?
 * à¤•à¥à¤¯à¤¾ à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾à¤“à¤‚ à¤•à¤¾ à¤¡à¥‡à¤Ÿà¤¾ à¤•à¥‡à¤µà¤² à¤…à¤§à¤¿à¤•à¥ƒà¤¤ à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾à¤“à¤‚ à¤”à¤° à¤¸à¤‚à¤¦à¤°à¥à¤­à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤¸à¥à¤²à¤­ à¤¹à¥ˆ ?
 * à¤•à¥à¤¯à¤¾ à¤¡à¥‡à¤Ÿà¤¾ à¤¸à¤¾à¤à¤¾ à¤¯à¤¾ à¤ªà¥à¤°à¤¸à¤¾à¤°à¤¿à¤¤ à¤¹à¥‹à¤¨à¥‡ à¤ªà¤° à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾à¤“à¤‚ à¤•à¥€ à¤—à¥‹à¤ªà¤¨à¥€à¤¯à¤¤à¤¾ à¤¬à¤¨à¥€ à¤°à¤¹à¤¤à¥€ à¤¹à¥ˆ ?
 * à¤•à¥à¤¯à¤¾ à¤•à¤¿à¤¸à¥€ à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾ à¤•à¥€ à¤ªà¤¹à¤šà¤¾à¤¨ à¤…à¤œà¥à¤žà¤¾à¤¤ à¤¡à¥‡à¤Ÿà¤¾à¤¸à¥‡à¤Ÿ à¤¸à¥‡ à¤•à¥€ à¤œà¤¾ à¤¸à¤•à¤¤à¥€ à¤¹à¥ˆ ?


#### 2.5 à¤­à¥‚à¤²à¤¾ à¤¦à¤¿à¤¯à¤¾ à¤œà¤¾à¤¨à¥‡ à¤•à¤¾ à¤…à¤§à¤¿à¤•à¤¾à¤°

[à¤­à¥‚à¤²à¤¾ à¤¦à¤¿à¤¯à¤¾ à¤œà¤¾à¤¨à¥‡ à¤•à¤¾ à¤…à¤§à¤¿à¤•à¤¾à¤°](https://en.wikipedia.org/wiki/Right_to_be_forgotten) à¤…à¤¤à¤¿à¤°à¤¿à¤•à¥à¤¤ à¤¸à¥à¤µà¤¿à¤§à¤¾à¤à¤‚ à¤ªà¥à¤°à¤¦à¤¾à¤¨ à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆ à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾à¤“à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤µà¥à¤¯à¤•à¥à¤¤à¤¿à¤—à¤¤ à¤¡à¥‡à¤Ÿà¤¾ à¤¸à¥à¤°à¤•à¥à¤·à¤¾à¥¤ à¤µà¤¿à¤¶à¥‡à¤· à¤°à¥‚à¤ª à¤¸à¥‡, à¤¯à¤¹ à¤‰à¤ªà¤¯à¥‹à¤—à¤•à¤°à¥à¤¤à¤¾à¤“à¤‚ à¤•à¥‹ à¤‡à¤‚à¤Ÿà¤°à¤¨à¥‡à¤Ÿ à¤–à¥‹à¤œà¥‹à¤‚ à¤”à¤° à¤…à¤¨à¥à¤¯ à¤¸à¥à¤¥à¤¾à¤¨à¥‹à¤‚ à¤¸à¥‡ à¤µà¥à¤¯à¤•à¥à¤¤à¤¿à¤—à¤¤ à¤¡à¥‡à¤Ÿà¤¾ à¤•à¥‹ à¤¹à¤Ÿà¤¾à¤¨à¥‡ à¤¯à¤¾ à¤¹à¤Ÿà¤¾à¤¨à¥‡ à¤•à¤¾ à¤…à¤¨à¥à¤°à¥‹à¤§ à¤•à¤°à¤¨à¥‡ à¤•à¤¾ à¤…à¤§à¤¿à¤•à¤¾à¤° à¤¦à¥‡à¤¤à¤¾ à¤¹à¥ˆ, _à¤µà¤¿à¤¶à¤¿à¤·à¥à¤Ÿ à¤ªà¤°à¤¿à¤¸à¥à¤¥à¤¿à¤¤à¤¿à¤¯à¥‹à¤‚ à¤®à¥‡à¤‚_ - à¤‰à¤¨à¥à¤¹à¥‡à¤‚ à¤‰à¤¨à¤•à¥‡ à¤–à¤¿à¤²à¤¾à¤« à¤ªà¤¿à¤›à¤²à¥€ à¤•à¤¾à¤°à¥à¤°à¤µà¤¾à¤ˆ à¤•à¤¿à¤ à¤¬à¤¿à¤¨à¤¾ à¤‘à¤¨à¤²à¤¾à¤‡à¤¨ à¤à¤• à¤¨à¤ˆ à¤¶à¥à¤°à¥à¤†à¤¤ à¤•à¤°à¤¨à¥‡ à¤•à¥€ à¤…à¤¨à¥à¤®à¤¤à¤¿ à¤¦à¥‡à¤¤à¤¾ à¤¹à¥ˆ à¥¤

à¤¯à¤¹à¤¾à¤‚ à¤¦à¥‡à¤–à¤¨à¥‡ à¤²à¤¾à¤¯à¤• à¤ªà¥à¤°à¤¶à¥à¤¨ à¤¹à¥ˆà¤‚ :
 * Does the system allow data subjects to request erasure?
 * Should the withdrawal of user consent trigger automated erasure?
 * Was data collected without consent or by unlawful means?
 * Are we compliant with government regulations for data privacy?


#### 2.6 Dataset Bias

Dataset or [Collection Bias](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) is about selecting a _non-representative_ subset of data for algorithm development, creating potential  unfairness in result outcomes for diverse groups. Types of bias include selection or sampling bias, volunteer bias, and instrument bias. 

Questions to explore here are:
 * Did we recruit a representative set of data subjects?
 * Did we test our collected or curated dataset for various biases?
 * Can we mitigate or remove any discovered biases?

#### 2.7 Data Quality

[Data Quality](https://lakefs.io/data-quality-testing/) looks at the validity of the curated dataset used to develop our algorithms, checking to see if features and records meet requirements for the level of accuracy and consistency needed for our AI purpose.

Questions to explore here are:
 * Did we capture valid _features_ for our use case?
 * Was data captured _consistently_ across diverse data sources?
 * Is the dataset _complete_ for diverse conditions or scenarios?
 * Is information captured _accurately_ in reflecting reality?

#### 2.8 Algorithm Fairness

[Algorithm Fairness](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) checks to see if the algorithm design systematically discriminates against specific subgroups of data subjects leading to [potential harms](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) in _allocation_ (where resources are denied or withheld from that group) and _quality of service_ (where AI is not as accurate for some subgroups as it is for others). 

Questions to explore here are:
 * Did we evaluate model accuracy for diverse subgroups and conditions?
 * Did we scrutinize the system for potential harms (e.g., stereotyping)?
 * Can we revise data or retrain models to mitigate identified harms?

Explore resources like [AI Fairness checklists](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) to learn more.

#### 2.9 Misrepresentation

[Data Misrepresentation](https://www.sciencedirect.com/topics/computer-science/misrepresentation) is about asking whether we are communicating insights from honestly reported data in a deceptive manner to support a desired narrative. 

Questions to explore here are:
 * Are we reporting incomplete or inaccurate data?
 * Are we visualizing data in a manner that drives misleading conclusions?
 * Are we using selective statistical techniques to manipulate outcomes?
 * Are there alternative explanations that may offer a different conclusion?

#### 2.10 Free Choice
The [Illusion of Free Choice](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) occurs when system "choice architectures" use decision-making algorithms to nudge people towards taking a preferred outcome while seeming to give them options and control. These [dark patterns](https://www.darkpatterns.org/) can cause social and economic harm to users. Because user decisions impact behavior profiles, these actions potentially drive future choices that can amplify or extend the impact of these harms.

Questions to explore here are:
 * Did the user understand the implications of making that choice?
 * Was the user aware of (alternative) choices and the pros & cons of each?
 * Can the user reverse an automated or influenced choice later?

### 3. Case Studies

To put these ethical challenges in real-world contexts, it helps to look at case studies that highlight the potential harms and consequences to individuals and society, when such ethics violations are overlooked. 

Here are a few examples:

| Ethics Challenge | Case Study  | 
|--- |--- |
| **Informed Consent** | 1972 - [Tuskegee Syphillis Study](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - African American men who participated in the study were promised free medical care _but deceived_ by researchers who failed to inform subjects of their diagnosis or about availability of treatment. Many subjects died & partners or children were affected; the study lasted 40 years. | 
| **Data Privacy** |  2007 - The [Netflix data prize](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) provided researchers with _10M anonymized movie rankings from 50K customers_ to help improve recommendation algorithms. However, researchers were able to correlate anonymized data with personally-identifiable data in _external datasets_ (e.g., IMDb comments) - effectively "de-anonymizing" some Netflix subscribers.|
| **Collection Bias**  | 2013 - The City of Boston [developed Street Bump](https://www.boston.gov/transportation/street-bump), an app that let citizens report potholes, giving the city better roadway data to find and fix issues. However, [people in lower income groups had less access to cars and phones](https://hbr.org/2013/04/the-hidden-biases-in-big-data), making their roadway issues invisible in this app. Developers worked with academics to _equitable access and digital divides_ issues for fairness. |
| **Algorithmic Fairness**  | 2018 - The MIT [Gender Shades Study](http://gendershades.org/overview.html) evaluated the accuracy of gender classification AI products, exposing gaps in accuracy for women and persons of color. A [2019 Apple Card](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) seemed to offer less credit to women than men. Both illustrated issues in algorithmic bias leading to socio-economic harms.|
| **Data Misrepresentation** | 2020 - The [Georgia Department of Public Health released COVID-19 charts](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) that appeared to mislead citizens about trends in confirmed cases with non-chronological ordering on the x-axis. This illustrates misrepresentation through visualization tricks. |
| **Illusion of free choice** | 2020 - Learning app [ABCmouse paid $10M to settle an FTC complaint](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/) where parents were trapped into paying for subscriptions they couldn't cancel. This illustrates dark patterns in choice architectures, where users were nudged towards potentially harmful choices. |
| **Data Privacy & User Rights** | 2021 - Facebook [Data Breach](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) exposed data from 530M users, resulting in a $5B settlement to the FTC. It however refused to notify users of the breach violating user rights around data transparency and access. |

Want to explore more case studies? Check out these resources:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - ethics dilemmas across diverse industries. 
* [Data Science Ethics course](https://www.coursera.org/learn/data-science-ethics#syllabus) - landmark case studies explored.
* [Where things have gone wrong](https://deon.drivendata.org/examples/) - deon checklist with examples

> ðŸš¨ Think about the case studies you've seen - have you experienced, or been affected by, a similar ethical challenge in your life? Can you think of at least one other case study that illustrates one of the ethical challenges we've discussed in this section?

## Applied Ethics

We've talked about ethics concepts, challenges ,and case studies in real-world contexts. But how do we get started _applying_ ethical principles and practices in our projects? And how do we _operationalize_ these practices for better governance? Let's explore some real-world solutions: 

### 1. Professional Codes

Professional Codes offer one option for organizations to "incentivize" members to support their ethical principles and mission statement. Codes are _moral guidelines_ for professional behavior, helping employees or members make decisions that align with their organization's principles. They are only as good as the voluntary compliance from members; however, many organizations offer additional rewards and penalties to motivate compliance from members.

Examples include:

 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Code of Ethics
 * [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Code of Conduct (created 2013)
 * [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (since 1993)

> ðŸš¨ Do you belong to a professional engineering or data science organization? Explore their site to see if they define a professional code of ethics. What does this say about their ethical principles? How are they "incentivizing" members to follow the code?

### 2. Ethics Checklists

While professional codes define required _ethical behavior_ from practitioners, they [have known limitations](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) in enforcement, particularly in large-scale projects. Instead, many data Science experts [advocate for checklists](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), that can **connect principles to practices** in more deterministic and actionable ways. 

Checklists convert questions into "yes/no" tasks that can be operationalized, allowing them to be tracked as part of standard product release workflows. 

Examples include:
 * [Deon](https://deon.drivendata.org/) - a general-purpose data ethics checklist created from [industry recommendations](https://deon.drivendata.org/#checklist-citations) with a command-line tool for easy integration.
 * [Privacy Audit Checklist](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - provides general guidance for information handling practices from legal and social exposure perspectives.
 * [AI Fairness Checklist](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - created by AI practitioners to support the adoption and integration of fairness checks into AI development cycles.
 * [22 questions for ethics in data and AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - more open-ended framework, structured for initial exploration of ethical issues in design, implementation, and organizational, contexts.

### 3. Ethics Regulations

Ethics is about defining shared values and doing the right thing _voluntarily_. **Compliance** is about _following the law_ if and where defined. **Governance** broadly covers all the ways in which organizations operate to enforce ethical principles and comply with established laws.

Today, governance takes two forms within organizations. First, it's about defining **ethical AI** principles and establishing practices to operationalize adoption across all AI-related projects in the organization. Second, it's about complying with all government-mandated **data protection regulations** for regions it operates in.

Examples of data protection and privacy regulations:

 * `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - regulates _federal govt._ collection, use ,and disclosure of personal information.
 * `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - protects personal health data.
 * `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - protects data privacy of children under 13.
 * `2018`, [General Data Protection Regulation (GDPR)](https://gdpr-info.eu/) - provides user rights, data protection ,and privacy.
 * `2018`, [California Consumer Privacy Act (CCPA)](https://www.oag.ca.gov/privacy/ccpa) gives consumers more _rights_ over their (personal) data.
 * `2021`, China's [Personal Information Protection Law](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) just passed, creating one of the strongest online data privacy regulations worldwide.

> ðŸš¨ The European Union defined GDPR (General Data Protection Regulation) remains one of the most influential data privacy regulations today. Did you know it also defines [8 user rights](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) to protect citizens' digital privacy and personal data? Learn about what these are, and why they matter.


### 4. Ethics Culture

Note that there remains an intangible gap between _compliance_ (doing enough to meet "the letter of the law") and addressing [systemic issues](https://www.coursera.org/learn/data-science-ethics/home/week/4) (like ossification, information asymmetry ,and distributional unfairness) that can speed up the weaponization of AI. 

The latter requires [collaborative approaches to defining ethics cultures](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f) that build emotional connections and consistent shared values _across organizations_ in the industry. This calls for more [formalized data ethics cultures](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) in organizations - allowing _anyone_ to [pull the Andon cord](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (to raise ethics concerns early in the process) and making _ethical assessments_ (e.g., in hiring) a core criteria team formation in AI projects.

---
## [Post-lecture quiz](https://red-water-0103e7a0f.azurestaticapps.net/quiz/3) ðŸŽ¯
## Review & Self Study 

Courses and books help with understanding core ethics concepts and challenges, while case studies and tools help with applied ethics practices in real-world contexts. Here are a few resources to start with.

* [Machine Learning For Beginners](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - lesson on Fairness, from Microsoft.
* [Principles of Responsible AI](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - free learning path from Microsoft Learn.
* [Ethics and Data Science](https://resources.oreilly.com/examples/0636920203964) - O'Reilly EBook (M. Loukides, H. Mason et. al)
* [Data Science Ethics](https://www.coursera.org/learn/data-science-ethics#syllabus) - online course from the University of Michigan.
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - case studies from the University of Texas.

# Assignment 

[Write A Data Ethics Case Study](assignment.md)
