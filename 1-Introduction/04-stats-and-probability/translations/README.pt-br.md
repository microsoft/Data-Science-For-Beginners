# Uma Breve Introdu√ß√£o a Estat√≠stica e Probabilidade

|![ Sketchnote por [(@sketchthedocs)](https://sketchthedocs.dev) ](../../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| Estat√≠stica e Probabilidade - _Sketchnote por [@nitya](https://twitter.com/nitya)_ |

Teoria da Probabilidade e Estat√≠stica s√£o duas √°reas altamente relacionadas da Matem√°tica que s√£o altamente relevante para a Ci√™ncia de Dados. √â poss√≠vel operar com dados sem um conhecimento aprofundado de matem√°tica, mas ainda √© bom saber pelo menos alguns conceitos. Aqui n√≥s vamos apresentar uma breve introdu√ß√£o que ajudar√° voc√™ a come√ßar.

[![V√≠deo de Introdu√ß√£o](../images/video-prob-and-stats.png)](https://youtu.be/Z5Zy85g4Yjw)


## [Quiz Pr√© Aula](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/6)

## Probabilidade e Vari√°veis Aleat√≥rias

**Probabilidade** √© um n√∫mero entre 0 e 1 que expressa o qu√£o prov√°vel um **evento** √©. √â definida como um n√∫mero de resultados positivos (que levam ao evento), divido pelo n√∫mero poss√≠vel de resultados, dado que todos os resultados s√£o igualmente prov√°veis. Por exemplo, quando jogamos um dado, a probabilidade de termos um n√∫mero par √© 3/6 = 0.5.

Quando falamos de eventos, usamos **vari√°veis aleat√≥rias**. Por exemplo, a vari√°vel aleat√≥ria que representa o n√∫mero obtido quando jogamos um dado assumiria valores entre 1 e 6. O conjunto de n√∫meros entre 1 a 6 √© chamado de **espa√ßo amostral**. Podemos falar sobre a probabilidade de uma vari√°vel aleat√≥ria ser um certo valor, como por exemplo P(X=3)=1/6.

A vari√°vel aleat√≥ria nos exemplos anteriores s√£o chamadas de **discretas**, pois possui um espa√ßo amostral cont√°vel, ex. existem valores separados que podem ser numerados. Existem casos onde o espa√ßo amostral √© uma gama de valores reais, ou todo o conjunto de n√∫meros reais. Essas vari√°veis s√£o chamadas de **cont√≠nuas**. Um bom exemplo √© a hora em que o √¥nibus chega.

## Distribui√ß√£o de Probabilidade

No caso de vari√°veis discretas, √© f√°cil descrever a probabilidade de cada um por uma fun√ß√£o P(X). Para cada valor *s* do espa√ßo amostrals *S* vai dar um n√∫mero entre 0 e 1, de modo que todos os valores P(X=s) para todos os eventos seria 1.

A distribui√ß√£o discreta mais conhecida √© a **distribui√ß√£o uniforme**, no qual existe um espa√ßo amostral de N elementos, com probabilidade de 1/N para todos eles.

√â mais dif√≠cil descrever a distribui√ß√£o de probabilidade para uma vari√°vel cont√≠nua, com valores sorteados dentro de um intervalo [a, b], ou todo o conjunto dos n√∫meros reais &Ropf;. Considere o caso da chegado do hor√°rio de √¥nibus. Na verdade, para cada hor√°rio de chegada exato $t$, a probabilidade do √¥nibus chegar exatamente naquele hor√°rio √© 0!

> Agora voc√™ sabe que eventos com probabilidade 0 acontecem, e muito frequentemente! Pelo menos toda vez que o √¥nibus chegar!

N√≥s s√≥ podemos falar da probabilidade de uma vari√°vel cair em um determinado intervalo de valores, ex. P(t<sub>1</sub>&le;X&lt;t<sub>2</sub>). Nesse caso, a distribui√ß√£o de probabilidade √© descrita por uma **fun√ß√£o densidade de probabilidade** p(x), sendo que

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](..//images/probability-density.png)

Um an√°logo cont√≠nuo de distribui√ß√£o uniforme √© chamado de **uniforme cont√≠nuo**, o qual √© definido em um intervalo finito. Uma probabilidade de que o valor X caia em um intervalo de tamanho l √© proporcional a l, e vai at√© 1.

Outra distribui√ß√£o importante √© a **distribui√ß√£o normal**, a qual vamos falar sobre em mais detalhes abaixo.

## M√©dia, Vari√¢ncia e Desvio Padr√£o

Vamos supor que sorteamos um sequ√™ncia de n amostras da vari√°vel aleat√≥ria X: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. N√≥s podemos definir o valor da **m√©dia** (ou **m√©dia aritm√©tica**) da sequ√™ncia da forma tradicional como (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n. Conforme aumentamos o tamanho da amostra (ex. obter o limite com n&rarr;&infin;), n√≥s vamos obter a m√©dia (tamb√©m chamada de **expect√¢ncia ou esperan√ßa**) da distribui√ß√£o. N√≥s vamos denot√°-la por **E**(x).

> Pode ser demonstrado que para qualquer distribui√ß√£o discreta com valores {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} e probabilidades correspondentes p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, a expectativa seria igual a E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>.

Para demonstrar o quanto os valores est√£o espalhados, n√≥s podemos computar a vari√¢ncia &sigma;sup>2</sup> = &sum;(x<sub>i</sub> - &mu;)<sup>2</sup>/n, onde &mu; √© a m√©dia da sequ√™ncia. O valor de &sigma; √© chamado de **desvio padr√£o**, e &sigma;<sup>2</sup> √© chamado de **vari√¢ncia**.

## Moda, M√©dia e Quartis

Algumas vezes, a m√©dia n√£o representa adequadamente o valor "t√≠pico" para dados. Por exemplo, quando existem poucos valores extremos que est√£o completamente fora da faixa, eles podem afetar a m√©dia. Outra boa indica√ß√£o √© a **mediana**, um valor sendo que metade dos pontos de dados est√£o abaixo dele, e a outra metade - acima.

Para nos ajudar a entender a distribui√ß√£o dos dados, √© √∫til falar de **quartis**:

* O primeiro quartil, ou Q1, √© um valor sendo que 25% dos dados estar√£o abaixo dele
* O terceiro quartil,ou Q3, √© um valor sendo que 75% dos dados estar√£o abaixo dele

Graficamente n√≥s podemos representar a rela√ß√£o entre mediana e quartis em um diagrama chamado de **box plot**:

<img src="../images/boxplot_explanation.png" width="50%"/>

N√≥s tamb√©m podemos computar o **intervalo interquartil** IQR=Q3-Q1, e os t√£o chamados **outliers** - valores que se localizam fora dos limites [Q1-1.5*IQR,Q3+1.5*IQR].

Para distribui√ß√µes finitas que contenham um pequeno n√∫mero de valores positivos, um bom valor "t√≠pico" √© aquele que aparece mais frequentemente, que √© chamado de **moda**. Geralmente √© aplicado para dados categ√≥ricos, como cores. Considere uma situa√ß√£o onde n√≥s temos dois grupos de pessoas - alguns preferem fortemente vermelho, enquanto outros preferem azul. Se atribuirmos n√∫meros a cores, o valor m√©dio para uma cor favorita estaria em algum lugar entre o espectro laranja-verde, o que n√£o indica, de fato, a prefer√™ncia de nenhum grupo. No entanto, a moda seria ou uma das cores, ou ambas as cores, se os n√∫meros de pessoas que votaram para elas fossem iguais (nesse caso n√≥s chamamos a amostra de **multimodal**).
## Dados do Mundo Real

Quando analisamos dados da vida real, eles normalmente n√£o s√£o vari√°veis aleat√≥rias como tal, no sentido de que n√£o realizamos experimentos com resultado desconhecido. Por exemplo, considere um time de jogadores de baseball, e os seus dados corporais, como altura, peso e idade. Esses n√∫merps n√£o s√£o exatamente aleat√≥rios, mas n√≥s podemos aplicar os mesmos conceitos matem√°ticos. Por exemplo, a sequ√™ncia da altura das pessoas pode ser considerada uma sequ√™ncia de valores sortidos de alguma vari√°vel aleat√≥ria. Abaixo  est√° a sequ√™ncia de pesos de jogadores reais da [Major League Baseball](http://mlb.mlb.com/index.jsp), retirados [desse dataset](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) (para a sua conveni√™ncia, apenas os primeiros 20 valores s√£o mostrados):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Nota**: Para ver o exemplo de trabalhar com esse dataset, olhe o [notebook](../notebook.ipynb). Existe tamb√©m um n√∫mero de desafios nessa aula, e voc√™ pode complet√°-los adicionando alguns c√≥digos nesse notebook. Se voc√™ n√£o tem certeza de como operar os dados, n√£o se preocupe - n√≥s vamos voltar a trabalhar com dados usando Python em um outro momento. Se voc√™ n√£o sabe como rodar c√≥digo no Jupyter Notebook, d√™ uma olhada [neste artigo](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

Aqui est√° o box plot mostrando a m√©dia, mediana e quartis para os nossos dados:

![Box Plot dos Pesos](../images/weight-boxplot.png)

J√° que os nossos dados possuem informa√ß√£o de **posi√ß√µes** diferentes dos jogadores, n√≥s podemos fazer o box plot baseado nas posi√ß√µes - permitir√° a gente ter uma ideia de como os valores dos par√¢metros mudam conforme diferentes posi√ß√µes. Agora vamos considerar a altura:

![Box plot por posi√ß√£o](../images/boxplot_byrole.png)

Esse diagrama sugere que, em m√©dia, a altura do jogador na primeira base √© maior do que a altura dos jogadores na segunda base. Mais tarde nessa aula n√≥s vamos aprender como podemos testar essa hip√≥tese mais formalmente, e como demonstrar que o nosso dado √© estatisticamente significante para mostrar isso.

> Quando trabalhando com dados do mundo real, n√≥s assumimos que todos os pontos de dados s√£o amostras sortidas de alguma distribui√ß√£o de probabilidade. Essa suposi√ß√£o permite que a gente aplica t√©cnicas de aprendizado de m√°quina e contrua modelos preditivos que funcionam.

Para ver qual a distribui√ß√£o dos nossos dados √©, n√≥s podemos "plotar" um gr√°fico chamado de **histograma**. O eixo x seria um n√∫mero de diferentes intervalos de valores para peso (chamados de **grupos** (bins)), e o eixo vertical mostrari o n√∫mero de vezes que a amostra da nossa vari√°vel aleat√≥ria estava dentro do intervalo dado.

![Histogram de dados do mundo real](../images/weight-histogram.png)

A partir desse histograma voc√™ pode ver que todos os valores est√£o centrados ao redor de uma certa m√©dia de peso, e quanto mais longe n√≥s formos - menos pesos desse valor s√£o encotnrados. Ex. √© muito improv√°vel que o peso de um jogador de baseball seja muito diferente da m√©dia de pesos. Vari√¢ncia dos pesos mostram at√© que pontos os pesos tendem a diferir da m√©dia.

> Se n√≥s pegarmos os pesos de outras pessoas, n√£o da liga de baseball, a distribui√ß√£o provavelmente ser√° diferente. No entante, a forma da distribui√ß√£o ser√° a mesma, mas a m√©dia e a vari√¢ncia iria mudar. Ent√£o, se treinarmos o modelo nos jogadores de baseball, provavelmente teremos resultados errados quando aplicado em estudantes de uma universidade, pois a distribui√ß√£o subjacente √© diferente.
## Distribui√ß√£o Normal

A distribui√ß√£o de pesos que vimos acima √© bem t√≠pica, e muitas medidas do mundo real seguem o mesmo tipo de distribui√ß√£o, mas com m√©dias e vari√¢ncias diferentes. Essa distribui√ß√£o √© chamada de **distribui√ß√£o normal**, e possui um papel importante na estat√≠stica.

Usar distribui√ß√£o normal √© uma forma correta de gerar pesos aleat√≥rios para potenciais jogadores de baseball. Uma vez que sabemos a m√©dia de pesso `mean` e desvio padr√£o `std`, n√≥s podemos gerar 1000 amostras de peso da seguinte forma:
```python
samples = np.random.normal(mean,std,1000)
``` 

Se "plotarmos" o histograma das amostras geradas n√≥s vamos ver a figura bem similar com a mostrada acima. Se aumentarmos o n√∫mero de amostrar e o n√∫mero de grupos (bins), n√≥s podemos gerar a figura de uma distribui√ß√£o normal que √© mais perto do ideal:

![Distribui√ß√£o Normal com mean=0 (m√©dia) e std.dev=1 (desvio padr√£o)](../images/normal-histogram.png)

*Distribui√ß√£o Normal com mean=0 e std.dev=1*

## Intervalos de Confi√¢n√ßa

Quando falamos sobre os pesos de jogadores de baseball, n√≥s assumimos que existem certas **vari√°veis aleat√≥rias W** que correspondem a distribui√ß√£o de probabilidade ideal dos pesos de todos os jogadores de baseball (chamados de **popula√ß√£o (population)**). Nossa sequ√™ncia de pesos correspondem a um subset de todos os jogadores que chamamos de **amostra**. Uma quest√£o interessante √©, n√≥s podemos saber os par√¢metros da distribui√ß√£o W, ex. m√©dia e vari√¢ncia de uma popula√ß√£o?

A resposta mais f√°cil seria calcular m√©dia e vari√¢ncia da nossa amostra. No entante, pode acontecer que nossa amostra aleat√≥ria n√£o representa precisamente a popula√ß√£o completa. Portanto faz sentido falar sobre **intervalos de confian√ßa**.

> **Intervalo de confian√ßa** √© a estima√ß√£o da m√©dia verdadeira de uma popula√ß√£o dada a nossa amostra, que √© precisa √© uma certa probabilidade (ou **n√≠vel de confian√ßa**).

Suponha que temos uma amostra X<sub>1</sub>, ..., X<sub>n</sub> da nossa distribui√ß√£o. Cada vez que sorteamos uma amostra da nossa distribui√ß√£o, n√≥s acabar√≠amos com diferentes valores de m√©dia &mu;. Portanto &mu; pode ser considerado uma vari√°vel aleat√≥ria. Um **intervalo de confian√ßa** com confian√ßa p √© um par de valores (L<sub>p</sub>,R<sub>p</sub>), de forma que **P**(L<sub>p</sub>&leq;&mu;&leq;R<sub>p</sub>) = p, ex. a probabilidade da m√©dia medida estar dentro do intervalo igual a p.

Vai al√©m da nossa pequena introdu√ß√£o discutir detalhadamente como esses intervalos de confian√ßa s√£o calculados. Mais detalhes podem ser encontrados [na Wikipedia](https://en.wikipedia.org/wiki/Confidence_interval). Resumidamente, n√≥s definimos a distribui√ß√£o da m√©dia da amostra computada em rela√ß√£o a m√©dia verdadeira da popula√ß√£o, que √© chamada de **distribui√ßao student (student distribution)**.

> **Fato interessante**: distribui√ß√£o Student √© nomeada em homenagem ao matem√°tico William Sealy Gosset, que publicou seu artigo com o pseud√¥nimo "Student". Ele trabalhou na cervejaria Guinness, e, de acordo com uma das vers√µes, seu empregador n√£o queria que o p√∫blico geral soubesse que eles estavam usando testes estat√≠sticos para determinar a qualidade de materiais brutos.

Se n√≥s quis√©ssemos estimar a m√©dia &mu; da nossa popula√ß√£o com confian√ßa p, n√≥s precisamos pegar *percentil n√∫mero (1-p)/2 ((1-p)/2-th percentile)* de uma distribui√ß√£o Student A, que pode ser coletada de tabelas, ou computadores usando alguma fun√ß√£o imbutida de uma software de estat√≠stica (ex. Python, R, etc.). Ent√£o o intervalo &mu; seria dados por X&pm;A*D/&radic;n, onde X √© a m√©dia obtida da amostra, D √© o desvio padr√£o.

> **Nota**: N√≥s tamb√©m omitimos a discuss√£o de um conceito importante de [degrees of freedom (graus de liberdade)](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)), que √© importante em rela√ß√£o a distribui√ß√£o Student. Voc√™ pode dar uma olhada em livros mais completos sobre estat√≠sticas para entender esse conceito mais profundadamente.

Um exemplo para calcular o intervalo de confian√ßa para pesos e alturas √© dado no [notebook](../notebook.ipynb).

| p | Weight mean |
|-----|-----------|
| 0.85 | 201.73¬±0.94 |
| 0.90 | 201.73¬±1.08 |
| 0.95 | 201.73¬±1.28 |

Perceba que quanto maior √© a probabilidade da confian√ßa, mais amplo √© o intervalo de confian√ßa.

## Testando Hip√≥teses
No nosso dataset de jogadores de baseball, existem diferentes posi√ß√µes, as quais podem ser sumarizadas abaixo (olhe o [notebook](../notebook.ipynb) para ver como essa tabela pode ser calculada):

| Role | Height | Weight | Count |
|------|--------|--------|-------|
| Catcher | 72.723684 | 204.328947 | 76 |
| Designated_Hitter | 74.222222 | 220.888889 | 18 |
| First_Baseman | 74.000000 | 213.109091 | 55 |
| Outfielder | 73.010309 | 199.113402 | 194 |
| Relief_Pitcher | 74.374603 | 203.517460 | 315 |
| Second_Baseman | 71.362069 | 184.344828 | 58 |
| Shortstop | 71.903846 | 182.923077 | 52 |
| Starting_Pitcher | 74.719457 | 205.163636 | 221 |
| Third_Baseman | 73.044444 | 200.955556 | 45 |

N√≥s podemos ver que a m√©dia das alturas dos jogadores na primeira base √© maior que a dos jogadores na segunda base. Portanto, n√≥s podemos ser tentados a concluir que **jogadores da primeira base √© maior que os da segunda base**.

> Essa afirma√ß√£o √© chamada de **uma hip√≥tese**, pois n√≥s n√£o sabemos se √© verdade ou n√£o.

No entanto, nem sempre √© √≥bvio fazer essa conclus√£o. A partir da discuss√£o acima n√≥s sabemos que cada m√©dia tem um intervalo de confian√ßa associado, e portante esse diferen√ßa pode ser apenas um erro estat√≠stico. N√≥s precisamos de formas mais formais de testar nossa hip√≥tes.

Vamos computar o intervalo de confian√ßa separadamente para as alturas dos jogadores na primeira base e dos jogadores da segunda base:

| Confidence | First Basemen | Second Basemen |
|------------|---------------|----------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

N√≥s podemos ver que sobre nenhuma confian√ßa os intervalos se sobrep√µem. Isso prova a nossa hip√≥tese de que os jogador na primeira base s√£o mais altos que os jogadores da segunda base.

Mais formalmente, o problema que estamos resolvendo √© ver se **duas distribui√ß√µes de probabilidades s√£o as mesmas**, ou se pelo menos possuem os mesmos par√¢metros. Dependendo da distribui√ß√£o, n√≥s precisamos usar diferentes testes para isso. Se n√≥s soubermos que a nossa distribui√ß√£o √© normal, n√≥s podemos aplicar **[Teste t de Student (Student t-test)](https://en.wikipedia.org/wiki/Student%27s_t-test)**.

No teste t de Student, n√≥s computamos o **valor t**, que indica a diferen√ßa entre a m√©dia, levando em conta a vari√¢ncia. √â demonstrado que o valor t segue a **distribui√ß√£o student**, o que nos permite ter o valor limite para um determinado n√≠vel de confian√ßa **p** (isso pode ser computado, ou procurado nas tabelas num√©ricas). N√≥s ent√£o comparamos o valor t para esse limite para aprovar ou rejeitar a hip√≥tese

Em Python, n√≥s podemos usar o pacote **SciPy**, o qual inclui a fun√ß√£o `ttest_ind` (e mais fun√ß√µes estat√≠sticas!). Ela computa o valor t para a gente, e tamb√©m faz a pesquisa inversa do valor de confian√ßa p, para que podemos apenas olhar para a confian√ßa para chegarmos a uma conclus√£o.

Por exemplo, nossa compara√ß√£o entre alturas dos jogadores da primeira base e da segunda base nos d√° o seguinte resultado:
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
No nosso caso, o valor p √© bem baixo, o que significa que existem fortes evid√™ncias que confirmam que os jogadores da primeira base s√£o maiores.

Existe tamb√©m outros tipos diferentes de hip√≥tes que podemos querer testar, por exemplo:
* Provar que uma dada amostra segue alguma distribui√ß√£o. No nosso caso n√≥s assumimos que alturas s√£o normalmente distribu√≠das, mas isso precisa de verifica√ß√£o estat√≠stica formal.
* Provar que uma valor m√©dia de uma amostra corresponde a algum valor predefinido
* Comparar as m√©dias de um n√∫mero de amostras (ex. qual √© a diferen√ßa em n√≠veis de felicidade entre diferentes faixas et√°rias)

## Lei dos N√∫meros Grandes e Teorema do Limite Central

Uma das raz√µes pelo qual a distribui√ß√£o normal √© t√£o importante √© a t√£o chamada **teorema do limite central**. Vamos supor que temos uma grande amostra de N valores independentes X<sub>1</sub>, ..., X<sub>N</sub>, amostrado de qualquer distribui√ß√£o com m√©dia &mu; e vari√¢ncia &sigma;<sup>2</sup>. Ent√£o, para N suficientemente grande (em outras palavras, quando N&rarr;&infin;), a m√©dia &Sigma;<sub>i</sub>X<sub>i</sub> seria normalmente distribu√≠da, com m√©dia &mu; e vari√¢ncia &sigma;<sup>2</sup>/N.

> Outra forma de interpretar o teorema do limite central √© dizer que independentemente da distribui√ß√£o, quando voc√™ computa a m√©dia da soma de quaisquer valores de vari√°vel aleat√≥ria voc√™ acabar√° com uma distribui√ß√£o normal.

A partir do teorema do limite central tamb√©m segue que, quando when N&rarr;&infin;, a probabilidade da m√©dia da amostra ser igual a &mu; se torna 1. Isso √© conhecido como a **lei dos n√∫meros grandes**.

## Covari√¢ncia e Correla√ß√£o

Uma das coisas que Ci√™ncia dos Dados faz √© encontrar rela√ß√µes entre dados. N√≥s dizemos que duas sequ√™ncias **correlacionam** quando elas exibem um comportamento similar ao mesmo tempo, ex. eles sobem/caem simult√¢neamente, ou uma sequ√™ncia sobe enquanto a outra desce e vice-versa. Em outras palavras, aparenta ter algum tipo de rela√ß√µa entre as duas sequ√™ncias.

> Correla√ß√£o n√£o necessariamente indica uma rela√ß√£o causal entre duas sequ√™ncias; algumas vezes ambas as vari√°veis podem depender de alguma causa externa, or pode ser puramente uma coincid√™ncia que duas sequ√™ncias se relacionem. No entanto, uma forte correla√ß√µe matem√°tica √© um bom ind√≠cio

 Matematicamente, o conceito principal que mostra uma rela√ß√µes entre duas vari√°vies aleat√≥rias √© **covari√¢ncia**, que √© computada da seguinte forma: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. N√≥s computamos o desvio de ambas as vari√°veis em rela√ß√£o a m√©dia, e ent√£o o produto desses desvios. Se ambas as vari√°veis desviam juntas, o produto seria sempre um valor positivo, que resulta em uma covari√¢ncia positiva. Se ambas as vari√°veis desviam de forma n√£o sincronizadas (ex. uma est√° abaixo da m√©dia enquanto outra est√° acima), n√≥s sempre vamos ter n√∫meros negativos, que resulta em uma covari√¢ncia negativa. Se os desvios n√£o s√£o dependentes, eles sempre v√£o resultar em quase zero.

O valor absoluto da  covari√¢ncia n√£o nos informa o qu√£o grande a correla√ß√£o √©, pois depende da magnitude dos valores reais. Para normalizar isso, n√≥s podemos dividir a covari√¢ncia pelo desvio padr√£o de ambas as vari√°veis, para conseguirmos a **correla√ß√£o**. O bom √© que a correla√ß√£o sempre vai estar na faixa de [-1, 1], onde 1 indica uma forte correla√ßao positiva entre os valores, -1 - forte correla√ß√£o negativa, e 0 - nenhuma correla√ß√£o (vari√°veis s√£o independentes).

**Exemplo**: N√≥s podemos computar a correla√ß√£o entre pesos e alturas de jogadores de baseball do dataset mencionado acima:
```python
print(np.corrcoef(weights,heights))
```
Como resultado, temos uma **matriz de correla√ß√£o** como essa:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> Matriz de correla√ß√£o C pode ser computada para qualquer n√∫mero de sequ√™ncias de input S<sub>1</sub>, ..., S<sub>n</sub>. O valor de C <sub>ij</sub> √© a correla√ß√£o entre S<sub>i</sub> e S<sub>j</sub>, e elementos diagonais s√£o sempre 1 (o que tamb√©m √© uma auto-correla√ß√£o de S<sub>i</sub>).

No nosso caso, o valor 0.53 indica que existe alguma correla√ß√£o entre peso e altura de uma pessoa. N√≥s podemos fazer um gr√°fico de pontos de um valor contra o outro para ver a rela√ß√£o visualmente:

![Rela√ß√£o entre peso e altura](../images/weight-height-relationship.png)

> Mais exemplos de correla√ß√£o e covari√¢ncia podem ser encontrados no [notebook](../notebook.ipynb).

## Conclus√£o

Nessa se√ß√£o n√≥s aprendemos:
* propriedades estat√≠sticas b√°sicas dos dados, como m√©dia, vari√¢ncia, moda e quartis
* diferentes distribui√ß√µes para vari√°veis aleat√≥rias, incluindo distribui√ß√£o normal
* como encontrar a correla√ß√£o entre propriedades diferentes
* como usar aparelhos de som de matem√°tica e estat√≠stica para provar algumas hip√≥teses,
* como computar intervalos de confi√¢ncia para vari√°veis aleat√≥rias dado uma amostra de dados

Enquanto essa definitivamente n√£o √© uma lista exaustiva de t√≥picos que existem dentro de probabilidade e estat√≠stica, deve ser o suficiente para voc√™ come√ßar bem esse curso.

## üöÄ Desafio

Use o c√≥digo de exemplo no notebook para testar outras hip√≥teses que:
1. Jogadores na primeira base e mais velhos que jogadores na segunda base
2. Jogadores na primeira base e mais altos que jogadores na terceira base
3. Interbases (Shortstops) s√£o maiores que jogadores na segunda base

## [Quis P√≥s Aula](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/7)

## Revis√£o e Autoestudo

Probabilidade e estat√≠stica √© um t√≥pico muito amplo que merece um curso pr√≥prio. Se voc√™ est√° interessado em aprofundar a teoria, talvez voc√™ queira continuar lendo alguns dos seguintes livros:

1. [Carlos Fernanderz-Granda](https://cims.nyu.edu/~cfgranda/) da Universidade de Nova Iorque (New York University) tem boas notas de aula [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (dispon√≠veis online)
1. [Peter and Andrew Bruce. Estat√≠stica pr√°tica para Cientistas de Dados (Practical Statistics for Data Scientists).](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[sample code in R](https://github.com/andrewgbruce/statistics-for-data-scientists)]. 
1. [James D. Miller. Estat√≠stica para Ci√™ncia de Dados (Statistics for Data Science)](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[sample code in R](https://github.com/PacktPublishing/Statistics-for-Data-Science)]

## Tarefa

[Small Diabetes Study (Pequeno Estudo de Diabetes)](assignment.pt-br.md)

## Cr√©ditos

Essa aula foi autorada com ‚ô•Ô∏è por [Dmitry Soshnikov](http://soshnikov.com)
