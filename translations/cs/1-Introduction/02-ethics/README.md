<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1341f6da63d434f5ba31b08ea951b02c",
  "translation_date": "2025-09-05T17:57:44+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "cs"
}
-->
# Ãšvod do datovÃ© etiky

|![ Sketchnote od [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Etika datovÃ© vÄ›dy - _Sketchnote od [@nitya](https://twitter.com/nitya)_ |

---

Jsme vÅ¡ichni obÄanÃ© datovÃ©ho svÄ›ta, Å¾ijÃ­cÃ­ v dobÄ›, kdy data hrajÃ­ klÃ­Äovou roli.

TrÅ¾nÃ­ trendy naznaÄujÃ­, Å¾e do roku 2022 bude 1 z 3 velkÃ½ch organizacÃ­ nakupovat a prodÃ¡vat svÃ¡ data prostÅ™ednictvÃ­m online [trÅ¾iÅ¡Å¥ a burz](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Jako **vÃ½vojÃ¡Å™i aplikacÃ­** zjistÃ­me, Å¾e je jednoduÅ¡Å¡Ã­ a levnÄ›jÅ¡Ã­ integrovat poznatky zaloÅ¾enÃ© na datech a automatizaci Å™Ã­zenou algoritmy do kaÅ¾dodennÃ­ch uÅ¾ivatelskÃ½ch zkuÅ¡enostÃ­. Ale jak se AI stÃ¡vÃ¡ vÅ¡udypÅ™Ã­tomnou, budeme takÃ© muset pochopit potenciÃ¡lnÃ­ Å¡kody zpÅ¯sobenÃ© [zneuÅ¾itÃ­m](https://www.youtube.com/watch?v=TQHs8SA1qpk) tÄ›chto algoritmÅ¯ ve velkÃ©m mÄ›Å™Ã­tku.

Trendy takÃ© ukazujÃ­, Å¾e do roku 2025 vytvoÅ™Ã­me a spotÅ™ebujeme pÅ™es [180 zettabytÅ¯](https://www.statista.com/statistics/871513/worldwide-data-created/) dat. Jako **datovÃ­ vÄ›dci** zÃ­skÃ¡me bezprecedentnÃ­ pÅ™Ã­stup k osobnÃ­m ÃºdajÅ¯m. To nÃ¡m umoÅ¾nÃ­ vytvÃ¡Å™et behaviorÃ¡lnÃ­ profily uÅ¾ivatelÅ¯ a ovlivÅˆovat rozhodovÃ¡nÃ­ zpÅ¯soby, kterÃ© mohou vytvÃ¡Å™et [iluzi svobodnÃ© volby](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice), zatÃ­mco potenciÃ¡lnÄ› smÄ›Å™ujeme uÅ¾ivatele k vÃ½sledkÅ¯m, kterÃ© preferujeme. To takÃ© vyvolÃ¡vÃ¡ Å¡irÅ¡Ã­ otÃ¡zky tÃ½kajÃ­cÃ­ se ochrany soukromÃ­ a prÃ¡v uÅ¾ivatelÅ¯.

DatovÃ¡ etika je nynÃ­ _nezbytnÃ½m ochrannÃ½m opatÅ™enÃ­m_ pro datovou vÄ›du a inÅ¾enÃ½rstvÃ­, kterÃ© nÃ¡m pomÃ¡hÃ¡ minimalizovat potenciÃ¡lnÃ­ Å¡kody a nechtÄ›nÃ© dÅ¯sledky naÅ¡ich akcÃ­ zaloÅ¾enÃ½ch na datech. [GartnerÅ¯v Hype Cycle pro AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) identifikuje relevantnÃ­ trendy v digitÃ¡lnÃ­ etice, odpovÄ›dnÃ© AI a sprÃ¡vÄ› AI jako klÃ­ÄovÃ© faktory pro vÄ›tÅ¡Ã­ megatrendy kolem _demokratizace_ a _industrializace_ AI.

![GartnerÅ¯v Hype Cycle pro AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

V tÃ©to lekci prozkoumÃ¡me fascinujÃ­cÃ­ oblast datovÃ© etiky - od zÃ¡kladnÃ­ch konceptÅ¯ a vÃ½zev, pÅ™es pÅ™Ã­padovÃ© studie aÅ¾ po aplikovanÃ© koncepty AI, jako je sprÃ¡va, kterÃ© pomÃ¡hajÃ­ vytvÃ¡Å™et kulturu etiky v tÃ½mech a organizacÃ­ch pracujÃ­cÃ­ch s daty a AI.

## [KvÃ­z pÅ™ed pÅ™ednÃ¡Å¡kou](https://ff-quizzes.netlify.app/en/ds/quiz/2) ğŸ¯

## ZÃ¡kladnÃ­ definice

ZaÄnÄ›me pochopenÃ­m zÃ¡kladnÃ­ terminologie.

Slovo "etika" pochÃ¡zÃ­ z [Å™eckÃ©ho slova "ethikos"](https://en.wikipedia.org/wiki/Ethics) (a jeho koÅ™ene "ethos"), coÅ¾ znamenÃ¡ _charakter nebo morÃ¡lnÃ­ povaha_.

**Etika** se tÃ½kÃ¡ sdÃ­lenÃ½ch hodnot a morÃ¡lnÃ­ch principÅ¯, kterÃ© Å™Ã­dÃ­ naÅ¡e chovÃ¡nÃ­ ve spoleÄnosti. Etika nenÃ­ zaloÅ¾ena na zÃ¡konech, ale na Å¡iroce pÅ™ijÃ­manÃ½ch normÃ¡ch toho, co je "sprÃ¡vnÃ© vs. Å¡patnÃ©". EtickÃ© Ãºvahy vÅ¡ak mohou ovlivnit iniciativy korporÃ¡tnÃ­ sprÃ¡vy a vlÃ¡dnÃ­ regulace, kterÃ© vytvÃ¡Å™ejÃ­ vÃ­ce pobÃ­dek k dodrÅ¾ovÃ¡nÃ­ pravidel.

**DatovÃ¡ etika** je [novÃ¡ odnoÅ¾ etiky](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1), kterÃ¡ "studuje a hodnotÃ­ morÃ¡lnÃ­ problÃ©my souvisejÃ­cÃ­ s _daty, algoritmy a odpovÃ­dajÃ­cÃ­mi praktikami_". Zde se **"data"** zamÄ›Å™ujÃ­ na akce spojenÃ© s generovÃ¡nÃ­m, zaznamenÃ¡vÃ¡nÃ­m, kurÃ¡torstvÃ­m, zpracovÃ¡nÃ­m, Å¡Ã­Å™enÃ­m, sdÃ­lenÃ­m a pouÅ¾Ã­vÃ¡nÃ­m, **"algoritmy"** se zamÄ›Å™ujÃ­ na AI, agenty, strojovÃ© uÄenÃ­ a roboty a **"praktiky"** se zamÄ›Å™ujÃ­ na tÃ©mata jako odpovÄ›dnÃ© inovace, programovÃ¡nÃ­, hacking a etickÃ© kodexy.

**AplikovanÃ¡ etika** je [praktickÃ¡ aplikace morÃ¡lnÃ­ch Ãºvah](https://en.wikipedia.org/wiki/Applied_ethics). Je to proces aktivnÃ­ho zkoumÃ¡nÃ­ etickÃ½ch otÃ¡zek v kontextu _reÃ¡lnÃ½ch akcÃ­, produktÅ¯ a procesÅ¯_ a pÅ™ijÃ­mÃ¡nÃ­ nÃ¡pravnÃ½ch opatÅ™enÃ­, aby zÅ¯staly v souladu s naÅ¡imi definovanÃ½mi etickÃ½mi hodnotami.

**Kultura etiky** se tÃ½kÃ¡ [_operacionalizace_ aplikovanÃ© etiky](https://hbr.org/2019/05/how-to-design-an-ethical-organization), aby bylo zajiÅ¡tÄ›no, Å¾e naÅ¡e etickÃ© principy a praktiky jsou pÅ™ijÃ­mÃ¡ny konzistentnÃ­m a Å¡kÃ¡lovatelnÃ½m zpÅ¯sobem napÅ™Ã­Ä celou organizacÃ­. ÃšspÄ›Å¡nÃ© kultury etiky definujÃ­ etickÃ© principy na Ãºrovni celÃ© organizace, poskytujÃ­ smysluplnÃ© pobÃ­dky k dodrÅ¾ovÃ¡nÃ­ pravidel a posilujÃ­ normy etiky podporou a zesilovÃ¡nÃ­m Å¾Ã¡doucÃ­ho chovÃ¡nÃ­ na kaÅ¾dÃ© Ãºrovni organizace.

## Koncepty etiky

V tÃ©to ÄÃ¡sti budeme diskutovat koncepty jako **sdÃ­lenÃ© hodnoty** (principy) a **etickÃ© vÃ½zvy** (problÃ©my) v oblasti datovÃ© etiky - a prozkoumÃ¡me **pÅ™Ã­padovÃ© studie**, kterÃ© vÃ¡m pomohou pochopit tyto koncepty v reÃ¡lnÃ½ch kontextech.

### 1. Principy etiky

KaÅ¾dÃ¡ strategie datovÃ© etiky zaÄÃ­nÃ¡ definovÃ¡nÃ­m _etickÃ½ch principÅ¯_ - "sdÃ­lenÃ½ch hodnot", kterÃ© popisujÃ­ pÅ™ijatelnÃ© chovÃ¡nÃ­ a Å™Ã­dÃ­ dodrÅ¾ovÃ¡nÃ­ pravidel v naÅ¡ich projektech zamÄ›Å™enÃ½ch na data a AI. Tyto principy mÅ¯Å¾ete definovat na individuÃ¡lnÃ­ nebo tÃ½movÃ© Ãºrovni. NicmÃ©nÄ› vÄ›tÅ¡ina velkÃ½ch organizacÃ­ je uvÃ¡dÃ­ v _etickÃ©m AI_ prohlÃ¡Å¡enÃ­ nebo rÃ¡mci, kterÃ½ je definovÃ¡n na korporÃ¡tnÃ­ Ãºrovni a dÅ¯slednÄ› prosazovÃ¡n napÅ™Ã­Ä vÅ¡emi tÃ½my.

**PÅ™Ã­klad:** Microsoftovo [odpovÄ›dnÃ© AI](https://www.microsoft.com/en-us/ai/responsible-ai) prohlÃ¡Å¡enÃ­ znÃ­: _"Jsme odhodlÃ¡ni k rozvoji AI Å™Ã­zenÃ© etickÃ½mi principy, kterÃ© stavÃ­ lidi na prvnÃ­ mÃ­sto"_ - identifikujÃ­cÃ­ 6 etickÃ½ch principÅ¯ v nÃ­Å¾e uvedenÃ©m rÃ¡mci:

![OdpovÄ›dnÃ© AI v Microsoftu](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

PojÄme si struÄnÄ› prozkoumat tyto principy. _Transparentnost_ a _odpovÄ›dnost_ jsou zÃ¡kladnÃ­ hodnoty, na kterÃ½ch jsou postaveny ostatnÃ­ principy - zaÄnÄ›me tedy zde:

* [**OdpovÄ›dnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) ÄinÃ­ praktiky _odpovÄ›dnÃ½mi_ za jejich operace s daty a AI a za dodrÅ¾ovÃ¡nÃ­ tÄ›chto etickÃ½ch principÅ¯.
* [**Transparentnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) zajiÅ¡Å¥uje, Å¾e akce s daty a AI jsou _srozumitelnÃ©_ (interpretovatelnÃ©) pro uÅ¾ivatele, vysvÄ›tlujÃ­cÃ­ co a proÄ za rozhodnutÃ­mi.
* [**Spravedlnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - zamÄ›Å™uje se na zajiÅ¡tÄ›nÃ­, Å¾e AI zachÃ¡zÃ­ _se vÅ¡emi lidmi_ spravedlivÄ›, Å™eÅ¡Ã­cÃ­ jakÃ©koli systÃ©movÃ© nebo implicitnÃ­ socio-technickÃ© pÅ™edsudky v datech a systÃ©mech.
* [**Spolehlivost a bezpeÄnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - zajiÅ¡Å¥uje, Å¾e AI se chovÃ¡ _konzistentnÄ›_ s definovanÃ½mi hodnotami, minimalizuje potenciÃ¡lnÃ­ Å¡kody nebo nechtÄ›nÃ© dÅ¯sledky.
* [**SoukromÃ­ a bezpeÄnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - se tÃ½kÃ¡ pochopenÃ­ pÅ¯vodu dat a poskytovÃ¡nÃ­ _ochrany soukromÃ­ a souvisejÃ­cÃ­ch prÃ¡v_ uÅ¾ivatelÅ¯m.
* [**Inkluzivita**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - se tÃ½kÃ¡ navrhovÃ¡nÃ­ AI Å™eÅ¡enÃ­ s Ãºmyslem, pÅ™izpÅ¯sobenÃ­ je tak, aby splÅˆovala _Å¡irokou Å¡kÃ¡lu lidskÃ½ch potÅ™eb_ a schopnostÃ­.

> ğŸš¨ Zamyslete se nad tÃ­m, jakÃ© by mohlo bÃ½t vaÅ¡e prohlÃ¡Å¡enÃ­ o datovÃ© etice. Prozkoumejte etickÃ© AI rÃ¡mce jinÃ½ch organizacÃ­ - zde jsou pÅ™Ã­klady od [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles) a [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). JakÃ© sdÃ­lenÃ© hodnoty majÃ­ spoleÄnÃ©? Jak se tyto principy vztahujÃ­ k AI produktÅ¯m nebo odvÄ›tvÃ­, ve kterÃ©m pÅ¯sobÃ­?

### 2. VÃ½zvy etiky

Jakmile mÃ¡me definovanÃ© etickÃ© principy, dalÅ¡Ã­m krokem je zhodnotit naÅ¡e akce v oblasti dat a AI, zda jsou v souladu s tÄ›mito sdÃ­lenÃ½mi hodnotami. Zamyslete se nad svÃ½mi akcemi ve dvou kategoriÃ­ch: _sbÄ›r dat_ a _nÃ¡vrh algoritmÅ¯_.

PÅ™i sbÄ›ru dat budou akce pravdÄ›podobnÄ› zahrnovat **osobnÃ­ Ãºdaje** nebo osobnÄ› identifikovatelnÃ© informace (PII) pro identifikovatelnÃ© Å¾ivÃ© jednotlivce. To zahrnuje [rÅ¯znÃ© poloÅ¾ky neosobnÃ­ch dat](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en), kterÃ© _spoleÄnÄ›_ identifikujÃ­ jednotlivce. EtickÃ© vÃ½zvy se mohou tÃ½kat _ochrany soukromÃ­_, _vlastnictvÃ­ dat_ a souvisejÃ­cÃ­ch tÃ©mat, jako je _informovanÃ½ souhlas_ a _prÃ¡va duÅ¡evnÃ­ho vlastnictvÃ­_ uÅ¾ivatelÅ¯.

PÅ™i nÃ¡vrhu algoritmÅ¯ budou akce zahrnovat sbÄ›r a kurÃ¡torstvÃ­ **datovÃ½ch sad**, potÃ© jejich pouÅ¾itÃ­ k trÃ©novÃ¡nÃ­ a nasazenÃ­ **datovÃ½ch modelÅ¯**, kterÃ© pÅ™edpovÃ­dajÃ­ vÃ½sledky nebo automatizujÃ­ rozhodovÃ¡nÃ­ v reÃ¡lnÃ½ch kontextech. EtickÃ© vÃ½zvy mohou vzniknout z _pÅ™edsudkÅ¯ v datovÃ½ch sadÃ¡ch_, _problÃ©mÅ¯ s kvalitou dat_, _nespravedlnosti_ a _zkreslenÃ­_ v algoritmech - vÄetnÄ› nÄ›kterÃ½ch problÃ©mÅ¯, kterÃ© jsou systÃ©movÃ© povahy.

V obou pÅ™Ã­padech etickÃ© vÃ½zvy zdÅ¯razÅˆujÃ­ oblasti, kde naÅ¡e akce mohou bÃ½t v konfliktu s naÅ¡imi sdÃ­lenÃ½mi hodnotami. Abychom tyto obavy detekovali, zmÃ­rnili, minimalizovali nebo eliminovali, musÃ­me si klÃ¡st morÃ¡lnÃ­ otÃ¡zky typu "ano/ne" tÃ½kajÃ­cÃ­ se naÅ¡ich akcÃ­ a potÃ© pÅ™ijmout nÃ¡pravnÃ¡ opatÅ™enÃ­ podle potÅ™eby. PodÃ­vejme se na nÄ›kterÃ© etickÃ© vÃ½zvy a morÃ¡lnÃ­ otÃ¡zky, kterÃ© vyvolÃ¡vajÃ­:

#### 2.1 VlastnictvÃ­ dat

SbÄ›r dat Äasto zahrnuje osobnÃ­ Ãºdaje, kterÃ© mohou identifikovat subjekty dat. [VlastnictvÃ­ dat](https://permission.io/blog/data-ownership) se tÃ½kÃ¡ _kontroly_ a [_prÃ¡v uÅ¾ivatelÅ¯_](https://permission.io/blog/data-ownership) souvisejÃ­cÃ­ch s vytvÃ¡Å™enÃ­m, zpracovÃ¡nÃ­m a Å¡Ã­Å™enÃ­m dat.

MorÃ¡lnÃ­ otÃ¡zky, kterÃ© je tÅ™eba si poloÅ¾it:
 * Kdo vlastnÃ­ data? (uÅ¾ivatel nebo organizace)
 * JakÃ¡ prÃ¡va majÃ­ subjekty dat? (napÅ™. pÅ™Ã­stup, vymazÃ¡nÃ­, pÅ™enositelnost)
 * JakÃ¡ prÃ¡va majÃ­ organizace? (napÅ™. oprava Å¡kodlivÃ½ch uÅ¾ivatelskÃ½ch recenzÃ­)

#### 2.2 InformovanÃ½ souhlas

[InformovanÃ½ souhlas](https://legaldictionary.net/informed-consent/) definuje akt, kdy uÅ¾ivatelÃ© souhlasÃ­ s akcÃ­ (napÅ™. sbÄ›rem dat) s _plnÃ½m pochopenÃ­m_ relevantnÃ­ch faktÅ¯, vÄetnÄ› ÃºÄelu, potenciÃ¡lnÃ­ch rizik a alternativ.

OtÃ¡zky k prozkoumÃ¡nÃ­:
 * Dal uÅ¾ivatel (subjekt dat) povolenÃ­ ke sbÄ›ru a pouÅ¾itÃ­ dat?
 * RozumÄ›l uÅ¾ivatel ÃºÄelu, pro kterÃ½ byla data sbÃ­rÃ¡na?
 * RozumÄ›l uÅ¾ivatel potenciÃ¡lnÃ­m rizikÅ¯m spojenÃ½m s jeho ÃºÄastÃ­?

#### 2.3 DuÅ¡evnÃ­ vlastnictvÃ­

[DuÅ¡evnÃ­ vlastnictvÃ­](https://en.wikipedia.org/wiki/Intellectual_property) se tÃ½kÃ¡ nehmotnÃ½ch vÃ½tvorÅ¯ vzniklÃ½ch z lidskÃ© iniciativy, kterÃ© mohou mÃ­t _ekonomickou hodnotu_ pro jednotlivce nebo firmy.

OtÃ¡zky k prozkoumÃ¡nÃ­:
 * MÄ›la shromÃ¡Å¾dÄ›nÃ¡ data ekonomickou hodnotu pro uÅ¾ivatele nebo firmu?
 * MÃ¡ **uÅ¾ivatel** zde duÅ¡evnÃ­ vlastnictvÃ­?
 * MÃ¡ **organizace** zde duÅ¡evnÃ­ vlastnictvÃ­?
 * Pokud tato prÃ¡va existujÃ­, jak je chrÃ¡nÃ­me?

#### 2.4 Ochrana soukromÃ­

[Ochrana soukromÃ­](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) nebo informaÄnÃ­ soukromÃ­ se tÃ½kÃ¡ zachovÃ¡nÃ­ soukromÃ­ uÅ¾ivatelÅ¯ a ochrany jejich identity ve vztahu k osobnÄ› identifikovatelnÃ½m informacÃ­m.

OtÃ¡zky k prozkoumÃ¡nÃ­:
 * Jsou osobnÃ­ data uÅ¾ivatelÅ¯ zabezpeÄena proti hackÅ¯m a ÃºnikÅ¯m?
 * Jsou data uÅ¾ivatelÅ¯ pÅ™Ã­stupnÃ¡ pouze autorizovanÃ½m uÅ¾ivatelÅ¯m a kontextÅ¯m?
 * Je anonymita uÅ¾ivatelÅ¯ zachovÃ¡na pÅ™i sdÃ­lenÃ­ nebo Å¡Ã­Å™enÃ­ dat?
 * MÅ¯Å¾e bÃ½t uÅ¾ivatel de-identifikovÃ¡n z anonymizovanÃ½ch datovÃ½ch sad?

#### 2.5 PrÃ¡vo bÃ½t zapomenut

[PrÃ¡vo bÃ½t zapomenut](https://en.wikipedia.org/wiki/Right_to_be_forgotten) nebo [PrÃ¡vo na vymazÃ¡nÃ­](https://www.gdpreu.org/right-to-be-forgotten/) poskytuje uÅ¾ivatelÅ¯m dodateÄnou ochranu osobnÃ­ch ÃºdajÅ¯. KonkrÃ©tnÄ› dÃ¡vÃ¡ uÅ¾ivatelÅ¯m prÃ¡vo poÅ¾adovat smazÃ¡nÃ­ nebo odstranÄ›nÃ­ osobnÃ­ch ÃºdajÅ¯ z internetovÃ½ch vyhledÃ¡vÃ¡nÃ­ a jinÃ½ch mÃ­st, _za specifickÃ½ch okolnostÃ­_ - umoÅ¾ÅˆujÃ­cÃ­ jim novÃ½ zaÄÃ¡tek online bez toho, aby byly jejich minulÃ© akce proti nim pouÅ¾ity.

OtÃ¡zky k prozkoumÃ¡nÃ­:
 * UmoÅ¾Åˆuje systÃ©m subjektÅ¯m dat poÅ¾adovat vymazÃ¡nÃ­?
 * MÄ›l by odvolÃ¡nÃ­ souhlasu uÅ¾ivatele automaticky spustit vymazÃ¡nÃ­?
 * Byla data sbÃ­rÃ¡na bez souhlasu nebo nezÃ¡konnÃ½mi prostÅ™edky?
 * Jsme v souladu s vlÃ¡dnÃ­mi regulacemi pro ochranu soukromÃ­ dat?

#### 2.6 PÅ™edsudky v datovÃ½ch sadÃ¡ch

PÅ™edsudky v datovÃ½ch sadÃ¡ch nebo [pÅ™edsudky pÅ™i sbÄ›ru dat](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) se tÃ½kajÃ­ vÃ½bÄ›ru _nereprezentativnÃ­ho_ podmnoÅ¾iny dat pro vÃ½voj algoritmÅ¯, coÅ¾ mÅ¯Å¾e vytvÃ¡Å™et potenciÃ¡lnÃ­ nespravedlnost ve vÃ½sledcÃ­ch pro rÅ¯znÃ© skupiny. Typy pÅ™edsudkÅ¯ zahrnujÃ­ vÃ½bÄ›rovÃ© nebo vzorkovacÃ­ pÅ™edsudky, dobrovolnickÃ© pÅ™edsudky a pÅ™edsudky nÃ¡strojÅ¯.

OtÃ¡zky k prozkoumÃ¡nÃ­:
 * Rekrutovali jsme reprezentativnÃ­ soubor subjektÅ¯ dat?
 * Testovali jsme naÅ¡i shromÃ¡Å¾dÄ›nou nebo kurÃ¡torovanou datovou sadu na rÅ¯znÃ© pÅ™edsudky?
 * MÅ¯Å¾eme zmÃ­rnit nebo odstranit jakÃ©koli objevenÃ© pÅ™edsudky?

#### 2.7 Kvalita dat

[Kvalita dat](https://lakefs.io/data-quality-testing/) se zamÄ›Å™uje na validitu kurÃ¡torovanÃ© datovÃ© sady pouÅ¾itÃ© k vÃ½voji naÅ¡ich algoritmÅ¯, kontroluje, zda funkce a zÃ¡znamy splÅˆujÃ­ poÅ¾adavky na ÃºroveÅˆ pÅ™esnosti a konzistence potÅ™ebnou pro nÃ¡Å¡ AI ÃºÄel.

OtÃ¡zky k prozkoumÃ¡nÃ­:
 * Zachytili jsme platnÃ© _funkce_ pro nÃ¡
[Algorithm Fairness](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) zkoumÃ¡, zda nÃ¡vrh algoritmu systematicky nediskriminuje specifickÃ© podskupiny subjektÅ¯, coÅ¾ mÅ¯Å¾e vÃ©st k [potenciÃ¡lnÃ­m Å¡kodÃ¡m](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) v _alokaci_ (kdy jsou zdroje odepÅ™eny nebo zadrÅ¾eny tÃ©to skupinÄ›) a _kvalitÄ› sluÅ¾eb_ (kdy AI nenÃ­ tak pÅ™esnÃ¡ pro nÄ›kterÃ© podskupiny jako pro jinÃ©).

OtÃ¡zky k zamyÅ¡lenÃ­:
 * Vyhodnotili jsme pÅ™esnost modelu pro rÅ¯znÃ© podskupiny a podmÃ­nky?
 * Prozkoumali jsme systÃ©m kvÅ¯li potenciÃ¡lnÃ­m Å¡kodÃ¡m (napÅ™. stereotypizaci)?
 * MÅ¯Å¾eme upravit data nebo znovu natrÃ©novat modely, abychom zmÃ­rnili identifikovanÃ© Å¡kody?

Prozkoumejte zdroje jako [AI Fairness checklists](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA), abyste se dozvÄ›dÄ›li vÃ­ce.

#### 2.9 ZkreslenÃ­ dat

[ZkreslenÃ­ dat](https://www.sciencedirect.com/topics/computer-science/misrepresentation) se tÃ½kÃ¡ otÃ¡zky, zda komunikujeme poznatky z poctivÄ› hlÃ¡Å¡enÃ½ch dat klamavÃ½m zpÅ¯sobem, abychom podpoÅ™ili poÅ¾adovanÃ½ narativ.

OtÃ¡zky k zamyÅ¡lenÃ­:
 * HlÃ¡sÃ­me neÃºplnÃ¡ nebo nepÅ™esnÃ¡ data?
 * Vizualizujeme data zpÅ¯sobem, kterÃ½ vede k zavÃ¡dÄ›jÃ­cÃ­m zÃ¡vÄ›rÅ¯m?
 * PouÅ¾Ã­vÃ¡me selektivnÃ­ statistickÃ© techniky k manipulaci s vÃ½sledky?
 * ExistujÃ­ alternativnÃ­ vysvÄ›tlenÃ­, kterÃ¡ mohou nabÃ­dnout jinÃ½ zÃ¡vÄ›r?

#### 2.10 SvobodnÃ¡ volba
[Iluze svobodnÃ© volby](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) nastÃ¡vÃ¡, kdyÅ¾ "architektury volby" systÃ©mu pouÅ¾Ã­vajÃ­ algoritmy rozhodovÃ¡nÃ­ k ovlivnÄ›nÃ­ lidÃ­, aby pÅ™ijali preferovanÃ½ vÃ½sledek, zatÃ­mco jim zdÃ¡nlivÄ› dÃ¡vajÃ­ moÅ¾nosti a kontrolu. Tyto [temnÃ© vzorce](https://www.darkpatterns.org/) mohou zpÅ¯sobit sociÃ¡lnÃ­ a ekonomickÃ© Å¡kody uÅ¾ivatelÅ¯m. ProtoÅ¾e rozhodnutÃ­ uÅ¾ivatelÅ¯ ovlivÅˆujÃ­ profily chovÃ¡nÃ­, tyto akce mohou potenciÃ¡lnÄ› Å™Ã­dit budoucÃ­ volby, kterÃ© mohou zesÃ­lit nebo rozÅ¡Ã­Å™it dopad tÄ›chto Å¡kod.

OtÃ¡zky k zamyÅ¡lenÃ­:
 * RozumÄ›l uÅ¾ivatel dÅ¯sledkÅ¯m svÃ©ho rozhodnutÃ­?
 * Byl uÅ¾ivatel informovÃ¡n o (alternativnÃ­ch) moÅ¾nostech a jejich vÃ½hodÃ¡ch a nevÃ½hodÃ¡ch?
 * MÅ¯Å¾e uÅ¾ivatel pozdÄ›ji zvrÃ¡tit automatizovanÃ© nebo ovlivnÄ›nÃ© rozhodnutÃ­?

### 3. PÅ™Ã­padovÃ© studie

Abychom tyto etickÃ© vÃ½zvy zasadili do reÃ¡lnÃ©ho kontextu, je uÅ¾iteÄnÃ© podÃ­vat se na pÅ™Ã­padovÃ© studie, kterÃ© zdÅ¯razÅˆujÃ­ potenciÃ¡lnÃ­ Å¡kody a dÅ¯sledky pro jednotlivce a spoleÄnost, pokud jsou etickÃ© problÃ©my pÅ™ehlÃ­Å¾eny.

Zde je nÄ›kolik pÅ™Ã­kladÅ¯:

| EtickÃ¡ vÃ½zva | PÅ™Ã­padovÃ¡ studie  | 
|--- |--- |
| **InformovanÃ½ souhlas** | 1972 - [Tuskegee Syphilis Study](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - AfroameriÄtÃ­ muÅ¾i, kteÅ™Ã­ se ÃºÄastnili studie, byli slibovÃ¡ni bezplatnou lÃ©kaÅ™skou pÃ©Äi, _ale byli podvedeni_ vÃ½zkumnÃ­ky, kteÅ™Ã­ jim neÅ™ekli o jejich diagnÃ³ze nebo dostupnosti lÃ©Äby. Mnoho subjektÅ¯ zemÅ™elo a jejich partneÅ™i Äi dÄ›ti byli ovlivnÄ›ni; studie trvala 40 let. | 
| **Ochrana dat** |  2007 - [Netflix data prize](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) poskytla vÃ½zkumnÃ­kÅ¯m _10M anonymizovanÃ½ch hodnocenÃ­ filmÅ¯ od 50K zÃ¡kaznÃ­kÅ¯_, aby pomohla zlepÅ¡it doporuÄovacÃ­ algoritmy. VÃ½zkumnÃ­ci vÅ¡ak byli schopni propojit anonymizovanÃ¡ data s osobnÄ› identifikovatelnÃ½mi daty v _externÃ­ch datovÃ½ch sadÃ¡ch_ (napÅ™. komentÃ¡Å™e na IMDb), ÄÃ­mÅ¾ efektivnÄ› "de-anonymizovali" nÄ›kterÃ© pÅ™edplatitele Netflixu.|
| **SbÄ›r dat s pÅ™edsudky**  | 2013 - MÄ›sto Boston [vyvinulo Street Bump](https://www.boston.gov/transportation/street-bump), aplikaci, kterÃ¡ umoÅ¾nila obÄanÅ¯m hlÃ¡sit vÃ½moly, ÄÃ­mÅ¾ mÄ›sto zÃ­skalo lepÅ¡Ã­ Ãºdaje o silnicÃ­ch pro identifikaci a opravu problÃ©mÅ¯. NicmÃ©nÄ› [lidÃ© z niÅ¾Å¡Ã­ch pÅ™Ã­jmovÃ½ch skupin mÄ›li menÅ¡Ã­ pÅ™Ã­stup k autÅ¯m a telefonÅ¯m](https://hbr.org/2013/04/the-hidden-biases-in-big-data), coÅ¾ Äinilo jejich problÃ©my na silnicÃ­ch neviditelnÃ½mi v tÃ©to aplikaci. VÃ½vojÃ¡Å™i spolupracovali s akademiky na _problÃ©mech spravedlivÃ©ho pÅ™Ã­stupu a digitÃ¡lnÃ­ch rozdÃ­lÅ¯_. |
| **Spravedlnost algoritmÅ¯**  | 2018 - MIT [Gender Shades Study](http://gendershades.org/overview.html) hodnotila pÅ™esnost AI produktÅ¯ pro klasifikaci pohlavÃ­, odhalila mezery v pÅ™esnosti pro Å¾eny a osoby jinÃ© barvy pleti. [Apple Card z roku 2019](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) se zdÃ¡la nabÃ­zet mÃ©nÄ› ÃºvÄ›ru Å¾enÃ¡m neÅ¾ muÅ¾Å¯m. Oba pÅ™Ã­pady ilustrujÃ­ problÃ©my s pÅ™edsudky v algoritmech vedoucÃ­ k socio-ekonomickÃ½m Å¡kodÃ¡m.|
| **ZkreslenÃ­ dat** | 2020 - [Georgia Department of Public Health zveÅ™ejnila COVID-19 grafy](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening), kterÃ© se zdÃ¡ly zavÃ¡dÄ›t obÄany ohlednÄ› trendÅ¯ potvrzenÃ½ch pÅ™Ã­padÅ¯ s nechronologickÃ½m uspoÅ™Ã¡dÃ¡nÃ­m na ose x. To ilustruje zkreslenÃ­ prostÅ™ednictvÃ­m vizualizaÄnÃ­ch trikÅ¯. |
| **Iluze svobodnÃ© volby** | 2020 - VÃ½ukovÃ¡ aplikace [ABCmouse zaplatila $10M za urovnÃ¡nÃ­ stÃ­Å¾nosti FTC](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/), kde rodiÄe byli uvÄ›znÄ›ni v platbÄ› za pÅ™edplatnÃ©, kterÃ© nemohli zruÅ¡it. To ilustruje temnÃ© vzorce v architekturÃ¡ch volby, kde byli uÅ¾ivatelÃ© ovlivnÄ›ni k potenciÃ¡lnÄ› Å¡kodlivÃ½m rozhodnutÃ­m. |
| **Ochrana dat a prÃ¡va uÅ¾ivatelÅ¯** | 2021 - Facebook [Data Breach](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) odhalil data 530M uÅ¾ivatelÅ¯, coÅ¾ vedlo k urovnÃ¡nÃ­ $5B s FTC. NicmÃ©nÄ› odmÃ­tl informovat uÅ¾ivatele o Ãºniku dat, ÄÃ­mÅ¾ poruÅ¡il prÃ¡va uÅ¾ivatelÅ¯ na transparentnost a pÅ™Ã­stup k datÅ¯m. |

Chcete prozkoumat vÃ­ce pÅ™Ã­padovÃ½ch studiÃ­? PodÃ­vejte se na tyto zdroje:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - etickÃ© dilemata napÅ™Ã­Ä rÅ¯znÃ½mi odvÄ›tvÃ­mi. 
* [Data Science Ethics course](https://www.coursera.org/learn/data-science-ethics#syllabus) - pÅ™ehled klÃ­ÄovÃ½ch pÅ™Ã­padovÃ½ch studiÃ­.
* [Where things have gone wrong](https://deon.drivendata.org/examples/) - deon checklist s pÅ™Ã­klady.


> ğŸš¨ Zamyslete se nad pÅ™Ã­padovÃ½mi studiemi, kterÃ© jste vidÄ›li - zaÅ¾ili jste nebo byli ovlivnÄ›ni podobnou etickou vÃ½zvou ve svÃ©m Å¾ivotÄ›? DokÃ¡Å¾ete si vybavit alespoÅˆ jednu dalÅ¡Ã­ pÅ™Ã­padovou studii, kterÃ¡ ilustruje jednu z etickÃ½ch vÃ½zev, o kterÃ½ch jsme diskutovali v tÃ©to sekci?

## AplikovanÃ¡ etika

Diskutovali jsme o etickÃ½ch konceptech, vÃ½zvÃ¡ch a pÅ™Ã­padovÃ½ch studiÃ­ch v reÃ¡lnÃ©m kontextu. Ale jak zaÄÃ­t _aplikovat_ etickÃ© principy a praktiky ve svÃ½ch projektech? A jak _zavÃ©st_ tyto praktiky pro lepÅ¡Ã­ Å™Ã­zenÃ­? PojÄme prozkoumat nÄ›kterÃ¡ reÃ¡lnÃ¡ Å™eÅ¡enÃ­: 

### 1. ProfesnÃ­ kodexy

ProfesnÃ­ kodexy nabÃ­zejÃ­ jednu moÅ¾nost, jak organizace mohou "motivovat" Äleny k podpoÅ™e svÃ½ch etickÃ½ch principÅ¯ a poslÃ¡nÃ­. Kodexy jsou _morÃ¡lnÃ­mi pokyny_ pro profesnÃ­ chovÃ¡nÃ­, kterÃ© pomÃ¡hajÃ­ zamÄ›stnancÅ¯m nebo ÄlenÅ¯m Äinit rozhodnutÃ­ v souladu s principy organizace. Jsou vÅ¡ak ÃºÄinnÃ© pouze tehdy, pokud ÄlenovÃ© dobrovolnÄ› dodrÅ¾ujÃ­ pravidla; mnoho organizacÃ­ vÅ¡ak nabÃ­zÃ­ dalÅ¡Ã­ odmÄ›ny a sankce, aby motivovaly Äleny k dodrÅ¾ovÃ¡nÃ­ pravidel.

PÅ™Ã­klady zahrnujÃ­:

 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Code of Ethics
 * [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Code of Conduct (vytvoÅ™en 2013)
 * [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (od roku 1993)

> ğŸš¨ Jste Älenem profesnÃ­ organizace pro inÅ¾enÃ½ry nebo datovÃ© vÄ›dce? Prozkoumejte jejich webovÃ© strÃ¡nky a zjistÄ›te, zda definujÃ­ profesnÃ­ kodex etiky. Co Å™Ã­kÃ¡ o jejich etickÃ½ch principech? Jak motivujÃ­ Äleny k dodrÅ¾ovÃ¡nÃ­ kodexu?

### 2. EtickÃ© kontrolnÃ­ seznamy

ZatÃ­mco profesnÃ­ kodexy definujÃ­ poÅ¾adovanÃ© _etickÃ© chovÃ¡nÃ­_ od praktikujÃ­cÃ­ch, majÃ­ [znÃ¡mÃ¡ omezenÃ­](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) v prosazovÃ¡nÃ­, zejmÃ©na u rozsÃ¡hlÃ½ch projektÅ¯. MÃ­sto toho mnoho odbornÃ­kÅ¯ na datovou vÄ›du [doporuÄuje kontrolnÃ­ seznamy](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), kterÃ© mohou **propojit principy s praxÃ­** deterministickÃ½m a akceschopnÃ½m zpÅ¯sobem.

KontrolnÃ­ seznamy pÅ™evÃ¡dÄ›jÃ­ otÃ¡zky na Ãºkoly "ano/ne", kterÃ© lze operacionalizovat, coÅ¾ umoÅ¾Åˆuje jejich sledovÃ¡nÃ­ jako souÄÃ¡st standardnÃ­ch pracovnÃ­ch postupÅ¯ pÅ™i vydÃ¡vÃ¡nÃ­ produktÅ¯.

PÅ™Ã­klady zahrnujÃ­:
 * [Deon](https://deon.drivendata.org/) - obecnÃ½ kontrolnÃ­ seznam datovÃ© etiky vytvoÅ™enÃ½ na zÃ¡kladÄ› [doporuÄenÃ­ z prÅ¯myslu](https://deon.drivendata.org/#checklist-citations) s nÃ¡strojem pÅ™Ã­kazovÃ©ho Å™Ã¡dku pro snadnou integraci.
 * [Privacy Audit Checklist](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - poskytuje obecnÃ© pokyny pro naklÃ¡dÃ¡nÃ­ s informacemi z prÃ¡vnÃ­ho a sociÃ¡lnÃ­ho hlediska.
 * [AI Fairness Checklist](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - vytvoÅ™enÃ½ odbornÃ­ky na AI na podporu pÅ™ijetÃ­ a integrace kontrol spravedlnosti do vÃ½vojovÃ½ch cyklÅ¯ AI.
 * [22 otÃ¡zek pro etiku v datech a AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - otevÅ™enÄ›jÅ¡Ã­ rÃ¡mec, strukturovanÃ½ pro poÄÃ¡teÄnÃ­ zkoumÃ¡nÃ­ etickÃ½ch problÃ©mÅ¯ v nÃ¡vrhu, implementaci a organizaÄnÃ­ch kontextech.

### 3. EtickÃ© regulace

Etika je o definovÃ¡nÃ­ sdÃ­lenÃ½ch hodnot a dobrovolnÃ©m dÄ›lÃ¡nÃ­ sprÃ¡vnÃ½ch vÄ›cÃ­. **DodrÅ¾ovÃ¡nÃ­ pÅ™edpisÅ¯** je o _dodrÅ¾ovÃ¡nÃ­ zÃ¡kona_, pokud je definovÃ¡n. **Å˜Ã­zenÃ­** obecnÄ› pokrÃ½vÃ¡ vÅ¡echny zpÅ¯soby, jakÃ½mi organizace fungujÃ­, aby prosazovaly etickÃ© principy a dodrÅ¾ovaly stanovenÃ© zÃ¡kony.

Dnes Å™Ã­zenÃ­ probÃ­hÃ¡ ve dvou formÃ¡ch v rÃ¡mci organizacÃ­. Za prvÃ©, jde o definovÃ¡nÃ­ principÅ¯ **etickÃ© AI** a zavedenÃ­ praktik pro operacionalizaci pÅ™ijetÃ­ napÅ™Ã­Ä vÅ¡emi projekty souvisejÃ­cÃ­mi s AI v organizaci. Za druhÃ©, jde o dodrÅ¾ovÃ¡nÃ­ vÅ¡ech vlÃ¡dou stanovenÃ½ch **regulacÃ­ ochrany dat** pro regiony, ve kterÃ½ch organizace pÅ¯sobÃ­.

PÅ™Ã­klady regulacÃ­ ochrany dat a soukromÃ­:

 * `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - reguluje _federÃ¡lnÃ­ vlÃ¡dnÃ­_ sbÄ›r, pouÅ¾itÃ­ a zveÅ™ejnÄ›nÃ­ osobnÃ­ch informacÃ­.
 * `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - chrÃ¡nÃ­ osobnÃ­ zdravotnÃ­ Ãºdaje.
 * `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - chrÃ¡nÃ­ soukromÃ­ dat dÄ›tÃ­ mladÅ¡Ã­ch 13 let.
 * `2018`, [General Data Protection Regulation (GDPR)](https://gdpr-info.eu/) - poskytuje prÃ¡va uÅ¾ivatelÅ¯, ochranu dat a soukromÃ­.
 * `2018`, [California Consumer Privacy Act (CCPA)](https://www.oag.ca.gov/privacy/ccpa) dÃ¡vÃ¡ spotÅ™ebitelÅ¯m vÃ­ce _prÃ¡v_ nad jejich (osobnÃ­mi) daty.
 * `2021`, ÄŒÃ­na [Personal Information Protection Law](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) prÃ¡vÄ› schvÃ¡lila, ÄÃ­mÅ¾ vytvoÅ™ila jednu z nejsilnÄ›jÅ¡Ã­ch regulacÃ­ online ochrany dat na svÄ›tÄ›.

> ğŸš¨ EvropskÃ¡ unie definovala GDPR (General Data Protection Regulation), kterÃ½ zÅ¯stÃ¡vÃ¡ jednou z nejvlivnÄ›jÅ¡Ã­ch regulacÃ­ ochrany dat dnes. VÄ›dÄ›li jste, Å¾e takÃ© definuje [8 prÃ¡v uÅ¾ivatelÅ¯](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) na ochranu digitÃ¡lnÃ­ho soukromÃ­ a osobnÃ­ch dat obÄanÅ¯? ZjistÄ›te, co to jsou a proÄ jsou dÅ¯leÅ¾itÃ¡.

### 4. EtickÃ¡ kultura

Poznamenejte, Å¾e stÃ¡le existuje nehmotnÃ¡ mezera mezi _dodrÅ¾ovÃ¡nÃ­m pÅ™edpisÅ¯_ (dÄ›lÃ¡nÃ­m dostateÄnÃ©ho pro splnÄ›nÃ­ "litery zÃ¡kona") a Å™eÅ¡enÃ­m [systÃ©movÃ½ch problÃ©mÅ¯](https://www.coursera.org/learn/data-science-ethics/home/week/4) (jako je zkostnatÄ›lost, informaÄnÃ­ asymetrie a distribuÄnÃ­ nespravedlnost), kterÃ© mohou urychlit zneuÅ¾itÃ­ AI.

To druhÃ© vyÅ¾aduje [spoluprÃ¡ci na definovÃ¡nÃ­ etickÃ½ch kultur](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f), kterÃ© budujÃ­ emocionÃ¡lnÃ­ spojenÃ­ a konzistentnÃ­ sdÃ­lenÃ© hodnoty _napÅ™Ã­Ä organizacemi_ v prÅ¯myslu. To volÃ¡ po vÃ­ce [formalizovanÃ½ch kulturÃ¡ch datovÃ© etiky](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) v organizacÃ­ch - umoÅ¾ÅˆujÃ­cÃ­ _komukoliv_ [zatÃ¡hnout za Andon Å¡ÅˆÅ¯ru](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (aby vÄas upozornil na etickÃ© problÃ©my) a uÄinit _etickÃ© hodnocenÃ­_ (napÅ™. pÅ™i nÃ¡boru) klÃ­ÄovÃ½m kritÃ©riem pro formovÃ¡nÃ­ tÃ½mÅ¯ v AI projektech.

---
## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ds/quiz/3) ğŸ¯
## PÅ™ehled a samostudium 

Kurzy a knihy pomÃ¡hajÃ­ pochopit zÃ¡kladnÃ­ etickÃ© koncepty a vÃ½zvy, zatÃ­mco pÅ™Ã­padovÃ© studie a nÃ¡stroje pomÃ¡hajÃ­ s aplikovanÃ½mi etickÃ½mi praktikami v reÃ¡lnÃ©m kontextu. Zde je nÄ›kolik zdrojÅ¯, kde zaÄÃ­t.

* [Machine Learning For Beginners](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - lekce o spravedlnosti od Microsoftu.
* [Principy odpovÄ›dnÃ© AI](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - bezplatnÃ¡ vzdÄ›lÃ¡vacÃ­ cesta od Microsoft Learn.
* [Etika a datovÃ¡ vÄ›da](https://resources.oreilly.com/examples/0636920203964) - EBook od O'Reilly (M. Loukides, H. Mason a kol.)
* [Etika datovÃ© vÄ›dy](https://www.coursera.org/learn/data-science-ethics#syllabus) - online kurz od University of Michigan.
* [Etika v praxi](https://ethicsunwrapped.utexas.edu/case-studies) - pÅ™Ã­padovÃ© studie od University of Texas.

# ZadÃ¡nÃ­

[Vypracujte pÅ™Ã­padovou studii o etice dat](assignment.md)

---

**ProhlÃ¡Å¡enÃ­**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ sluÅ¾by pro automatickÃ½ pÅ™eklad [Co-op Translator](https://github.com/Azure/co-op-translator). AÄkoli se snaÅ¾Ã­me o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatickÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho pÅ¯vodnÃ­m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za autoritativnÃ­ zdroj. Pro dÅ¯leÅ¾itÃ© informace doporuÄujeme profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. NeodpovÃ­dÃ¡me za Å¾Ã¡dnÃ¡ nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© interpretace vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.