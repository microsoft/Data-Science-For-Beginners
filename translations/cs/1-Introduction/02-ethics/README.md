<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "58860ce9a4b8a564003d2752f7c72851",
  "translation_date": "2025-10-03T16:54:39+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "cs"
}
-->
# Ãšvod do datovÃ© etiky

|![ Sketchnote od [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Etika datovÃ© vÄ›dy - _Sketchnote od [@nitya](https://twitter.com/nitya)_ |

---

Jsme vÅ¡ichni datovÃ­ obÄanÃ© Å¾ijÃ­cÃ­ ve svÄ›tÄ› plnÃ©m dat.

TrÅ¾nÃ­ trendy naznaÄujÃ­, Å¾e do roku 2022 bude 1 z 3 velkÃ½ch organizacÃ­ nakupovat a prodÃ¡vat svÃ¡ data prostÅ™ednictvÃ­m online [trÅ¾iÅ¡Å¥ a burz](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Jako **vÃ½vojÃ¡Å™i aplikacÃ­** zjistÃ­me, Å¾e je snazÅ¡Ã­ a levnÄ›jÅ¡Ã­ integrovat poznatky zaloÅ¾enÃ© na datech a automatizaci Å™Ã­zenou algoritmy do kaÅ¾dodennÃ­ch uÅ¾ivatelskÃ½ch zkuÅ¡enostÃ­. Ale jak se AI stÃ¡vÃ¡ vÅ¡udypÅ™Ã­tomnou, budeme takÃ© muset pochopit potenciÃ¡lnÃ­ Å¡kody zpÅ¯sobenÃ© [zneuÅ¾itÃ­m](https://www.youtube.com/watch?v=TQHs8SA1qpk) tÄ›chto algoritmÅ¯ ve velkÃ©m mÄ›Å™Ã­tku.

Trendy naznaÄujÃ­, Å¾e do roku 2025 budeme generovat a spotÅ™ebovÃ¡vat vÃ­ce neÅ¾ [180 zettabytÅ¯](https://www.statista.com/statistics/871513/worldwide-data-created/) dat. Pro **datovÃ© vÄ›dce** tento vÃ½buch informacÃ­ poskytuje bezprecedentnÃ­ pÅ™Ã­stup k osobnÃ­m a behaviorÃ¡lnÃ­m datÅ¯m. S tÃ­m pÅ™ichÃ¡zÃ­ moc vytvÃ¡Å™et podrobnÃ© uÅ¾ivatelskÃ© profily a jemnÄ› ovlivÅˆovat rozhodovÃ¡nÃ­ â€“ Äasto zpÅ¯soby, kterÃ© podporujÃ­ [iluzi svobodnÃ© volby](https://www.datasciencecentral.com/the-pareto-set-and-the-paradox-of-choice/). ZatÃ­mco to mÅ¯Å¾e bÃ½t pouÅ¾ito k nasmÄ›rovÃ¡nÃ­ uÅ¾ivatelÅ¯ k preferovanÃ½m vÃ½sledkÅ¯m, takÃ© to vyvolÃ¡vÃ¡ zÃ¡sadnÃ­ otÃ¡zky o ochranÄ› dat, autonomii a etickÃ½ch hranicÃ­ch algoritmickÃ©ho vlivu.

DatovÃ¡ etika je nynÃ­ _nezbytnÃ½m zÃ¡bradlÃ­m_ pro datovou vÄ›du a inÅ¾enÃ½rstvÃ­, kterÃ© nÃ¡m pomÃ¡hÃ¡ minimalizovat potenciÃ¡lnÃ­ Å¡kody a nechtÄ›nÃ© dÅ¯sledky naÅ¡ich akcÃ­ zaloÅ¾enÃ½ch na datech. [GartnerÅ¯v Hype Cycle pro AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) identifikuje relevantnÃ­ trendy v digitÃ¡lnÃ­ etice, odpovÄ›dnÃ© AI a sprÃ¡vÄ› AI jako klÃ­ÄovÃ© faktory pro vÄ›tÅ¡Ã­ megatrendy kolem _demokratizace_ a _industrializace_ AI.

![GartnerÅ¯v Hype Cycle pro AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

V tÃ©to lekci prozkoumÃ¡me fascinujÃ­cÃ­ oblast datovÃ© etiky â€“ od zÃ¡kladnÃ­ch konceptÅ¯ a vÃ½zev po pÅ™Ã­padovÃ© studie a aplikovanÃ© koncepty AI, jako je sprÃ¡va â€“ kterÃ© pomÃ¡hajÃ­ vytvoÅ™it kulturu etiky v tÃ½mech a organizacÃ­ch pracujÃ­cÃ­ch s daty a AI.




## [KvÃ­z pÅ™ed pÅ™ednÃ¡Å¡kou](https://ff-quizzes.netlify.app/en/ds/quiz/2) ğŸ¯

## ZÃ¡kladnÃ­ definice

ZaÄnÄ›me pochopenÃ­m zÃ¡kladnÃ­ terminologie.

Slovo "etika" pochÃ¡zÃ­ z [Å™eckÃ©ho slova "ethikos"](https://en.wikipedia.org/wiki/Ethics) (a jeho koÅ™ene "ethos"), coÅ¾ znamenÃ¡ _charakter nebo morÃ¡lnÃ­ povaha_. 

**Etika** se tÃ½kÃ¡ sdÃ­lenÃ½ch hodnot a morÃ¡lnÃ­ch principÅ¯, kterÃ© Å™Ã­dÃ­ naÅ¡e chovÃ¡nÃ­ ve spoleÄnosti. Etika nenÃ­ zaloÅ¾ena na zÃ¡konech, ale na Å¡iroce pÅ™ijÃ­manÃ½ch normÃ¡ch toho, co je "sprÃ¡vnÃ© vs. Å¡patnÃ©". NicmÃ©nÄ› etickÃ© Ãºvahy mohou ovlivnit iniciativy korporÃ¡tnÃ­ sprÃ¡vy a vlÃ¡dnÃ­ regulace, kterÃ© vytvÃ¡Å™ejÃ­ vÃ­ce pobÃ­dek k dodrÅ¾ovÃ¡nÃ­ pravidel.

**DatovÃ¡ etika** je [novÃ¡ odnoÅ¾ etiky](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1), kterÃ¡ "studuje a hodnotÃ­ morÃ¡lnÃ­ problÃ©my souvisejÃ­cÃ­ s _daty, algoritmy a odpovÃ­dajÃ­cÃ­mi praktikami_". Zde se **"data"** zamÄ›Å™ujÃ­ na akce souvisejÃ­cÃ­ s generovÃ¡nÃ­m, zaznamenÃ¡vÃ¡nÃ­m, kurÃ¡torstvÃ­m, zpracovÃ¡nÃ­m, Å¡Ã­Å™enÃ­m, sdÃ­lenÃ­m a pouÅ¾Ã­vÃ¡nÃ­m, **"algoritmy"** se zamÄ›Å™ujÃ­ na AI, agenty, strojovÃ© uÄenÃ­ a roboty a **"praktiky"** se zamÄ›Å™ujÃ­ na tÃ©mata jako odpovÄ›dnÃ© inovace, programovÃ¡nÃ­, hacking a etickÃ© kodexy.

**AplikovanÃ¡ etika** je [praktickÃ¡ aplikace morÃ¡lnÃ­ch Ãºvah](https://en.wikipedia.org/wiki/Applied_ethics). Je to proces aktivnÃ­ho zkoumÃ¡nÃ­ etickÃ½ch otÃ¡zek v kontextu _reÃ¡lnÃ½ch akcÃ­, produktÅ¯ a procesÅ¯_ a pÅ™ijÃ­mÃ¡nÃ­ nÃ¡pravnÃ½ch opatÅ™enÃ­, aby tyto zÅ¯staly v souladu s naÅ¡imi definovanÃ½mi etickÃ½mi hodnotami.

**Kultura etiky** se tÃ½kÃ¡ [_operacionalizace_ aplikovanÃ© etiky](https://hbr.org/2019/05/how-to-design-an-ethical-organization), aby bylo zajiÅ¡tÄ›no, Å¾e naÅ¡e etickÃ© principy a praktiky jsou pÅ™ijÃ­mÃ¡ny konzistentnÃ­m a Å¡kÃ¡lovatelnÃ½m zpÅ¯sobem napÅ™Ã­Ä celou organizacÃ­. ÃšspÄ›Å¡nÃ© kultury etiky definujÃ­ etickÃ© principy na Ãºrovni celÃ© organizace, poskytujÃ­ smysluplnÃ© pobÃ­dky k dodrÅ¾ovÃ¡nÃ­ pravidel a posilujÃ­ normy etiky tÃ­m, Å¾e podporujÃ­ a zesilujÃ­ poÅ¾adovanÃ© chovÃ¡nÃ­ na kaÅ¾dÃ© Ãºrovni organizace.


## Koncepty etiky

V tÃ©to sekci budeme diskutovat koncepty jako **sdÃ­lenÃ© hodnoty** (principy) a **etickÃ© vÃ½zvy** (problÃ©my) pro datovou etiku â€“ a prozkoumÃ¡me **pÅ™Ã­padovÃ© studie**, kterÃ© vÃ¡m pomohou pochopit tyto koncepty v reÃ¡lnÃ½ch kontextech.

### 1. Principy etiky

KaÅ¾dÃ¡ strategie datovÃ© etiky zaÄÃ­nÃ¡ definovÃ¡nÃ­m _etickÃ½ch principÅ¯_ â€“ "sdÃ­lenÃ½ch hodnot", kterÃ© popisujÃ­ pÅ™ijatelnÃ© chovÃ¡nÃ­ a Å™Ã­dÃ­ souladnÃ© akce v naÅ¡ich projektech zamÄ›Å™enÃ½ch na data a AI. Tyto principy mÅ¯Å¾ete definovat na individuÃ¡lnÃ­ nebo tÃ½movÃ© Ãºrovni. NicmÃ©nÄ› vÄ›tÅ¡ina velkÃ½ch organizacÃ­ je stanovuje v _etickÃ©m AI_ prohlÃ¡Å¡enÃ­ nebo rÃ¡mci, kterÃ½ je definovÃ¡n na korporÃ¡tnÃ­ Ãºrovni a dÅ¯slednÄ› prosazovÃ¡n napÅ™Ã­Ä vÅ¡emi tÃ½my.

**PÅ™Ã­klad:** ProhlÃ¡Å¡enÃ­ Microsoftu o [odpovÄ›dnÃ© AI](https://www.microsoft.com/en-us/ai/responsible-ai) znÃ­: _"Jsme odhodlÃ¡ni k rozvoji AI Å™Ã­zenÃ© etickÃ½mi principy, kterÃ© stavÃ­ lidi na prvnÃ­ mÃ­sto"_ â€“ identifikujÃ­cÃ­ 6 etickÃ½ch principÅ¯ v rÃ¡mci nÃ­Å¾e:

![OdpovÄ›dnÃ¡ AI v Microsoftu](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

PojÄme si struÄnÄ› prozkoumat tyto principy. _Transparentnost_ a _odpovÄ›dnost_ jsou zÃ¡kladnÃ­ hodnoty, na kterÃ½ch jsou postaveny ostatnÃ­ principy â€“ zaÄnÄ›me tedy zde:

* [**OdpovÄ›dnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) ÄinÃ­ praktiky _odpovÄ›dnÃ½mi_ za jejich operace s daty a AI a za dodrÅ¾ovÃ¡nÃ­ tÄ›chto etickÃ½ch principÅ¯.
* [**Transparentnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) zajiÅ¡Å¥uje, Å¾e akce s daty a AI jsou _srozumitelnÃ©_ (interpretovatelnÃ©) pro uÅ¾ivatele, vysvÄ›tlujÃ­cÃ­ co a proÄ za rozhodnutÃ­mi.
* [**Spravedlnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) â€“ zamÄ›Å™uje se na zajiÅ¡tÄ›nÃ­, Å¾e AI zachÃ¡zÃ­ _se vÅ¡emi lidmi_ spravedlivÄ›, Å™eÅ¡Ã­cÃ­ jakÃ©koli systÃ©movÃ© nebo implicitnÃ­ socio-technickÃ© pÅ™edsudky v datech a systÃ©mech.
* [**Spolehlivost a bezpeÄnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) â€“ zajiÅ¡Å¥uje, Å¾e AI se chovÃ¡ _konzistentnÄ›_ s definovanÃ½mi hodnotami, minimalizuje potenciÃ¡lnÃ­ Å¡kody nebo nechtÄ›nÃ© dÅ¯sledky.
* [**SoukromÃ­ a bezpeÄnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) â€“ jde o pochopenÃ­ pÅ¯vodu dat a poskytovÃ¡nÃ­ _ochrany soukromÃ­ dat_ uÅ¾ivatelÅ¯m.
* [**Inkluzivita**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) â€“ jde o navrhovÃ¡nÃ­ AI Å™eÅ¡enÃ­ s Ãºmyslem, pÅ™izpÅ¯sobujÃ­cÃ­ je tak, aby splÅˆovala _Å¡irokou Å¡kÃ¡lu lidskÃ½ch potÅ™eb_ a schopnostÃ­.

> ğŸš¨ Zamyslete se nad tÃ­m, jakÃ© by mohlo bÃ½t vaÅ¡e prohlÃ¡Å¡enÃ­ o datovÃ© etice. Prozkoumejte rÃ¡mce etickÃ© AI od jinÃ½ch organizacÃ­ â€“ zde jsou pÅ™Ã­klady od [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles) a [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). JakÃ© sdÃ­lenÃ© hodnoty majÃ­ spoleÄnÃ©? Jak se tyto principy vztahujÃ­ k AI produktÅ¯m nebo prÅ¯myslu, ve kterÃ©m pÅ¯sobÃ­?

### 2. VÃ½zvy etiky

Jakmile mÃ¡me definovanÃ© etickÃ© principy, dalÅ¡Ã­m krokem je vyhodnotit naÅ¡e akce s daty a AI, zda jsou v souladu s tÄ›mito sdÃ­lenÃ½mi hodnotami. Zamyslete se nad svÃ½mi akcemi ve dvou kategoriÃ­ch: _sbÄ›r dat_ a _nÃ¡vrh algoritmÅ¯_. 

PÅ™i sbÄ›ru dat budou akce pravdÄ›podobnÄ› zahrnovat **osobnÃ­ Ãºdaje** nebo osobnÄ› identifikovatelnÃ© informace (PII) pro identifikovatelnÃ© Å¾ivÃ© jednotlivce. To zahrnuje [rÅ¯znÃ© poloÅ¾ky neosobnÃ­ch dat](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en), kterÃ© _spoleÄnÄ›_ identifikujÃ­ jednotlivce. EtickÃ© vÃ½zvy se mohou tÃ½kat _ochrany dat_, _vlastnictvÃ­ dat_ a souvisejÃ­cÃ­ch tÃ©mat, jako je _informovanÃ½ souhlas_ a _prÃ¡va duÅ¡evnÃ­ho vlastnictvÃ­_ uÅ¾ivatelÅ¯.

PÅ™i nÃ¡vrhu algoritmÅ¯ budou akce zahrnovat sbÄ›r a kurÃ¡torstvÃ­ **datovÃ½ch sad**, potÃ© jejich pouÅ¾itÃ­ k trÃ©novÃ¡nÃ­ a nasazenÃ­ **datovÃ½ch modelÅ¯**, kterÃ© pÅ™edpovÃ­dajÃ­ vÃ½sledky nebo automatizujÃ­ rozhodovÃ¡nÃ­ v reÃ¡lnÃ½ch kontextech. EtickÃ© vÃ½zvy mohou vzniknout z _pÅ™edsudkÅ¯ v datovÃ½ch sadÃ¡ch_, _problÃ©mÅ¯ s kvalitou dat_, _nespravedlnosti_ a _zkreslenÃ­_ v algoritmech â€“ vÄetnÄ› nÄ›kterÃ½ch problÃ©mÅ¯, kterÃ© jsou systÃ©movÃ© povahy.

V obou pÅ™Ã­padech etickÃ© vÃ½zvy zdÅ¯razÅˆujÃ­ oblasti, kde naÅ¡e akce mohou narazit na konflikt s naÅ¡imi sdÃ­lenÃ½mi hodnotami. Abychom tyto obavy detekovali, zmÃ­rnili, minimalizovali nebo eliminovali, musÃ­me klÃ¡st morÃ¡lnÃ­ otÃ¡zky typu "ano/ne" souvisejÃ­cÃ­ s naÅ¡imi akcemi a potÃ© pÅ™ijmout nÃ¡pravnÃ¡ opatÅ™enÃ­ podle potÅ™eby. PodÃ­vejme se na nÄ›kterÃ© etickÃ© vÃ½zvy a morÃ¡lnÃ­ otÃ¡zky, kterÃ© vyvolÃ¡vajÃ­:


#### 2.1 VlastnictvÃ­ dat

SbÄ›r dat Äasto zahrnuje osobnÃ­ Ãºdaje, kterÃ© mohou identifikovat subjekty dat. [VlastnictvÃ­ dat](https://permission.io/blog/data-ownership) se tÃ½kÃ¡ _kontroly_ a [_uÅ¾ivatelskÃ½ch prÃ¡v_](https://permission.io/blog/data-ownership) souvisejÃ­cÃ­ch s vytvÃ¡Å™enÃ­m, zpracovÃ¡nÃ­m a Å¡Ã­Å™enÃ­m dat. 

MorÃ¡lnÃ­ otÃ¡zky, kterÃ© musÃ­me klÃ¡st, jsou: 
 * Kdo vlastnÃ­ data? (uÅ¾ivatel nebo organizace)
 * JakÃ¡ prÃ¡va majÃ­ subjekty dat? (napÅ™. pÅ™Ã­stup, vymazÃ¡nÃ­, pÅ™enositelnost)
 * JakÃ¡ prÃ¡va majÃ­ organizace? (napÅ™. oprava Å¡kodlivÃ½ch uÅ¾ivatelskÃ½ch recenzÃ­)

#### 2.2 InformovanÃ½ souhlas

[InformovanÃ½ souhlas](https://legaldictionary.net/informed-consent/) definuje akt, kdy uÅ¾ivatelÃ© souhlasÃ­ s akcÃ­ (napÅ™. sbÄ›rem dat) s _plnÃ½m pochopenÃ­m_ relevantnÃ­ch faktÅ¯, vÄetnÄ› ÃºÄelu, potenciÃ¡lnÃ­ch rizik a alternativ. 

OtÃ¡zky k prozkoumÃ¡nÃ­ zde jsou:
 * Dal uÅ¾ivatel (subjekt dat) povolenÃ­ ke sbÄ›ru a pouÅ¾itÃ­ dat?
 * RozumÄ›l uÅ¾ivatel ÃºÄelu, pro kterÃ½ byla data sbÃ­rÃ¡na?
 * RozumÄ›l uÅ¾ivatel potenciÃ¡lnÃ­m rizikÅ¯m z jejich ÃºÄasti?

#### 2.3 DuÅ¡evnÃ­ vlastnictvÃ­

[DuÅ¡evnÃ­ vlastnictvÃ­](https://en.wikipedia.org/wiki/Intellectual_property) se tÃ½kÃ¡ nehmotnÃ½ch vÃ½tvorÅ¯ vzniklÃ½ch z lidskÃ© iniciativy, kterÃ© mohou _mÃ­t ekonomickou hodnotu_ pro jednotlivce nebo firmy. 

OtÃ¡zky k prozkoumÃ¡nÃ­ zde jsou:
 * MÄ›la sbÃ­ranÃ¡ data ekonomickou hodnotu pro uÅ¾ivatele nebo firmu?
 * MÃ¡ zde **uÅ¾ivatel** duÅ¡evnÃ­ vlastnictvÃ­?
 * MÃ¡ zde **organizace** duÅ¡evnÃ­ vlastnictvÃ­?
 * Pokud tato prÃ¡va existujÃ­, jak je chrÃ¡nÃ­me?

#### 2.4 Ochrana dat

[Ochrana dat](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) nebo informaÄnÃ­ soukromÃ­ se tÃ½kÃ¡ zachovÃ¡nÃ­ soukromÃ­ uÅ¾ivatelÅ¯ a ochrany identity uÅ¾ivatelÅ¯ ve vztahu k osobnÄ› identifikovatelnÃ½m informacÃ­m. 

OtÃ¡zky k prozkoumÃ¡nÃ­ zde jsou:
 * Jsou osobnÃ­ data uÅ¾ivatelÅ¯ zabezpeÄena proti hackÅ¯m a ÃºnikÅ¯m?
 * Jsou data uÅ¾ivatelÅ¯ pÅ™Ã­stupnÃ¡ pouze autorizovanÃ½m uÅ¾ivatelÅ¯m a kontextÅ¯m?
 * Je anonymita uÅ¾ivatelÅ¯ zachovÃ¡na pÅ™i sdÃ­lenÃ­ nebo Å¡Ã­Å™enÃ­ dat?
 * MÅ¯Å¾e bÃ½t uÅ¾ivatel de-identifikovÃ¡n z anonymizovanÃ½ch datovÃ½ch sad?


#### 2.5 PrÃ¡vo bÃ½t zapomenut

[PrÃ¡vo bÃ½t zapomenut](https://en.wikipedia.org/wiki/Right_to_be_forgotten) nebo [prÃ¡vo na vymazÃ¡nÃ­](https://www.gdpreu.org/right-to-be-forgotten/) poskytuje uÅ¾ivatelÅ¯m dodateÄnou ochranu osobnÃ­ch dat. KonkrÃ©tnÄ› dÃ¡vÃ¡ uÅ¾ivatelÅ¯m prÃ¡vo poÅ¾adovat smazÃ¡nÃ­ nebo odstranÄ›nÃ­ osobnÃ­ch dat z internetovÃ½ch vyhledÃ¡vÃ¡nÃ­ a jinÃ½ch mÃ­st, _za specifickÃ½ch okolnostÃ­_ â€“ umoÅ¾ÅˆujÃ­cÃ­ jim novÃ½ zaÄÃ¡tek online bez toho, aby byly jejich minulÃ© akce proti nim pouÅ¾ity.

OtÃ¡zky k prozkoumÃ¡nÃ­ zde jsou:
 * UmoÅ¾Åˆuje systÃ©m subjektÅ¯m dat poÅ¾adovat vymazÃ¡nÃ­?
 * MÄ›l by odvolÃ¡nÃ­ souhlasu uÅ¾ivatele spustit automatickÃ© vymazÃ¡nÃ­?
 * Byla data sbÃ­rÃ¡na bez souhlasu nebo nezÃ¡konnÃ½mi prostÅ™edky?
 * Jsme v souladu s vlÃ¡dnÃ­mi regulacemi pro ochranu dat?


#### 2.6 PÅ™edsudky v datovÃ½ch sadÃ¡ch

PÅ™edsudky v datovÃ½ch sadÃ¡ch nebo [pÅ™edsudky pÅ™i sbÄ›ru](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) se tÃ½kajÃ­ vÃ½bÄ›ru _nereprezentativnÃ­ho_ podmnoÅ¾iny dat pro vÃ½voj algoritmÅ¯, coÅ¾ vytvÃ¡Å™Ã­ potenciÃ¡lnÃ­ nespravedlnost ve vÃ½sledcÃ­ch pro rÅ¯znÃ© skupiny. Typy pÅ™edsudkÅ¯ zahrnujÃ­ vÃ½bÄ›rovÃ© nebo vzorkovacÃ­ pÅ™edsudky, dobrovolnickÃ© pÅ™edsudky a pÅ™edsudky nÃ¡strojÅ¯. 

OtÃ¡zky k prozkoumÃ¡nÃ­ zde jsou:
 * Rekrutovali jsme reprezentativnÃ­ sadu subjektÅ¯ dat?
 * Testovali jsme naÅ¡i sbÃ­ranou nebo kurÃ¡torovanou datovou sadu na rÅ¯znÃ© pÅ™edsudky?
 * MÅ¯Å¾eme zmÃ­rnit nebo odstranit jakÃ©koli objevenÃ© pÅ™edsudky?

#### 2.7 Kvalita dat

[Kvalita dat](https://lakefs.io/data-quality-testing/) se zamÄ›Å™uje na validitu kurÃ¡torovanÃ© datovÃ© sady pouÅ¾itÃ© k vÃ½voji naÅ¡ich algoritmÅ¯, kontroluje, zda funkce a zÃ¡znamy splÅˆujÃ­ poÅ¾adavky na ÃºroveÅˆ pÅ™esnosti a konzistence potÅ™ebnÃ© pro nÃ¡Å¡ AI ÃºÄel.

OtÃ¡zky k prozkoumÃ¡nÃ­ zde jsou:
 * Zachytili jsme validnÃ­ _funkce
* Jsou informace zachyceny _pÅ™esnÄ›_ tak, aby odrÃ¡Å¾ely realitu?

#### 2.8 Spravedlnost algoritmÅ¯

[Spravedlnost algoritmÅ¯](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) zkoumÃ¡, zda nÃ¡vrh algoritmu systematicky nediskriminuje urÄitÃ© podskupiny subjektÅ¯, coÅ¾ mÅ¯Å¾e vÃ©st k [potenciÃ¡lnÃ­m Å¡kodÃ¡m](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) v _alokaci_ (kdy jsou zdroje odmÃ­tnuty nebo zadrÅ¾eny pro danou skupinu) a _kvalitÄ› sluÅ¾eb_ (kdy AI nenÃ­ tak pÅ™esnÃ¡ pro nÄ›kterÃ© podskupiny jako pro jinÃ©).

OtÃ¡zky k zamyÅ¡lenÃ­:
* Hodnotili jsme pÅ™esnost modelu pro rÅ¯znÃ© podskupiny a podmÃ­nky?
* Zkoumali jsme systÃ©m kvÅ¯li potenciÃ¡lnÃ­m Å¡kodÃ¡m (napÅ™. stereotypizaci)?
* MÅ¯Å¾eme upravit data nebo pÅ™eÅ¡kolit modely, abychom zmÃ­rnili identifikovanÃ© Å¡kody?

Prozkoumejte zdroje, jako jsou [kontrolnÃ­ seznamy spravedlnosti AI](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA), abyste se dozvÄ›dÄ›li vÃ­ce.

#### 2.9 ZkreslenÃ­ dat

[ZkreslenÃ­ dat](https://www.sciencedirect.com/topics/computer-science/misrepresentation) se zamÄ›Å™uje na otÃ¡zku, zda komunikujeme poznatky z poctivÄ› hlÃ¡Å¡enÃ½ch dat klamavÃ½m zpÅ¯sobem, abychom podpoÅ™ili poÅ¾adovanÃ½ narativ.

OtÃ¡zky k zamyÅ¡lenÃ­:
* HlÃ¡Å¡Ã­me neÃºplnÃ¡ nebo nepÅ™esnÃ¡ data?
* Vizualizujeme data zpÅ¯sobem, kterÃ½ vede k zavÃ¡dÄ›jÃ­cÃ­m zÃ¡vÄ›rÅ¯m?
* PouÅ¾Ã­vÃ¡me selektivnÃ­ statistickÃ© techniky k manipulaci s vÃ½sledky?
* ExistujÃ­ alternativnÃ­ vysvÄ›tlenÃ­, kterÃ¡ mohou nabÃ­dnout jinÃ½ zÃ¡vÄ›r?

#### 2.10 SvobodnÃ¡ volba

[Iluze svobodnÃ© volby](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) nastÃ¡vÃ¡, kdyÅ¾ systÃ©my "architektury volby" pouÅ¾Ã­vajÃ­ algoritmy rozhodovÃ¡nÃ­ k ovlivnÄ›nÃ­ lidÃ­, aby pÅ™ijali preferovanÃ½ vÃ½sledek, zatÃ­mco jim zdÃ¡nlivÄ› dÃ¡vajÃ­ moÅ¾nosti a kontrolu. Tyto [temnÃ© vzory](https://www.darkpatterns.org/) mohou zpÅ¯sobit sociÃ¡lnÃ­ a ekonomickÃ© Å¡kody uÅ¾ivatelÅ¯m. ProtoÅ¾e rozhodnutÃ­ uÅ¾ivatelÅ¯ ovlivÅˆujÃ­ profily chovÃ¡nÃ­, tyto akce mohou potenciÃ¡lnÄ› Å™Ã­dit budoucÃ­ volby, kterÃ© mohou zesÃ­lit nebo rozÅ¡Ã­Å™it dopad tÄ›chto Å¡kod.

OtÃ¡zky k zamyÅ¡lenÃ­:
* RozumÄ›l uÅ¾ivatel dÅ¯sledkÅ¯m svÃ©ho rozhodnutÃ­?
* Byl uÅ¾ivatel informovÃ¡n o (alternativnÃ­ch) moÅ¾nostech a jejich vÃ½hodÃ¡ch a nevÃ½hodÃ¡ch?
* MÅ¯Å¾e uÅ¾ivatel pozdÄ›ji zvrÃ¡tit automatizovanÃ© nebo ovlivnÄ›nÃ© rozhodnutÃ­?

### 3. PÅ™Ã­padovÃ© studie

Abychom uvedli tyto etickÃ© vÃ½zvy do kontextu reÃ¡lnÃ©ho svÄ›ta, je uÅ¾iteÄnÃ© podÃ­vat se na pÅ™Ã­padovÃ© studie, kterÃ© zdÅ¯razÅˆujÃ­ potenciÃ¡lnÃ­ Å¡kody a dÅ¯sledky pro jednotlivce a spoleÄnost, pokud jsou tyto etickÃ© problÃ©my pÅ™ehlÃ­Å¾eny.

Zde je nÄ›kolik pÅ™Ã­kladÅ¯:

| EtickÃ¡ vÃ½zva | PÅ™Ã­padovÃ¡ studie | 
|--- |--- |
| **InformovanÃ½ souhlas** | 1972 - [Studie syfilis v Tuskegee](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - AfroameriÄtÃ­ muÅ¾i, kteÅ™Ã­ se studie zÃºÄastnili, byli slibovÃ¡ni bezplatnou lÃ©kaÅ™skou pÃ©Äi, _ale byli podvedeni_ vÃ½zkumnÃ­ky, kteÅ™Ã­ jim neÅ™ekli o jejich diagnÃ³ze ani o dostupnosti lÃ©Äby. Mnoho subjektÅ¯ zemÅ™elo a jejich partneÅ™i nebo dÄ›ti byli ovlivnÄ›ni; studie trvala 40 let. | 
| **Ochrana dat** | 2007 - [Netflix data prize](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) poskytla vÃ½zkumnÃ­kÅ¯m _10M anonymizovanÃ½ch hodnocenÃ­ filmÅ¯ od 50K zÃ¡kaznÃ­kÅ¯_, aby pomohla zlepÅ¡it doporuÄovacÃ­ algoritmy. VÃ½zkumnÃ­ci vÅ¡ak byli schopni propojit anonymizovanÃ¡ data s osobnÄ› identifikovatelnÃ½mi daty v _externÃ­ch datovÃ½ch sadÃ¡ch_ (napÅ™. komentÃ¡Å™e na IMDb) - efektivnÄ› "de-anonymizovali" nÄ›kterÃ© pÅ™edplatitele Netflixu.|
| **SbÄ›r dat s pÅ™edsudky** | 2013 - MÄ›sto Boston [vyvinulo Street Bump](https://www.boston.gov/transportation/street-bump), aplikaci, kterÃ¡ umoÅ¾nila obÄanÅ¯m hlÃ¡sit vÃ½moly, coÅ¾ mÄ›stu poskytlo lepÅ¡Ã­ Ãºdaje o silnicÃ­ch pro identifikaci a opravu problÃ©mÅ¯. NicmÃ©nÄ› [lidÃ© z niÅ¾Å¡Ã­ch pÅ™Ã­jmovÃ½ch skupin mÄ›li menÅ¡Ã­ pÅ™Ã­stup k autÅ¯m a telefonÅ¯m](https://hbr.org/2013/04/the-hidden-biases-in-big-data), coÅ¾ jejich problÃ©my na silnicÃ­ch Äinilo v tÃ©to aplikaci neviditelnÃ½mi. VÃ½vojÃ¡Å™i spolupracovali s akademiky na _problÃ©mech spravedlivÃ©ho pÅ™Ã­stupu a digitÃ¡lnÃ­ch rozdÃ­lÅ¯_. |
| **Spravedlnost algoritmÅ¯** | 2018 - MIT [Gender Shades Study](http://gendershades.org/overview.html) hodnotila pÅ™esnost AI produktÅ¯ pro klasifikaci pohlavÃ­, odhalila mezery v pÅ™esnosti pro Å¾eny a osoby jinÃ© barvy pleti. [Apple Card z roku 2019](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) se zdÃ¡la nabÃ­zet mÃ©nÄ› ÃºvÄ›ru Å¾enÃ¡m neÅ¾ muÅ¾Å¯m. Oba pÅ™Ã­pady ilustrujÃ­ problÃ©my algoritmickÃ© zaujatosti vedoucÃ­ k socio-ekonomickÃ½m Å¡kodÃ¡m.|
| **ZkreslenÃ­ dat** | 2020 - [Ministerstvo zdravotnictvÃ­ stÃ¡tu Georgia zveÅ™ejnilo grafy COVID-19](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening), kterÃ© se zdÃ¡ly zavÃ¡dÄ›t obÄany ohlednÄ› trendÅ¯ potvrzenÃ½ch pÅ™Ã­padÅ¯ s nechronologickÃ½m uspoÅ™Ã¡dÃ¡nÃ­m na ose x. To ilustruje zkreslenÃ­ prostÅ™ednictvÃ­m vizualizaÄnÃ­ch trikÅ¯. |
| **Iluze svobodnÃ© volby** | 2020 - VzdÄ›lÃ¡vacÃ­ aplikace [ABCmouse zaplatila 10M USD za urovnÃ¡nÃ­ stÃ­Å¾nosti FTC](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/), kde byli rodiÄe uvÄ›znÄ›ni v platbÃ¡ch za pÅ™edplatnÃ©, kterÃ© nemohli zruÅ¡it. To ilustruje temnÃ© vzory v architektuÅ™e volby, kde byli uÅ¾ivatelÃ© ovlivnÄ›ni smÄ›rem k potenciÃ¡lnÄ› Å¡kodlivÃ½m rozhodnutÃ­m. |
| **Ochrana dat a prÃ¡va uÅ¾ivatelÅ¯** | 2021 - Facebook [Ãšnik dat](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) odhalil data 530M uÅ¾ivatelÅ¯, coÅ¾ vedlo k urovnÃ¡nÃ­ ve vÃ½Å¡i 5B USD s FTC. NicmÃ©nÄ› odmÃ­tl informovat uÅ¾ivatele o Ãºniku, ÄÃ­mÅ¾ poruÅ¡il prÃ¡va uÅ¾ivatelÅ¯ na transparentnost a pÅ™Ã­stup k datÅ¯m. |

Chcete prozkoumat vÃ­ce pÅ™Ã­padovÃ½ch studiÃ­? PodÃ­vejte se na tyto zdroje:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - etickÃ© dilemata napÅ™Ã­Ä rÅ¯znÃ½mi odvÄ›tvÃ­mi.
* [Kurz etiky datovÃ© vÄ›dy](https://www.coursera.org/learn/data-science-ethics#syllabus) - prozkoumÃ¡ny vÃ½znamnÃ© pÅ™Ã­padovÃ© studie.
* [Kde se vÄ›ci pokazily](https://deon.drivendata.org/examples/) - kontrolnÃ­ seznam Deon s pÅ™Ã­klady.

> ğŸš¨ Zamyslete se nad pÅ™Ã­padovÃ½mi studiemi, kterÃ© jste vidÄ›li - zaÅ¾ili jste nebo byli ovlivnÄ›ni podobnou etickou vÃ½zvou ve svÃ©m Å¾ivotÄ›? DokÃ¡Å¾ete si pÅ™edstavit alespoÅˆ jednu dalÅ¡Ã­ pÅ™Ã­padovou studii, kterÃ¡ ilustruje jednu z etickÃ½ch vÃ½zev, o kterÃ½ch jsme v tÃ©to sekci diskutovali?

## AplikovanÃ¡ etika

HovoÅ™ili jsme o etickÃ½ch konceptech, vÃ½zvÃ¡ch a pÅ™Ã­padovÃ½ch studiÃ­ch v kontextu reÃ¡lnÃ©ho svÄ›ta. Ale jak zaÄÃ­t _aplikovat_ etickÃ© principy a postupy ve svÃ½ch projektech? A jak _zprovoznit_ tyto postupy pro lepÅ¡Ã­ Å™Ã­zenÃ­? PojÄme prozkoumat nÄ›kterÃ¡ Å™eÅ¡enÃ­ z reÃ¡lnÃ©ho svÄ›ta:

### 1. ProfesnÃ­ kodexy

ProfesnÃ­ kodexy nabÃ­zejÃ­ jednu moÅ¾nost, jak organizace mohou "motivovat" Äleny k podpoÅ™e svÃ½ch etickÃ½ch principÅ¯ a poslÃ¡nÃ­. Kodexy jsou _morÃ¡lnÃ­mi pokyny_ pro profesnÃ­ chovÃ¡nÃ­, kterÃ© pomÃ¡hajÃ­ zamÄ›stnancÅ¯m nebo ÄlenÅ¯m Äinit rozhodnutÃ­ v souladu s principy jejich organizace. Jsou vÅ¡ak ÃºÄinnÃ© pouze tehdy, pokud ÄlenovÃ© dobrovolnÄ› dodrÅ¾ujÃ­; mnoho organizacÃ­ vÅ¡ak nabÃ­zÃ­ dalÅ¡Ã­ odmÄ›ny a sankce, aby motivovaly Äleny k dodrÅ¾ovÃ¡nÃ­.

PÅ™Ã­klady zahrnujÃ­:

* [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) EtickÃ½ kodex
* [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Kodex chovÃ¡nÃ­ (vytvoÅ™en 2013)
* [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (od roku 1993)

> ğŸš¨ Jste Älenem profesnÃ­ organizace pro inÅ¾enÃ½ry nebo datovÃ© vÄ›dce? Prozkoumejte jejich web, zda definujÃ­ profesnÃ­ kodex etiky. Co Å™Ã­kÃ¡ o jejich etickÃ½ch principech? Jak motivujÃ­ Äleny k dodrÅ¾ovÃ¡nÃ­ kodexu?

### 2. EtickÃ© kontrolnÃ­ seznamy

ZatÃ­mco profesnÃ­ kodexy definujÃ­ poÅ¾adovanÃ© _etickÃ© chovÃ¡nÃ­_ od praktikujÃ­cÃ­ch, majÃ­ [znÃ¡mÃ© omezenÃ­](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) pÅ™i vynucovÃ¡nÃ­, zejmÃ©na u rozsÃ¡hlÃ½ch projektÅ¯. MÃ­sto toho mnoho odbornÃ­kÅ¯ na datovou vÄ›du [prosazuje kontrolnÃ­ seznamy](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), kterÃ© mohou **propojit principy s praxÃ­** deterministickÃ½m a akceschopnÃ½m zpÅ¯sobem.

KontrolnÃ­ seznamy pÅ™evÃ¡dÄ›jÃ­ otÃ¡zky na Ãºkoly "ano/ne", kterÃ© lze zprovoznit, coÅ¾ umoÅ¾Åˆuje jejich sledovÃ¡nÃ­ jako souÄÃ¡st standardnÃ­ch pracovnÃ­ch postupÅ¯ pÅ™i vydÃ¡vÃ¡nÃ­ produktÅ¯.

PÅ™Ã­klady zahrnujÃ­:
* [Deon](https://deon.drivendata.org/) - obecnÃ½ kontrolnÃ­ seznam etiky dat vytvoÅ™enÃ½ na zÃ¡kladÄ› [doporuÄenÃ­ z prÅ¯myslu](https://deon.drivendata.org/#checklist-citations) s nÃ¡strojem pÅ™Ã­kazovÃ©ho Å™Ã¡dku pro snadnou integraci.
* [KontrolnÃ­ seznam auditu ochrany soukromÃ­](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - poskytuje obecnÃ© pokyny pro naklÃ¡dÃ¡nÃ­ s informacemi z prÃ¡vnÃ­ho a sociÃ¡lnÃ­ho hlediska.
* [KontrolnÃ­ seznam spravedlnosti AI](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - vytvoÅ™enÃ½ odbornÃ­ky na AI na podporu pÅ™ijetÃ­ a integrace kontrol spravedlnosti do vÃ½vojovÃ½ch cyklÅ¯ AI.
* [22 otÃ¡zek pro etiku v datech a AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - otevÅ™enÄ›jÅ¡Ã­ rÃ¡mec, strukturovanÃ½ pro poÄÃ¡teÄnÃ­ zkoumÃ¡nÃ­ etickÃ½ch problÃ©mÅ¯ v designu, implementaci a organizaÄnÃ­ch kontextech.

### 3. EtickÃ© regulace

Etika je o definovÃ¡nÃ­ sdÃ­lenÃ½ch hodnot a dÄ›lÃ¡nÃ­ sprÃ¡vnÃ© vÄ›ci _dobrovolnÄ›_. **DodrÅ¾ovÃ¡nÃ­ pÅ™edpisÅ¯** je o _dodrÅ¾ovÃ¡nÃ­ zÃ¡kona_, pokud je definovÃ¡n. **Å˜Ã­zenÃ­** obecnÄ› pokrÃ½vÃ¡ vÅ¡echny zpÅ¯soby, jakÃ½mi organizace fungujÃ­, aby prosazovaly etickÃ© principy a dodrÅ¾ovaly stanovenÃ© zÃ¡kony.

Dnes Å™Ã­zenÃ­ probÃ­hÃ¡ ve dvou formÃ¡ch v rÃ¡mci organizacÃ­. Za prvÃ©, jde o definovÃ¡nÃ­ **etickÃ½ch principÅ¯ AI** a zavedenÃ­ postupÅ¯ pro zprovoznÄ›nÃ­ pÅ™ijetÃ­ napÅ™Ã­Ä vÅ¡emi projekty souvisejÃ­cÃ­mi s AI v organizaci. Za druhÃ©, jde o dodrÅ¾ovÃ¡nÃ­ vÅ¡ech vlÃ¡dou naÅ™Ã­zenÃ½ch **regulacÃ­ ochrany dat** pro regiony, ve kterÃ½ch organizace pÅ¯sobÃ­.

PÅ™Ã­klady regulacÃ­ ochrany dat a soukromÃ­:

* `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - reguluje _sbÄ›r, pouÅ¾itÃ­ a zveÅ™ejnÄ›nÃ­_ osobnÃ­ch informacÃ­ federÃ¡lnÃ­ vlÃ¡dou.
* `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - chrÃ¡nÃ­ osobnÃ­ zdravotnÃ­ Ãºdaje.
* `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - chrÃ¡nÃ­ soukromÃ­ dat dÄ›tÃ­ mladÅ¡Ã­ch 13 let.
* `2018`, [General Data Protection Regulation (GDPR)](https://gdpr-info.eu/) - poskytuje prÃ¡va uÅ¾ivatelÅ¯, ochranu dat a soukromÃ­.
* `2018`, [California Consumer Privacy Act (CCPA)](https://www.oag.ca.gov/privacy/ccpa) - dÃ¡vÃ¡ spotÅ™ebitelÅ¯m vÃ­ce _prÃ¡v_ nad jejich (osobnÃ­mi) daty.
* `2021`, ÄŒÃ­na [ZÃ¡kon o ochranÄ› osobnÃ­ch ÃºdajÅ¯](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) prÃ¡vÄ› schvÃ¡lila, ÄÃ­mÅ¾ vytvoÅ™ila jednu z nejsilnÄ›jÅ¡Ã­ch regulacÃ­ online ochrany dat na svÄ›tÄ›.

> ğŸš¨ EvropskÃ¡ unie definovala GDPR (General Data Protection Regulation), kterÃ½ zÅ¯stÃ¡vÃ¡ jednou z nejvlivnÄ›jÅ¡Ã­ch regulacÃ­ ochrany dat dnes. VÄ›dÄ›li jste, Å¾e takÃ© definuje [8 prÃ¡v uÅ¾ivatelÅ¯](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) na ochranu digitÃ¡lnÃ­ho soukromÃ­ a osobnÃ­ch dat obÄanÅ¯? ZjistÄ›te, co to jsou a proÄ jsou dÅ¯leÅ¾itÃ¡.

### 4. EtickÃ¡ kultura

VÅ¡imnÄ›te si, Å¾e stÃ¡le existuje nehmotnÃ¡ mezera mezi _dodrÅ¾ovÃ¡nÃ­m pÅ™edpisÅ¯_ (dÄ›lÃ¡nÃ­ dostateÄnÃ©ho pro splnÄ›nÃ­ "litery zÃ¡kona") a Å™eÅ¡enÃ­m [systÃ©movÃ½ch problÃ©mÅ¯](https://www.coursera.org/learn/data-science-ethics/home/week/4) (jako je zkostnatÄ›lost, informaÄnÃ­ asymetrie a distribuÄnÃ­ nespravedlnost), kterÃ© mohou urychlit zneuÅ¾itÃ­ AI.

To druhÃ© vyÅ¾aduje [spoluprÃ¡ci na definovÃ¡nÃ­ etickÃ½ch kultur](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f), kterÃ© budujÃ­ emocionÃ¡lnÃ­ spojenÃ­ a konzistentnÃ­ sdÃ­lenÃ© hodnoty _napÅ™Ã­Ä organizacemi_ v prÅ¯myslu. To vyÅ¾aduje vÃ­ce [formalizovanÃ½ch kultur etiky dat](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) v organizacÃ­ch - umoÅ¾ÅˆujÃ­cÃ­ _komukoli_ [zatÃ¡hnout za Andon Å¡ÅˆÅ¯ru](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (aby vÄas upozornil na etickÃ© problÃ©my) a uÄinit _etickÃ© hodnocenÃ­_ (napÅ™. pÅ™i nÃ¡boru) klÃ­ÄovÃ½m kritÃ©riem pro formovÃ¡nÃ­ tÃ½mÅ¯ v projektech AI.

---
## [KvÃ­z po pÅ™ednÃ¡Å¡ce](https://ff-quizzes.netlify.app/en/ds/quiz/3) ğŸ¯
## PÅ™ehled a samostudium

Kurzy a knihy pomÃ¡hajÃ­ pochopit zÃ¡kladnÃ­ etickÃ© koncepty a vÃ½zvy, zatÃ­mco pÅ™Ã­padovÃ© studie a nÃ¡stroje pomÃ¡hajÃ­ s aplikovanÃ½mi etickÃ½mi postupy v kontextu reÃ¡lnÃ©ho svÄ›ta. Zde je nÄ›kolik zdrojÅ¯, kde zaÄÃ­t.
* [Machine Learning For Beginners](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - lekce o spravedlnosti od Microsoftu.
* [Principy odpovÄ›dnÃ© AI](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - bezplatnÃ¡ vzdÄ›lÃ¡vacÃ­ cesta od Microsoft Learn.
* [Etika a datovÃ¡ vÄ›da](https://resources.oreilly.com/examples/0636920203964) - e-kniha od O'Reilly (M. Loukides, H. Mason a kol.)
* [Etika datovÃ© vÄ›dy](https://www.coursera.org/learn/data-science-ethics#syllabus) - online kurz od University of Michigan.
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - pÅ™Ã­padovÃ© studie od University of Texas.

# ZadÃ¡nÃ­

[Vypracujte pÅ™Ã­padovou studii o etice dat](assignment.md)

---

**UpozornÄ›nÃ­**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ sluÅ¾by pro automatickÃ½ pÅ™eklad [Co-op Translator](https://github.com/Azure/co-op-translator). I kdyÅ¾ se snaÅ¾Ã­me o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatickÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho pÅ¯vodnÃ­m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za zÃ¡vaznÃ½ zdroj. Pro dÅ¯leÅ¾itÃ© informace doporuÄujeme profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. NeodpovÃ­dÃ¡me za Å¾Ã¡dnÃ¡ nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© interpretace vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.