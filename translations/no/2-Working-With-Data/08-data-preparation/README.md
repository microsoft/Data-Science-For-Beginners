<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3ade580a06b5f04d57cc83a768a8fb77",
  "translation_date": "2025-08-26T20:57:25+00:00",
  "source_file": "2-Working-With-Data/08-data-preparation/README.md",
  "language_code": "no"
}
-->
# Arbeide med data: Datapreparering

|![ Sketchnote av [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/08-DataPreparation.png)|
|:---:|
|Datapreparering - _Sketchnote av [@nitya](https://twitter.com/nitya)_ |

## [Quiz f칮r forelesning](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/14)

Avhengig av kilden kan r친data inneholde noen inkonsistenser som skaper utfordringer i analyse og modellering. Med andre ord kan disse dataene kategoriseres som "skitne" og m친 rengj칮res. Denne leksjonen fokuserer p친 teknikker for 친 rense og transformere data for 친 h친ndtere utfordringer som manglende, un칮yaktige eller ufullstendige data. Temaene som dekkes i denne leksjonen vil bruke Python og Pandas-biblioteket og vil bli [demonstrert i notatboken](notebook.ipynb) i denne katalogen.

## Viktigheten av 친 rense data

- **Enkel bruk og gjenbruk**: N친r data er riktig organisert og normalisert, er det lettere 친 s칮ke, bruke og dele med andre.

- **Konsistens**: Datascience krever ofte arbeid med mer enn ett datasett, der datasett fra ulike kilder m친 kobles sammen. 칀 sikre at hvert enkelt datasett har felles standardisering vil sikre at dataene fortsatt er nyttige n친r de kombineres til ett datasett.

- **Modelln칮yaktighet**: Rensede data forbedrer n칮yaktigheten til modellene som er avhengige av dem.

## Vanlige m친l og strategier for datarensing

- **Utforske et datasett**: Datautforskning, som dekkes i en [senere leksjon](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/4-Data-Science-Lifecycle/15-analyzing), kan hjelpe deg med 친 oppdage data som m친 renses. Visuell observasjon av verdier i et datasett kan sette forventninger til hvordan resten av det vil se ut, eller gi en id칠 om problemer som kan l칮ses. Utforskning kan inneb칝re grunnleggende sp칮rringer, visualiseringer og pr칮vetaking.

- **Formatering**: Avhengig av kilden kan data ha inkonsistenser i hvordan de presenteres. Dette kan skape problemer med 친 s칮ke etter og representere verdien, der den er synlig i datasettet, men ikke riktig representert i visualiseringer eller sp칮rringsresultater. Vanlige formateringsproblemer involverer 친 l칮se mellomrom, datoer og datatyper. 칀 l칮se formateringsproblemer er vanligvis opp til de som bruker dataene. For eksempel kan standarder for hvordan datoer og tall presenteres variere fra land til land.

- **Duplikasjoner**: Data som har mer enn 칠n forekomst kan gi un칮yaktige resultater og b칮r vanligvis fjernes. Dette kan v칝re en vanlig forekomst n친r to eller flere datasett kobles sammen. Imidlertid finnes det tilfeller der duplisering i sammensl친tte datasett inneholder deler som kan gi tilleggsinformasjon og kanskje m친 bevares.

- **Manglende data**: Manglende data kan f칮re til un칮yaktigheter samt svake eller skjeve resultater. Noen ganger kan dette l칮ses ved 친 "laste inn" dataene p친 nytt, fylle inn de manglende verdiene med beregninger og kode som Python, eller rett og slett fjerne verdien og tilh칮rende data. Det finnes mange grunner til hvorfor data kan mangle, og handlingene som tas for 친 l칮se disse manglende verdiene kan avhenge av hvordan og hvorfor de forsvant.

## Utforske informasjon i DataFrame
> **L칝ringsm친l:** Ved slutten av denne delen b칮r du v칝re komfortabel med 친 finne generell informasjon om data lagret i pandas DataFrames.

N친r du har lastet inn dataene dine i pandas, vil de mest sannsynlig v칝re i en DataFrame (se den forrige [leksjonen](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/2-Working-With-Data/07-python#dataframe) for en detaljert oversikt). Men hvis datasettet i din DataFrame har 60 000 rader og 400 kolonner, hvordan begynner du 친 f친 en f칮lelse av hva du jobber med? Heldigvis gir [pandas](https://pandas.pydata.org/) noen praktiske verkt칮y for raskt 친 se overordnet informasjon om en DataFrame i tillegg til de f칮rste og siste radene.

For 친 utforske denne funksjonaliteten, vil vi importere Python scikit-learn-biblioteket og bruke et ikonisk datasett: **Iris-datasettet**.

```python
import pandas as pd
from sklearn.datasets import load_iris

iris = load_iris()
iris_df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])
```
|                                        |sepal lengde (cm)|sepal bredde (cm)|petal lengde (cm)|petal bredde (cm)|
|----------------------------------------|-----------------|-----------------|-----------------|-----------------|
|0                                       |5.1              |3.5             |1.4              |0.2             |
|1                                       |4.9              |3.0             |1.4              |0.2             |
|2                                       |4.7              |3.2             |1.3              |0.2             |
|3                                       |4.6              |3.1             |1.5              |0.2             |
|4                                       |5.0              |3.6             |1.4              |0.2             |

- **DataFrame.info**: For 친 begynne, brukes `info()`-metoden til 친 skrive ut en oppsummering av innholdet i en `DataFrame`. La oss se p친 dette datasettet for 친 se hva vi har:
```python
iris_df.info()
```
```
RangeIndex: 150 entries, 0 to 149
Data columns (total 4 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   sepal length (cm)  150 non-null    float64
 1   sepal width (cm)   150 non-null    float64
 2   petal length (cm)  150 non-null    float64
 3   petal width (cm)   150 non-null    float64
dtypes: float64(4)
memory usage: 4.8 KB
```
Fra dette vet vi at *Iris*-datasettet har 150 oppf칮ringer i fire kolonner uten nullverdier. Alle dataene er lagret som 64-biters flyttall.

- **DataFrame.head()**: Deretter, for 친 sjekke det faktiske innholdet i `DataFrame`, bruker vi `head()`-metoden. La oss se hva de f칮rste radene i v친r `iris_df` ser ut som:
```python
iris_df.head()
```
```
   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
0                5.1               3.5                1.4               0.2
1                4.9               3.0                1.4               0.2
2                4.7               3.2                1.3               0.2
3                4.6               3.1                1.5               0.2
4                5.0               3.6                1.4               0.2
```
- **DataFrame.tail()**: For 친 sjekke de siste radene i `DataFrame`, bruker vi `tail()`-metoden:
```python
iris_df.tail()
```
```
     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
145                6.7               3.0                5.2               2.3
146                6.3               2.5                5.0               1.9
147                6.5               3.0                5.2               2.0
148                6.2               3.4                5.4               2.3
149                5.9               3.0                5.1               1.8
```
> **Oppsummering:** Bare ved 친 se p친 metadataene om informasjonen i en DataFrame eller de f칮rste og siste verdiene, kan du f친 en umiddelbar id칠 om st칮rrelsen, formen og innholdet i dataene du jobber med.

## H친ndtering av manglende data
> **L칝ringsm친l:** Ved slutten av denne delen b칮r du vite hvordan du erstatter eller fjerner nullverdier fra DataFrames.

Ofte har datasettene du 칮nsker 친 bruke (eller m친 bruke) manglende verdier. Hvordan manglende data h친ndteres inneb칝rer subtile avveininger som kan p친virke din endelige analyse og virkelige resultater.

Pandas h친ndterer manglende verdier p친 to m친ter. Den f칮rste har du sett f칮r i tidligere seksjoner: `NaN`, eller Not a Number. Dette er faktisk en spesiell verdi som er en del av IEEE-flyttallsstandarden og brukes kun til 친 indikere manglende flyttallsverdier.

For manglende verdier som ikke er flyttall, bruker pandas Python-objektet `None`. Selv om det kan virke forvirrende at du vil m칮te to forskjellige typer verdier som i hovedsak sier det samme, er det gode programmatiske grunner for dette designvalget, og i praksis gir denne tiln칝rmingen pandas en god balanse for de aller fleste tilfeller. Likevel har b친de `None` og `NaN` begrensninger som du m친 v칝re oppmerksom p친 med hensyn til hvordan de kan brukes.

Les mer om `NaN` og `None` fra [notatboken](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/4-Data-Science-Lifecycle/15-analyzing/notebook.ipynb)!

- **Oppdage nullverdier**: I `pandas` er `isnull()` og `notnull()` metodene dine prim칝re verkt칮y for 친 oppdage nullverdier. Begge returnerer boolske masker over dataene dine. Vi vil bruke `numpy` for `NaN`-verdier:
```python
import numpy as np

example1 = pd.Series([0, np.nan, '', None])
example1.isnull()
```
```
0    False
1     True
2    False
3     True
dtype: bool
```
Se n칮ye p친 utdataene. Er noe av det overraskende? Selv om `0` er en aritmetisk null, er det likevel et fullverdig heltall, og pandas behandler det som s친dan. `''` er litt mer subtil. Selv om vi brukte det i seksjon 1 for 친 representere en tom strengverdi, er det likevel et strengobjekt og ikke en representasjon av null i pandas.

N친, la oss snu dette rundt og bruke disse metodene p친 en m친te som ligner mer p친 hvordan du vil bruke dem i praksis. Du kan bruke boolske masker direkte som en ``Series`` eller ``DataFrame``-indeks, noe som kan v칝re nyttig n친r du pr칮ver 친 jobbe med isolerte manglende (eller tilstedev칝rende) verdier.

> **Oppsummering**: B친de `isnull()` og `notnull()`-metodene gir lignende resultater n친r du bruker dem i `DataFrame`s: de viser resultatene og indeksen til disse resultatene, noe som vil hjelpe deg enormt n친r du jobber med dataene dine.

- **Fjerne nullverdier**: Utover 친 identifisere manglende verdier, gir pandas en praktisk m친te 친 fjerne nullverdier fra `Series` og `DataFrame`s. (Spesielt for store datasett er det ofte mer tilr친delig 친 bare fjerne manglende [NA] verdier fra analysen din enn 친 h친ndtere dem p친 andre m친ter.) For 친 se dette i praksis, la oss g친 tilbake til `example1`:
```python
example1 = example1.dropna()
example1
```
```
0    0
2     
dtype: object
```
Merk at dette b칮r se ut som utdataene dine fra `example3[example3.notnull()]`. Forskjellen her er at, i stedet for bare 친 indeksere p친 de maskerte verdiene, har `dropna` fjernet de manglende verdiene fra `Series` `example1`.

Siden `DataFrame`s har to dimensjoner, gir de flere alternativer for 친 fjerne data.

```python
example2 = pd.DataFrame([[1,      np.nan, 7], 
                         [2,      5,      8], 
                         [np.nan, 6,      9]])
example2
```
|      | 0 | 1 | 2 |
|------|---|---|---|
|0     |1.0|NaN|7  |
|1     |2.0|5.0|8  |
|2     |NaN|6.0|9  |

(La du merke til at pandas oppgraderte to av kolonnene til flyttall for 친 im칮tekomme `NaN`-ene?)

Du kan ikke fjerne en enkelt verdi fra en `DataFrame`, s친 du m친 fjerne hele rader eller kolonner. Avhengig av hva du gj칮r, kan du 칮nske 친 gj칮re det ene eller det andre, og pandas gir deg alternativer for begge. Siden kolonner vanligvis representerer variabler og rader representerer observasjoner i datavitenskap, er det mer sannsynlig at du fjerner rader med data; standardinnstillingen for `dropna()` er 친 fjerne alle rader som inneholder nullverdier:

```python
example2.dropna()
```
```
	0	1	2
1	2.0	5.0	8
```
Hvis n칮dvendig, kan du fjerne NA-verdier fra kolonner. Bruk `axis=1` for 친 gj칮re dette:
```python
example2.dropna(axis='columns')
```
```
	2
0	7
1	8
2	9
```
Merk at dette kan fjerne mye data som du kanskje vil beholde, spesielt i mindre datasett. Hva om du bare vil fjerne rader eller kolonner som inneholder flere eller til og med bare alle nullverdier? Du spesifiserer disse innstillingene i `dropna` med `how` og `thresh`-parametrene.

Som standard er `how='any'` (hvis du vil sjekke selv eller se hvilke andre parametere metoden har, kj칮r `example4.dropna?` i en kodecelle). Du kan alternativt spesifisere `how='all'` for 친 bare fjerne rader eller kolonner som inneholder alle nullverdier. La oss utvide v친rt eksempel `DataFrame` for 친 se dette i praksis.

```python
example2[3] = np.nan
example2
```
|      |0  |1  |2  |3  |
|------|---|---|---|---|
|0     |1.0|NaN|7  |NaN|
|1     |2.0|5.0|8  |NaN|
|2     |NaN|6.0|9  |NaN|

`thresh`-parameteren gir deg mer detaljert kontroll: du angir antall *ikke-null* verdier som en rad eller kolonne m친 ha for 친 beholdes:
```python
example2.dropna(axis='rows', thresh=3)
```
```
	0	1	2	3
1	2.0	5.0	8	NaN
```
Her har den f칮rste og siste raden blitt fjernet, fordi de inneholder bare to ikke-null verdier.

- **Fylle nullverdier**: Avhengig av datasettet ditt, kan det noen ganger v칝re mer fornuftig 친 fylle nullverdier med gyldige verdier i stedet for 친 fjerne dem. Du kan bruke `isnull` til 친 gj칮re dette direkte, men det kan v칝re arbeidskrevende, spesielt hvis du har mange verdier 친 fylle. Siden dette er en s친 vanlig oppgave i datavitenskap, gir pandas `fillna`, som returnerer en kopi av `Series` eller `DataFrame` med de manglende verdiene erstattet med en verdi du velger. La oss lage et annet eksempel `Series` for 친 se hvordan dette fungerer i praksis.
```python
example3 = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))
example3
```
```
a    1.0
b    NaN
c    2.0
d    NaN
e    3.0
dtype: float64
```
Du kan fylle alle nullverdiene med en enkelt verdi, som `0`:
```python
example3.fillna(0)
```
```
a    1.0
b    0.0
c    2.0
d    0.0
e    3.0
dtype: float64
```
Du kan **fremoverfylle** nullverdier, som vil bruke den siste gyldige verdien til 친 fylle en null:
```python
example3.fillna(method='ffill')
```
```
a    1.0
b    1.0
c    2.0
d    2.0
e    3.0
dtype: float64
```
Du kan ogs친 **bakoverfylle** for 친 propagere den neste gyldige verdien bakover for 친 fylle en null:
```python
example3.fillna(method='bfill')
```
```
a    1.0
b    2.0
c    2.0
d    3.0
e    3.0
dtype: float64
```
Som du kanskje gjetter, fungerer dette p친 samme m친te med `DataFrame`s, men du kan ogs친 spesifisere en `axis` langs hvilken du vil fylle nullverdier. Ved 친 bruke det tidligere brukte `example2` igjen:
```python
example2.fillna(method='ffill', axis=1)
```
```
	0	1	2	3
0	1.0	1.0	7.0	7.0
1	2.0	5.0	8.0	8.0
2	NaN	6.0	9.0	9.0
```
Merk at n친r en tidligere verdi ikke er tilgjengelig for fremoverfylling, forblir nullverdien.
> **Hovedpoeng:** Det finnes flere m친ter 친 h친ndtere manglende verdier i datasettene dine. Den spesifikke strategien du velger (fjerne dem, erstatte dem, eller hvordan du erstatter dem) b칮r styres av egenskapene til dataene. Du vil utvikle en bedre forst친else for hvordan du h친ndterer manglende verdier jo mer du jobber med og interagerer med datasett.

## Fjerne dupliserte data

> **L칝ringsm친l:** Etter denne delen b칮r du v칝re komfortabel med 친 identifisere og fjerne dupliserte verdier fra DataFrames.

I tillegg til manglende data vil du ofte st칮te p친 dupliserte data i virkelige datasett. Heldigvis gir `pandas` en enkel m친te 친 oppdage og fjerne dupliserte oppf칮ringer.

- **Identifisere duplikater: `duplicated`**: Du kan enkelt finne dupliserte verdier ved 친 bruke `duplicated`-metoden i pandas, som returnerer en boolsk maske som indikerer om en oppf칮ring i en `DataFrame` er en duplikat av en tidligere. La oss lage et annet eksempel p친 en `DataFrame` for 친 se dette i praksis.
```python
example4 = pd.DataFrame({'letters': ['A','B'] * 2 + ['B'],
                         'numbers': [1, 2, 1, 3, 3]})
example4
```
|      |letters|numbers|
|------|-------|-------|
|0     |A      |1      |
|1     |B      |2      |
|2     |A      |1      |
|3     |B      |3      |
|4     |B      |3      |

```python
example4.duplicated()
```
```
0    False
1    False
2     True
3    False
4     True
dtype: bool
```
- **Fjerne duplikater: `drop_duplicates`:** returnerer enkelt en kopi av dataene der alle `duplicated`-verdier er `False`:
```python
example4.drop_duplicates()
```
```
	letters	numbers
0	A	1
1	B	2
3	B	3
```
B친de `duplicated` og `drop_duplicates` vurderer som standard alle kolonner, men du kan spesifisere at de kun skal unders칮ke et delsett av kolonner i din `DataFrame`:
```python
example4.drop_duplicates(['letters'])
```
```
letters	numbers
0	A	1
1	B	2
```

> **Hovedpoeng:** 칀 fjerne dupliserte data er en essensiell del av nesten alle dataanalyseprosjekter. Dupliserte data kan endre resultatene av analysene dine og gi deg un칮yaktige resultater!


## 游 Utfordring

Alt materiale som er diskutert er tilgjengelig som en [Jupyter Notebook](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/2-Working-With-Data/08-data-preparation/notebook.ipynb). I tillegg finnes det 칮velser etter hver seksjon, pr칮v dem!

## [Quiz etter forelesning](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/15)



## Gjennomgang & Selvstudie

Det finnes mange m친ter 친 oppdage og tiln칝rme seg forberedelse av data for analyse og modellering, og rengj칮ring av data er et viktig steg som krever praktisk erfaring. Pr칮v disse utfordringene fra Kaggle for 친 utforske teknikker som ikke ble dekket i denne leksjonen.

- [Data Cleaning Challenge: Parsing Dates](https://www.kaggle.com/rtatman/data-cleaning-challenge-parsing-dates/)

- [Data Cleaning Challenge: Scale and Normalize Data](https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data)


## Oppgave

[Evaluering av data fra et skjema](assignment.md)

---

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi tilstreber n칮yaktighet, vennligst v칝r oppmerksom p친 at automatiserte oversettelser kan inneholde feil eller un칮yaktigheter. Det originale dokumentet p친 sitt opprinnelige spr친k b칮r betraktes som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst친elser eller feiltolkninger som oppst친r ved bruk av denne oversettelsen.