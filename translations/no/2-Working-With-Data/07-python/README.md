<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7bfec050f4717dcc2dfd028aca9d21f3",
  "translation_date": "2025-09-06T15:47:35+00:00",
  "source_file": "2-Working-With-Data/07-python/README.md",
  "language_code": "no"
}
-->
# Arbeide med Data: Python og Pandas-biblioteket

| ![ Sketchnote av [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/07-WorkWithPython.png) |
| :-------------------------------------------------------------------------------------------------------: |
|                 Arbeide med Python - _Sketchnote av [@nitya](https://twitter.com/nitya)_                 |

[![Introduksjonsvideo](../../../../translated_images/no/video-ds-python.245247dc811db8e4d5ac420246de8a118c63fd28f6a56578d08b630ae549f260.png)](https://youtu.be/dZjWOGbsN4Y)

Mens databaser tilbyr sv칝rt effektive m친ter 친 lagre data og hente dem ved hjelp av sp칮rringsspr친k, er den mest fleksible m친ten 친 behandle data p친 친 skrive ditt eget program for 친 manipulere data. I mange tilfeller vil en databasesp칮rring v칝re en mer effektiv l칮sning. Men i noen tilfeller, n친r mer kompleks databehandling er n칮dvendig, kan det ikke enkelt gj칮res med SQL. 
Databehandling kan programmeres i hvilket som helst programmeringsspr친k, men det finnes visse spr친k som er mer tilpasset arbeid med data. Dataforskere foretrekker vanligvis ett av f칮lgende spr친k:

* **[Python](https://www.python.org/)**, et allsidig programmeringsspr친k, som ofte anses som et av de beste alternativene for nybegynnere p친 grunn av sin enkelhet. Python har mange tilleggslibrier som kan hjelpe deg med 친 l칮se praktiske problemer, som 친 hente data fra en ZIP-fil eller konvertere et bilde til gr친toner. I tillegg til dataforskning brukes Python ogs친 ofte til webutvikling. 
* **[R](https://www.r-project.org/)** er en tradisjonell verkt칮ykasse utviklet med statistisk databehandling i tankene. Det inneholder ogs친 et stort bibliotek (CRAN), som gj칮r det til et godt valg for databehandling. R er imidlertid ikke et allsidig programmeringsspr친k og brukes sjelden utenfor dataforskningsomr친det.
* **[Julia](https://julialang.org/)** er et annet spr친k utviklet spesielt for dataforskning. Det er ment 친 gi bedre ytelse enn Python, noe som gj칮r det til et flott verkt칮y for vitenskapelige eksperimenter.

I denne leksjonen vil vi fokusere p친 친 bruke Python for enkel databehandling. Vi antar grunnleggende kjennskap til spr친ket. Hvis du 칮nsker en dypere innf칮ring i Python, kan du se p친 en av f칮lgende ressurser:

* [L칝r Python p친 en morsom m친te med Turtle Graphics og Fractals](https://github.com/shwars/pycourse) - GitHub-basert introduksjonskurs i Python-programmering
* [Ta dine f칮rste steg med Python](https://docs.microsoft.com/en-us/learn/paths/python-first-steps/?WT.mc_id=academic-77958-bethanycheum) L칝ringssti p친 [Microsoft Learn](http://learn.microsoft.com/?WT.mc_id=academic-77958-bethanycheum)

Data kan komme i mange former. I denne leksjonen vil vi se p친 tre former for data - **tabul칝re data**, **tekst** og **bilder**.

Vi vil fokusere p친 noen f친 eksempler p친 databehandling, i stedet for 친 gi deg en fullstendig oversikt over alle relaterte biblioteker. Dette vil gi deg en id칠 om hva som er mulig, og gi deg forst친else for hvor du kan finne l칮sninger p친 dine problemer n친r du trenger dem.

> **Det mest nyttige r친det**. N친r du trenger 친 utf칮re en operasjon p친 data som du ikke vet hvordan du skal gj칮re, pr칮v 친 s칮ke etter det p친 internett. [Stackoverflow](https://stackoverflow.com/) inneholder ofte mange nyttige kodeeksempler i Python for mange typiske oppgaver.



## [Quiz f칮r leksjonen](https://ff-quizzes.netlify.app/en/ds/quiz/12)

## Tabul칝re data og Dataframes

Du har allerede m칮tt tabul칝re data da vi snakket om relasjonsdatabaser. N친r du har mye data, og det er lagret i mange forskjellige koblede tabeller, gir det definitivt mening 친 bruke SQL for 친 arbeide med det. Men det finnes mange tilfeller der vi har en tabell med data, og vi trenger 친 f친 en **forst친else** eller **innsikt** om disse dataene, som fordeling, korrelasjon mellom verdier, osv. Innen dataforskning er det mange tilfeller der vi m친 utf칮re noen transformasjoner av de opprinnelige dataene, etterfulgt av visualisering. Begge disse trinnene kan enkelt gj칮res med Python.

Det finnes to mest nyttige biblioteker i Python som kan hjelpe deg med 친 h친ndtere tabul칝re data:
* **[Pandas](https://pandas.pydata.org/)** lar deg manipulere s친kalte **Dataframes**, som er analoge med relasjonstabeller. Du kan ha navngitte kolonner og utf칮re forskjellige operasjoner p친 rader, kolonner og dataframes generelt. 
* **[Numpy](https://numpy.org/)** er et bibliotek for 친 arbeide med **tensorer**, dvs. flerdimensjonale **arrays**. Arrays har verdier av samme underliggende type, og det er enklere enn dataframe, men det tilbyr flere matematiske operasjoner og skaper mindre overhead.

Det finnes ogs친 et par andre biblioteker du b칮r kjenne til:
* **[Matplotlib](https://matplotlib.org/)** er et bibliotek som brukes til datavisualisering og graftegning
* **[SciPy](https://www.scipy.org/)** er et bibliotek med noen ekstra vitenskapelige funksjoner. Vi har allerede kommet over dette biblioteket da vi snakket om sannsynlighet og statistikk

Her er et stykke kode som du vanligvis vil bruke for 친 importere disse bibliotekene i begynnelsen av ditt Python-program:
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import ... # you need to specify exact sub-packages that you need
``` 

Pandas er sentrert rundt noen f친 grunnleggende konsepter.

### Series 

**Series** er en sekvens av verdier, lik en liste eller numpy-array. Den st칮rste forskjellen er at series ogs친 har en **indeks**, og n친r vi opererer p친 series (f.eks. legger dem sammen), tas indeksen med i betraktning. Indeksen kan v칝re s친 enkel som et heltall radnummer (det er standardindeksen n친r man oppretter en series fra en liste eller array), eller den kan ha en kompleks struktur, som et datointervall.

> **Merk**: Det finnes noe innledende Pandas-kode i den medf칮lgende notatboken [`notebook.ipynb`](notebook.ipynb). Vi skisserer bare noen av eksemplene her, og du er definitivt velkommen til 친 sjekke ut hele notatboken.

Tenk p친 et eksempel: vi 칮nsker 친 analysere salget fra v친r iskrembutikk. La oss generere en series med salgstall (antall solgte varer hver dag) for en tidsperiode:

```python
start_date = "Jan 1, 2020"
end_date = "Mar 31, 2020"
idx = pd.date_range(start_date,end_date)
print(f"Length of index is {len(idx)}")
items_sold = pd.Series(np.random.randint(25,50,size=len(idx)),index=idx)
items_sold.plot()
```
![Tidsserieplott](../../../../translated_images/no/timeseries-1.80de678ab1cf727e50e00bcf24009fa2b0a8b90ebc43e34b99a345227d28e467.png)

N친 antar vi at vi hver uke arrangerer en fest for venner, og vi tar med oss 10 ekstra pakker med iskrem til festen. Vi kan lage en annen series, indeksert etter uke, for 친 demonstrere dette:
```python
additional_items = pd.Series(10,index=pd.date_range(start_date,end_date,freq="W"))
```
N친r vi legger sammen to series, f친r vi totalt antall:
```python
total_items = items_sold.add(additional_items,fill_value=0)
total_items.plot()
```
![Tidsserieplott](../../../../translated_images/no/timeseries-2.aae51d575c55181ceda81ade8c546a2fc2024f9136934386d57b8a189d7570ff.png)

> **Merk** at vi ikke bruker enkel syntaks `total_items+additional_items`. Hvis vi gjorde det, ville vi f친tt mange `NaN` (*Not a Number*) verdier i den resulterende serien. Dette skyldes at det mangler verdier for noen av indeksene i `additional_items`-serien, og 친 legge til `NaN` til noe resulterer i `NaN`. Derfor m친 vi spesifisere `fill_value`-parameteren under addisjonen.

Med tidsserier kan vi ogs친 **resample** serien med forskjellige tidsintervaller. For eksempel, hvis vi 칮nsker 친 beregne gjennomsnittlig salgsvolum m친nedlig, kan vi bruke f칮lgende kode:
```python
monthly = total_items.resample("1M").mean()
ax = monthly.plot(kind='bar')
```
![M친nedlige tidsserie-gjennomsnitt](../../../../translated_images/no/timeseries-3.f3147cbc8c624881008564bc0b5d9fcc15e7374d339da91766bd0e1c6bd9e3af.png)

### DataFrame

En DataFrame er i hovedsak en samling av series med samme indeks. Vi kan kombinere flere series sammen til en DataFrame:
```python
a = pd.Series(range(1,10))
b = pd.Series(["I","like","to","play","games","and","will","not","change"],index=range(0,9))
df = pd.DataFrame([a,b])
```
Dette vil lage en horisontal tabell som denne:
|     | 0   | 1    | 2   | 3   | 4      | 5   | 6      | 7    | 8    |
| --- | --- | ---- | --- | --- | ------ | --- | ------ | ---- | ---- |
| 0   | 1   | 2    | 3   | 4   | 5      | 6   | 7      | 8    | 9    |
| 1   | I   | like | to  | use | Python | and | Pandas | very | much |

Vi kan ogs친 bruke Series som kolonner og spesifisere kolonnenavn ved hjelp av en ordbok:
```python
df = pd.DataFrame({ 'A' : a, 'B' : b })
```
Dette vil gi oss en tabell som denne:

|     | A   | B      |
| --- | --- | ------ |
| 0   | 1   | I      |
| 1   | 2   | like   |
| 2   | 3   | to     |
| 3   | 4   | use    |
| 4   | 5   | Python |
| 5   | 6   | and    |
| 6   | 7   | Pandas |
| 7   | 8   | very   |
| 8   | 9   | much   |

**Merk** at vi ogs친 kan f친 denne tabelloppsettet ved 친 transponere den forrige tabellen, f.eks. ved 친 skrive 
```python
df = pd.DataFrame([a,b]).T..rename(columns={ 0 : 'A', 1 : 'B' })
```
Her betyr `.T` operasjonen med 친 transponere DataFrame, dvs. bytte rader og kolonner, og `rename`-operasjonen lar oss gi nytt navn til kolonner for 친 matche det forrige eksemplet.

Her er noen av de viktigste operasjonene vi kan utf칮re p친 DataFrames:

**Kolonnevalg**. Vi kan velge individuelle kolonner ved 친 skrive `df['A']` - denne operasjonen returnerer en Series. Vi kan ogs친 velge et delsett av kolonner til en annen DataFrame ved 친 skrive `df[['B','A']]` - dette returnerer en annen DataFrame.

**Filtrering** av kun visse rader basert p친 kriterier. For eksempel, for 친 beholde kun rader med kolonne `A` st칮rre enn 5, kan vi skrive `df[df['A']>5]`.

> **Merk**: M친ten filtrering fungerer p친 er som f칮lger. Uttrykket `df['A']<5` returnerer en boolsk series, som indikerer om uttrykket er `True` eller `False` for hvert element i den opprinnelige serien `df['A']`. N친r boolsk series brukes som indeks, returnerer det et delsett av rader i DataFrame. Derfor er det ikke mulig 친 bruke vilk친rlige Python boolske uttrykk, for eksempel, 친 skrive `df[df['A']>5 and df['A']<7]` ville v칝re feil. I stedet b칮r du bruke spesialoperasjonen `&` p친 boolske serier, ved 친 skrive `df[(df['A']>5) & (df['A']<7)]` (*parenteser er viktige her*).

**Opprette nye beregnbare kolonner**. Vi kan enkelt opprette nye beregnbare kolonner for v친r DataFrame ved 친 bruke intuitive uttrykk som dette:
```python
df['DivA'] = df['A']-df['A'].mean() 
``` 
Dette eksemplet beregner avviket til A fra gjennomsnittsverdien. Det som faktisk skjer her er at vi beregner en series, og deretter tilordner denne serien til venstre side, og oppretter en ny kolonne. Derfor kan vi ikke bruke operasjoner som ikke er kompatible med series, for eksempel, koden nedenfor er feil:
```python
# Wrong code -> df['ADescr'] = "Low" if df['A'] < 5 else "Hi"
df['LenB'] = len(df['B']) # <- Wrong result
``` 
Det siste eksemplet, selv om det er syntaktisk korrekt, gir oss feil resultat, fordi det tilordner lengden p친 serien `B` til alle verdier i kolonnen, og ikke lengden p친 individuelle elementer som vi hadde tenkt.

Hvis vi trenger 친 beregne komplekse uttrykk som dette, kan vi bruke `apply`-funksjonen. Det siste eksemplet kan skrives som f칮lger:
```python
df['LenB'] = df['B'].apply(lambda x : len(x))
# or 
df['LenB'] = df['B'].apply(len)
```

Etter operasjonene ovenfor, vil vi ende opp med f칮lgende DataFrame:

|     | A   | B      | DivA | LenB |
| --- | --- | ------ | ---- | ---- |
| 0   | 1   | I      | -4.0 | 1    |
| 1   | 2   | like   | -3.0 | 4    |
| 2   | 3   | to     | -2.0 | 2    |
| 3   | 4   | use    | -1.0 | 3    |
| 4   | 5   | Python | 0.0  | 6    |
| 5   | 6   | and    | 1.0  | 3    |
| 6   | 7   | Pandas | 2.0  | 6    |
| 7   | 8   | very   | 3.0  | 4    |
| 8   | 9   | much   | 4.0  | 4    |

**Velge rader basert p친 nummer** kan gj칮res ved hjelp av `iloc`-konstruksjonen. For eksempel, for 친 velge de f칮rste 5 radene fra DataFrame:
```python
df.iloc[:5]
```

**Gruppering** brukes ofte for 친 f친 et resultat som ligner p친 *pivot-tabeller* i Excel. Anta at vi 칮nsker 친 beregne gjennomsnittsverdien av kolonnen `A` for hver gitt verdi av `LenB`. Da kan vi gruppere v친r DataFrame etter `LenB`, og kalle `mean`:
```python
df.groupby(by='LenB')[['A','DivA']].mean()
```
Hvis vi trenger 친 beregne gjennomsnitt og antall elementer i gruppen, kan vi bruke en mer kompleks `aggregate`-funksjon:
```python
df.groupby(by='LenB') \
 .aggregate({ 'DivA' : len, 'A' : lambda x: x.mean() }) \
 .rename(columns={ 'DivA' : 'Count', 'A' : 'Mean'})
```
Dette gir oss f칮lgende tabell:

| LenB | Count | Mean     |
| ---- | ----- | -------- |
| 1    | 1     | 1.000000 |
| 2    | 1     | 3.000000 |
| 3    | 2     | 5.000000 |
| 4    | 3     | 6.333333 |
| 6    | 2     | 6.000000 |

### Hente Data
Vi har sett hvor enkelt det er 친 konstruere Series og DataFrames fra Python-objekter. Imidlertid kommer data vanligvis i form av en tekstfil eller en Excel-tabell. Heldigvis tilbyr Pandas oss en enkel m친te 친 laste inn data fra disk. For eksempel, 친 lese en CSV-fil er s친 enkelt som dette:
```python
df = pd.read_csv('file.csv')
```
Vi vil se flere eksempler p친 hvordan man laster inn data, inkludert 친 hente det fra eksterne nettsteder, i "Utfordring"-seksjonen.

### Utskrift og Visualisering

En Data Scientist m친 ofte utforske dataene, og derfor er det viktig 친 kunne visualisere dem. N친r en DataFrame er stor, 칮nsker vi ofte bare 친 forsikre oss om at vi gj칮r alt riktig ved 친 skrive ut de f칮rste radene. Dette kan gj칮res ved 친 kalle `df.head()`. Hvis du kj칮rer det fra Jupyter Notebook, vil det skrive ut DataFrame i en fin tabellform.

Vi har ogs친 sett bruken av `plot`-funksjonen for 친 visualisere noen kolonner. Selv om `plot` er veldig nyttig for mange oppgaver og st칮tter mange forskjellige grafetyper via `kind=`-parameteren, kan du alltid bruke det r친 `matplotlib`-biblioteket for 친 lage noe mer komplekst. Vi vil dekke datavisualisering i detalj i separate kursleksjoner.

Denne oversikten dekker de viktigste konseptene i Pandas, men biblioteket er veldig rikt, og det er ingen grenser for hva du kan gj칮re med det! La oss n친 bruke denne kunnskapen til 친 l칮se spesifikke problemer.

## 游 Utfordring 1: Analysere COVID-spredning

Det f칮rste problemet vi skal fokusere p친 er modellering av epidemisk spredning av COVID-19. For 친 gj칮re dette, vil vi bruke data om antall smittede individer i forskjellige land, levert av [Center for Systems Science and Engineering](https://systems.jhu.edu/) (CSSE) ved [Johns Hopkins University](https://jhu.edu/). Datasettet er tilgjengelig i [denne GitHub-repositorien](https://github.com/CSSEGISandData/COVID-19).

Siden vi 칮nsker 친 demonstrere hvordan man h친ndterer data, inviterer vi deg til 친 친pne [`notebook-covidspread.ipynb`](notebook-covidspread.ipynb) og lese det fra topp til bunn. Du kan ogs친 kj칮re cellene og gj칮re noen utfordringer som vi har lagt igjen til deg p친 slutten.

![COVID-spredning](../../../../translated_images/no/covidspread.f3d131c4f1d260ab0344d79bac0abe7924598dd754859b165955772e1bd5e8a2.png)

> Hvis du ikke vet hvordan du kj칮rer kode i Jupyter Notebook, ta en titt p친 [denne artikkelen](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

## Arbeide med Ustrukturert Data

Selv om data ofte kommer i tabellform, m친 vi i noen tilfeller h친ndtere mindre strukturert data, for eksempel tekst eller bilder. I slike tilfeller, for 친 bruke databehandlingsteknikker vi har sett ovenfor, m친 vi p친 en eller annen m친te **ekstrahere** strukturert data. Her er noen eksempler:

* Ekstrahere n칮kkelord fra tekst og se hvor ofte disse n칮kkelordene vises
* Bruke nevrale nettverk for 친 hente informasjon om objekter p친 et bilde
* F친 informasjon om f칮lelsene til mennesker p친 videokamera-feed

## 游 Utfordring 2: Analysere COVID-artikler

I denne utfordringen fortsetter vi med temaet COVID-pandemien og fokuserer p친 behandling av vitenskapelige artikler om emnet. Det finnes [CORD-19 Dataset](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) med mer enn 7000 (p친 tidspunktet for skriving) artikler om COVID, tilgjengelig med metadata og sammendrag (og for omtrent halvparten av dem er ogs친 fulltekst tilgjengelig).

Et fullstendig eksempel p친 analyse av dette datasettet ved bruk av [Text Analytics for Health](https://docs.microsoft.com/azure/cognitive-services/text-analytics/how-tos/text-analytics-for-health/?WT.mc_id=academic-77958-bethanycheum) kognitive tjeneste er beskrevet [i denne bloggposten](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). Vi vil diskutere en forenklet versjon av denne analysen.

> **NOTE**: Vi gir ikke en kopi av datasettet som en del av denne repositorien. Du m친 kanskje f칮rst laste ned [`metadata.csv`](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge?select=metadata.csv)-filen fra [dette datasettet p친 Kaggle](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge). Registrering hos Kaggle kan v칝re n칮dvendig. Du kan ogs친 laste ned datasettet uten registrering [herfra](https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/historical_releases.html), men det vil inkludere alle fulltekster i tillegg til metadatafilen.

칀pne [`notebook-papers.ipynb`](notebook-papers.ipynb) og les det fra topp til bunn. Du kan ogs친 kj칮re cellene og gj칮re noen utfordringer som vi har lagt igjen til deg p친 slutten.

![Covid Medisinsk Behandling](../../../../translated_images/no/covidtreat.b2ba59f57ca45fbcda36e0ddca3f8cfdddeeed6ca879ea7f866d93fa6ec65791.png)

## Behandling av Bildedata

Nylig har sv칝rt kraftige AI-modeller blitt utviklet som lar oss forst친 bilder. Det finnes mange oppgaver som kan l칮ses ved bruk av forh친ndstrente nevrale nettverk eller skytjenester. Noen eksempler inkluderer:

* **Bildeklassifisering**, som kan hjelpe deg med 친 kategorisere bildet i en av de forh친ndsdefinerte klassene. Du kan enkelt trene dine egne bildeklassifiserere ved bruk av tjenester som [Custom Vision](https://azure.microsoft.com/services/cognitive-services/custom-vision-service/?WT.mc_id=academic-77958-bethanycheum)
* **Objektdeteksjon** for 친 oppdage forskjellige objekter i bildet. Tjenester som [computer vision](https://azure.microsoft.com/services/cognitive-services/computer-vision/?WT.mc_id=academic-77958-bethanycheum) kan oppdage en rekke vanlige objekter, og du kan trene [Custom Vision](https://azure.microsoft.com/services/cognitive-services/custom-vision-service/?WT.mc_id=academic-77958-bethanycheum)-modellen til 친 oppdage spesifikke objekter av interesse.
* **Ansiktsdeteksjon**, inkludert alder, kj칮nn og f칮lelsesdeteksjon. Dette kan gj칮res via [Face API](https://azure.microsoft.com/services/cognitive-services/face/?WT.mc_id=academic-77958-bethanycheum).

Alle disse skytjenestene kan kalles ved bruk av [Python SDKs](https://docs.microsoft.com/samples/azure-samples/cognitive-services-python-sdk-samples/cognitive-services-python-sdk-samples/?WT.mc_id=academic-77958-bethanycheum), og kan derfor enkelt integreres i din datautforskningsarbeidsflyt.

Her er noen eksempler p친 utforsking av data fra bildedatakilder:
* I bloggposten [Hvordan l칝re datavitenskap uten koding](https://soshnikov.com/azure/how-to-learn-data-science-without-coding/) utforsker vi Instagram-bilder, og pr칮ver 친 forst친 hva som f친r folk til 친 gi flere likes til et bilde. Vi ekstraherer f칮rst s친 mye informasjon som mulig fra bilder ved bruk av [computer vision](https://azure.microsoft.com/services/cognitive-services/computer-vision/?WT.mc_id=academic-77958-bethanycheum), og bruker deretter [Azure Machine Learning AutoML](https://docs.microsoft.com/azure/machine-learning/concept-automated-ml/?WT.mc_id=academic-77958-bethanycheum) for 친 bygge en tolkbar modell.
* I [Facial Studies Workshop](https://github.com/CloudAdvocacy/FaceStudies) bruker vi [Face API](https://azure.microsoft.com/services/cognitive-services/face/?WT.mc_id=academic-77958-bethanycheum) for 친 ekstrahere f칮lelser hos mennesker p친 fotografier fra arrangementer, for 친 pr칮ve 친 forst친 hva som gj칮r folk glade.

## Konklusjon

Enten du allerede har strukturert eller ustrukturert data, kan du ved bruk av Python utf칮re alle trinn relatert til databehandling og forst친else. Det er sannsynligvis den mest fleksible m친ten 친 behandle data p친, og det er grunnen til at flertallet av dataforskere bruker Python som sitt prim칝re verkt칮y. 칀 l칝re Python i dybden er sannsynligvis en god id칠 hvis du er seri칮s med din datavitenskapsreise!

## [Quiz etter forelesning](https://ff-quizzes.netlify.app/en/ds/quiz/13)

## Gjennomgang og Selvstudium

**B칮ker**
* [Wes McKinney. Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython](https://www.amazon.com/gp/product/1491957662)

**Nettressurser**
* Offisiell [10 minutter til Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)-veiledning
* [Dokumentasjon om Pandas-visualisering](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html)

**L칝re Python**
* [L칝r Python p친 en morsom m친te med Turtle Graphics og Fractals](https://github.com/shwars/pycourse)
* [Ta dine f칮rste steg med Python](https://docs.microsoft.com/learn/paths/python-first-steps/?WT.mc_id=academic-77958-bethanycheum) L칝ringssti p친 [Microsoft Learn](http://learn.microsoft.com/?WT.mc_id=academic-77958-bethanycheum)

## Oppgave

[Utf칮r en mer detaljert datastudie for utfordringene ovenfor](assignment.md)

## Kreditering

Denne leksjonen er skrevet med 鮫봺잺 av [Dmitry Soshnikov](http://soshnikov.com)

---

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n칮yaktighet, v칝r oppmerksom p친 at automatiske oversettelser kan inneholde feil eller un칮yaktigheter. Det originale dokumentet p친 sitt opprinnelige spr친k b칮r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for misforst친elser eller feiltolkninger som oppst친r ved bruk av denne oversettelsen.