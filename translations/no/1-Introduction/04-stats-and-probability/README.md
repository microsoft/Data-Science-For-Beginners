<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b706a07cfa87ba091cbb91e0aa775600",
  "translation_date": "2025-08-26T21:45:11+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "no"
}
-->
# En Kort Introduksjon til Statistikk og Sannsynlighet

|![ Sketchnote av [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| Statistikk og Sannsynlighet - _Sketchnote av [@nitya](https://twitter.com/nitya)_ |

Statistikk og sannsynlighetsteori er to n√¶rt relaterte omr√•der innen matematikk som er sv√¶rt relevante for datavitenskap. Det er mulig √• jobbe med data uten dyp kunnskap om matematikk, men det er likevel bedre √• kjenne til noen grunnleggende konsepter. Her vil vi presentere en kort introduksjon som kan hjelpe deg i gang.

[![Introduksjonsvideo](../../../../translated_images/video-prob-and-stats.e4282e5efa2f2543400843ed98b1057065c9600cebfc8a728e8931b5702b2ae4.no.png)](https://youtu.be/Z5Zy85g4Yjw)

## [Quiz f√∏r forelesning](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/6)

## Sannsynlighet og Tilfeldige Variabler

**Sannsynlighet** er et tall mellom 0 og 1 som uttrykker hvor sannsynlig en **hendelse** er. Det defineres som antall positive utfall (som f√∏rer til hendelsen), delt p√• totalt antall utfall, gitt at alle utfall er like sannsynlige. For eksempel, n√•r vi kaster en terning, er sannsynligheten for √• f√• et partall 3/6 = 0.5.

N√•r vi snakker om hendelser, bruker vi **tilfeldige variabler**. For eksempel, den tilfeldige variabelen som representerer tallet vi f√•r n√•r vi kaster en terning, vil ha verdier fra 1 til 6. Mengden av tall fra 1 til 6 kalles **utvalgsrom**. Vi kan snakke om sannsynligheten for at en tilfeldig variabel tar en bestemt verdi, for eksempel P(X=3)=1/6.

Den tilfeldige variabelen i det forrige eksempelet kalles **diskret**, fordi den har et tellbart utvalgsrom, dvs. det finnes separate verdier som kan telles opp. Det finnes tilfeller der utvalgsrommet er et intervall av reelle tall, eller hele settet av reelle tall. Slike variabler kalles **kontinuerlige**. Et godt eksempel er tidspunktet n√•r bussen ankommer.

## Sannsynlighetsfordeling

For diskrete tilfeldige variabler er det enkelt √• beskrive sannsynligheten for hver hendelse med en funksjon P(X). For hver verdi *s* fra utvalgsrommet *S* vil den gi et tall fra 0 til 1, slik at summen av alle verdier av P(X=s) for alle hendelser blir 1.

Den mest kjente diskrete fordelingen er **uniform fordeling**, der det finnes et utvalgsrom med N elementer, med lik sannsynlighet p√• 1/N for hver av dem.

Det er mer utfordrende √• beskrive sannsynlighetsfordelingen for en kontinuerlig variabel, med verdier trukket fra et intervall [a,b], eller hele settet av reelle tall ‚Ñù. Tenk p√• tilfelle med busstider. Faktisk, for hvert eksakte tidspunkt *t*, er sannsynligheten for at bussen ankommer akkurat da lik 0!

> N√• vet du at hendelser med sannsynlighet 0 skjer, og veldig ofte! I det minste hver gang bussen ankommer!

Vi kan bare snakke om sannsynligheten for at en variabel faller innenfor et gitt intervall av verdier, f.eks. P(t<sub>1</sub>‚â§X<t<sub>2</sub>). I dette tilfellet beskrives sannsynlighetsfordelingen av en **sannsynlighetstetthetsfunksjon** p(x), slik at

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../translated_images/probability-density.a8aad29f17a14afb519b407c7b6edeb9f3f9aa5f69c9e6d9445f604e5f8a2bf7.no.png)

En kontinuerlig analog av uniform fordeling kalles **kontinuerlig uniform**, som er definert p√• et begrenset intervall. Sannsynligheten for at verdien X faller innenfor et intervall med lengde l er proporsjonal med l, og stiger opp til 1.

En annen viktig fordeling er **normalfordeling**, som vi skal snakke mer om nedenfor.

## Gjennomsnitt, Varians og Standardavvik

Anta at vi trekker en sekvens av n pr√∏ver av en tilfeldig variabel X: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. Vi kan definere **gjennomsnitt** (eller **aritmetisk middelverdi**) av sekvensen p√• tradisjonelt vis som (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n. N√•r vi √∏ker st√∏rrelsen p√• pr√∏ven (dvs. tar grensen med n‚Üí‚àû), vil vi f√• gjennomsnittet (ogs√• kalt **forventning**) av fordelingen. Vi vil betegne forventning med **E**(x).

> Det kan vises at for enhver diskret fordeling med verdier {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} og tilsvarende sannsynligheter p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, vil forventningen v√¶re E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>.

For √• identifisere hvor langt verdiene er spredt, kan vi beregne variansen œÉ<sup>2</sup> = ‚àë(x<sub>i</sub> - Œº)<sup>2</sup>/n, der Œº er gjennomsnittet av sekvensen. Verdien œÉ kalles **standardavvik**, og œÉ<sup>2</sup> kalles **varians**.

## Typetall, Median og Kvartiler

Noen ganger representerer ikke gjennomsnittet tilstrekkelig den "typiske" verdien for data. For eksempel, n√•r det finnes noen ekstreme verdier som er helt utenfor rekkevidde, kan de p√•virke gjennomsnittet. Et annet godt m√•l er **median**, en verdi slik at halvparten av datapunktene er lavere enn den, og den andre halvparten - h√∏yere.

For √• hjelpe oss med √• forst√• fordelingen av data, er det nyttig √• snakke om **kvartiler**:

* F√∏rste kvartil, eller Q1, er en verdi slik at 25% av dataene faller under den
* Tredje kvartil, eller Q3, er en verdi slik at 75% av dataene faller under den

Grafisk kan vi representere forholdet mellom median og kvartiler i et diagram kalt **boksplott**:

<img src="images/boxplot_explanation.png" width="50%"/>

Her beregner vi ogs√• **interkvartilavstand** IQR=Q3-Q1, og s√•kalte **uteliggere** - verdier som ligger utenfor grensene [Q1-1.5*IQR,Q3+1.5*IQR].

For en begrenset fordeling som inneholder et lite antall mulige verdier, er en god "typisk" verdi den som forekommer oftest, og som kalles **typetall**. Det brukes ofte p√• kategoriske data, som farger. Tenk p√• en situasjon der vi har to grupper mennesker - noen som sterkt foretrekker r√∏dt, og andre som foretrekker bl√•tt. Hvis vi koder farger med tall, vil gjennomsnittsverdien for favorittfarge v√¶re et sted i det oransje-gr√∏nne spekteret, som ikke indikerer den faktiske preferansen til noen av gruppene. Typetallet vil imidlertid v√¶re enten en av fargene, eller begge fargene, hvis antallet personer som stemmer for dem er likt (i dette tilfellet kaller vi utvalget **multimodalt**).

## Data fra Virkeligheten

N√•r vi analyserer data fra virkeligheten, er de ofte ikke tilfeldige variabler i den forstand at vi ikke utf√∏rer eksperimenter med ukjent resultat. For eksempel, vurder et lag med baseballspillere og deres kroppslige data, som h√∏yde, vekt og alder. Disse tallene er ikke akkurat tilfeldige, men vi kan fortsatt bruke de samme matematiske konseptene. For eksempel kan en sekvens av folks vekter betraktes som en sekvens av verdier trukket fra en tilfeldig variabel. Nedenfor er sekvensen av vekter til faktiske baseballspillere fra [Major League Baseball](http://mlb.mlb.com/index.jsp), hentet fra [dette datasettet](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) (for enkelhets skyld vises bare de f√∏rste 20 verdiene):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Merk**: For √• se et eksempel p√• hvordan man jobber med dette datasettet, ta en titt p√• [den medf√∏lgende notatboken](notebook.ipynb). Det finnes ogs√• en rekke utfordringer gjennom denne leksjonen, og du kan fullf√∏re dem ved √• legge til litt kode i den notatboken. Hvis du ikke er sikker p√• hvordan du opererer med data, ikke bekymre deg - vi kommer tilbake til √• jobbe med data ved hjelp av Python senere. Hvis du ikke vet hvordan du kj√∏rer kode i Jupyter Notebook, ta en titt p√• [denne artikkelen](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

Her er boksplottet som viser gjennomsnitt, median og kvartiler for v√•re data:

![Vekt Boksplott](../../../../translated_images/weight-boxplot.1dbab1c03af26f8a008fff4e17680082c8ab147d6df646cbac440bbf8f5b9c42.no.png)

Siden v√•re data inneholder informasjon om forskjellige spiller **roller**, kan vi ogs√• lage boksplott etter rolle - det vil gi oss en id√© om hvordan parameterverdier varierer mellom roller. Denne gangen vil vi vurdere h√∏yde:

![Boksplott etter rolle](../../../../translated_images/boxplot_byrole.036b27a1c3f52d42f66fba2324ec5cde0a1bca6a01a619eeb0ce7cd054b2527b.no.png)

Dette diagrammet antyder at, i gjennomsnitt, er h√∏yden til f√∏rstemenn h√∏yere enn h√∏yden til andremenn. Senere i denne leksjonen vil vi l√¶re hvordan vi kan teste denne hypotesen mer formelt, og hvordan vi kan demonstrere at v√•re data er statistisk signifikante for √• vise dette.

> N√•r vi jobber med data fra virkeligheten, antar vi at alle datapunkter er pr√∏ver trukket fra en sannsynlighetsfordeling. Denne antagelsen lar oss bruke maskinl√¶ringsteknikker og bygge fungerende prediktive modeller.

For √• se hva fordelingen av v√•re data er, kan vi lage et diagram kalt **histogram**. X-aksen vil inneholde et antall forskjellige vektintervaller (s√•kalte **bins**), og den vertikale aksen vil vise antall ganger v√•r tilfeldige variabelpr√∏ve var innenfor et gitt intervall.

![Histogram av virkelige data](../../../../translated_images/weight-histogram.bfd00caf7fc30b145b21e862dba7def41c75635d5280de25d840dd7f0b00545e.no.png)

Fra dette histogrammet kan du se at alle verdier er sentrert rundt et visst gjennomsnittlig vekt, og jo lenger vi g√•r fra den vekten - jo f√¶rre vekter av den verdien blir observert. Dvs., det er sv√¶rt usannsynlig at vekten til en baseballspiller vil v√¶re veldig forskjellig fra gjennomsnittsvekten. Variansen i vekter viser i hvilken grad vekter sannsynligvis vil avvike fra gjennomsnittet.

> Hvis vi tar vekter av andre mennesker, ikke fra baseballligaen, vil fordelingen sannsynligvis v√¶re annerledes. Imidlertid vil formen p√• fordelingen v√¶re den samme, men gjennomsnitt og varians vil endre seg. S√•, hvis vi trener v√•r modell p√• baseballspillere, er det sannsynlig at den gir feil resultater n√•r den brukes p√• studenter ved et universitet, fordi den underliggende fordelingen er forskjellig.

## Normalfordeling

Fordelingen av vekter som vi har sett ovenfor er sv√¶rt typisk, og mange m√•linger fra virkeligheten f√∏lger samme type fordeling, men med forskjellig gjennomsnitt og varians. Denne fordelingen kalles **normalfordeling**, og den spiller en sv√¶rt viktig rolle i statistikk.

√Ö bruke normalfordeling er en korrekt m√•te √• generere tilfeldige vekter av potensielle baseballspillere. N√•r vi kjenner gjennomsnittsvekt `mean` og standardavvik `std`, kan vi generere 1000 vektpr√∏ver p√• f√∏lgende m√•te:
```python
samples = np.random.normal(mean,std,1000)
``` 

Hvis vi plotter histogrammet av de genererte pr√∏vene, vil vi se et bilde som ligner veldig p√• det som er vist ovenfor. Og hvis vi √∏ker antall pr√∏ver og antall bins, kan vi generere et bilde av en normalfordeling som er n√¶rmere ideell:

![Normalfordeling med mean=0 og std.dev=1](../../../../translated_images/normal-histogram.dfae0d67c202137d552d0015fb87581eca263925e512404f3c12d8885315432e.no.png)

*Normalfordeling med mean=0 og std.dev=1*

## Konfidensintervaller

N√•r vi snakker om vekter til baseballspillere, antar vi at det finnes en viss **tilfeldig variabel W** som tilsvarer den ideelle sannsynlighetsfordelingen av vektene til alle baseballspillere (s√•kalt **populasjon**). V√•r sekvens av vekter tilsvarer et utvalg av alle baseballspillere som vi kaller **pr√∏ve**. Et interessant sp√∏rsm√•l er, kan vi kjenne parameterne til fordelingen av W, dvs. gjennomsnitt og varians for populasjonen?

Det enkleste svaret ville v√¶re √• beregne gjennomsnitt og varians for v√•r pr√∏ve. Imidlertid kan det hende at v√•rt tilfeldige utvalg ikke n√∏yaktig representerer hele populasjonen. Derfor gir det mening √• snakke om **konfidensintervall**.
> **Konfidensintervall** er en estimering av den sanne gjennomsnittet for en populasjon basert p√• v√•rt utvalg, som er n√∏yaktig med en viss sannsynlighet (eller **konfidensniv√•**).
Anta at vi har et utvalg X<sub>1</sub>, ..., X<sub>n</sub> fra v√•r distribusjon. Hver gang vi trekker et utvalg fra distribusjonen, vil vi ende opp med en forskjellig gjennomsnittsverdi Œº. Dermed kan Œº betraktes som en tilfeldig variabel. Et **konfidensintervall** med konfidens p er et par verdier (L<sub>p</sub>,R<sub>p</sub>), slik at **P**(L<sub>p</sub>‚â§Œº‚â§R<sub>p</sub>) = p, alts√• sannsynligheten for at den m√•lte gjennomsnittsverdien faller innenfor intervallet er lik p.

Det g√•r utover v√•r korte introduksjon √• diskutere i detalj hvordan disse konfidensintervallene beregnes. Noen flere detaljer kan finnes [p√• Wikipedia](https://en.wikipedia.org/wiki/Confidence_interval). Kort sagt definerer vi distribusjonen av beregnet utvalgsgjennomsnitt i forhold til den sanne gjennomsnittet av populasjonen, som kalles **studentdistribusjon**.

> **Interessant fakta**: Studentdistribusjonen er oppkalt etter matematikeren William Sealy Gosset, som publiserte sitt arbeid under pseudonymet "Student". Han jobbet i Guinness-bryggeriet, og if√∏lge en av versjonene √∏nsket ikke arbeidsgiveren hans at allmennheten skulle vite at de brukte statistiske tester for √• bestemme kvaliteten p√• r√•varene.

Hvis vi √∏nsker √• estimere gjennomsnittet Œº av v√•r populasjon med konfidens p, m√• vi ta *(1-p)/2-te percentil* av en Student-distribusjon A, som enten kan hentes fra tabeller eller beregnes ved hjelp av innebygde funksjoner i statistikkprogramvare (f.eks. Python, R, etc.). Deretter vil intervallet for Œº v√¶re gitt av X¬±A*D/‚àön, der X er det oppn√•dde gjennomsnittet av utvalget, D er standardavviket.

> **Merk**: Vi utelater ogs√• diskusjonen om et viktig konsept kalt [frihetsgrader](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)), som er viktig i forhold til Student-distribusjonen. Du kan referere til mer komplette b√∏ker om statistikk for √• forst√• dette konseptet bedre.

Et eksempel p√• beregning av konfidensintervall for vekt og h√∏yde er gitt i [tilh√∏rende notatb√∏ker](notebook.ipynb).

| p | Vektgjennomsnitt |
|-----|----------------|
| 0.85 | 201.73¬±0.94 |
| 0.90 | 201.73¬±1.08 |
| 0.95 | 201.73¬±1.28 |

Legg merke til at jo h√∏yere konfidenssannsynligheten er, jo bredere er konfidensintervallet.

## Hypotesetesting 

I v√•rt datasett med baseballspillere finnes det ulike spillerroller, som kan oppsummeres nedenfor (se [tilh√∏rende notatbok](notebook.ipynb) for √• se hvordan denne tabellen kan beregnes):

| Rolle | H√∏yde | Vekt | Antall |
|-------|-------|------|--------|
| Catcher | 72.723684 | 204.328947 | 76 |
| Designated_Hitter | 74.222222 | 220.888889 | 18 |
| First_Baseman | 74.000000 | 213.109091 | 55 |
| Outfielder | 73.010309 | 199.113402 | 194 |
| Relief_Pitcher | 74.374603 | 203.517460 | 315 |
| Second_Baseman | 71.362069 | 184.344828 | 58 |
| Shortstop | 71.903846 | 182.923077 | 52 |
| Starting_Pitcher | 74.719457 | 205.163636 | 221 |
| Third_Baseman | 73.044444 | 200.955556 | 45 |

Vi kan legge merke til at gjennomsnittsh√∏yden til f√∏rstemenn er h√∏yere enn den til andremenn. Dermed kan vi bli fristet til √• konkludere med at **f√∏rstemenn er h√∏yere enn andremenn**.

> Denne uttalelsen kalles **en hypotese**, fordi vi ikke vet om dette faktisk er sant eller ikke.

Det er imidlertid ikke alltid √•penbart om vi kan trekke denne konklusjonen. Fra diskusjonen ovenfor vet vi at hvert gjennomsnitt har et tilh√∏rende konfidensintervall, og dermed kan denne forskjellen bare v√¶re en statistisk feil. Vi trenger en mer formell m√•te √• teste hypotesen v√•r p√•.

La oss beregne konfidensintervaller separat for h√∏ydene til f√∏rstemenn og andremenn:

| Konfidens | F√∏rstemenn | Andremenn |
|-----------|------------|-----------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

Vi kan se at under ingen konfidens overlapper intervallene. Det beviser hypotesen v√•r om at f√∏rstemenn er h√∏yere enn andremenn.

Mer formelt er problemet vi l√∏ser √• se om **to sannsynlighetsfordelinger er de samme**, eller i det minste har de samme parametrene. Avhengig av distribusjonen m√• vi bruke forskjellige tester for dette. Hvis vi vet at distribusjonene v√•re er normale, kan vi bruke **[Student t-test](https://en.wikipedia.org/wiki/Student%27s_t-test)**.

I Student t-test beregner vi den s√•kalte **t-verdien**, som indikerer forskjellen mellom gjennomsnittene, tatt i betraktning variansen. Det er demonstrert at t-verdien f√∏lger **studentdistribusjonen**, som lar oss f√• terskelverdien for et gitt konfidensniv√• **p** (dette kan beregnes eller finnes i numeriske tabeller). Vi sammenligner deretter t-verdien med denne terskelen for √• godkjenne eller avvise hypotesen.

I Python kan vi bruke **SciPy**-pakken, som inkluderer funksjonen `ttest_ind` (i tillegg til mange andre nyttige statistiske funksjoner!). Den beregner t-verdien for oss, og gj√∏r ogs√• den omvendte oppslaget av konfidens p-verdi, slik at vi bare kan se p√• konfidensen for √• trekke konklusjonen.

For eksempel gir v√•r sammenligning mellom h√∏ydene til f√∏rstemenn og andremenn oss f√∏lgende resultater: 
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
I v√•rt tilfelle er p-verdien sv√¶rt lav, noe som betyr at det er sterk evidens som st√∏tter at f√∏rstemenn er h√∏yere.

Det finnes ogs√• andre typer hypoteser vi kan teste, for eksempel:
* √Ö bevise at et gitt utvalg f√∏lger en distribusjon. I v√•rt tilfelle har vi antatt at h√∏yder er normalt fordelt, men det trenger formell statistisk verifikasjon. 
* √Ö bevise at gjennomsnittsverdien av et utvalg samsvarer med en forh√•ndsdefinert verdi
* √Ö sammenligne gjennomsnittene av flere utvalg (f.eks. hva er forskjellen i lykkef√∏lelse mellom ulike aldersgrupper)

## Lov om store tall og sentralgrenseteoremet

En av grunnene til at normalfordelingen er s√• viktig er det s√•kalte **sentralgrenseteoremet**. Anta at vi har et stort utvalg av uavhengige N verdier X<sub>1</sub>, ..., X<sub>N</sub>, hentet fra en hvilken som helst distribusjon med gjennomsnitt Œº og varians œÉ<sup>2</sup>. Da, for tilstrekkelig stor N (med andre ord, n√•r N‚Üí‚àû), vil gjennomsnittet Œ£<sub>i</sub>X<sub>i</sub> v√¶re normalt fordelt, med gjennomsnitt Œº og varians œÉ<sup>2</sup>/N.

> En annen m√•te √• tolke sentralgrenseteoremet p√• er √• si at uavhengig av distribusjonen, n√•r du beregner gjennomsnittet av en sum av tilfeldige variabelverdier, ender du opp med normalfordeling. 

Fra sentralgrenseteoremet f√∏lger det ogs√• at, n√•r N‚Üí‚àû, blir sannsynligheten for at utvalgsgjennomsnittet er lik Œº lik 1. Dette er kjent som **loven om store tall**.

## Kovarians og korrelasjon

En av tingene Data Science gj√∏r er √• finne relasjoner mellom data. Vi sier at to sekvenser **korrelerer** n√•r de viser lignende oppf√∏rsel samtidig, dvs. de enten stiger/faller samtidig, eller √©n sekvens stiger n√•r en annen faller og omvendt. Med andre ord ser det ut til √• v√¶re en relasjon mellom to sekvenser.

> Korrelasjon indikerer ikke n√∏dvendigvis en √•rsakssammenheng mellom to sekvenser; noen ganger kan begge variablene avhenge av en ekstern √•rsak, eller det kan v√¶re ren tilfeldighet at de korrelerer. Sterk matematisk korrelasjon er imidlertid en god indikasjon p√• at to variabler er p√• en eller annen m√•te koblet.

Matematisk er hovedkonseptet som viser relasjonen mellom to tilfeldige variabler **kovarians**, som beregnes slik: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. Vi beregner avviket til begge variablene fra deres gjennomsnittsverdier, og deretter produktet av disse avvikene. Hvis begge variablene avviker sammen, vil produktet alltid v√¶re en positiv verdi, som vil gi positiv kovarians. Hvis begge variablene avviker usynkront (dvs. √©n faller under gjennomsnittet n√•r en annen stiger over gjennomsnittet), vil vi alltid f√• negative tall, som vil gi negativ kovarians. Hvis avvikene ikke er avhengige, vil de gi omtrent null.

Den absolutte verdien av kovarians sier ikke mye om hvor stor korrelasjonen er, fordi den avhenger av st√∏rrelsen p√• de faktiske verdiene. For √• normalisere den kan vi dele kovariansen med standardavviket til begge variablene, for √• f√• **korrelasjon**. Det fine er at korrelasjonen alltid er i omr√•det [-1,1], der 1 indikerer sterk positiv korrelasjon mellom verdier, -1 - sterk negativ korrelasjon, og 0 - ingen korrelasjon i det hele tatt (variablene er uavhengige). 

**Eksempel**: Vi kan beregne korrelasjon mellom vekt og h√∏yde til baseballspillere fra datasettet nevnt ovenfor:
```python
print(np.corrcoef(weights,heights))
```
Som et resultat f√•r vi **korrelasjonsmatrise** som denne:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> Korrelasjonsmatrisen C kan beregnes for et hvilket som helst antall inngangssekvenser S<sub>1</sub>, ..., S<sub>n</sub>. Verdien av C<sub>ij</sub> er korrelasjonen mellom S<sub>i</sub> og S<sub>j</sub>, og diagonalelementene er alltid 1 (som ogs√• er selvkorrelasjon av S<sub>i</sub>).

I v√•rt tilfelle indikerer verdien 0.53 at det er en viss korrelasjon mellom vekt og h√∏yde til en person. Vi kan ogs√• lage et spredningsdiagram av √©n verdi mot den andre for √• se relasjonen visuelt:

![Relasjon mellom vekt og h√∏yde](../../../../translated_images/weight-height-relationship.3f06bde4ca2aba9974182c4ef037ed602acd0fbbbbe2ca91cefd838a9e66bcf9.no.png)

> Flere eksempler p√• korrelasjon og kovarians kan finnes i [tilh√∏rende notatbok](notebook.ipynb).

## Konklusjon

I denne seksjonen har vi l√¶rt:

* grunnleggende statistiske egenskaper ved data, som gjennomsnitt, varians, modus og kvartiler
* forskjellige fordelinger av tilfeldige variabler, inkludert normalfordeling
* hvordan finne korrelasjon mellom forskjellige egenskaper
* hvordan bruke matematisk og statistisk apparat for √• bevise hypoteser
* hvordan beregne konfidensintervaller for tilfeldige variabler gitt et datapr√∏ve

Selv om dette definitivt ikke er en utt√∏mmende liste over emner innen sannsynlighet og statistikk, b√∏r det v√¶re nok til √• gi deg en god start p√• dette kurset.

## üöÄ Utfordring

Bruk eksempelkoden i notatboken for √• teste andre hypoteser som: 
1. F√∏rstemenn er eldre enn andremenn
2. F√∏rstemenn er h√∏yere enn tredjemenn
3. Shortstops er h√∏yere enn andremenn

## [Quiz etter forelesning](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/7)

## Gjennomgang og selvstudium

Sannsynlighet og statistikk er et s√• bredt tema at det fortjener sitt eget kurs. Hvis du er interessert i √• g√• dypere inn i teorien, kan du lese noen av f√∏lgende b√∏ker:

1. [Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/) fra New York University har flotte forelesningsnotater [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (tilgjengelig online)
1. [Peter og Andrew Bruce. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[eksempelkode i R](https://github.com/andrewgbruce/statistics-for-data-scientists)]. 
1. [James D. Miller. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[eksempelkode i R](https://github.com/PacktPublishing/Statistics-for-Data-Science)]

## Oppgave

[Small Diabetes Study](assignment.md)

## Kreditering

Denne leksjonen er skrevet med ‚ô•Ô∏è av [Dmitry Soshnikov](http://soshnikov.com)

---

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n√∏yaktighet, v√¶r oppmerksom p√• at automatiserte oversettelser kan inneholde feil eller un√∏yaktigheter. Det originale dokumentet p√• sitt opprinnelige spr√•k b√∏r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.