<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1cf49f029ba1f25a54f0d5bc2fa575fc",
  "translation_date": "2025-09-05T22:27:10+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "no"
}
-->
# En kort introduksjon til statistikk og sannsynlighet

|![ Sketchnote av [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| Statistikk og sannsynlighet - _Sketchnote av [@nitya](https://twitter.com/nitya)_ |

Statistikk og sannsynlighetsteori er to n√¶rt beslektede omr√•der innen matematikk som er sv√¶rt relevante for datavitenskap. Det er mulig √• jobbe med data uten dyp kunnskap om matematikk, men det er likevel bedre √• kjenne til noen grunnleggende konsepter. Her vil vi presentere en kort introduksjon som kan hjelpe deg i gang.

[![Introduksjonsvideo](../../../../1-Introduction/04-stats-and-probability/images/video-prob-and-stats.png)](https://youtu.be/Z5Zy85g4Yjw)

## [Quiz f√∏r forelesning](https://ff-quizzes.netlify.app/en/ds/quiz/6)

## Sannsynlighet og tilfeldige variabler

**Sannsynlighet** er et tall mellom 0 og 1 som uttrykker hvor sannsynlig en **hendelse** er. Det defineres som antall positive utfall (som f√∏rer til hendelsen), delt p√• totalt antall utfall, gitt at alle utfall er like sannsynlige. For eksempel, n√•r vi kaster en terning, er sannsynligheten for √• f√• et partall 3/6 = 0,5.

N√•r vi snakker om hendelser, bruker vi **tilfeldige variabler**. For eksempel vil den tilfeldige variabelen som representerer tallet vi f√•r n√•r vi kaster en terning, ta verdier fra 1 til 6. Mengden av tall fra 1 til 6 kalles **utvalgsrom**. Vi kan snakke om sannsynligheten for at en tilfeldig variabel tar en bestemt verdi, for eksempel P(X=3)=1/6.

Den tilfeldige variabelen i det forrige eksempelet kalles **diskret**, fordi den har et tellbart utvalgsrom, dvs. det finnes separate verdier som kan telles opp. Det finnes tilfeller der utvalgsrommet er et intervall av reelle tall, eller hele mengden av reelle tall. Slike variabler kalles **kontinuerlige**. Et godt eksempel er tidspunktet n√•r bussen ankommer.

## Sannsynlighetsfordeling

I tilfellet med diskrete tilfeldige variabler er det enkelt √• beskrive sannsynligheten for hver hendelse med en funksjon P(X). For hver verdi *s* fra utvalgsrommet *S* vil den gi et tall fra 0 til 1, slik at summen av alle verdier av P(X=s) for alle hendelser blir 1.

Den mest kjente diskrete fordelingen er **uniform fordeling**, der det finnes et utvalgsrom med N elementer, med lik sannsynlighet p√• 1/N for hver av dem.

Det er vanskeligere √• beskrive sannsynlighetsfordelingen til en kontinuerlig variabel, med verdier hentet fra et intervall [a,b], eller hele mengden av reelle tall ‚Ñù. Tenk p√• tilfellet med busstiden. Faktisk, for hvert eksakte tidspunkt *t*, er sannsynligheten for at bussen ankommer akkurat da, 0!

> N√• vet du at hendelser med sannsynlighet 0 skjer, og ganske ofte! I hvert fall hver gang bussen ankommer!

Vi kan bare snakke om sannsynligheten for at en variabel faller innenfor et gitt intervall av verdier, f.eks. P(t<sub>1</sub>‚â§X<t<sub>2</sub>). I dette tilfellet beskrives sannsynlighetsfordelingen av en **tetthetsfunksjon** p(x), slik at

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../1-Introduction/04-stats-and-probability/images/probability-density.png)

En kontinuerlig analog av uniform fordeling kalles **kontinuerlig uniform**, som er definert p√• et endelig intervall. Sannsynligheten for at verdien X faller innenfor et intervall med lengde l er proporsjonal med l, og stiger opp til 1.

En annen viktig fordeling er **normalfordeling**, som vi skal snakke mer om nedenfor.

## Gjennomsnitt, varians og standardavvik

Anta at vi trekker en sekvens av n pr√∏ver av en tilfeldig variabel X: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. Vi kan definere **gjennomsnitt** (eller **aritmetisk middelverdi**) for sekvensen p√• tradisjonelt vis som (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n. N√•r vi √∏ker st√∏rrelsen p√• pr√∏ven (dvs. tar grensen n√•r n‚Üí‚àû), vil vi oppn√• gjennomsnittet (ogs√• kalt **forventning**) for fordelingen. Vi vil betegne forventning med **E**(x).

> Det kan vises at for enhver diskret fordeling med verdier {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} og tilsvarende sannsynligheter p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, vil forventningen v√¶re E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>.

For √• identifisere hvor spredt verdiene er, kan vi beregne variansen œÉ<sup>2</sup> = ‚àë(x<sub>i</sub> - Œº)<sup>2</sup>/n, der Œº er gjennomsnittet for sekvensen. Verdien œÉ kalles **standardavvik**, og œÉ<sup>2</sup> kalles **varians**.

## Typetall, median og kvartiler

Noen ganger representerer ikke gjennomsnittet den "typiske" verdien for dataene p√• en god m√•te. For eksempel, n√•r det finnes noen ekstreme verdier som er helt utenfor rekkevidde, kan de p√•virke gjennomsnittet. Et annet godt m√•l er **median**, en verdi slik at halvparten av datapunktene er lavere enn den, og den andre halvparten - h√∏yere.

For √• hjelpe oss med √• forst√• fordelingen av dataene, er det nyttig √• snakke om **kvartiler**:

* F√∏rste kvartil, eller Q1, er en verdi slik at 25 % av dataene ligger under den
* Tredje kvartil, eller Q3, er en verdi slik at 75 % av dataene ligger under den

Grafisk kan vi representere forholdet mellom median og kvartiler i et diagram kalt **boksplott**:

<img src="images/boxplot_explanation.png" width="50%"/>

Her beregner vi ogs√• **interkvartilavstand** IQR=Q3-Q1, og s√•kalte **uteliggere** - verdier som ligger utenfor grensene [Q1-1.5*IQR,Q3+1.5*IQR].

For en endelig fordeling som inneholder et lite antall mulige verdier, er en god "typisk" verdi den som forekommer oftest, og som kalles **typetall**. Det brukes ofte p√• kategoriske data, som farger. Tenk p√• en situasjon der vi har to grupper mennesker - noen som sterkt foretrekker r√∏dt, og andre som foretrekker bl√•tt. Hvis vi koder farger med tall, vil gjennomsnittsverdien for en favorittfarge v√¶re et sted i det oransje-gr√∏nne spekteret, noe som ikke indikerer den faktiske preferansen til noen av gruppene. Typetallet vil imidlertid v√¶re en av fargene, eller begge fargene, hvis antallet personer som stemmer p√• dem er likt (i dette tilfellet kaller vi utvalget **multimodalt**).

## Data fra virkeligheten

N√•r vi analyserer data fra virkeligheten, er de ofte ikke tilfeldige variabler i streng forstand, i den forstand at vi ikke utf√∏rer eksperimenter med ukjent resultat. For eksempel, vurder et lag med baseballspillere og deres kroppslige data, som h√∏yde, vekt og alder. Disse tallene er ikke akkurat tilfeldige, men vi kan fortsatt bruke de samme matematiske konseptene. For eksempel kan en sekvens av folks vekter betraktes som en sekvens av verdier hentet fra en tilfeldig variabel. Nedenfor er sekvensen av vekter til faktiske baseballspillere fra [Major League Baseball](http://mlb.mlb.com/index.jsp), hentet fra [dette datasettet](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) (for enkelhets skyld vises kun de f√∏rste 20 verdiene):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Merk**: For √• se et eksempel p√• hvordan du jobber med dette datasettet, ta en titt p√• [den medf√∏lgende notatboken](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb). Det finnes ogs√• en rekke utfordringer gjennom denne leksjonen, og du kan fullf√∏re dem ved √• legge til litt kode i den notatboken. Hvis du ikke er sikker p√• hvordan du opererer med data, ikke bekymre deg - vi kommer tilbake til √• jobbe med data ved hjelp av Python senere. Hvis du ikke vet hvordan du kj√∏rer kode i Jupyter Notebook, ta en titt p√• [denne artikkelen](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

Her er boksplottet som viser gjennomsnitt, median og kvartiler for dataene v√•re:

![Vekt boksplott](../../../../1-Introduction/04-stats-and-probability/images/weight-boxplot.png)

Siden dataene v√•re inneholder informasjon om forskjellige spiller**roller**, kan vi ogs√• lage boksplott etter rolle - dette vil gi oss en id√© om hvordan parameterverdiene varierer mellom rollene. Denne gangen vil vi vurdere h√∏yde:

![Boksplott etter rolle](../../../../1-Introduction/04-stats-and-probability/images/boxplot_byrole.png)

Dette diagrammet antyder at h√∏yden til f√∏rstemenn p√• laget i gjennomsnitt er h√∏yere enn h√∏yden til andremenn. Senere i denne leksjonen vil vi l√¶re hvordan vi kan teste denne hypotesen mer formelt, og hvordan vi kan vise at dataene v√•re er statistisk signifikante for √• bevise dette.

> N√•r vi jobber med data fra virkeligheten, antar vi at alle datapunkter er pr√∏ver hentet fra en sannsynlighetsfordeling. Denne antagelsen lar oss bruke maskinl√¶ringsteknikker og bygge fungerende prediktive modeller.

For √• se hvordan fordelingen av dataene v√•re er, kan vi lage en graf kalt et **histogram**. X-aksen vil inneholde et antall forskjellige vektintervaller (s√•kalte **b√∏tter**), og Y-aksen vil vise antall ganger v√•r tilfeldige variabelpr√∏ve var innenfor et gitt intervall.

![Histogram av data fra virkeligheten](../../../../1-Introduction/04-stats-and-probability/images/weight-histogram.png)

Fra dette histogrammet kan du se at alle verdier er sentrert rundt en viss gjennomsnittsvekt, og jo lenger vi beveger oss fra den vekten, desto f√¶rre vekter av den verdien blir observert. Det vil si, det er sv√¶rt usannsynlig at vekten til en baseballspiller vil v√¶re veldig forskjellig fra gjennomsnittsvekten. Variansen i vektene viser i hvilken grad vektene sannsynligvis avviker fra gjennomsnittet.

> Hvis vi tar vektene til andre mennesker, ikke fra baseballigaen, vil fordelingen sannsynligvis v√¶re annerledes. Imidlertid vil formen p√• fordelingen v√¶re den samme, men gjennomsnittet og variansen vil endre seg. S√• hvis vi trener modellen v√•r p√• baseballspillere, vil den sannsynligvis gi feil resultater n√•r den brukes p√• studenter ved et universitet, fordi den underliggende fordelingen er annerledes.

## Normalfordeling

Fordelingen av vekter som vi har sett ovenfor er sv√¶rt typisk, og mange m√•linger fra virkeligheten f√∏lger samme type fordeling, men med forskjellig gjennomsnitt og varians. Denne fordelingen kalles **normalfordeling**, og den spiller en sv√¶rt viktig rolle i statistikk.

√Ö bruke normalfordeling er en korrekt m√•te √• generere tilfeldige vekter for potensielle baseballspillere. N√•r vi kjenner gjennomsnittsvekten `mean` og standardavviket `std`, kan vi generere 1000 vektpr√∏ver p√• f√∏lgende m√•te:
```python
samples = np.random.normal(mean,std,1000)
```

Hvis vi plottet histogrammet for de genererte pr√∏vene, vil vi se et bilde som ligner veldig p√• det som er vist ovenfor. Og hvis vi √∏ker antall pr√∏ver og antall b√∏tter, kan vi generere et bilde av en normalfordeling som er n√¶rmere ideell:

![Normalfordeling med gjennomsnitt=0 og std.avvik=1](../../../../1-Introduction/04-stats-and-probability/images/normal-histogram.png)

*Normalfordeling med gjennomsnitt=0 og std.avvik=1*

## Konfidensintervaller

N√•r vi snakker om vektene til baseballspillere, antar vi at det finnes en viss **tilfeldig variabel W** som tilsvarer den ideelle sannsynlighetsfordelingen av vektene til alle baseballspillere (den s√•kalte **populasjonen**). V√•r sekvens av vekter tilsvarer et utvalg av alle baseballspillere som vi kaller **utvalg**. Et interessant sp√∏rsm√•l er: Kan vi vite parameterne for fordelingen av W, dvs. gjennomsnittet og variansen for populasjonen?

Det enkleste svaret ville v√¶re √• beregne gjennomsnittet og variansen for v√•rt utvalg. Men det kan hende at v√•rt tilfeldige utvalg ikke n√∏yaktig representerer hele populasjonen. Derfor gir det mening √• snakke om **konfidensintervaller**.

> **Konfidensintervall** er en estimering av den sanne middelverdien for populasjonen gitt v√•rt utvalg, som er n√∏yaktig med en viss sannsynlighet (eller **konfidensniv√•**).

Anta at vi har et utvalg X...

1</sub>, ..., X<sub>n</sub> fra v√•r fordeling. Hver gang vi trekker et utvalg fra fordelingen, vil vi ende opp med en forskjellig gjennomsnittsverdi Œº. Dermed kan Œº betraktes som en stokastisk variabel. Et **konfidensintervall** med konfidens p er et par verdier (L<sub>p</sub>,R<sub>p</sub>), slik at **P**(L<sub>p</sub>‚â§Œº‚â§R<sub>p</sub>) = p, alts√• sannsynligheten for at den m√•lte gjennomsnittsverdien faller innenfor intervallet er lik p.

Det g√•r utover v√•r korte introduksjon √• diskutere i detalj hvordan disse konfidensintervallene beregnes. Flere detaljer kan finnes [p√• Wikipedia](https://en.wikipedia.org/wiki/Confidence_interval). Kort sagt definerer vi fordelingen av beregnet utvalgsgjennomsnitt i forhold til populasjonens sanne gjennomsnitt, som kalles **studentfordeling**.

> **Interessant fakta**: Studentfordelingen er oppkalt etter matematikeren William Sealy Gosset, som publiserte sitt arbeid under pseudonymet "Student". Han jobbet i Guinness-bryggeriet, og if√∏lge en av versjonene √∏nsket ikke arbeidsgiveren at allmennheten skulle vite at de brukte statistiske tester for √• bestemme kvaliteten p√• r√•varene.

Hvis vi √∏nsker √• estimere gjennomsnittet Œº av v√•r populasjon med konfidens p, m√• vi ta *(1-p)/2-te persentil* av en Studentfordeling A, som enten kan hentes fra tabeller eller beregnes ved hjelp av innebygde funksjoner i statistikkprogramvare (f.eks. Python, R, osv.). Da vil intervallet for Œº v√¶re gitt av X¬±A*D/‚àön, hvor X er det oppn√•dde gjennomsnittet av utvalget, og D er standardavviket.

> **Merk**: Vi utelater ogs√• diskusjonen om et viktig konsept kalt [frihetsgrader](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)), som er viktig i forhold til Studentfordelingen. Du kan referere til mer komplette b√∏ker om statistikk for √• forst√• dette konseptet dypere.

Et eksempel p√• beregning av konfidensintervall for vekt og h√∏yde er gitt i [tilh√∏rende notatb√∏ker](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb).

| p | Vektgjennomsnitt |
|-----|----------------|
| 0.85 | 201.73¬±0.94 |
| 0.90 | 201.73¬±1.08 |
| 0.95 | 201.73¬±1.28 |

Legg merke til at jo h√∏yere konfidenssannsynligheten er, desto bredere er konfidensintervallet.

## Hypotesetesting 

I v√•rt datasett med baseballspillere finnes det ulike spillerroller, som kan oppsummeres nedenfor (se [tilh√∏rende notatbok](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) for √• se hvordan denne tabellen kan beregnes):

| Rolle | H√∏yde | Vekt | Antall |
|-------|-------|------|--------|
| Catcher | 72.723684 | 204.328947 | 76 |
| Designated_Hitter | 74.222222 | 220.888889 | 18 |
| First_Baseman | 74.000000 | 213.109091 | 55 |
| Outfielder | 73.010309 | 199.113402 | 194 |
| Relief_Pitcher | 74.374603 | 203.517460 | 315 |
| Second_Baseman | 71.362069 | 184.344828 | 58 |
| Shortstop | 71.903846 | 182.923077 | 52 |
| Starting_Pitcher | 74.719457 | 205.163636 | 221 |
| Third_Baseman | 73.044444 | 200.955556 | 45 |

Vi kan legge merke til at gjennomsnittsh√∏yden til f√∏rstemenn er h√∏yere enn for andremenn. Dermed kan vi bli fristet til √• konkludere at **f√∏rstemenn er h√∏yere enn andremenn**.

> Denne p√•standen kalles **en hypotese**, fordi vi ikke vet om dette faktisk er sant eller ikke.

Det er imidlertid ikke alltid √•penbart om vi kan trekke denne konklusjonen. Fra diskusjonen ovenfor vet vi at hvert gjennomsnitt har et tilh√∏rende konfidensintervall, og dermed kan denne forskjellen bare v√¶re en statistisk feil. Vi trenger en mer formell m√•te √• teste hypotesen v√•r p√•.

La oss beregne konfidensintervaller separat for h√∏ydene til f√∏rstemenn og andremenn:

| Konfidens | F√∏rstemenn | Andremenn |
|-----------|------------|-----------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

Vi kan se at under ingen konfidens overlapper intervallene. Dette beviser v√•r hypotese om at f√∏rstemenn er h√∏yere enn andremenn.

Mer formelt er problemet vi l√∏ser √• se om **to sannsynlighetsfordelinger er de samme**, eller i det minste har de samme parameterne. Avhengig av fordelingen m√• vi bruke forskjellige tester for dette. Hvis vi vet at fordelingene v√•re er normale, kan vi bruke **[Student t-test](https://en.wikipedia.org/wiki/Student%27s_t-test)**.

I Student t-test beregner vi den s√•kalte **t-verdien**, som indikerer forskjellen mellom gjennomsnittene, tatt i betraktning variansen. Det er vist at t-verdien f√∏lger **studentfordelingen**, som lar oss finne terskelverdien for et gitt konfidensniv√• **p** (dette kan beregnes eller sl√•s opp i numeriske tabeller). Vi sammenligner deretter t-verdien med denne terskelen for √• godkjenne eller forkaste hypotesen.

I Python kan vi bruke **SciPy**-pakken, som inkluderer funksjonen `ttest_ind` (i tillegg til mange andre nyttige statistiske funksjoner!). Den beregner t-verdien for oss, og gj√∏r ogs√• det omvendte oppslaget av konfidens p-verdi, slik at vi bare kan se p√• konfidensen for √• trekke en konklusjon.

For eksempel gir v√•r sammenligning mellom h√∏ydene til f√∏rstemenn og andremenn f√∏lgende resultater: 
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
I v√•rt tilfelle er p-verdien sv√¶rt lav, noe som betyr at det er sterk evidens for at f√∏rstemenn er h√∏yere.

Det finnes ogs√• andre typer hypoteser vi kan teste, for eksempel:
* √Ö bevise at et gitt utvalg f√∏lger en bestemt fordeling. I v√•rt tilfelle har vi antatt at h√∏ydene er normalfordelte, men dette trenger formell statistisk bekreftelse.
* √Ö bevise at gjennomsnittsverdien av et utvalg tilsvarer en forh√•ndsdefinert verdi.
* √Ö sammenligne gjennomsnittene av flere utvalg (f.eks. hva er forskjellen i lykkeniv√•er mellom ulike aldersgrupper).

## Store talls lov og sentralgrenseteoremet

En av grunnene til at normalfordelingen er s√• viktig, er det s√•kalte **sentralgrenseteoremet**. Anta at vi har et stort utvalg av uavhengige N verdier X<sub>1</sub>, ..., X<sub>N</sub>, trukket fra en hvilken som helst fordeling med gjennomsnitt Œº og varians œÉ<sup>2</sup>. Da, for tilstrekkelig stort N (med andre ord, n√•r N‚Üí‚àû), vil gjennomsnittet Œ£<sub>i</sub>X<sub>i</sub> v√¶re normalfordelt, med gjennomsnitt Œº og varians œÉ<sup>2</sup>/N.

> En annen m√•te √• tolke sentralgrenseteoremet p√• er √• si at uansett fordeling, n√•r du beregner gjennomsnittet av summen av tilfeldige variabelverdier, ender du opp med en normalfordeling.

Fra sentralgrenseteoremet f√∏lger det ogs√• at n√•r N‚Üí‚àû, blir sannsynligheten for at utvalgsgjennomsnittet er lik Œº lik 1. Dette er kjent som **store talls lov**.

## Kovarians og korrelasjon

En av oppgavene i Data Science er √• finne relasjoner mellom data. Vi sier at to sekvenser **korrelerer** n√•r de viser lignende oppf√∏rsel samtidig, dvs. de enten stiger/faller samtidig, eller √©n sekvens stiger n√•r en annen faller og omvendt. Med andre ord ser det ut til √• v√¶re en relasjon mellom de to sekvensene.

> Korrelasjon indikerer ikke n√∏dvendigvis en √•rsakssammenheng mellom to sekvenser; noen ganger kan begge variablene avhenge av en ekstern √•rsak, eller det kan v√¶re ren tilfeldighet at de to sekvensene korrelerer. Likevel er sterk matematisk korrelasjon en god indikasjon p√• at to variabler p√• en eller annen m√•te er koblet.

Matematisk er hovedkonseptet som viser relasjonen mellom to stokastiske variabler **kovarians**, som beregnes slik: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. Vi beregner avviket til begge variablene fra deres gjennomsnittsverdier, og deretter produktet av disse avvikene. Hvis begge variablene avviker sammen, vil produktet alltid v√¶re en positiv verdi, som vil gi positiv kovarians. Hvis begge variablene avviker usynkront (dvs. √©n faller under gjennomsnittet n√•r en annen stiger over gjennomsnittet), vil vi alltid f√• negative tall, som vil gi negativ kovarians. Hvis avvikene er uavhengige, vil de summere seg til omtrent null.

Den absolutte verdien av kovarians sier ikke mye om hvor sterk korrelasjonen er, fordi den avhenger av st√∏rrelsen p√• de faktiske verdiene. For √• normalisere den kan vi dele kovariansen p√• standardavviket til begge variablene for √• f√• **korrelasjon**. Det fine er at korrelasjonen alltid er i omr√•det [-1,1], hvor 1 indikerer sterk positiv korrelasjon mellom verdier, -1 - sterk negativ korrelasjon, og 0 - ingen korrelasjon i det hele tatt (variablene er uavhengige).

**Eksempel**: Vi kan beregne korrelasjonen mellom vekter og h√∏yder til baseballspillere fra datasettet nevnt ovenfor:
```python
print(np.corrcoef(weights,heights))
```
Som et resultat f√•r vi **korrelasjonsmatrisen** som denne:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> Korrelasjonsmatrisen C kan beregnes for et hvilket som helst antall inngangssekvenser S<sub>1</sub>, ..., S<sub>n</sub>. Verdien av C<sub>ij</sub> er korrelasjonen mellom S<sub>i</sub> og S<sub>j</sub>, og diagonalelementene er alltid 1 (som ogs√• er selvkorrelasjonen til S<sub>i</sub>).

I v√•rt tilfelle indikerer verdien 0.53 at det er en viss korrelasjon mellom en persons vekt og h√∏yde. Vi kan ogs√• lage et spredningsdiagram av √©n verdi mot den andre for √• se relasjonen visuelt:

![Forhold mellom vekt og h√∏yde](../../../../1-Introduction/04-stats-and-probability/images/weight-height-relationship.png)

> Flere eksempler p√• korrelasjon og kovarians kan finnes i [tilh√∏rende notatbok](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb).

## Konklusjon

I denne delen har vi l√¶rt:

* grunnleggende statistiske egenskaper ved data, som gjennomsnitt, varians, modus og kvartiler
* ulike fordelinger av stokastiske variabler, inkludert normalfordeling
* hvordan finne korrelasjon mellom ulike egenskaper
* hvordan bruke matematikk og statistikk for √• bevise hypoteser
* hvordan beregne konfidensintervaller for stokastiske variabler gitt et datasett

Selv om dette definitivt ikke er en utt√∏mmende liste over emner innen sannsynlighet og statistikk, b√∏r det v√¶re nok til √• gi deg en god start p√• dette kurset.

## üöÄ Utfordring

Bruk eksempelkoden i notatboken for √• teste andre hypoteser som: 
1. F√∏rstemenn er eldre enn andremenn
2. F√∏rstemenn er h√∏yere enn tredjemenn
3. Shortstops er h√∏yere enn andremenn

## [Quiz etter forelesning](https://ff-quizzes.netlify.app/en/ds/quiz/7)

## Gjennomgang og selvstudium

Sannsynlighet og statistikk er et s√• bredt emne at det fortjener sitt eget kurs. Hvis du er interessert i √• g√• dypere inn i teorien, kan du lese noen av f√∏lgende b√∏ker:

1. [Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/) fra New York University har flotte forelesningsnotater [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (tilgjengelig online)
1. [Peter og Andrew Bruce. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[eksempelkode i R](https://github.com/andrewgbruce/statistics-for-data-scientists)]. 
1. [James D. Miller. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[eksempelkode i R](https://github.com/PacktPublishing/Statistics-for-Data-Science)]

## Oppgave

[Lite diabetesstudie](assignment.md)

## Kreditering

Denne leksjonen er laget med ‚ô•Ô∏è av [Dmitry Soshnikov](http://soshnikov.com)

---

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi tilstreber n√∏yaktighet, vennligst v√¶r oppmerksom p√• at automatiske oversettelser kan inneholde feil eller un√∏yaktigheter. Det originale dokumentet p√• sitt opprinnelige spr√•k b√∏r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.