<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1341f6da63d434f5ba31b08ea951b02c",
  "translation_date": "2025-09-05T22:29:59+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "no"
}
-->
# Introduksjon til Dataetikk

|![ Sketchnote av [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Data Science Ethics - _Sketchnote av [@nitya](https://twitter.com/nitya)_ |

---

Vi er alle databorgere som lever i en verden preget av data.

Markedsanalyser viser at innen 2022 vil 칠n av tre store organisasjoner kj칮pe og selge data gjennom online [markedsplasser og utvekslinger](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Som **apputviklere** vil vi oppleve at det blir enklere og billigere 친 integrere datadrevne innsikter og algoritmestyrt automatisering i daglige brukeropplevelser. Men etter hvert som AI blir mer utbredt, m친 vi ogs친 forst친 de potensielle skadene som kan oppst친 ved [v친penisering](https://www.youtube.com/watch?v=TQHs8SA1qpk) av slike algoritmer i stor skala.

Trender viser ogs친 at vi vil skape og konsumere over [180 zettabyte](https://www.statista.com/statistics/871513/worldwide-data-created/) med data innen 2025. Som **dataforskere** gir dette oss enest친ende tilgang til personlig data. Dette betyr at vi kan bygge atferdsprofiler av brukere og p친virke beslutningstaking p친 m친ter som skaper en [illusjon av fri vilje](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice), samtidig som vi potensielt dytter brukere mot utfall vi foretrekker. Det reiser ogs친 bredere sp칮rsm친l om databeskyttelse og brukerrettigheter.

Dataetikk er n친 _n칮dvendige retningslinjer_ for dataforskning og ingeni칮rarbeid, som hjelper oss med 친 minimere potensielle skader og utilsiktede konsekvenser av v친re datadrevne handlinger. [Gartner Hype Cycle for AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) identifiserer relevante trender innen digital etikk, ansvarlig AI og AI-styring som n칮kkeldrivere for st칮rre megatrender rundt _demokratisering_ og _industrialisering_ av AI.

![Gartner's Hype Cycle for AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

I denne leksjonen skal vi utforske det fascinerende omr친det dataetikk - fra grunnleggende konsepter og utfordringer, til casestudier og anvendte AI-konsepter som styring - som hjelper med 친 etablere en etikkultur i team og organisasjoner som jobber med data og AI.

## [Quiz f칮r forelesning](https://ff-quizzes.netlify.app/en/ds/quiz/2) 游꿢

## Grunnleggende definisjoner

La oss starte med 친 forst친 grunnleggende terminologi.

Ordet "etikk" kommer fra det [greske ordet "ethikos"](https://en.wikipedia.org/wiki/Ethics) (og roten "ethos") som betyr _karakter eller moralsk natur_. 

**Etikk** handler om de delte verdiene og moralske prinsippene som styrer v친r oppf칮rsel i samfunnet. Etikk er ikke basert p친 lover, men p친 allment aksepterte normer for hva som er "riktig vs. galt". Imidlertid kan etiske hensyn p친virke initiativer for selskapsstyring og myndighetsreguleringer som skaper flere insentiver for samsvar.

**Dataetikk** er en [ny gren av etikk](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1) som "studerer og evaluerer moralske problemer knyttet til _data, algoritmer og tilh칮rende praksis_". Her fokuserer **"data"** p친 handlinger relatert til generering, registrering, kuratering, behandling, spredning, deling og bruk, **"algoritmer"** fokuserer p친 AI, agenter, maskinl칝ring og roboter, og **"praksis"** fokuserer p친 temaer som ansvarlig innovasjon, programmering, hacking og etiske koder.

**Anvendt etikk** er den [praktiske anvendelsen av moralske hensyn](https://en.wikipedia.org/wiki/Applied_ethics). Det er prosessen med aktivt 친 unders칮ke etiske sp칮rsm친l i konteksten av _virkelige handlinger, produkter og prosesser_, og ta korrigerende tiltak for 친 sikre at disse forblir i tr친d med v친re definerte etiske verdier.

**Etikkultur** handler om [_operasjonalisering_ av anvendt etikk](https://hbr.org/2019/05/how-to-design-an-ethical-organization) for 친 sikre at v친re etiske prinsipper og praksiser blir tatt i bruk p친 en konsekvent og skalerbar m친te i hele organisasjonen. Vellykkede etikkulturer definerer organisasjonsomfattende etiske prinsipper, gir meningsfulle insentiver for samsvar, og forsterker etiske normer ved 친 oppmuntre og forsterke 칮nsket atferd p친 alle niv친er i organisasjonen.

## Etiske konsepter

I denne delen skal vi diskutere konsepter som **delte verdier** (prinsipper) og **etiske utfordringer** (problemer) for dataetikk - og utforske **casestudier** som hjelper deg med 친 forst친 disse konseptene i virkelige kontekster.

### 1. Etiske prinsipper

Hver dataetikkstrategi begynner med 친 definere _etiske prinsipper_ - de "delte verdiene" som beskriver akseptabel oppf칮rsel og veileder samsvarende handlinger i v친re data- og AI-prosjekter. Du kan definere disse p친 individ- eller teamniv친. Imidlertid skisserer de fleste store organisasjoner disse i en _etisk AI_-misjonserkl칝ring eller rammeverk som er definert p친 selskapsniv친 og h친ndhevet konsekvent p친 tvers av alle team.

**Eksempel:** Microsofts [Responsible AI](https://www.microsoft.com/en-us/ai/responsible-ai)-misjonserkl칝ring lyder: _"Vi er forpliktet til 친 fremme AI drevet av etiske prinsipper som setter mennesker f칮rst"_ - og identifiserer 6 etiske prinsipper i rammeverket nedenfor:

![Responsible AI hos Microsoft](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

La oss kort utforske disse prinsippene. _칀penhet_ og _ansvarlighet_ er grunnleggende verdier som de andre prinsippene bygger p친 - s친 la oss begynne der:

* [**Ansvarlighet**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) gj칮r ut칮vere _ansvarlige_ for sine data- og AI-operasjoner, og samsvar med disse etiske prinsippene.
* [**칀penhet**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) sikrer at data- og AI-handlinger er _forst친elige_ (tolkbare) for brukere, og forklarer hva og hvorfor bak beslutninger.
* [**Rettferdighet**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - fokuserer p친 친 sikre at AI behandler _alle mennesker_ rettferdig, og adresserer eventuelle systemiske eller implisitte sosio-tekniske skjevheter i data og systemer.
* [**P친litelighet og sikkerhet**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - sikrer at AI oppf칮rer seg _konsekvent_ med definerte verdier, og minimerer potensielle skader eller utilsiktede konsekvenser.
* [**Personvern og sikkerhet**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - handler om 친 forst친 dataopprinnelse og gi _databeskyttelse og relaterte rettigheter_ til brukere.
* [**Inkludering**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - handler om 친 designe AI-l칮sninger med intensjon, og tilpasse dem for 친 m칮te et _bredt spekter av menneskelige behov_ og evner.

> 游뚿 Tenk p친 hva din dataetikk-misjonserkl칝ring kunne v칝rt. Utforsk etiske AI-rammeverk fra andre organisasjoner - her er eksempler fra [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles), og [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Hvilke delte verdier har de til felles? Hvordan relaterer disse prinsippene seg til AI-produktet eller industrien de opererer i?

### 2. Etiske utfordringer

N친r vi har definert etiske prinsipper, er neste steg 친 evaluere v친re data- og AI-handlinger for 친 se om de samsvarer med disse delte verdiene. Tenk p친 handlingene dine i to kategorier: _datainnsamling_ og _algoritmedesign_. 

Ved datainnsamling vil handlingene sannsynligvis involvere **personlig data** eller personlig identifiserbar informasjon (PII) for identifiserbare levende individer. Dette inkluderer [mangfoldige elementer av ikke-personlig data](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) som _samlet sett_ identifiserer en person. Etiske utfordringer kan relatere seg til _databeskyttelse_, _dataeierskap_, og relaterte temaer som _informert samtykke_ og _immaterielle rettigheter_ for brukere.

Ved algoritmedesign vil handlingene involvere innsamling og kuratering av **datasett**, og deretter bruke dem til 친 trene og distribuere **datamodeller** som forutsier utfall eller automatiserer beslutninger i virkelige kontekster. Etiske utfordringer kan oppst친 fra _datasett-skjevhet_, _datakvalitetsproblemer_, _urettferdighet_, og _feilrepresentasjon_ i algoritmer - inkludert noen problemer som er systemiske i natur.

I begge tilfeller fremhever etiske utfordringer omr친der der v친re handlinger kan komme i konflikt med v친re delte verdier. For 친 oppdage, redusere, minimere eller eliminere disse bekymringene - m친 vi stille moralske "ja/nei"-sp칮rsm친l relatert til v친re handlinger, og deretter ta korrigerende tiltak etter behov. La oss se p친 noen etiske utfordringer og de moralske sp칮rsm친lene de reiser:

#### 2.1 Dataeierskap

Datainnsamling involverer ofte personlig data som kan identifisere datasubjektene. [Dataeierskap](https://permission.io/blog/data-ownership) handler om _kontroll_ og [_brukerrettigheter_](https://permission.io/blog/data-ownership) relatert til opprettelse, behandling og spredning av data. 

De moralske sp칮rsm친lene vi m친 stille er: 
 * Hvem eier dataene? (bruker eller organisasjon)
 * Hvilke rettigheter har datasubjektene? (f.eks. tilgang, sletting, portabilitet)
 * Hvilke rettigheter har organisasjoner? (f.eks. rette opp ondsinnede brukeranmeldelser)

#### 2.2 Informert samtykke

[Informert samtykke](https://legaldictionary.net/informed-consent/) definerer handlingen der brukere samtykker til en handling (som datainnsamling) med en _full forst친else_ av relevante fakta, inkludert form친l, potensielle risikoer og alternativer. 

Sp칮rsm친l 친 utforske her er:
 * Ga brukeren (datasubjektet) tillatelse til datainnsamling og bruk?
 * Forsto brukeren form친let med datainnsamlingen?
 * Forsto brukeren de potensielle risikoene ved deltakelsen?

#### 2.3 Immaterielle rettigheter

[Immaterielle rettigheter](https://en.wikipedia.org/wiki/Intellectual_property) refererer til immaterielle skapelser som resultat av menneskelig initiativ, som kan _ha 칮konomisk verdi_ for individer eller bedrifter. 

Sp칮rsm친l 친 utforske her er:
 * Hadde de innsamlede dataene 칮konomisk verdi for en bruker eller bedrift?
 * Har **brukeren** immaterielle rettigheter her?
 * Har **organisasjonen** immaterielle rettigheter her?
 * Hvis disse rettighetene eksisterer, hvordan beskytter vi dem?

#### 2.4 Databeskyttelse

[Databeskyttelse](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) eller informasjonsbeskyttelse refererer til bevaring av brukerens personvern og beskyttelse av brukerens identitet med hensyn til personlig identifiserbar informasjon. 

Sp칮rsm친l 친 utforske her er:
 * Er brukernes (personlige) data sikret mot hacking og lekkasjer?
 * Er brukernes data kun tilgjengelig for autoriserte brukere og kontekster?
 * Bevares brukernes anonymitet n친r data deles eller spres?
 * Kan en bruker bli avidentifisert fra anonymiserte datasett?

#### 2.5 Rett til 친 bli glemt

[Rett til 친 bli glemt](https://en.wikipedia.org/wiki/Right_to_be_forgotten) eller [rett til sletting](https://www.gdpreu.org/right-to-be-forgotten/) gir ekstra beskyttelse av personlig data til brukere. Spesielt gir det brukere rett til 친 be om sletting eller fjerning av personlig data fra internett-s칮k og andre steder, _under spesifikke omstendigheter_ - slik at de kan f친 en ny start online uten at tidligere handlinger holdes mot dem.

Sp칮rsm친l 친 utforske her er:
 * Tillater systemet datasubjekter 친 be om sletting?
 * B칮r tilbaketrekking av brukersamtykke utl칮se automatisk sletting?
 * Ble data samlet inn uten samtykke eller p친 ulovlig vis?
 * Er vi i samsvar med myndighetsreguleringer for databeskyttelse?

#### 2.6 Datasett-skjevhet

Datasett eller [innsamlingsskjevhet](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) handler om 친 velge et _ikke-representativt_ datasett for algoritmeutvikling, noe som kan skape potensielle urettferdigheter i resultatene for ulike grupper. Typer skjevhet inkluderer utvalgs- eller pr칮vetakingsskjevhet, frivillighetsskjevhet og instrumentell skjevhet. 

Sp칮rsm친l 친 utforske her er:
 * Rekrutterte vi et representativt sett med datasubjekter?
 * Testet vi v친rt innsamlede eller kuraterte datasett for ulike skjevheter?
 * Kan vi redusere eller fjerne oppdagede skjevheter?

#### 2.7 Datakvalitet

[Datakvalitet](https://lakefs.io/data-quality-testing/) ser p친 gyldigheten av det kuraterte datasettet som brukes til 친 utvikle v친re algoritmer, og sjekker om funksjoner og poster oppfyller kravene til n칮yaktighet og konsistens som trengs for v친rt AI-form친l.

Sp칮rsm친l 친 utforske her er:
 * Fanget vi gyldige _funksjoner_ for v친rt brukstilfelle?
 * Ble data fanget _konsekvent_ p친 tvers av ulike datakilder?
 * Er datasettet _komplett_ for ulike forhold eller scenarier?
 * Er informasjonen fanget _n칮yaktig_ i 친 reflektere virkeligheten?

#### 2.8 Algoritme-rettferdighet
[Algorithmisk rettferdighet](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) unders칮ker om algoritmedesign systematisk diskriminerer spesifikke undergrupper av datasubjekter, noe som kan f칮re til [potensielle skader](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) innen _fordeling_ (der ressurser nektes eller holdes tilbake fra denne gruppen) og _tjenestekvalitet_ (der AI ikke er like n칮yaktig for noen undergrupper som for andre).

Sp칮rsm친l 친 utforske her er:
 * Evaluerte vi modellens n칮yaktighet for ulike undergrupper og forhold?
 * Unders칮kte vi systemet for potensielle skader (f.eks. stereotypier)?
 * Kan vi revidere data eller trene opp modeller p친 nytt for 친 redusere identifiserte skader?

Utforsk ressurser som [AI Fairness-sjekklister](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) for 친 l칝re mer.

#### 2.9 Feilrepresentasjon

[Datamisrepresentasjon](https://www.sciencedirect.com/topics/computer-science/misrepresentation) handler om 친 sp칮rre om vi kommuniserer innsikter fra 칝rlig rapporterte data p친 en villedende m친te for 친 st칮tte en 칮nsket fortelling.

Sp칮rsm친l 친 utforske her er:
 * Rapporterer vi ufullstendige eller un칮yaktige data?
 * Visualiserer vi data p친 en m친te som f칮rer til misvisende konklusjoner?
 * Bruker vi selektive statistiske teknikker for 친 manipulere resultater?
 * Finnes det alternative forklaringer som kan gi en annen konklusjon?

#### 2.10 Fri vilje
[Illusjonen av fri vilje](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) oppst친r n친r systemets "valgarkitekturer" bruker beslutningsalgoritmer for 친 p친virke folk til 친 ta et foretrukket utfall, samtidig som det ser ut som om de har alternativer og kontroll. Disse [m칮rke m칮nstrene](https://www.darkpatterns.org/) kan for친rsake sosial og 칮konomisk skade for brukere. Fordi brukerbeslutninger p친virker atferdsprofiler, kan disse handlingene potensielt drive fremtidige valg som forsterker eller utvider virkningen av disse skadene.

Sp칮rsm친l 친 utforske her er:
 * Forsto brukeren konsekvensene av 친 ta det valget?
 * Var brukeren klar over (alternative) valg og fordeler og ulemper ved hvert?
 * Kan brukeren senere omgj칮re et automatisert eller p친virket valg?

### 3. Case-studier

For 친 sette disse etiske utfordringene i en virkelighetsn칝r kontekst, er det nyttig 친 se p친 case-studier som fremhever potensielle skader og konsekvenser for enkeltpersoner og samfunnet n친r slike etiske brudd overses.

Her er noen eksempler:

| Etisk utfordring | Case-studie  | 
|--- |--- |
| **Informert samtykke** | 1972 - [Tuskegee-syfilisstudien](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - Afroamerikanske menn som deltok i studien ble lovet gratis medisinsk behandling, _men ble lurt_ av forskere som ikke informerte deltakerne om diagnosen eller tilgjengelig behandling. Mange d칮de, og partnere eller barn ble p친virket; studien varte i 40 친r. | 
| **Datapersonvern** | 2007 - [Netflix-dataprisen](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) ga forskere _10 millioner anonymiserte filmvurderinger fra 50 000 kunder_ for 친 forbedre anbefalingsalgoritmer. Forskere klarte imidlertid 친 korrelere anonymiserte data med personlig identifiserbare data i _eksterne datasett_ (f.eks. IMDb-kommentarer) - og "de-anonymiserte" dermed noen Netflix-abonnenter.|
| **Innsamlingsskjevhet**  | 2013 - Byen Boston [utviklet Street Bump](https://www.boston.gov/transportation/street-bump), en app som lot innbyggere rapportere hull i veien, og ga byen bedre data for 친 finne og fikse problemer. Imidlertid hadde [folk i lavinntektsgrupper mindre tilgang til biler og telefoner](https://hbr.org/2013/04/the-hidden-biases-in-big-data), noe som gjorde deres veiproblemer usynlige i appen. Utviklere samarbeidet med akademikere for 친 l칮se _rettferdig tilgang og digitale skiller_. |
| **Algoritmisk rettferdighet**  | 2018 - MITs [Gender Shades-studie](http://gendershades.org/overview.html) evaluerte n칮yaktigheten til AI-produkter for kj칮nnsidentifikasjon og avdekket forskjeller i n칮yaktighet for kvinner og personer med m칮rk hud. Et [2019 Apple Card](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) s친 ut til 친 tilby mindre kreditt til kvinner enn menn. Begge eksemplene illustrerer problemer med algoritmisk skjevhet som f칮rer til sosio칮konomiske skader.|
| **Datamisrepresentasjon** | 2020 - [Georgia Department of Public Health publiserte COVID-19-diagrammer](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) som s친 ut til 친 villede innbyggerne om trender i bekreftede tilfeller med ikke-kronologisk rekkef칮lge p친 x-aksen. Dette illustrerer feilrepresentasjon gjennom visualiseringstriks. |
| **Illusjon av fri vilje** | 2020 - L칝ringsappen [ABCmouse betalte $10M for 친 l칮se en FTC-klage](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/) der foreldre ble fanget i 친 betale for abonnementer de ikke kunne kansellere. Dette illustrerer m칮rke m칮nstre i valgarkitekturer, der brukere ble p친virket til potensielt skadelige valg. |
| **Datapersonvern og brukerrettigheter** | 2021 - Facebook [datainnbrudd](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) eksponerte data fra 530 millioner brukere, noe som resulterte i et forlik p친 $5 milliarder med FTC. Facebook nektet imidlertid 친 varsle brukerne om bruddet, noe som br칮t brukerrettigheter rundt datatransparens og tilgang. |

Vil du utforske flere case-studier? Sjekk ut disse ressursene:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - etiske dilemmaer p친 tvers av ulike bransjer. 
* [Data Science Ethics course](https://www.coursera.org/learn/data-science-ethics#syllabus) - utforsker viktige case-studier.
* [Where things have gone wrong](https://deon.drivendata.org/examples/) - deon-sjekkliste med eksempler.


> 游뚿 Tenk p친 case-studiene du har sett - har du opplevd, eller blitt p친virket av, en lignende etisk utfordring i ditt liv? Kan du komme p친 minst 칠n annen case-studie som illustrerer en av de etiske utfordringene vi har diskutert i denne delen?

## Anvendt etikk

Vi har snakket om etiske konsepter, utfordringer og case-studier i virkelighetsn칝re kontekster. Men hvordan kommer vi i gang med 친 _anvende_ etiske prinsipper og praksiser i prosjektene v친re? Og hvordan kan vi _operasjonalisere_ disse praksisene for bedre styring? La oss utforske noen l칮sninger fra virkeligheten:

### 1. Profesjonelle retningslinjer

Profesjonelle retningslinjer tilbyr en m친te for organisasjoner 친 "inspirere" medlemmer til 친 st칮tte deres etiske prinsipper og misjonserkl칝ring. Retningslinjer er _moralske veiledninger_ for profesjonell atferd, som hjelper ansatte eller medlemmer med 친 ta beslutninger som samsvarer med organisasjonens prinsipper. De er kun effektive dersom medlemmene frivillig f칮lger dem; mange organisasjoner tilbyr imidlertid ogs친 bel칮nninger og sanksjoner for 친 motivere etterlevelse.

Eksempler inkluderer:

 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Code of Ethics
 * [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Code of Conduct (opprettet 2013)
 * [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (siden 1993)

> 游뚿 Tilh칮rer du en profesjonell ingeni칮r- eller datavitenskapsorganisasjon? Utforsk nettsiden deres for 친 se om de definerer en profesjonell etisk kodeks. Hva sier dette om deres etiske prinsipper? Hvordan "inspirerer" de medlemmene til 친 f칮lge koden?

### 2. Etiske sjekklister

Mens profesjonelle retningslinjer definerer n칮dvendig _etisk atferd_ fra ut칮vere, har de [kjente begrensninger](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) i h친ndhevelse, spesielt i storskala prosjekter. I stedet anbefaler mange eksperter innen datavitenskap [sjekklister](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), som kan **koble prinsipper til praksis** p친 mer deterministiske og handlingsrettede m친ter.

Sjekklister omgj칮r sp칮rsm친l til "ja/nei"-oppgaver som kan operasjonaliseres, slik at de kan spores som en del av standard arbeidsflyter for produktlansering.

Eksempler inkluderer:
 * [Deon](https://deon.drivendata.org/) - en generell sjekkliste for dataetikk laget fra [bransjeanbefalinger](https://deon.drivendata.org/#checklist-citations) med et kommandolinjeverkt칮y for enkel integrasjon.
 * [Privacy Audit Checklist](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - gir generell veiledning for informasjonsbehandling fra juridiske og sosiale eksponeringsperspektiver.
 * [AI Fairness Checklist](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - laget av AI-ut칮vere for 친 st칮tte adopsjon og integrasjon av rettferdighetssjekker i AI-utviklingssykluser.
 * [22 sp칮rsm친l for etikk i data og AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - et mer 친pent rammeverk, strukturert for innledende utforskning av etiske problemstillinger i design, implementering og organisatoriske kontekster.

### 3. Etiske reguleringer

Etikk handler om 친 definere felles verdier og gj칮re det rette _frivillig_. **Etterlevelse** handler om _친 f칮lge loven_ der den er definert. **Styring** dekker bredt alle m친tene organisasjoner opererer p친 for 친 h친ndheve etiske prinsipper og overholde etablerte lover.

I dag tar styring to former innen organisasjoner. For det f칮rste handler det om 친 definere **etiske AI-prinsipper** og etablere praksiser for 친 operasjonalisere adopsjon p친 tvers av alle AI-relaterte prosjekter i organisasjonen. For det andre handler det om 친 overholde alle myndighetsp친lagte **databeskyttelsesreguleringer** for regionene organisasjonen opererer i.

Eksempler p친 databeskyttelses- og personvernreguleringer:

 * `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - regulerer _f칮deral regjering_ sin innsamling, bruk og deling av personlig informasjon.
 * `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - beskytter personlig helsedata.
 * `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - beskytter dataprivacy for barn under 13 친r.
 * `2018`, [General Data Protection Regulation (GDPR)](https://gdpr-info.eu/) - gir brukerrettigheter, databeskyttelse og personvern.
 * `2018`, [California Consumer Privacy Act (CCPA)](https://www.oag.ca.gov/privacy/ccpa) gir forbrukere flere _rettigheter_ over deres (personlige) data.
 * `2021`, Kinas [Personopplysningsvernslov](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) ble nettopp vedtatt, og skaper en av verdens sterkeste online databeskyttelsesreguleringer.

> 游뚿 Den europeiske unionens GDPR (General Data Protection Regulation) forblir en av de mest innflytelsesrike databeskyttelsesreguleringene i dag. Visste du at den ogs친 definerer [8 brukerrettigheter](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) for 친 beskytte borgernes digitale personvern og personopplysninger? L칝r om hva disse er, og hvorfor de er viktige.

### 4. Etisk kultur

Merk at det fortsatt er et immaterielt gap mellom _etterlevelse_ (친 gj칮re nok for 친 oppfylle "lovens bokstav") og 친 adressere [systemiske problemer](https://www.coursera.org/learn/data-science-ethics/home/week/4) (som fastl친sthet, informasjonsasymmetri og fordelingsurettferdighet) som kan akselerere v친peniseringen av AI.

Det sistnevnte krever [samarbeidsbaserte tiln칝rminger for 친 definere etiske kulturer](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f) som bygger emosjonelle forbindelser og konsistente felles verdier _p친 tvers av organisasjoner_ i bransjen. Dette krever mer [formaliserte dataetiske kulturer](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) i organisasjoner - som lar _hvem som helst_ [trekke Andon-snoren](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (for 친 reise etiske bekymringer tidlig i prosessen) og gj칮re _etiske vurderinger_ (f.eks. i ansettelser) til et kjernekrav for teamdannelse i AI-prosjekter.

---
## [Etterforelesningsquiz](https://ff-quizzes.netlify.app/en/ds/quiz/3) 游꿢
## Gjennomgang og selvstudium 

Kurs og b칮ker hjelper med 친 forst친 kjernebegreper og utfordringer innen etikk, mens case-studier og verkt칮y hjelper med anvendt etikk i virkelige kontekster. Her er noen ressurser for 친 komme i gang:

* [Machine Learning For Beginners](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - leksjon om rettferdighet, fra Microsoft.
* [Prinsipper for ansvarlig AI](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - gratis l칝ringssti fra Microsoft Learn.
* [Etikk og datavitenskap](https://resources.oreilly.com/examples/0636920203964) - O'Reilly EBook (M. Loukides, H. Mason m.fl.)
* [Etikk innen datavitenskap](https://www.coursera.org/learn/data-science-ethics#syllabus) - nettkurs fra University of Michigan.
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - casestudier fra University of Texas.

# Oppgave

[Skriv en casestudie om dataetikk](assignment.md)

---

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi tilstreber n칮yaktighet, vennligst v칝r oppmerksom p친 at automatiske oversettelser kan inneholde feil eller un칮yaktigheter. Det originale dokumentet p친 sitt opprinnelige spr친k b칮r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst친elser eller feiltolkninger som oppst친r ved bruk av denne oversettelsen.