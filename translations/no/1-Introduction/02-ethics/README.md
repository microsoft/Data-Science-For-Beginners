<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8796f41f566a0a8ebb72863a83d558ed",
  "translation_date": "2025-08-26T21:23:49+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "no"
}
-->
# Introduksjon til Dataetikk

|![ Sketchnote av [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Data Science Ethics - _Sketchnote av [@nitya](https://twitter.com/nitya)_ |

---

Vi er alle databorgerne som lever i en datafisert verden.

Markedsanalyser viser at innen 2022 vil 1 av 3 store organisasjoner kj√∏pe og selge dataene sine gjennom nettbaserte [markedsplasser og b√∏rser](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Som **apputviklere** vil vi oppleve at det blir enklere og billigere √• integrere datadrevne innsikter og algoritmestyrt automatisering i daglige brukeropplevelser. Men etter hvert som AI blir mer utbredt, m√• vi ogs√• forst√• de potensielle skadene som kan oppst√• ved [v√•penisering](https://www.youtube.com/watch?v=TQHs8SA1qpk) av slike algoritmer i stor skala.

Trender viser ogs√• at vi innen 2025 vil skape og konsumere over [180 zettabyte](https://www.statista.com/statistics/871513/worldwide-data-created/) med data. Som **datascientists** gir dette oss enest√•ende tilgang til personopplysninger. Dette betyr at vi kan bygge atferdsprofiler av brukere og p√•virke beslutningstaking p√• m√•ter som skaper en [illusjon av fritt valg](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice), samtidig som vi potensielt dytter brukere mot utfall vi foretrekker. Det reiser ogs√• st√∏rre sp√∏rsm√•l om databeskyttelse og brukerrettigheter.

Dataetikk er n√• _n√∏dvendige retningslinjer_ for datavitenskap og ingeni√∏rarbeid, som hjelper oss med √• minimere potensielle skader og utilsiktede konsekvenser av v√•re datadrevne handlinger. [Gartner Hype Cycle for AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) identifiserer relevante trender innen digital etikk, ansvarlig AI og AI-styring som n√∏kkeldrivere for st√∏rre megatrender rundt _demokratisering_ og _industrialisering_ av AI.

![Gartner's Hype Cycle for AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

I denne leksjonen skal vi utforske det fascinerende omr√•det dataetikk - fra kjernebegreper og utfordringer til casestudier og anvendte AI-konsepter som styring - som bidrar til √• etablere en etikkultur i team og organisasjoner som jobber med data og AI.

## [Quiz f√∏r forelesning](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/2) üéØ

## Grunnleggende definisjoner

La oss starte med √• forst√• grunnleggende terminologi.

Ordet "etikk" kommer fra det [greske ordet "ethikos"](https://en.wikipedia.org/wiki/Ethics) (og roten "ethos") som betyr _karakter eller moralsk natur_. 

**Etikk** handler om de delte verdiene og moralske prinsippene som styrer v√•r oppf√∏rsel i samfunnet. Etikk er ikke basert p√• lover, men p√• allment aksepterte normer for hva som er "riktig vs. galt". Likevel kan etiske vurderinger p√•virke initiativer for selskapsstyring og myndighetsreguleringer som skaper flere insentiver for samsvar.

**Dataetikk** er en [ny gren av etikk](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1) som "studerer og evaluerer moralske problemer knyttet til _data, algoritmer og tilh√∏rende praksiser_". Her fokuserer **"data"** p√• handlinger knyttet til generering, registrering, kuratering, behandling, spredning, deling og bruk, **"algoritmer"** p√• AI, agenter, maskinl√¶ring og roboter, og **"praksiser"** p√• temaer som ansvarlig innovasjon, programmering, hacking og etiske koder.

**Anvendt etikk** er den [praktiske anvendelsen av moralske vurderinger](https://en.wikipedia.org/wiki/Applied_ethics). Det er prosessen med aktivt √• unders√∏ke etiske sp√∏rsm√•l i konteksten av _virkelige handlinger, produkter og prosesser_, og ta korrigerende tiltak for √• sikre at disse forblir i tr√•d med v√•re definerte etiske verdier.

**Etikkultur** handler om [_operasjonalisering_ av anvendt etikk](https://hbr.org/2019/05/how-to-design-an-ethical-organization) for √• sikre at v√•re etiske prinsipper og praksiser blir vedtatt p√• en konsekvent og skalerbar m√•te i hele organisasjonen. Vellykkede etikkulturer definerer organisasjonsomfattende etiske prinsipper, gir meningsfulle insentiver for samsvar og forsterker etiske normer ved √• oppmuntre og forsterke √∏nsket atferd p√• alle niv√•er i organisasjonen.

## Etiske konsepter

I denne delen skal vi diskutere konsepter som **delte verdier** (prinsipper) og **etiske utfordringer** (problemer) for dataetikk - og utforske **casestudier** som hjelper deg med √• forst√• disse konseptene i virkelige sammenhenger.

### 1. Etiske prinsipper

Hver dataetikkstrategi begynner med √• definere _etiske prinsipper_ - de "delte verdiene" som beskriver akseptabel atferd og veileder samsvarende handlinger i v√•re data- og AI-prosjekter. Du kan definere disse p√• individ- eller teamniv√•. Imidlertid skisserer de fleste store organisasjoner disse i en _etisk AI_-misjonserkl√¶ring eller rammeverk som er definert p√• bedriftsniv√• og h√•ndheves konsekvent p√• tvers av alle team.

**Eksempel:** Microsofts [Responsible AI](https://www.microsoft.com/en-us/ai/responsible-ai)-misjonserkl√¶ring lyder: _"Vi er forpliktet til √• fremme AI drevet av etiske prinsipper som setter mennesker f√∏rst"_ - og identifiserer 6 etiske prinsipper i rammeverket nedenfor:

![Responsible AI hos Microsoft](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

La oss kort utforske disse prinsippene. _√Öpenhet_ og _ansvarlighet_ er grunnleggende verdier som de andre prinsippene bygger p√• - s√• la oss starte der:

* [**Ansvarlighet**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) gj√∏r ut√∏vere _ansvarlige_ for sine data- og AI-operasjoner og samsvar med disse etiske prinsippene.
* [**√Öpenhet**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) sikrer at data- og AI-handlinger er _forst√•elige_ (tolkbare) for brukere, og forklarer hva og hvorfor bak beslutninger.
* [**Rettferdighet**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) fokuserer p√• √• sikre at AI behandler _alle mennesker_ rettferdig, og adresserer eventuelle systemiske eller implisitte sosio-tekniske skjevheter i data og systemer.
* [**P√•litelighet og sikkerhet**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) sikrer at AI oppf√∏rer seg _konsekvent_ med definerte verdier, og minimerer potensielle skader eller utilsiktede konsekvenser.
* [**Personvern og sikkerhet**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) handler om √• forst√• dataenes opprinnelse og gi _personvern og relaterte beskyttelser_ til brukere.
* [**Inkludering**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) handler om √• designe AI-l√∏sninger med intensjon, og tilpasse dem for √• m√∏te et _bredt spekter av menneskelige behov_ og evner.

> üö® Tenk p√• hva din dataetikk-misjonserkl√¶ring kunne v√¶rt. Utforsk etiske AI-rammeverk fra andre organisasjoner - her er eksempler fra [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles) og [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Hvilke delte verdier har de til felles? Hvordan relaterer disse prinsippene seg til AI-produktet eller bransjen de opererer i?

### 2. Etiske utfordringer

N√•r vi har definert etiske prinsipper, er neste steg √• evaluere v√•re data- og AI-handlinger for √• se om de er i tr√•d med disse delte verdiene. Tenk p√• handlingene dine i to kategorier: _datainnsamling_ og _algoritmedesign_.

Ved datainnsamling vil handlinger sannsynligvis involvere **personopplysninger** eller personlig identifiserbar informasjon (PII) for identifiserbare levende individer. Dette inkluderer [mangfoldige elementer av ikke-personlige data](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) som _samlet sett_ identifiserer en person. Etiske utfordringer kan relatere seg til _personvern_, _dataeierskap_ og relaterte temaer som _informert samtykke_ og _immaterielle rettigheter_ for brukere.

Ved algoritmedesign vil handlinger involvere innsamling og kuratering av **datasett**, og deretter bruke dem til √• trene og distribuere **datamodeller** som forutsier utfall eller automatiserer beslutninger i virkelige sammenhenger. Etiske utfordringer kan oppst√• fra _datasett-skjevhet_, _datakvalitetsproblemer_, _urettferdighet_ og _feilrepresentasjon_ i algoritmer - inkludert noen problemer som er systemiske i natur.

I begge tilfeller fremhever etiske utfordringer omr√•der der v√•re handlinger kan komme i konflikt med v√•re delte verdier. For √• oppdage, redusere, minimere eller eliminere disse bekymringene m√• vi stille moralske "ja/nei"-sp√∏rsm√•l knyttet til v√•re handlinger, og deretter ta korrigerende tiltak etter behov. La oss se p√• noen etiske utfordringer og de moralske sp√∏rsm√•lene de reiser:

#### 2.1 Dataeierskap

Datainnsamling involverer ofte personopplysninger som kan identifisere datasubjektene. [Dataeierskap](https://permission.io/blog/data-ownership) handler om _kontroll_ og [_brukerrettigheter_](https://permission.io/blog/data-ownership) knyttet til opprettelse, behandling og spredning av data.

De moralske sp√∏rsm√•lene vi m√• stille er: 
 * Hvem eier dataene? (bruker eller organisasjon)
 * Hvilke rettigheter har datasubjektene? (f.eks. tilgang, sletting, portabilitet)
 * Hvilke rettigheter har organisasjoner? (f.eks. rette opp ondsinnede brukeranmeldelser)

#### 2.2 Informert samtykke

[Informert samtykke](https://legaldictionary.net/informed-consent/) definerer handlingen der brukere gir tillatelse til en handling (som datainnsamling) med en _full forst√•else_ av relevante fakta, inkludert form√•l, potensielle risikoer og alternativer.

Sp√∏rsm√•l √• utforske her er:
 * Ga brukeren (datasubjektet) tillatelse til datainnsamling og bruk?
 * Forsto brukeren form√•let med at dataene ble samlet inn?
 * Forsto brukeren de potensielle risikoene ved deres deltakelse?

#### 2.3 Immaterielle rettigheter

[Immaterielle rettigheter](https://en.wikipedia.org/wiki/Intellectual_property) refererer til immaterielle skapelser som f√∏lge av menneskelig initiativ, som kan _ha √∏konomisk verdi_ for enkeltpersoner eller virksomheter.

Sp√∏rsm√•l √• utforske her er:
 * Hadde de innsamlede dataene √∏konomisk verdi for en bruker eller virksomhet?
 * Har **brukeren** immaterielle rettigheter her?
 * Har **organisasjonen** immaterielle rettigheter her?
 * Hvis disse rettighetene eksisterer, hvordan beskytter vi dem?

#### 2.4 Datapersonvern

[Datapersonvern](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) eller informasjonsvern refererer til bevaring av brukerens personvern og beskyttelse av brukerens identitet med hensyn til personlig identifiserbar informasjon.

Sp√∏rsm√•l √• utforske her er:
 * Er brukernes (personlige) data sikret mot hacking og lekkasjer?
 * Er brukernes data kun tilgjengelig for autoriserte brukere og kontekster?
 * Bevares brukernes anonymitet n√•r data deles eller spres?
 * Kan en bruker bli avidentifisert fra anonymiserte datasett?

#### 2.5 Rett til √• bli glemt

[Rett til √• bli glemt](https://en.wikipedia.org/wiki/Right_to_be_forgotten) eller [rett til sletting](https://www.gdpreu.org/right-to-be-forgotten/) gir ekstra beskyttelse av personopplysninger til brukere. Spesielt gir det brukere rett til √• be om sletting eller fjerning av personopplysninger fra internett og andre steder, _under spesifikke omstendigheter_ - slik at de kan starte p√• nytt uten at tidligere handlinger holdes mot dem.

Sp√∏rsm√•l √• utforske her er:
 * Tillater systemet datasubjekter √• be om sletting?
 * B√∏r tilbaketrekking av brukersamtykke utl√∏se automatisk sletting?
 * Ble data samlet inn uten samtykke eller p√• ulovlig vis?
 * Er vi i samsvar med myndighetsreguleringer for databeskyttelse?

#### 2.6 Datasett-skjevhet

Datasett- eller [innsamlingsskjevhet](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) handler om √• velge et _ikke-representativt_ datasett for algoritmeutvikling, noe som kan skape potensielle urettferdigheter i resultatene for ulike grupper. Typer skjevhet inkluderer utvalgs- eller pr√∏vetakingsskjevhet, frivillighetsskjevhet og instrumentell skjevhet.

Sp√∏rsm√•l √• utforske her er:
 * Rekrutterte vi et representativt sett med datasubjekter?
 * Testet vi v√•rt innsamlede eller kuraterte datasett for ulike skjevheter?
 * Kan vi redusere eller fjerne oppdagede skjevheter?

#### 2.7 Datakvalitet

[Datakvalitet](https://lakefs.io/data-quality-testing/) ser p√• gyldigheten av det kuraterte datasettet som brukes til √• utvikle algoritmene v√•re, og sjekker om funksjoner og poster oppfyller kravene til n√∏yaktighet og konsistens som trengs for v√•rt AI-form√•l.

Sp√∏rsm√•l √• utforske her er:
 * Fanget vi gyldige _funksjoner_ for v√•rt brukstilfelle?
 * Ble data fanget _konsistent_ p√• tvers av ulike datakilder?
 * Er datasettet _komplett_ for ulike forhold eller scenarier?
 * Er informasjonen fanget _n√∏yaktig_ i √• gjenspeile virkeligheten?

#### 2.8 Algoritme-rettferdighet
[Algorithmisk rettferdighet](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) unders√∏ker om algoritmedesign systematisk diskriminerer spesifikke undergrupper av datasubjekter, noe som kan f√∏re til [potensielle skader](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) innen _fordeling_ (der ressurser nektes eller holdes tilbake fra en gruppe) og _tjenestekvalitet_ (der AI ikke er like n√∏yaktig for noen undergrupper som for andre).

Sp√∏rsm√•l √• utforske her er:
 * Evaluerte vi modellens n√∏yaktighet for ulike undergrupper og forhold?
 * Unders√∏kte vi systemet for potensielle skader (f.eks. stereotypier)?
 * Kan vi revidere data eller trene opp modeller p√• nytt for √• redusere identifiserte skader?

Utforsk ressurser som [AI Fairness-sjekklister](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) for √• l√¶re mer.

#### 2.9 Feilrepresentasjon

[Feilrepresentasjon av data](https://www.sciencedirect.com/topics/computer-science/misrepresentation) handler om √• sp√∏rre om vi kommuniserer innsikter fra √¶rlig rapporterte data p√• en villedende m√•te for √• st√∏tte en √∏nsket fortelling.

Sp√∏rsm√•l √• utforske her er:
 * Rapporterer vi ufullstendige eller un√∏yaktige data?
 * Visualiserer vi data p√• en m√•te som f√∏rer til misvisende konklusjoner?
 * Bruker vi selektive statistiske teknikker for √• manipulere resultater?
 * Finnes det alternative forklaringer som kan gi en annen konklusjon?

#### 2.10 Fri vilje
[Illusjonen av fri vilje](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) oppst√•r n√•r systemets "valgarkitekturer" bruker beslutningsalgoritmer for √• dytte folk mot et foretrukket utfall, samtidig som det ser ut som om de har alternativer og kontroll. Disse [m√∏rke m√∏nstrene](https://www.darkpatterns.org/) kan for√•rsake sosial og √∏konomisk skade for brukere. Fordi brukerbeslutninger p√•virker atferdsprofiler, kan disse handlingene potensielt drive fremtidige valg som forsterker eller utvider skaden.

Sp√∏rsm√•l √• utforske her er:
 * Forsto brukeren konsekvensene av √• ta det valget?
 * Var brukeren klar over (alternative) valg og fordeler og ulemper ved hvert av dem?
 * Kan brukeren omgj√∏re et automatisert eller p√•virket valg senere?

### 3. Case-studier

For √• sette disse etiske utfordringene i en virkelighetsn√¶r kontekst, kan det v√¶re nyttig √• se p√• case-studier som fremhever potensielle skader og konsekvenser for enkeltpersoner og samfunnet n√•r slike etiske brudd overses.

Her er noen eksempler:

| Etisk utfordring | Case-studie  | 
|--- |--- |
| **Informert samtykke** | 1972 - [Tuskegee-syfilisstudien](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - Afroamerikanske menn som deltok i studien ble lovet gratis medisinsk behandling, _men ble lurt_ av forskere som ikke informerte dem om diagnosen eller tilgjengelig behandling. Mange d√∏de, og partnere eller barn ble p√•virket; studien varte i 40 √•r. | 
| **Datapersonvern** | 2007 - [Netflix data-prisen](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) ga forskere _10M anonymiserte filmvurderinger fra 50K kunder_ for √• forbedre anbefalingsalgoritmer. Forskere klarte imidlertid √• korrelere anonymiserte data med personlig identifiserbare data i _eksterne datasett_ (f.eks. IMDb-kommentarer), og "de-anonymiserte" dermed noen Netflix-abonnenter.|
| **Innsamlingsskjevhet**  | 2013 - Byen Boston [utviklet Street Bump](https://www.boston.gov/transportation/street-bump), en app som lot innbyggere rapportere hull i veien, og ga byen bedre data for √• finne og fikse problemer. Men [folk i lavinntektsgrupper hadde mindre tilgang til biler og telefoner](https://hbr.org/2013/04/the-hidden-biases-in-big-data), noe som gjorde deres veiutfordringer usynlige i appen. Utviklerne samarbeidet med akademikere for √• l√∏se _rettferdig tilgang og digitale skiller_. |
| **Algoritmisk rettferdighet**  | 2018 - MITs [Gender Shades-studie](http://gendershades.org/overview.html) evaluerte n√∏yaktigheten til AI-produkter for kj√∏nnsidentifikasjon og avdekket forskjeller i n√∏yaktighet for kvinner og personer med m√∏rk hud. Et [2019 Apple Card](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) s√• ut til √• tilby mindre kreditt til kvinner enn menn. Begge eksemplene illustrerer problemer med algoritmisk skjevhet som f√∏rer til sosio√∏konomiske skader.|
| **Feilrepresentasjon av data** | 2020 - [Georgia Department of Public Health publiserte COVID-19-diagrammer](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) som s√• ut til √• villede innbyggerne om trender i bekreftede tilfeller ved √• bruke ikke-kronologisk rekkef√∏lge p√• x-aksen. Dette illustrerer feilrepresentasjon gjennom visualiseringstriks. |
| **Illusjon av fri vilje** | 2020 - L√¶ringsappen [ABCmouse betalte $10M for √• l√∏se en FTC-klage](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/) der foreldre ble fanget i √• betale for abonnementer de ikke kunne kansellere. Dette illustrerer m√∏rke m√∏nstre i valgarkitekturer, der brukere ble dyttet mot potensielt skadelige valg. |
| **Datapersonvern og brukerrettigheter** | 2021 - Facebook [datainnbrudd](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) eksponerte data fra 530M brukere, noe som resulterte i et forlik p√• $5B med FTC. Facebook nektet imidlertid √• varsle brukerne om bruddet, noe som krenket brukernes rettigheter til datatransparens og tilgang. |

Vil du utforske flere case-studier? Sjekk ut disse ressursene:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - etiske dilemmaer p√• tvers av ulike bransjer. 
* [Data Science Ethics-kurs](https://www.coursera.org/learn/data-science-ethics#syllabus) - utforsker viktige case-studier.
* [Hvor ting har g√•tt galt](https://deon.drivendata.org/examples/) - deon-sjekkliste med eksempler.

> üö® Tenk p√• case-studiene du har sett ‚Äì har du opplevd, eller blitt p√•virket av, en lignende etisk utfordring i ditt liv? Kan du komme p√• minst √©n annen case-studie som illustrerer en av de etiske utfordringene vi har diskutert i denne delen?

## Anvendt etikk

Vi har snakket om etiske konsepter, utfordringer og case-studier i virkelighetsn√¶re kontekster. Men hvordan kommer vi i gang med √• _anvende_ etiske prinsipper og praksiser i prosjektene v√•re? Og hvordan kan vi _operasjonalisere_ disse praksisene for bedre styring? La oss utforske noen l√∏sninger fra virkeligheten:

### 1. Profesjonelle retningslinjer

Profesjonelle retningslinjer tilbyr en m√•te for organisasjoner √• "incentivere" medlemmer til √• st√∏tte deres etiske prinsipper og misjonserkl√¶ring. Retningslinjer er _moralske veiledninger_ for profesjonell atferd, som hjelper ansatte eller medlemmer med √• ta beslutninger som samsvarer med organisasjonens prinsipper. De er kun effektive dersom medlemmene frivillig f√∏lger dem; mange organisasjoner tilbyr imidlertid bel√∏nninger og sanksjoner for √• motivere etterlevelse.

Eksempler inkluderer:

 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Code of Ethics
 * [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Code of Conduct (opprettet 2013)
 * [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (siden 1993)

> üö® Tilh√∏rer du en profesjonell ingeni√∏r- eller dataorganisasjon? Utforsk nettsiden deres for √• se om de definerer en profesjonell etikkodeks. Hva sier dette om deres etiske prinsipper? Hvordan "incentiverer" de medlemmene til √• f√∏lge kodeksen?

### 2. Etiske sjekklister

Mens profesjonelle retningslinjer definerer n√∏dvendig _etisk atferd_ fra ut√∏vere, har de [kjente begrensninger](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) i h√•ndhevelse, spesielt i storskala prosjekter. Mange eksperter innen datafag [foresl√•r sjekklister](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) som kan **koble prinsipper til praksis** p√• mer deterministiske og handlingsrettede m√•ter.

Sjekklister omgj√∏r sp√∏rsm√•l til "ja/nei"-oppgaver som kan operasjonaliseres, slik at de kan spores som en del av standard arbeidsflyter for produktlansering.

Eksempler inkluderer:
 * [Deon](https://deon.drivendata.org/) - en generell sjekkliste for dataetikk laget fra [bransjeanbefalinger](https://deon.drivendata.org/#checklist-citations) med et kommandolinjeverkt√∏y for enkel integrasjon.
 * [Privacy Audit Checklist](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - gir generell veiledning for informasjonsbehandling fra juridiske og sosiale eksponeringsperspektiver.
 * [AI Fairness Checklist](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - laget av AI-ut√∏vere for √• st√∏tte adopsjon og integrasjon av rettferdighetssjekker i AI-utviklingssykluser.
 * [22 sp√∏rsm√•l for etikk i data og AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - en mer √•pen ramme, strukturert for innledende utforskning av etiske problemstillinger i design, implementering og organisatoriske kontekster.

### 3. Etiske reguleringer

Etikk handler om √• definere felles verdier og gj√∏re det rette _frivillig_. **Etterlevelse** handler om _√• f√∏lge loven_ der den er definert. **Styring** dekker bredt alle m√•tene organisasjoner opererer p√• for √• h√•ndheve etiske prinsipper og overholde etablerte lover.

I dag tar styring to former i organisasjoner. For det f√∏rste handler det om √• definere **etiske AI-prinsipper** og etablere praksiser for √• operasjonalisere adopsjon p√• tvers av alle AI-relaterte prosjekter i organisasjonen. For det andre handler det om √• overholde alle myndighetsp√•lagte **databeskyttelsesreguleringer** for regionene de opererer i.

Eksempler p√• databeskyttelses- og personvernreguleringer:

 * `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - regulerer _f√∏deral regjering_ sin innsamling, bruk og deling av personlig informasjon.
 * `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - beskytter personlig helsedata.
 * `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - beskytter barns personvern under 13 √•r.
 * `2018`, [General Data Protection Regulation (GDPR)](https://gdpr-info.eu/) - gir brukere rettigheter, databeskyttelse og personvern.
 * `2018`, [California Consumer Privacy Act (CCPA)](https://www.oag.ca.gov/privacy/ccpa) gir forbrukere flere _rettigheter_ over deres (personlige) data.
 * `2021`, Kinas [Personopplysningslov](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) ble nylig vedtatt og skaper en av verdens sterkeste personvernreguleringer p√• nett.

> üö® Den europeiske unionens GDPR (General Data Protection Regulation) er fortsatt en av de mest innflytelsesrike personvernreguleringene i dag. Visste du at den ogs√• definerer [8 brukerrettigheter](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) for √• beskytte borgernes digitale personvern og personopplysninger? L√¶r om hva disse er, og hvorfor de er viktige.

### 4. Etisk kultur

Merk at det fortsatt er et immaterielt gap mellom _etterlevelse_ (√• gj√∏re nok for √• oppfylle "lovens bokstav") og √• adressere [systemiske problemer](https://www.coursera.org/learn/data-science-ethics/home/week/4) (som fastl√•sthet, informasjonsasymmetri og fordelingsmessig urettferdighet) som kan akselerere v√•peniseringen av AI.

Det sistnevnte krever [samarbeidende tiln√¶rminger for √• definere etiske kulturer](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f) som bygger emosjonelle forbindelser og konsistente felles verdier _p√• tvers av organisasjoner_ i bransjen. Dette krever mer [formaliserte dataetiske kulturer](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) i organisasjoner ‚Äì som lar _hvem som helst_ [trekke Andon-snoren](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (for √• reise etiske bekymringer tidlig i prosessen) og gj√∏r _etiske vurderinger_ (f.eks. i ansettelser) til et kjernekrav for teamdannelse i AI-prosjekter.

---
## [Etterforelesningsquiz](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/3) üéØ
## Gjennomgang og selvstudium 

Kurs og b√∏ker hjelper med √• forst√• kjernebegreper og utfordringer innen etikk, mens case-studier og verkt√∏y hjelper med anvendt etikk i virkelige kontekster. Her er noen ressurser for √• komme i gang:

* [Machine Learning For Beginners](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - leksjon om rettferdighet, fra Microsoft.
* [Prinsipper for ansvarlig AI](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - gratis l√¶ringssti fra Microsoft Learn.
* [Etikk og datavitenskap](https://resources.oreilly.com/examples/0636920203964) - O'Reilly EBook (M. Loukides, H. Mason m.fl.)
* [Etikk innen datavitenskap](https://www.coursera.org/learn/data-science-ethics#syllabus) - nettkurs fra University of Michigan.
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - casestudier fra University of Texas.

# Oppgave

[Skriv en casestudie om dataetikk](assignment.md)

---

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n√∏yaktighet, v√¶r oppmerksom p√• at automatiske oversettelser kan inneholde feil eller un√∏yaktigheter. Det originale dokumentet p√• sitt opprinnelige spr√•k b√∏r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.