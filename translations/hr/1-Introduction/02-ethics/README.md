<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3a34157cc63516eba97c89a0b2f8c3e6",
  "translation_date": "2025-09-03T21:53:36+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "hr"
}
-->
# Uvod u etiku podataka

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Etika u znanosti o podacima - _Sketchnote by [@nitya](https://twitter.com/nitya)_ |

---

Svi smo mi graÄ‘ani podataka koji Å¾ivimo u svijetu prepunom podataka.

TrÅ¾iÅ¡ni trendovi pokazuju da Ä‡e do 2022. godine jedna od tri velike organizacije kupovati i prodavati svoje podatke putem online [trÅ¾nica i burzi](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Kao **razvijatelji aplikacija**, bit Ä‡e nam lakÅ¡e i jeftinije integrirati uvide temeljene na podacima i automatizaciju voÄ‘enu algoritmima u svakodnevna korisniÄka iskustva. No, kako umjetna inteligencija postaje sveprisutna, morat Ä‡emo razumjeti i potencijalne Å¡tete koje moÅ¾e prouzroÄiti [oruÅ¾avanje](https://www.youtube.com/watch?v=TQHs8SA1qpk) takvih algoritama u velikim razmjerima.

Trendovi takoÄ‘er pokazuju da Ä‡emo do 2025. godine stvoriti i konzumirati preko [180 zettabajta](https://www.statista.com/statistics/871513/worldwide-data-created/) podataka. Kao **znanstvenici podataka**, to nam daje neviÄ‘enu razinu pristupa osobnim podacima. To znaÄi da moÅ¾emo izgraditi profile ponaÅ¡anja korisnika i utjecati na donoÅ¡enje odluka na naÄine koji stvaraju [iluziju slobodnog izbora](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice), dok potencijalno usmjeravamo korisnike prema ishodima koji nama odgovaraju. TakoÄ‘er se postavljaju Å¡ira pitanja o privatnosti podataka i zaÅ¡titi korisnika.

Etika podataka sada su _nuÅ¾ne zaÅ¡titne mjere_ za znanost o podacima i inÅ¾enjering, pomaÅ¾uÄ‡i nam da minimiziramo potencijalne Å¡tete i nenamjerne posljedice naÅ¡ih radnji voÄ‘enih podacima. [Gartnerov Hype Cycle za AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) identificira relevantne trendove u digitalnoj etici, odgovornoj AI i upravljanju AI-jem kao kljuÄne pokretaÄe veÄ‡ih megatrendova oko _demokratizacije_ i _industrijalizacije_ AI-ja.

![Gartnerov Hype Cycle za AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

U ovoj lekciji istraÅ¾it Ä‡emo fascinantno podruÄje etike podataka - od osnovnih pojmova i izazova, do studija sluÄaja i primijenjenih AI koncepata poput upravljanja - koji pomaÅ¾u uspostaviti kulturu etike u timovima i organizacijama koje rade s podacima i AI-jem.

## [Kviz prije predavanja](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/2) ğŸ¯

## Osnovne definicije

PoÄnimo s razumijevanjem osnovne terminologije.

RijeÄ "etika" dolazi od [grÄke rijeÄi "ethikos"](https://en.wikipedia.org/wiki/Ethics) (i njenog korijena "ethos") Å¡to znaÄi _karakter ili moralna priroda_.

**Etika** se odnosi na zajedniÄke vrijednosti i moralna naÄela koja upravljaju naÅ¡im ponaÅ¡anjem u druÅ¡tvu. Etika se ne temelji na zakonima, veÄ‡ na Å¡iroko prihvaÄ‡enim normama o tome Å¡to je "ispravno naspram pogreÅ¡nog". MeÄ‘utim, etiÄka razmatranja mogu utjecati na inicijative korporativnog upravljanja i vladine regulative koje stvaraju viÅ¡e poticaja za usklaÄ‘enost.

**Etika podataka** je [nova grana etike](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1) koja "prouÄava i procjenjuje moralne probleme povezane s _podacima, algoritmima i odgovarajuÄ‡im praksama_". Ovdje se **"podaci"** fokusiraju na radnje povezane s generiranjem, snimanjem, kuriranjem, obradom, Å¡irenjem, dijeljenjem i koriÅ¡tenjem, **"algoritmi"** se fokusiraju na AI, agente, strojno uÄenje i robote, a **"prakse"** se fokusiraju na teme poput odgovorne inovacije, programiranja, hakiranja i etiÄkih kodeksa.

**Primijenjena etika** je [praktiÄna primjena moralnih razmatranja](https://en.wikipedia.org/wiki/Applied_ethics). To je proces aktivnog istraÅ¾ivanja etiÄkih pitanja u kontekstu _stvarnih radnji, proizvoda i procesa_, te poduzimanja korektivnih mjera kako bi se osiguralo da ostanu usklaÄ‘eni s naÅ¡im definiranim etiÄkim vrijednostima.

**Kultura etike** odnosi se na [_operacionalizaciju_ primijenjene etike](https://hbr.org/2019/05/how-to-design-an-ethical-organization) kako bi se osiguralo da se naÅ¡i etiÄki principi i prakse dosljedno i skalabilno usvajaju u cijeloj organizaciji. UspjeÅ¡ne kulture etike definiraju etiÄke principe na razini organizacije, pruÅ¾aju znaÄajne poticaje za usklaÄ‘enost i jaÄaju norme etike poticanjem i amplifikacijom Å¾eljenih ponaÅ¡anja na svakoj razini organizacije.

## Koncepti etike

U ovom dijelu raspravljat Ä‡emo o konceptima poput **zajedniÄkih vrijednosti** (principa) i **etiÄkih izazova** (problema) za etiku podataka - te istraÅ¾iti **studije sluÄaja** koje vam pomaÅ¾u razumjeti ove koncepte u stvarnim kontekstima.

### 1. Principi etike

Svaka strategija etike podataka poÄinje definiranjem _etiÄkih principa_ - "zajedniÄkih vrijednosti" koje opisuju prihvatljiva ponaÅ¡anja i vode usklaÄ‘ene radnje u naÅ¡im projektima vezanim uz podatke i AI. MoÅ¾ete ih definirati na individualnoj ili timskoj razini. MeÄ‘utim, veÄ‡ina velikih organizacija ih navodi u _misiji etiÄkog AI-ja_ ili okviru koji je definiran na korporativnoj razini i dosljedno proveden u svim timovima.

**Primjer:** Microsoftova [Odgovorna AI](https://www.microsoft.com/en-us/ai/responsible-ai) misija glasi: _"PosveÄ‡eni smo razvoju AI-ja voÄ‘enog etiÄkim principima koji stavljaju ljude na prvo mjesto"_ - identificirajuÄ‡i 6 etiÄkih principa u okviru ispod:

![Odgovorna AI u Microsoftu](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

Kratko Ä‡emo istraÅ¾iti ove principe. _Transparentnost_ i _odgovornost_ su temeljne vrijednosti na kojima se grade ostali principi - pa krenimo od njih:

* [**Odgovornost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) Äini praktiÄare _odgovornima_ za njihove operacije s podacima i AI-jem, te usklaÄ‘enost s ovim etiÄkim principima.
* [**Transparentnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) osigurava da su radnje vezane uz podatke i AI _razumljive_ korisnicima, objaÅ¡njavajuÄ‡i Å¡to i zaÅ¡to iza odluka.
* [**Pravednost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - fokusira se na osiguranje da AI _sve ljude_ tretira pravedno, rjeÅ¡avajuÄ‡i bilo kakve sustavne ili implicitne socio-tehniÄke pristranosti u podacima i sustavima.
* [**Pouzdanost i sigurnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - osigurava da AI djeluje _dosljedno_ s definiranim vrijednostima, minimizirajuÄ‡i potencijalne Å¡tete ili nenamjerne posljedice.
* [**Privatnost i sigurnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - odnosi se na razumijevanje podrijetla podataka i pruÅ¾anje _privatnosti podataka i povezanih zaÅ¡tita_ korisnicima.
* [**UkljuÄivost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - odnosi se na dizajniranje AI rjeÅ¡enja s namjerom, prilagoÄ‘avajuÄ‡i ih kako bi zadovoljila _Å¡irok raspon ljudskih potreba_ i sposobnosti.

> ğŸš¨ Razmislite o tome Å¡to bi mogla biti vaÅ¡a misija etike podataka. IstraÅ¾ite okvire etiÄkog AI-ja drugih organizacija - ovdje su primjeri iz [IBM-a](https://www.ibm.com/cloud/learn/ai-ethics), [Googlea](https://ai.google/principles) i [Facebooka](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Koje zajedniÄke vrijednosti imaju? Kako se ti principi odnose na AI proizvod ili industriju u kojoj djeluju?

### 2. EtiÄki izazovi

Nakon Å¡to definiramo etiÄke principe, sljedeÄ‡i korak je procijeniti naÅ¡e radnje vezane uz podatke i AI kako bismo vidjeli jesu li usklaÄ‘ene s tim zajedniÄkim vrijednostima. Razmislite o svojim radnjama u dvije kategorije: _prikupljanje podataka_ i _dizajn algoritama_.

Kod prikupljanja podataka, radnje Ä‡e vjerojatno ukljuÄivati **osobne podatke** ili osobno prepoznatljive informacije (PII) za identificirane Å¾ive pojedince. To ukljuÄuje [razliÄite stavke neosobnih podataka](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) koje _zajedno_ identificiraju pojedinca. EtiÄki izazovi mogu se odnositi na _privatnost podataka_, _vlasniÅ¡tvo podataka_ i povezane teme poput _informiranog pristanka_ i _prava intelektualnog vlasniÅ¡tva_ za korisnike.

Kod dizajna algoritama, radnje Ä‡e ukljuÄivati prikupljanje i kuriranje **skupova podataka**, a zatim njihovo koriÅ¡tenje za treniranje i implementaciju **modela podataka** koji predviÄ‘aju ishode ili automatiziraju odluke u stvarnim kontekstima. EtiÄki izazovi mogu proizaÄ‡i iz _pristranosti skupa podataka_, problema _kvalitete podataka_, _nepravednosti_ i _pogreÅ¡nog predstavljanja_ u algoritmima - ukljuÄujuÄ‡i neke probleme koji su sustavne prirode.

U oba sluÄaja, etiÄki izazovi istiÄu podruÄja gdje naÅ¡e radnje mogu biti u sukobu s naÅ¡im zajedniÄkim vrijednostima. Kako bismo otkrili, ublaÅ¾ili, minimizirali ili eliminirali ove zabrinutosti - trebamo postavljati moralna "da/ne" pitanja vezana uz naÅ¡e radnje, a zatim poduzeti korektivne mjere prema potrebi. Pogledajmo neke etiÄke izazove i moralna pitanja koja postavljaju:

#### 2.1 VlasniÅ¡tvo podataka

Prikupljanje podataka Äesto ukljuÄuje osobne podatke koji mogu identificirati subjekte podataka. [VlasniÅ¡tvo podataka](https://permission.io/blog/data-ownership) odnosi se na _kontrolu_ i [_prava korisnika_](https://permission.io/blog/data-ownership) vezana uz stvaranje, obradu i Å¡irenje podataka.

Moralna pitanja koja trebamo postaviti su:
* Tko posjeduje podatke? (korisnik ili organizacija)
* Koja prava imaju subjekti podataka? (npr. pristup, brisanje, prenosivost)
* Koja prava imaju organizacije? (npr. ispravljanje zlonamjernih korisniÄkih recenzija)

#### 2.2 Informirani pristanak

[Informirani pristanak](https://legaldictionary.net/informed-consent/) definira Äin korisnika koji pristaju na radnju (poput prikupljanja podataka) uz _potpuno razumijevanje_ relevantnih Äinjenica, ukljuÄujuÄ‡i svrhu, potencijalne rizike i alternative.

Pitanja za istraÅ¾ivanje ovdje su:
* Je li korisnik (subjekt podataka) dao dopuÅ¡tenje za prikupljanje i koriÅ¡tenje podataka?
* Je li korisnik razumio svrhu za koju su ti podaci prikupljeni?
* Je li korisnik razumio potencijalne rizike od sudjelovanja?

#### 2.3 Intelektualno vlasniÅ¡tvo

[Intelektualno vlasniÅ¡tvo](https://en.wikipedia.org/wiki/Intellectual_property) odnosi se na nematerijalne kreacije koje proizlaze iz ljudske inicijative, a koje mogu _imati ekonomsku vrijednost_ za pojedince ili tvrtke.

Pitanja za istraÅ¾ivanje ovdje su:
* Jesu li prikupljeni podaci imali ekonomsku vrijednost za korisnika ili tvrtku?
* Ima li **korisnik** intelektualno vlasniÅ¡tvo ovdje?
* Ima li **organizacija** intelektualno vlasniÅ¡tvo ovdje?
* Ako ta prava postoje, kako ih Å¡titimo?

#### 2.4 Privatnost podataka

[Privatnost podataka](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) ili informacijska privatnost odnosi se na oÄuvanje privatnosti korisnika i zaÅ¡titu identiteta korisnika u vezi s osobno prepoznatljivim informacijama.

Pitanja za istraÅ¾ivanje ovdje su:
* Jesu li korisniÄki (osobni) podaci zaÅ¡tiÄ‡eni od hakiranja i curenja?
* Jesu li korisniÄki podaci dostupni samo ovlaÅ¡tenim korisnicima i kontekstima?
* Je li anonimnost korisnika oÄuvana kada se podaci dijele ili Å¡ire?
* MoÅ¾e li se korisnik de-identificirati iz anonimiziranih skupova podataka?

#### 2.5 Pravo na zaborav

[Pravo na zaborav](https://en.wikipedia.org/wiki/Right_to_be_forgotten) ili [Pravo na brisanje](https://www.gdpreu.org/right-to-be-forgotten/) pruÅ¾a dodatnu zaÅ¡titu osobnih podataka korisnicima. Konkretno, daje korisnicima pravo da zatraÅ¾e brisanje ili uklanjanje osobnih podataka iz internetskih pretraÅ¾ivanja i drugih lokacija, _pod odreÄ‘enim okolnostima_ - omoguÄ‡ujuÄ‡i im novi poÄetak online bez da se proÅ¡le radnje drÅ¾e protiv njih.

Pitanja za istraÅ¾ivanje ovdje su:
* OmoguÄ‡ava li sustav subjektima podataka da zatraÅ¾e brisanje?
* Treba li povlaÄenje korisniÄkog pristanka automatski pokrenuti brisanje?
* Jesu li podaci prikupljeni bez pristanka ili nezakonitim sredstvima?
* Jesmo li usklaÄ‘eni s vladinim regulativama za privatnost podataka?

#### 2.6 Pristranost skupa podataka

Pristranost skupa podataka ili [pristranost prikupljanja](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) odnosi se na odabir _nereprezentativnog_ podskupa podataka za razvoj algoritama, stvarajuÄ‡i potencijalnu nepravednost u ishodima za razliÄite skupine. Vrste pristranosti ukljuÄuju pristranost odabira ili uzorkovanja, pristranost volontera i pristranost instrumenata.

Pitanja za istraÅ¾ivanje ovdje su:
* Jesmo li regrutirali reprezentativni skup subjekata podataka?
* Jesmo li testirali naÅ¡ prikupljeni ili kurirani skup podataka na razne pristranosti?
* MoÅ¾emo li ublaÅ¾iti ili ukloniti otkrivene pristranosti?

#### 2.7 Kvaliteta podataka

[Kvaliteta podataka](https://lakefs.io/data-quality-testing/) ispituje valjanost kuriranog skupa podataka koriÅ¡tenog za razvoj naÅ¡ih algoritama, provjeravajuÄ‡i jesu li znaÄajke i zapisi u skladu s zahtjevima za razinu toÄnosti i dosljednosti potrebnu za naÅ¡ AI cilj.

Pitanja za istraÅ¾ivanje ovdje su:
* Jesmo li uhvatili valjane _znaÄajke_ za naÅ¡u svrhu?
* Jesu li podaci dosljedno prikupljeni iz razliÄitih izvora podataka?
* Je li skup podataka _potpun_ za razliÄite uvjete ili scenarije?
* Jesu li informacije toÄno uhvaÄ‡ene u odraÅ¾avanju stvarnosti?
[Algorithm Fairness](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) provjerava dizajn algoritma kako bi se utvrdilo diskriminira li sustavno odreÄ‘ene podskupine subjekata podataka, Å¡to moÅ¾e dovesti do [potencijalnih Å¡teta](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) u _dodjeli_ (gdje se resursi uskraÄ‡uju ili odbijaju toj skupini) i _kvaliteti usluge_ (gdje AI nije jednako precizan za neke podskupine kao za druge).

Pitanja za istraÅ¾ivanje:
 * Jesmo li procijenili toÄnost modela za razliÄite podskupine i uvjete?
 * Jesmo li detaljno analizirali sustav zbog potencijalnih Å¡teta (npr. stereotipiziranja)?
 * MoÅ¾emo li revidirati podatke ili ponovno trenirati modele kako bismo ublaÅ¾ili identificirane Å¡tete?

IstraÅ¾ite resurse poput [AI Fairness checklists](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) za viÅ¡e informacija.

#### 2.9 PogreÅ¡no predstavljanje

[PogreÅ¡no predstavljanje podataka](https://www.sciencedirect.com/topics/computer-science/misrepresentation) odnosi se na pitanje jesmo li komunikaciju utemeljenu na iskreno prijavljenim podacima koristili na obmanjujuÄ‡i naÄin kako bismo podrÅ¾ali Å¾eljeni narativ.

Pitanja za istraÅ¾ivanje:
 * Prijavljujemo li nepotpune ili netoÄne podatke?
 * Vizualiziramo li podatke na naÄin koji vodi do pogreÅ¡nih zakljuÄaka?
 * Koristimo li selektivne statistiÄke tehnike za manipulaciju rezultatima?
 * Postoje li alternativna objaÅ¡njenja koja mogu ponuditi drugaÄiji zakljuÄak?

#### 2.10 Slobodan izbor
[Iluzija slobodnog izbora](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) dogaÄ‘a se kada sustavi "arhitekture izbora" koriste algoritme za donoÅ¡enje odluka kako bi potaknuli ljude na odabir preferiranog ishoda, dok im se istovremeno Äini da imaju opcije i kontrolu. Ovi [tamni obrasci](https://www.darkpatterns.org/) mogu uzrokovati druÅ¡tvene i ekonomske Å¡tete korisnicima. BuduÄ‡i da odluke korisnika utjeÄu na profile ponaÅ¡anja, te radnje potencijalno oblikuju buduÄ‡e izbore koji mogu pojaÄati ili proÅ¡iriti utjecaj tih Å¡teta.

Pitanja za istraÅ¾ivanje:
 * Je li korisnik razumio implikacije donoÅ¡enja tog izbora?
 * Je li korisnik bio svjestan (alternativnih) izbora i prednosti i nedostataka svakog?
 * MoÅ¾e li korisnik kasnije poniÅ¡titi automatizirani ili utjecani izbor?

### 3. Studije sluÄaja

Kako bismo ove etiÄke izazove stavili u kontekst stvarnog svijeta, korisno je pogledati studije sluÄaja koje istiÄu potencijalne Å¡tete i posljedice za pojedince i druÅ¡tvo kada se zanemaruju etiÄka krÅ¡enja.

Evo nekoliko primjera:

| EtiÄki izazov | Studija sluÄaja  | 
|--- |--- |
| **Informirani pristanak** | 1972 - [Tuskegee Syphilis Study](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - AfroameriÄkim muÅ¡karcima koji su sudjelovali u studiji obeÄ‡ana je besplatna medicinska skrb _ali su ih istraÅ¾ivaÄi obmanuli_ ne informirajuÄ‡i ih o dijagnozi ili dostupnosti lijeÄenja. Mnogi su umrli, a partneri i djeca su bili pogoÄ‘eni; studija je trajala 40 godina. | 
| **Privatnost podataka** |  2007 - [Netflix data prize](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) pruÅ¾io je istraÅ¾ivaÄima _10M anonimiziranih ocjena filmova od 50K korisnika_ kako bi se poboljÅ¡ali algoritmi preporuka. MeÄ‘utim, istraÅ¾ivaÄi su uspjeli povezati anonimizirane podatke s osobno identificiranim podacima u _vanjskim skupovima podataka_ (npr. IMDb komentari) - uÄinkovito "deanonimizirajuÄ‡i" neke Netflix pretplatnike.|
| **Pristranost u prikupljanju podataka**  | 2013 - Grad Boston [razvio Street Bump](https://www.boston.gov/transportation/street-bump), aplikaciju koja je omoguÄ‡ila graÄ‘anima da prijave rupe na cestama, dajuÄ‡i gradu bolje podatke o cestama za pronalaÅ¾enje i popravak problema. MeÄ‘utim, [ljudi s niÅ¾im prihodima imali su manje pristupa automobilima i telefonima](https://hbr.org/2013/04/the-hidden-biases-in-big-data), ÄineÄ‡i njihove probleme s cestama nevidljivima u ovoj aplikaciji. Programeri su suraÄ‘ivali s akademicima na _pristupu i digitalnim podjelama_ radi pravednosti. |
| **Pravednost algoritma**  | 2018 - MIT [Gender Shades Study](http://gendershades.org/overview.html) procijenila je toÄnost AI proizvoda za klasifikaciju spola, otkrivajuÄ‡i nedostatke u toÄnosti za Å¾ene i osobe tamnije boje koÅ¾e. [Apple Card iz 2019.](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) Äinilo se da nudi manje kredita Å¾enama nego muÅ¡karcima. Oba primjera ilustriraju probleme pristranosti algoritma koji dovode do socio-ekonomskih Å¡teta.|
| **PogreÅ¡no predstavljanje podataka** | 2020 - [Georgia Department of Public Health objavio COVID-19 grafikone](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) koji su izgledali kao da obmanjuju graÄ‘ane o trendovima potvrÄ‘enih sluÄajeva s ne-kronoloÅ¡kim redoslijedom na x-osi. Ovo ilustrira pogreÅ¡no predstavljanje kroz trikove vizualizacije. |
| **Iluzija slobodnog izbora** | 2020 - Edukativna aplikacija [ABCmouse platila $10M za nagodbu s FTC-om](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/) gdje su roditelji bili zarobljeni u plaÄ‡anju pretplata koje nisu mogli otkazati. Ovo ilustrira tamne obrasce u arhitekturama izbora, gdje su korisnici bili potaknuti na potencijalno Å¡tetne odluke. |
| **Privatnost podataka i prava korisnika** | 2021 - Facebook [Data Breach](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) otkrio podatke 530M korisnika, Å¡to je rezultiralo nagodbom od $5B s FTC-om. MeÄ‘utim, odbio je obavijestiti korisnike o povredi, krÅ¡eÄ‡i prava korisnika na transparentnost i pristup podacima. |

Å½elite istraÅ¾iti viÅ¡e studija sluÄaja? Pogledajte ove resurse:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - etiÄke dileme u raznim industrijama. 
* [Data Science Ethics course](https://www.coursera.org/learn/data-science-ethics#syllabus) - studije sluÄaja u fokusu.
* [Where things have gone wrong](https://deon.drivendata.org/examples/) - Deon popis s primjerima.


> ğŸš¨ Razmislite o studijama sluÄaja koje ste vidjeli - jeste li doÅ¾ivjeli ili bili pogoÄ‘eni sliÄnim etiÄkim izazovom u svom Å¾ivotu? MoÅ¾ete li se sjetiti barem jedne druge studije sluÄaja koja ilustrira jedan od etiÄkih izazova koje smo raspravili u ovom odjeljku?

## Primijenjena etika

Razgovarali smo o konceptima etike, izazovima i studijama sluÄaja u kontekstu stvarnog svijeta. No, kako zapoÄeti _primjenu_ etiÄkih naÄela i praksi u naÅ¡im projektima? I kako _operacionalizirati_ ove prakse za bolju upravu? IstraÅ¾imo neka rjeÅ¡enja iz stvarnog svijeta:

### 1. Profesionalni kodeksi

Profesionalni kodeksi nude jednu opciju za organizacije da "potaknu" Älanove na podrÅ¡ku njihovim etiÄkim naÄelima i misiji. Kodeksi su _moralne smjernice_ za profesionalno ponaÅ¡anje, pomaÅ¾uÄ‡i zaposlenicima ili Älanovima da donose odluke koje su u skladu s naÄelima njihove organizacije. Oni su uÄinkoviti koliko i dobrovoljna usklaÄ‘enost Älanova; meÄ‘utim, mnoge organizacije nude dodatne nagrade i kazne kako bi motivirale usklaÄ‘enost.

Primjeri ukljuÄuju:

 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Kodeks etike
 * [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Kodeks ponaÅ¡anja (kreiran 2013.)
 * [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (od 1993.)

> ğŸš¨ Pripadate li profesionalnoj inÅ¾enjerskoj ili organizaciji za podatkovnu znanost? IstraÅ¾ite njihovu stranicu kako biste vidjeli definiraju li profesionalni kodeks etike. Å to to govori o njihovim etiÄkim naÄelima? Kako "potiÄu" Älanove da slijede kodeks?

### 2. EtiÄke kontrolne liste

Dok profesionalni kodeksi definiraju potrebna _etiÄka ponaÅ¡anja_ od praktiÄara, oni [imaju poznata ograniÄenja](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) u provedbi, posebno u projektima velikih razmjera. Umjesto toga, mnogi struÄnjaci za podatkovnu znanost [zagovaraju kontrolne liste](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), koje mogu **povezati naÄela s praksama** na deterministiÄki i provediv naÄin.

Kontrolne liste pretvaraju pitanja u zadatke "da/ne" koji se mogu operacionalizirati, omoguÄ‡ujuÄ‡i njihovo praÄ‡enje kao dio standardnih tijekova rada za izdavanje proizvoda.

Primjeri ukljuÄuju:
 * [Deon](https://deon.drivendata.org/) - opÄ‡a kontrolna lista za etiku podataka kreirana iz [preporuka industrije](https://deon.drivendata.org/#checklist-citations) s alatom naredbenog retka za jednostavnu integraciju.
 * [Privacy Audit Checklist](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - pruÅ¾a opÄ‡e smjernice za praksu rukovanja informacijama iz pravne i druÅ¡tvene perspektive.
 * [AI Fairness Checklist](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - kreirana od strane AI praktiÄara za podrÅ¡ku usvajanju i integraciji provjera pravednosti u AI razvojne cikluse.
 * [22 pitanja za etiku u podacima i AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - otvoreniji okvir, strukturiran za poÄetno istraÅ¾ivanje etiÄkih pitanja u dizajnu, implementaciji i organizacijskim kontekstima.

### 3. EtiÄke regulative

Etika se odnosi na definiranje zajedniÄkih vrijednosti i Äinjenje ispravnih stvari _dobrovoljno_. **UsklaÄ‘enost** se odnosi na _poÅ¡tivanje zakona_ ako i gdje je definiran. **Upravljanje** opÄ‡enito pokriva sve naÄine na koje organizacije djeluju kako bi provele etiÄka naÄela i uskladile se s utvrÄ‘enim zakonima.

Danas upravljanje ima dva oblika unutar organizacija. Prvo, radi se o definiranju **etiÄkih AI** naÄela i uspostavljanju praksi za operacionalizaciju usvajanja u svim AI projektima organizacije. Drugo, radi se o usklaÄ‘ivanju sa svim vladinim propisima o zaÅ¡titi podataka za regije u kojima djeluje.

Primjeri propisa o zaÅ¡titi podataka i privatnosti:

 * `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - regulira _saveznu vladu_ u prikupljanju, koriÅ¡tenju i otkrivanju osobnih podataka.
 * `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - Å¡titi osobne zdravstvene podatke.
 * `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - Å¡titi privatnost podataka djece mlaÄ‘e od 13 godina.
 * `2018`, [General Data Protection Regulation (GDPR)](https://gdpr-info.eu/) - pruÅ¾a prava korisnika, zaÅ¡titu podataka i privatnost.
 * `2018`, [California Consumer Privacy Act (CCPA)](https://www.oag.ca.gov/privacy/ccpa) daje potroÅ¡aÄima viÅ¡e _prava_ nad njihovim (osobnim) podacima.
 * `2021`, Kineski [Zakon o zaÅ¡titi osobnih podataka](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) upravo je donesen, stvarajuÄ‡i jedan od najjaÄih propisa o privatnosti podataka na internetu u svijetu.

> ğŸš¨ Europska unija definirala je GDPR (OpÄ‡a uredba o zaÅ¡titi podataka) koji ostaje jedan od najutjecajnijih propisa o privatnosti podataka danas. Jeste li znali da takoÄ‘er definira [8 prava korisnika](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) za zaÅ¡titu digitalne privatnosti i osobnih podataka graÄ‘ana? Saznajte koja su to prava i zaÅ¡to su vaÅ¾na.

### 4. Kultura etike

Napominjemo da i dalje postoji nematerijalni jaz izmeÄ‘u _usklaÄ‘enosti_ (Äinjenja dovoljno da se zadovolji "slovo zakona") i rjeÅ¡avanja [sustavnih problema](https://www.coursera.org/learn/data-science-ethics/home/week/4) (poput osifikacije, asimetrije informacija i distribucijske nepravednosti) koji mogu ubrzati "oruÅ¾avanje" AI-a.

Ovo drugo zahtijeva [suradniÄke pristupe za definiranje kultura etike](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f) koje grade emocionalne veze i dosljedne zajedniÄke vrijednosti _meÄ‘u organizacijama_ u industriji. To poziva na viÅ¡e [formaliziranih kultura etike podataka](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) u organizacijama - omoguÄ‡ujuÄ‡i _svima_ da [povuku Andon konopac](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (kako bi rano ukazali na etiÄke probleme) i ÄineÄ‡i _etiÄke procjene_ (npr. pri zapoÅ¡ljavanju) kljuÄnim kriterijem za formiranje timova u AI projektima.

---
## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ds/) ğŸ¯
## Pregled i samostalno uÄenje 

TeÄajevi i knjige pomaÅ¾u u razumijevanju osnovnih etiÄkih koncepata i izazova, dok studije sluÄaja i alati pomaÅ¾u u primjeni etiÄkih praksi u stvarnim kontekstima. Evo nekoliko resursa za poÄetak.

* [Machine Learning For Beginners](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - lekcija o pravednosti, od Microsofta.
* [Principi odgovorne umjetne inteligencije](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - besplatni obrazovni program od Microsoft Learn.
* [Etika i znanost o podacima](https://resources.oreilly.com/examples/0636920203964) - O'Reilly EBook (M. Loukides, H. Mason i dr.)
* [Etika u znanosti o podacima](https://www.coursera.org/learn/data-science-ethics#syllabus) - online teÄaj SveuÄiliÅ¡ta Michigan.
* [Etika razotkrivena](https://ethicsunwrapped.utexas.edu/case-studies) - studije sluÄaja SveuÄiliÅ¡ta Texas.

# Zadatak

[NapiÅ¡ite studiju sluÄaja o etici podataka](assignment.md)

---

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden pomoÄ‡u AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati toÄnost, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kljuÄne informacije preporuÄuje se profesionalni prijevod od strane ljudskog prevoditelja. Ne preuzimamo odgovornost za nesporazume ili pogreÅ¡ne interpretacije koje mogu proizaÄ‡i iz koriÅ¡tenja ovog prijevoda.