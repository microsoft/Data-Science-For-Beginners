<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "58860ce9a4b8a564003d2752f7c72851",
  "translation_date": "2025-10-03T17:03:32+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "hr"
}
-->
# Uvod u etiku podataka

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Etika u znanosti o podacima - _Sketchnote by [@nitya](https://twitter.com/nitya)_ |

---

Svi smo mi graÄ‘ani podataka koji Å¾ivimo u svijetu prepunom podataka.

TrÅ¾iÅ¡ni trendovi pokazuju da Ä‡e do 2022. godine jedna od tri velike organizacije kupovati i prodavati svoje podatke putem online [trÅ¾nica i razmjena](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Kao **razvijatelji aplikacija**, bit Ä‡e nam lakÅ¡e i jeftinije integrirati uvide temeljene na podacima i automatizaciju voÄ‘enu algoritmima u svakodnevna korisniÄka iskustva. No, kako umjetna inteligencija postaje sveprisutna, morat Ä‡emo razumjeti i potencijalne Å¡tete uzrokovane [oruÅ¾avanjem](https://www.youtube.com/watch?v=TQHs8SA1qpk) takvih algoritama u velikim razmjerima.

Trendovi sugeriraju da Ä‡emo do 2025. godine generirati i konzumirati preko [180 zettabajta](https://www.statista.com/statistics/871513/worldwide-data-created/) podataka. Za **znanstvenike o podacima**, ova eksplozija informacija pruÅ¾a neviÄ‘en pristup osobnim i ponaÅ¡ajnim podacima. S time dolazi moÄ‡ izrade detaljnih korisniÄkih profila i suptilnog utjecaja na donoÅ¡enje odlukaâ€”Äesto na naÄine koji stvaraju [iluziju slobodnog izbora](https://www.datasciencecentral.com/the-pareto-set-and-the-paradox-of-choice/). Iako se to moÅ¾e koristiti za usmjeravanje korisnika prema Å¾eljenim ishodima, takoÄ‘er postavlja kljuÄna pitanja o privatnosti podataka, autonomiji i etiÄkim granicama algoritamskog utjecaja.

Etika podataka sada su _nuÅ¾ne zaÅ¡titne mjere_ za znanost o podacima i inÅ¾enjering, pomaÅ¾uÄ‡i nam minimizirati potencijalne Å¡tete i nenamjerne posljedice naÅ¡ih radnji voÄ‘enih podacima. [Gartnerov Hype Cycle za AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) identificira relevantne trendove u digitalnoj etici, odgovornoj AI i upravljanju AI-jem kao kljuÄne pokretaÄe veÄ‡ih megatrendova oko _demokratizacije_ i _industrijalizacije_ AI-ja.

![Gartnerov Hype Cycle za AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

U ovoj lekciji istraÅ¾it Ä‡emo fascinantno podruÄje etike podataka - od osnovnih pojmova i izazova, do studija sluÄaja i primijenjenih AI koncepata poput upravljanja - koji pomaÅ¾u uspostaviti kulturu etike u timovima i organizacijama koje rade s podacima i AI-jem.




## [Kviz prije predavanja](https://ff-quizzes.netlify.app/en/ds/quiz/2) ğŸ¯

## Osnovne definicije

ZapoÄnimo razumijevanjem osnovne terminologije.

RijeÄ "etika" dolazi od [grÄke rijeÄi "ethikos"](https://en.wikipedia.org/wiki/Ethics) (i njenog korijena "ethos") Å¡to znaÄi _karakter ili moralna priroda_. 

**Etika** se odnosi na zajedniÄke vrijednosti i moralne principe koji upravljaju naÅ¡im ponaÅ¡anjem u druÅ¡tvu. Etika se ne temelji na zakonima, veÄ‡ na Å¡iroko prihvaÄ‡enim normama o tome Å¡to je "ispravno naspram pogreÅ¡nog". MeÄ‘utim, etiÄka razmatranja mogu utjecati na inicijative korporativnog upravljanja i vladine regulative koje stvaraju viÅ¡e poticaja za usklaÄ‘enost.

**Etika podataka** je [nova grana etike](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1) koja "prouÄava i procjenjuje moralne probleme povezane s _podacima, algoritmima i odgovarajuÄ‡im praksama_". Ovdje se **"podaci"** fokusiraju na radnje povezane s generiranjem, snimanjem, kuriranjem, obradom, Å¡irenjem, dijeljenjem i koriÅ¡tenjem, **"algoritmi"** se fokusiraju na AI, agente, strojno uÄenje i robote, a **"prakse"** se fokusiraju na teme poput odgovorne inovacije, programiranja, hakiranja i kodeksa etike.

**Primijenjena etika** je [praktiÄna primjena moralnih razmatranja](https://en.wikipedia.org/wiki/Applied_ethics). To je proces aktivnog istraÅ¾ivanja etiÄkih pitanja u kontekstu _stvarnih radnji, proizvoda i procesa_, te poduzimanja korektivnih mjera kako bi se osiguralo da ostanu usklaÄ‘eni s naÅ¡im definiranim etiÄkim vrijednostima.

**Kultura etike** odnosi se na [_operacionalizaciju_ primijenjene etike](https://hbr.org/2019/05/how-to-design-an-ethical-organization) kako bi se osiguralo da se naÅ¡i etiÄki principi i prakse dosljedno i skalabilno usvajaju u cijeloj organizaciji. UspjeÅ¡ne kulture etike definiraju etiÄke principe na razini organizacije, pruÅ¾aju znaÄajne poticaje za usklaÄ‘enost i jaÄaju norme etike poticanjem i amplifikacijom Å¾eljenih ponaÅ¡anja na svakoj razini organizacije.


## Koncepti etike

U ovom odjeljku raspravljat Ä‡emo o konceptima poput **zajedniÄkih vrijednosti** (principa) i **etiÄkih izazova** (problema) za etiku podataka - te istraÅ¾iti **studije sluÄaja** koje vam pomaÅ¾u razumjeti ove koncepte u stvarnim kontekstima.

### 1. Principi etike

Svaka strategija etike podataka zapoÄinje definiranjem _etiÄkih principa_ - "zajedniÄkih vrijednosti" koje opisuju prihvatljiva ponaÅ¡anja i vode usklaÄ‘ene radnje u naÅ¡im projektima podataka i AI-ja. MoÅ¾ete ih definirati na individualnoj ili timskoj razini. MeÄ‘utim, veÄ‡ina velikih organizacija ih navodi u _misiji etiÄkog AI-ja_ ili okviru koji je definiran na korporativnoj razini i dosljedno proveden u svim timovima.

**Primjer:** Microsoftova [misija odgovornog AI-ja](https://www.microsoft.com/en-us/ai/responsible-ai) glasi: _"PosveÄ‡eni smo razvoju AI-ja voÄ‘enog etiÄkim principima koji stavljaju ljude na prvo mjesto"_ - identificirajuÄ‡i 6 etiÄkih principa u okviru prikazanom dolje:

![Odgovorni AI u Microsoftu](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

Pogledajmo ukratko ove principe. _Transparentnost_ i _odgovornost_ su temeljne vrijednosti na kojima se grade ostali principi - pa krenimo od njih:

* [**Odgovornost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) Äini praktiÄare _odgovornima_ za njihove operacije s podacima i AI-jem te usklaÄ‘enost s ovim etiÄkim principima.
* [**Transparentnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) osigurava da su radnje s podacima i AI-jem _razumljive_ korisnicima, objaÅ¡njavajuÄ‡i Å¡to i zaÅ¡to iza odluka.
* [**Pravednost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - fokusira se na osiguranje da AI tretira _sve ljude_ pravedno, rjeÅ¡avajuÄ‡i bilo kakve sustavne ili implicitne socio-tehniÄke pristranosti u podacima i sustavima.
* [**Pouzdanost i sigurnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - osigurava da se AI ponaÅ¡a _dosljedno_ s definiranim vrijednostima, minimizirajuÄ‡i potencijalne Å¡tete ili nenamjerne posljedice.
* [**Privatnost i sigurnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - odnosi se na razumijevanje porijekla podataka i pruÅ¾anje _zaÅ¡tite privatnosti podataka_ korisnicima.
* [**UkljuÄivost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - odnosi se na dizajniranje AI rjeÅ¡enja s namjerom, prilagoÄ‘avajuÄ‡i ih za zadovoljavanje _Å¡irokog raspona ljudskih potreba_ i sposobnosti.

> ğŸš¨ Razmislite o tome Å¡to bi mogla biti vaÅ¡a misija etike podataka. IstraÅ¾ite okvire etiÄkog AI-ja drugih organizacija - ovdje su primjeri iz [IBM-a](https://www.ibm.com/cloud/learn/ai-ethics), [Googlea](https://ai.google/principles) i [Facebooka](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Koje zajedniÄke vrijednosti imaju? Kako se ti principi odnose na AI proizvod ili industriju u kojoj djeluju?

### 2. EtiÄki izazovi

Nakon Å¡to definiramo etiÄke principe, sljedeÄ‡i korak je procjena naÅ¡ih radnji s podacima i AI-jem kako bismo vidjeli jesu li usklaÄ‘ene s tim zajedniÄkim vrijednostima. Razmislite o svojim radnjama u dvije kategorije: _prikupljanje podataka_ i _dizajn algoritama_. 

Kod prikupljanja podataka, radnje Ä‡e vjerojatno ukljuÄivati **osobne podatke** ili osobno prepoznatljive informacije (PII) za prepoznatljive Å¾ive pojedince. To ukljuÄuje [razliÄite stavke neosobnih podataka](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) koje _zajedno_ identificiraju pojedinca. EtiÄki izazovi mogu se odnositi na _privatnost podataka_, _vlasniÅ¡tvo podataka_ i povezane teme poput _informiranog pristanka_ i _prava intelektualnog vlasniÅ¡tva_ za korisnike.

Kod dizajna algoritama, radnje Ä‡e ukljuÄivati prikupljanje i kuriranje **skupova podataka**, a zatim njihovo koriÅ¡tenje za treniranje i implementaciju **modela podataka** koji predviÄ‘aju ishode ili automatiziraju odluke u stvarnim kontekstima. EtiÄki izazovi mogu nastati zbog _pristranosti skupa podataka_, problema s _kvalitetom podataka_, _nepravednosti_ i _pogreÅ¡nog predstavljanja_ u algoritmima - ukljuÄujuÄ‡i neke probleme koji su sustavne prirode.

U oba sluÄaja, etiÄki izazovi istiÄu podruÄja gdje naÅ¡e radnje mogu doÄ‡i u sukob s naÅ¡im zajedniÄkim vrijednostima. Kako bismo otkrili, ublaÅ¾ili, minimizirali ili eliminirali ove zabrinutosti - moramo postavljati moralna "da/ne" pitanja vezana uz naÅ¡e radnje, a zatim poduzeti korektivne mjere prema potrebi. Pogledajmo neke etiÄke izazove i moralna pitanja koja postavljaju:


#### 2.1 VlasniÅ¡tvo nad podacima

Prikupljanje podataka Äesto ukljuÄuje osobne podatke koji mogu identificirati subjekte podataka. [VlasniÅ¡tvo nad podacima](https://permission.io/blog/data-ownership) odnosi se na _kontrolu_ i [_prava korisnika_](https://permission.io/blog/data-ownership) vezana uz stvaranje, obradu i Å¡irenje podataka. 

Moralna pitanja koja trebamo postaviti su: 
 * Tko posjeduje podatke? (korisnik ili organizacija)
 * Koja prava imaju subjekti podataka? (npr. pristup, brisanje, prenosivost)
 * Koja prava imaju organizacije? (npr. ispravljanje zlonamjernih korisniÄkih recenzija)

#### 2.2 Informirani pristanak

[Informirani pristanak](https://legaldictionary.net/informed-consent/) definira Äin korisnika koji pristaju na radnju (poput prikupljanja podataka) uz _potpuno razumijevanje_ relevantnih Äinjenica, ukljuÄujuÄ‡i svrhu, potencijalne rizike i alternative. 

Pitanja za istraÅ¾ivanje ovdje su:
 * Je li korisnik (subjekt podataka) dao dopuÅ¡tenje za prikupljanje i koriÅ¡tenje podataka?
 * Je li korisnik razumio svrhu za koju su ti podaci prikupljeni?
 * Je li korisnik razumio potencijalne rizike od svog sudjelovanja?

#### 2.3 Intelektualno vlasniÅ¡tvo

[Intelektualno vlasniÅ¡tvo](https://en.wikipedia.org/wiki/Intellectual_property) odnosi se na nematerijalne kreacije koje proizlaze iz ljudske inicijative, a koje mogu _imati ekonomsku vrijednost_ za pojedince ili tvrtke. 

Pitanja za istraÅ¾ivanje ovdje su:
 * Jesu li prikupljeni podaci imali ekonomsku vrijednost za korisnika ili tvrtku?
 * Ima li **korisnik** intelektualno vlasniÅ¡tvo ovdje?
 * Ima li **organizacija** intelektualno vlasniÅ¡tvo ovdje?
 * Ako ta prava postoje, kako ih Å¡titimo?

#### 2.4 Privatnost podataka

[Privatnost podataka](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) ili informacijska privatnost odnosi se na oÄuvanje privatnosti korisnika i zaÅ¡titu identiteta korisnika u vezi s osobno prepoznatljivim informacijama. 

Pitanja za istraÅ¾ivanje ovdje su:
 * Jesu li korisniÄki (osobni) podaci osigurani protiv hakiranja i curenja?
 * Jesu li korisniÄki podaci dostupni samo ovlaÅ¡tenim korisnicima i kontekstima?
 * Je li anonimnost korisnika oÄuvana kada se podaci dijele ili Å¡ire?
 * MoÅ¾e li se korisnik de-identificirati iz anonimiziranih skupova podataka?


#### 2.5 Pravo na zaborav

[Pravo na zaborav](https://en.wikipedia.org/wiki/Right_to_be_forgotten) ili [Pravo na brisanje](https://www.gdpreu.org/right-to-be-forgotten/) pruÅ¾a dodatnu zaÅ¡titu osobnih podataka korisnicima. Konkretno, daje korisnicima pravo da zatraÅ¾e brisanje ili uklanjanje osobnih podataka iz internetskih pretraÅ¾ivanja i drugih lokacija, _pod odreÄ‘enim okolnostima_ - omoguÄ‡ujuÄ‡i im novi poÄetak online bez da ih proÅ¡le radnje optereÄ‡uju.

Pitanja za istraÅ¾ivanje ovdje su:
 * OmoguÄ‡uje li sustav subjektima podataka da zatraÅ¾e brisanje?
 * Treba li povlaÄenje korisniÄkog pristanka automatski pokrenuti brisanje?
 * Jesu li podaci prikupljeni bez pristanka ili nezakonitim sredstvima?
 * Jesmo li usklaÄ‘eni s vladinim regulativama za privatnost podataka?


#### 2.6 Pristranost skupa podataka

Pristranost skupa podataka ili [pristranost prikupljanja](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) odnosi se na odabir _nereprezentativnog_ podskupa podataka za razvoj algoritama, stvarajuÄ‡i potencijalnu nepravednost u rezultatima za razliÄite skupine. Vrste pristranosti ukljuÄuju pristranost odabira ili uzorkovanja, pristranost volontera i pristranost instrumenata. 

Pitanja za istraÅ¾ivanje ovdje su:
 * Jesmo li angaÅ¾irali reprezentativni skup subjekata podataka?
 * Jesmo li testirali naÅ¡ prikupljeni ili kurirani skup podataka na razne pristranosti?
 * MoÅ¾emo li ublaÅ¾iti ili ukloniti otkrivene pristranosti?

#### 2.7 Kvaliteta podataka

[Kvaliteta podataka](https://lakefs.io/data-quality-testing/) ispituje valjanost kuriranog skupa podataka koriÅ¡tenog za razvoj naÅ¡ih algoritama, provjeravajuÄ‡i jesu li znaÄajke i zapisi u skladu sa zahtjevima za razinu toÄnosti i dosljednosti potrebnu za naÅ¡u AI svrhu.

Pitanja za istraÅ¾ivanje ovdje su:
 * Jesmo li uhvatili valjane _znaÄajke_ za naÅ¡ sluÄaj upotrebe?
 * Jesu li podaci dosljedno prikupljeni iz razliÄitih izvora podataka?
 * Je li skup podataka _potpun_ za razliÄite uvjete ili scenarije?
* Je li informacija zabiljeÅ¾ena _toÄno_ u odraÅ¾avanju stvarnosti?

#### 2.8 Pravednost algoritma

[Pravednost algoritma](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) provjerava dizajn algoritma kako bi se utvrdilo diskriminira li sustavno odreÄ‘ene podskupine ispitanika, Å¡to moÅ¾e dovesti do [potencijalnih Å¡teta](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) u _raspodjeli_ (kada se resursi uskraÄ‡uju toj skupini) i _kvaliteti usluge_ (kada AI nije jednako precizan za sve podskupine).

Pitanja za razmatranje:
* Jesmo li procijenili toÄnost modela za razliÄite podskupine i uvjete?
* Jesmo li detaljno analizirali sustav zbog potencijalnih Å¡teta (npr. stereotipiziranja)?
* MoÅ¾emo li revidirati podatke ili ponovno trenirati modele kako bismo ublaÅ¾ili identificirane Å¡tete?

IstraÅ¾ite resurse poput [AI Fairness checklists](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) za viÅ¡e informacija.

#### 2.9 PogreÅ¡no predstavljanje

[PogreÅ¡no predstavljanje podataka](https://www.sciencedirect.com/topics/computer-science/misrepresentation) odnosi se na pitanje jesmo li komunikaciju utemeljenu na iskreno prijavljenim podacima koristili na obmanjujuÄ‡i naÄin kako bismo podrÅ¾ali Å¾eljeni narativ.

Pitanja za razmatranje:
* Prijavljujemo li nepotpune ili netoÄne podatke?
* Vizualiziramo li podatke na naÄin koji vodi do obmanjujuÄ‡ih zakljuÄaka?
* Koristimo li selektivne statistiÄke tehnike za manipulaciju rezultatima?
* Postoje li alternativna objaÅ¡njenja koja mogu ponuditi drugaÄiji zakljuÄak?

#### 2.10 Slobodan izbor

[Iluzija slobodnog izbora](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) dogaÄ‘a se kada sustavi "arhitekture izbora" koriste algoritme za donoÅ¡enje odluka kako bi potaknuli ljude na preferirani ishod, dok im se pritom Äini da imaju opcije i kontrolu. Ovi [tamni obrasci](https://www.darkpatterns.org/) mogu uzrokovati druÅ¡tvene i ekonomske Å¡tete korisnicima. BuduÄ‡i da odluke korisnika utjeÄu na profile ponaÅ¡anja, te radnje potencijalno oblikuju buduÄ‡e izbore koji mogu pojaÄati ili proÅ¡iriti utjecaj tih Å¡teta.

Pitanja za razmatranje:
* Je li korisnik razumio implikacije donoÅ¡enja tog izbora?
* Je li korisnik bio svjestan (alternativnih) izbora i prednosti i nedostataka svakog?
* MoÅ¾e li korisnik kasnije poniÅ¡titi automatizirani ili utjecani izbor?

### 3. Studije sluÄaja

Kako bismo ove etiÄke izazove stavili u kontekst stvarnog svijeta, korisno je pogledati studije sluÄaja koje istiÄu potencijalne Å¡tete i posljedice za pojedince i druÅ¡tvo kada se zanemaruju etiÄka naÄela.

Evo nekoliko primjera:

| EtiÄki izazov | Studija sluÄaja | 
|--- |--- |
| **Informirani pristanak** | 1972. - [Studija o sifilisu u Tuskegeeju](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - AfroameriÄkim muÅ¡karcima koji su sudjelovali u studiji obeÄ‡ana je besplatna medicinska skrb, _ali su ih istraÅ¾ivaÄi obmanuli_ ne informirajuÄ‡i ih o dijagnozi ili dostupnosti lijeÄenja. Mnogi su umrli, a partneri i djeca su bili pogoÄ‘eni; studija je trajala 40 godina. | 
| **Privatnost podataka** | 2007. - [Netflix nagrada za podatke](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) omoguÄ‡ila je istraÅ¾ivaÄima pristup _10M anonimnih ocjena filmova od 50K korisnika_ kako bi poboljÅ¡ali algoritme preporuka. MeÄ‘utim, istraÅ¾ivaÄi su uspjeli povezati anonimne podatke s osobno identificirajuÄ‡im podacima u _vanjskim skupovima podataka_ (npr. IMDb komentari) - uÄinkovito "deanonimizirajuÄ‡i" neke Netflix pretplatnike.|
| **Pristranost u prikupljanju podataka** | 2013. - Grad Boston [razvio Street Bump](https://www.boston.gov/transportation/street-bump), aplikaciju koja je omoguÄ‡ila graÄ‘anima prijavu rupa na cestama, dajuÄ‡i gradu bolje podatke o cestama za pronalaÅ¾enje i popravak problema. MeÄ‘utim, [ljudi s niÅ¾im prihodima imali su manje pristupa automobilima i telefonima](https://hbr.org/2013/04/the-hidden-biases-in-big-data), ÄineÄ‡i njihove probleme na cestama nevidljivima u ovoj aplikaciji. Programeri su suraÄ‘ivali s akademicima na rjeÅ¡avanju pitanja _pravednog pristupa i digitalnih podjela_. |
| **Pravednost algoritma** | 2018. - MIT [Gender Shades Study](http://gendershades.org/overview.html) procijenila je toÄnost AI proizvoda za klasifikaciju spola, otkrivajuÄ‡i nedostatke u toÄnosti za Å¾ene i osobe tamnije boje koÅ¾e. [Apple Card iz 2019.](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) Äinilo se da nudi manje kredita Å¾enama nego muÅ¡karcima. Oba primjera ilustriraju probleme pristranosti algoritma koji dovode do socio-ekonomskih Å¡teta.|
| **PogreÅ¡no predstavljanje podataka** | 2020. - [Odjel za javno zdravstvo Georgije objavio COVID-19 grafikone](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) koji su izgledali kao da obmanjuju graÄ‘ane o trendovima potvrÄ‘enih sluÄajeva s ne-kronoloÅ¡kim redoslijedom na x-osi. Ovo ilustrira pogreÅ¡no predstavljanje kroz trikove vizualizacije. |
| **Iluzija slobodnog izbora** | 2020. - Edukativna aplikacija [ABCmouse platila je 10M dolara za nagodbu s FTC-om](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/) gdje su roditelji bili prisiljeni plaÄ‡ati pretplate koje nisu mogli otkazati. Ovo ilustrira tamne obrasce u arhitekturi izbora, gdje su korisnici bili potaknuti na potencijalno Å¡tetne odluke. |
| **Privatnost podataka i prava korisnika** | 2021. - Facebook [curenje podataka](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) otkrilo je podatke 530M korisnika, Å¡to je rezultiralo nagodbom od 5B dolara s FTC-om. MeÄ‘utim, odbio je obavijestiti korisnike o curenju, krÅ¡eÄ‡i prava korisnika na transparentnost i pristup podacima. |

Å½elite istraÅ¾iti viÅ¡e studija sluÄaja? Pogledajte ove resurse:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - etiÄke dileme u raznim industrijama. 
* [TeÄaj o etici u znanosti o podacima](https://www.coursera.org/learn/data-science-ethics#syllabus) - kljuÄne studije sluÄaja.
* [Primjeri gdje su stvari krenule po zlu](https://deon.drivendata.org/examples/) - Deon popis s primjerima.

> ğŸš¨ Razmislite o studijama sluÄaja koje ste vidjeli - jeste li doÅ¾ivjeli ili bili pogoÄ‘eni sliÄnim etiÄkim izazovom u svom Å¾ivotu? MoÅ¾ete li se sjetiti barem jedne druge studije sluÄaja koja ilustrira jedan od etiÄkih izazova o kojima smo raspravljali u ovom odjeljku?

## Primijenjena etika

Razgovarali smo o konceptima etike, izazovima i studijama sluÄaja u kontekstu stvarnog svijeta. No, kako zapoÄeti _primjenu_ etiÄkih naÄela i praksi u naÅ¡im projektima? I kako _operacionalizirati_ ove prakse za bolju upravu? IstraÅ¾imo neka rjeÅ¡enja iz stvarnog svijeta:

### 1. Profesionalni kodeksi

Profesionalni kodeksi nude jednu opciju za organizacije da "potaknu" Älanove na podrÅ¡ku njihovim etiÄkim naÄelima i misiji. Kodeksi su _moralne smjernice_ za profesionalno ponaÅ¡anje, pomaÅ¾uÄ‡i zaposlenicima ili Älanovima donositi odluke koje su u skladu s naÄelima organizacije. Oni su uÄinkoviti koliko i dobrovoljna usklaÄ‘enost Älanova; meÄ‘utim, mnoge organizacije nude dodatne nagrade i kazne kako bi motivirale Älanove na usklaÄ‘enost.

Primjeri ukljuÄuju:

* [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Kodeks etike
* [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Kodeks ponaÅ¡anja (kreiran 2013.)
* [ACM Kodeks etike i profesionalnog ponaÅ¡anja](https://www.acm.org/code-of-ethics) (od 1993.)

> ğŸš¨ Pripadate li profesionalnoj organizaciji za inÅ¾enjering ili znanost o podacima? IstraÅ¾ite njihovu stranicu kako biste vidjeli definiraju li profesionalni kodeks etike. Å to to govori o njihovim etiÄkim naÄelima? Kako "potiÄu" Älanove na pridrÅ¾avanje kodeksa?

### 2. EtiÄki popisi za provjeru

Dok profesionalni kodeksi definiraju zahtijevano _etiÄko ponaÅ¡anje_ od praktiÄara, oni [imaju poznata ograniÄenja](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) u provedbi, posebno u velikim projektima. Umjesto toga, mnogi struÄnjaci za znanost o podacima [zagovaraju popise za provjeru](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), koji mogu **povezati naÄela s praksama** na deterministiÄki i provediv naÄin.

Popisi za provjeru pretvaraju pitanja u zadatke "da/ne" koji se mogu operacionalizirati, omoguÄ‡ujuÄ‡i njihovo praÄ‡enje kao dio standardnih tijekova rada za izdavanje proizvoda.

Primjeri ukljuÄuju:
* [Deon](https://deon.drivendata.org/) - opÄ‡i popis za etiku podataka kreiran prema [preporukama industrije](https://deon.drivendata.org/#checklist-citations) s alatom naredbenog retka za jednostavnu integraciju.
* [Popis za provjeru privatnosti](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - pruÅ¾a opÄ‡e smjernice za praksu rukovanja informacijama iz pravne i druÅ¡tvene perspektive.
* [Popis za provjeru pravednosti AI-a](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - kreiran od strane AI praktiÄara za podrÅ¡ku usvajanju i integraciji provjera pravednosti u cikluse razvoja AI-a.
* [22 pitanja za etiku u podacima i AI-u](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - otvoreniji okvir, strukturiran za poÄetno istraÅ¾ivanje etiÄkih pitanja u dizajnu, implementaciji i organizacijskim kontekstima.

### 3. EtiÄki propisi

Etika se odnosi na definiranje zajedniÄkih vrijednosti i Äinjenje ispravnih stvari _dobrovoljno_. **UsklaÄ‘enost** se odnosi na _poÅ¡tivanje zakona_ ako i gdje je definiran. **Upravljanje** opÄ‡enito pokriva sve naÄine na koje organizacije djeluju kako bi provele etiÄka naÄela i uskladile se s utvrÄ‘enim zakonima.

Danas upravljanje ima dva oblika unutar organizacija. Prvo, radi se o definiranju **etiÄkih AI** naÄela i uspostavljanju praksi za operacionalizaciju usvajanja u svim AI projektima organizacije. Drugo, radi se o usklaÄ‘ivanju sa svim vladinim propisima o **zaÅ¡titi podataka** za regije u kojima djeluje.

Primjeri propisa o zaÅ¡titi podataka i privatnosti:

* `1974`, [Zakon o privatnosti SAD-a](https://www.justice.gov/opcl/privacy-act-1974) - regulira _prikupljanje, koriÅ¡tenje i otkrivanje_ osobnih podataka od strane savezne vlade.
* `1996`, [Zakon o prenosivosti i odgovornosti zdravstvenog osiguranja SAD-a (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - Å¡titi osobne zdravstvene podatke.
* `1998`, [Zakon o zaÅ¡titi privatnosti djece na internetu SAD-a (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - Å¡titi privatnost podataka djece mlaÄ‘e od 13 godina.
* `2018`, [OpÄ‡a uredba o zaÅ¡titi podataka (GDPR)](https://gdpr-info.eu/) - pruÅ¾a prava korisnicima, zaÅ¡titu podataka i privatnost.
* `2018`, [Zakon o privatnosti potroÅ¡aÄa Kalifornije (CCPA)](https://www.oag.ca.gov/privacy/ccpa) daje potroÅ¡aÄima viÅ¡e _prava_ nad njihovim (osobnim) podacima.
* `2021`, Kineski [Zakon o zaÅ¡titi osobnih podataka](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) upravo je donesen, stvarajuÄ‡i jedan od najjaÄih propisa o privatnosti podataka na internetu u svijetu.

> ğŸš¨ Europska unija definirala je GDPR (OpÄ‡a uredba o zaÅ¡titi podataka), koji ostaje jedan od najutjecajnijih propisa o privatnosti podataka danas. Jeste li znali da takoÄ‘er definira [8 prava korisnika](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) za zaÅ¡titu digitalne privatnosti i osobnih podataka graÄ‘ana? Saznajte koja su to prava i zaÅ¡to su vaÅ¾na.

### 4. Kultura etike

Napominjemo da i dalje postoji nematerijalni jaz izmeÄ‘u _usklaÄ‘enosti_ (Äinjenja dovoljno da se zadovolji "slovo zakona") i rjeÅ¡avanja [sustavnih problema](https://www.coursera.org/learn/data-science-ethics/home/week/4) (poput osifikacije, asimetrije informacija i distribucijske nepravednosti) koji mogu ubrzati upotrebu AI-a u Å¡tetne svrhe.

Ovo drugo zahtijeva [suradniÄke pristupe za definiranje kultura etike](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f) koje grade emocionalne veze i dosljedne zajedniÄke vrijednosti _meÄ‘u organizacijama_ u industriji. To poziva na viÅ¡e [formaliziranih kultura etike podataka](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) u organizacijama - omoguÄ‡ujuÄ‡i _svima_ da [povuku Andon konop](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (kako bi rano ukazali na etiÄke probleme) i ÄineÄ‡i _etiÄke procjene_ (npr. pri zapoÅ¡ljavanju) kljuÄnim kriterijem za formiranje timova u AI projektima.

---
## [Kviz nakon predavanja](https://ff-quizzes.netlify.app/en/ds/quiz/3) ğŸ¯
## Pregled i samostalno uÄenje

TeÄajevi i knjige pomaÅ¾u u razumijevanju osnovnih etiÄkih koncepata i izazova, dok studije sluÄaja i alati pomaÅ¾u u primjeni etiÄkih praksi u stvarnim kontekstima. Evo nekoliko resursa za poÄetak.
* [Strojno uÄenje za poÄetnike](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - lekcija o pravednosti, od Microsofta.  
* [Principi odgovorne umjetne inteligencije](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - besplatni obrazovni put na Microsoft Learn.  
* [Etika i znanost o podacima](https://resources.oreilly.com/examples/0636920203964) - O'Reilly e-knjiga (M. Loukides, H. Mason i dr.)  
* [Etika znanosti o podacima](https://www.coursera.org/learn/data-science-ethics#syllabus) - online teÄaj SveuÄiliÅ¡ta Michigan.  
* [Etika razotkrivena](https://ethicsunwrapped.utexas.edu/case-studies) - studije sluÄaja SveuÄiliÅ¡ta Texas.  

# Zadatak  

[NapiÅ¡ite studiju sluÄaja o etici podataka](assignment.md)  

---

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden pomoÄ‡u AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati toÄnost, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kljuÄne informacije preporuÄuje se profesionalni prijevod od strane struÄnjaka. Ne preuzimamo odgovornost za nesporazume ili pogreÅ¡na tumaÄenja koja mogu proizaÄ‡i iz koriÅ¡tenja ovog prijevoda.