<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1b560955ff39a2bcf2a049fce474a951",
  "translation_date": "2025-09-05T12:22:36+00:00",
  "source_file": "2-Working-With-Data/08-data-preparation/README.md",
  "language_code": "fr"
}
-->
# Travailler avec les donn√©es : Pr√©paration des donn√©es

|![ Sketchnote par [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/08-DataPreparation.png)|
|:---:|
|Pr√©paration des donn√©es - _Sketchnote par [@nitya](https://twitter.com/nitya)_ |

## [Quiz avant le cours](https://ff-quizzes.netlify.app/en/ds/quiz/14)

Selon sa source, les donn√©es brutes peuvent contenir des incoh√©rences qui posent des d√©fis pour l'analyse et la mod√©lisation. En d'autres termes, ces donn√©es peuvent √™tre qualifi√©es de "sales" et n√©cessiter un nettoyage. Cette le√ßon se concentre sur les techniques de nettoyage et de transformation des donn√©es pour g√©rer les probl√®mes de donn√©es manquantes, inexactes ou incompl√®tes. Les sujets abord√©s dans cette le√ßon utiliseront Python et la biblioth√®que Pandas et seront [illustr√©s dans le notebook](../../../../2-Working-With-Data/08-data-preparation/notebook.ipynb) de ce r√©pertoire.

## L'importance de nettoyer les donn√©es

- **Facilit√© d'utilisation et de r√©utilisation** : Lorsque les donn√©es sont correctement organis√©es et normalis√©es, il est plus facile de les rechercher, les utiliser et les partager avec d'autres.

- **Coh√©rence** : La science des donn√©es n√©cessite souvent de travailler avec plusieurs ensembles de donn√©es, o√π des ensembles provenant de diff√©rentes sources doivent √™tre fusionn√©s. S'assurer que chaque ensemble de donn√©es individuel respecte une standardisation commune garantit que les donn√©es restent utiles une fois fusionn√©es.

- **Pr√©cision des mod√®les** : Des donn√©es nettoy√©es am√©liorent la pr√©cision des mod√®les qui en d√©pendent.

## Objectifs et strat√©gies courants de nettoyage

- **Explorer un ensemble de donn√©es** : L'exploration des donn√©es, qui est abord√©e dans une [le√ßon ult√©rieure](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/4-Data-Science-Lifecycle/15-analyzing), peut vous aider √† identifier les donn√©es n√©cessitant un nettoyage. Observer visuellement les valeurs dans un ensemble de donn√©es peut donner une id√©e de ce √† quoi s'attendre pour le reste ou fournir une id√©e des probl√®mes √† r√©soudre. L'exploration peut inclure des requ√™tes basiques, des visualisations et des √©chantillonnages.

- **Formatage** : Selon la source, les donn√©es peuvent pr√©senter des incoh√©rences dans leur pr√©sentation. Cela peut poser des probl√®mes pour la recherche et la repr√©sentation des valeurs, o√π elles sont visibles dans l'ensemble de donn√©es mais mal repr√©sent√©es dans les visualisations ou les r√©sultats de requ√™tes. Les probl√®mes courants de formatage incluent la gestion des espaces blancs, des dates et des types de donn√©es. La r√©solution de ces probl√®mes d√©pend souvent des utilisateurs des donn√©es. Par exemple, les normes sur la pr√©sentation des dates et des nombres peuvent varier selon les pays.

- **Doublons** : Les donn√©es ayant plusieurs occurrences peuvent produire des r√©sultats inexacts et doivent g√©n√©ralement √™tre supprim√©es. Cela peut se produire fr√©quemment lors de la fusion de plusieurs ensembles de donn√©es. Cependant, il existe des cas o√π les doublons contiennent des informations suppl√©mentaires et doivent √™tre conserv√©s.

- **Donn√©es manquantes** : Les donn√©es manquantes peuvent entra√Æner des r√©sultats biais√©s ou faibles. Parfois, elles peuvent √™tre r√©solues par un "rechargement" des donn√©es, en remplissant les valeurs manquantes par des calculs et du code comme Python, ou simplement en supprimant la valeur et les donn√©es correspondantes. Les raisons des donn√©es manquantes et les actions prises pour les r√©soudre d√©pendent souvent de leur origine.

## Explorer les informations des DataFrames
> **Objectif d'apprentissage** : √Ä la fin de cette sous-section, vous devriez √™tre √† l'aise pour trouver des informations g√©n√©rales sur les donn√©es stock√©es dans les DataFrames de pandas.

Une fois vos donn√©es charg√©es dans pandas, elles seront probablement dans un DataFrame (voir la [le√ßon pr√©c√©dente](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/2-Working-With-Data/07-python#dataframe) pour un aper√ßu d√©taill√©). Cependant, si votre DataFrame contient 60 000 lignes et 400 colonnes, comment commencer √† comprendre ce que vous avez ? Heureusement, [pandas](https://pandas.pydata.org/) offre des outils pratiques pour examiner rapidement les informations g√©n√©rales sur un DataFrame, ainsi que les premi√®res et derni√®res lignes.

Pour explorer cette fonctionnalit√©, nous allons importer la biblioth√®que Python scikit-learn et utiliser un ensemble de donn√©es embl√©matique : l'ensemble de donn√©es **Iris**.

```python
import pandas as pd
from sklearn.datasets import load_iris

iris = load_iris()
iris_df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])
```
|                                        |longueur du s√©pale (cm)|largeur du s√©pale (cm)|longueur du p√©tale (cm)|largeur du p√©tale (cm)|
|----------------------------------------|-----------------------|----------------------|-----------------------|----------------------|
|0                                       |5.1                    |3.5                   |1.4                    |0.2                   |
|1                                       |4.9                    |3.0                   |1.4                    |0.2                   |
|2                                       |4.7                    |3.2                   |1.3                    |0.2                   |
|3                                       |4.6                    |3.1                   |1.5                    |0.2                   |
|4                                       |5.0                    |3.6                   |1.4                    |0.2                   |

- **DataFrame.info** : Pour commencer, la m√©thode `info()` est utilis√©e pour afficher un r√©sum√© du contenu pr√©sent dans un `DataFrame`. Jetons un coup d'≈ìil √† cet ensemble de donn√©es pour voir ce que nous avons :
```python
iris_df.info()
```
```
RangeIndex: 150 entries, 0 to 149
Data columns (total 4 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   sepal length (cm)  150 non-null    float64
 1   sepal width (cm)   150 non-null    float64
 2   petal length (cm)  150 non-null    float64
 3   petal width (cm)   150 non-null    float64
dtypes: float64(4)
memory usage: 4.8 KB
```
D'apr√®s cela, nous savons que l'ensemble de donn√©es *Iris* contient 150 entr√©es r√©parties sur quatre colonnes sans valeurs nulles. Toutes les donn√©es sont stock√©es sous forme de nombres √† virgule flottante 64 bits.

- **DataFrame.head()** : Ensuite, pour v√©rifier le contenu r√©el du `DataFrame`, nous utilisons la m√©thode `head()`. Voyons √† quoi ressemblent les premi√®res lignes de notre `iris_df` :
```python
iris_df.head()
```
```
   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
0                5.1               3.5                1.4               0.2
1                4.9               3.0                1.4               0.2
2                4.7               3.2                1.3               0.2
3                4.6               3.1                1.5               0.2
4                5.0               3.6                1.4               0.2
```
- **DataFrame.tail()** : √Ä l'inverse, pour v√©rifier les derni√®res lignes du `DataFrame`, nous utilisons la m√©thode `tail()` :
```python
iris_df.tail()
```
```
     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
145                6.7               3.0                5.2               2.3
146                6.3               2.5                5.0               1.9
147                6.5               3.0                5.2               2.0
148                6.2               3.4                5.4               2.3
149                5.9               3.0                5.1               1.8
```
> **√Ä retenir** : En examinant simplement les m√©tadonn√©es sur les informations d'un DataFrame ou les premi√®res et derni√®res valeurs, vous pouvez obtenir une id√©e imm√©diate de la taille, de la forme et du contenu des donn√©es avec lesquelles vous travaillez.

## G√©rer les donn√©es manquantes
> **Objectif d'apprentissage** : √Ä la fin de cette sous-section, vous devriez savoir comment remplacer ou supprimer les valeurs nulles des DataFrames.

La plupart du temps, les ensembles de donn√©es que vous souhaitez utiliser (ou devez utiliser) contiennent des valeurs manquantes. La mani√®re dont les donn√©es manquantes sont g√©r√©es implique des compromis subtils qui peuvent affecter votre analyse finale et les r√©sultats r√©els.

Pandas g√®re les valeurs manquantes de deux mani√®res. La premi√®re, que vous avez d√©j√† vue dans les sections pr√©c√©dentes, est `NaN`, ou Not a Number. Il s'agit d'une valeur sp√©ciale faisant partie de la sp√©cification IEEE pour les nombres √† virgule flottante et utilis√©e uniquement pour indiquer des valeurs manquantes de type flottant.

Pour les valeurs manquantes autres que les flottants, pandas utilise l'objet Python `None`. Bien que cela puisse sembler d√©routant d'avoir deux types de valeurs indiquant essentiellement la m√™me chose, il existe des raisons programmatiques solides pour ce choix de conception. En pratique, cela permet √† pandas de proposer un compromis efficace dans la grande majorit√© des cas. Cependant, `None` et `NaN` ont des restrictions qu'il est important de conna√Ætre concernant leur utilisation.

D√©couvrez-en davantage sur `NaN` et `None` dans le [notebook](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/4-Data-Science-Lifecycle/15-analyzing/notebook.ipynb) !

- **D√©tecter les valeurs nulles** : Dans `pandas`, les m√©thodes `isnull()` et `notnull()` sont vos principales m√©thodes pour d√©tecter les donn√©es nulles. Les deux renvoient des masques bool√©ens sur vos donn√©es. Nous utiliserons `numpy` pour les valeurs `NaN` :
```python
import numpy as np

example1 = pd.Series([0, np.nan, '', None])
example1.isnull()
```
```
0    False
1     True
2    False
3     True
dtype: bool
```
Regardez attentivement la sortie. Y a-t-il quelque chose qui vous surprend ? Bien que `0` soit un nul arithm√©tique, il reste n√©anmoins un entier valide et pandas le traite comme tel. `''` est un peu plus subtil. Bien que nous l'ayons utilis√© dans la Section 1 pour repr√©senter une cha√Æne vide, il reste un objet cha√Æne et non une repr√©sentation de null pour pandas.

Maintenant, retournons cela et utilisons ces m√©thodes de mani√®re plus proche de leur utilisation pratique. Vous pouvez utiliser des masques bool√©ens directement comme index de ``Series`` ou ``DataFrame``, ce qui peut √™tre utile pour travailler avec des valeurs manquantes (ou pr√©sentes) isol√©es.

> **√Ä retenir** : Les m√©thodes `isnull()` et `notnull()` produisent des r√©sultats similaires lorsqu'elles sont utilis√©es dans des `DataFrame`s : elles montrent les r√©sultats et l'index de ces r√©sultats, ce qui vous aidera √©norm√©ment √† g√©rer vos donn√©es.

- **Supprimer les valeurs nulles** : Au-del√† de l'identification des valeurs manquantes, pandas offre un moyen pratique de supprimer les valeurs nulles des `Series` et `DataFrame`s. (En particulier pour les grands ensembles de donn√©es, il est souvent plus conseill√© de simplement supprimer les valeurs manquantes [NA] de votre analyse plut√¥t que de les traiter autrement.) Pour voir cela en action, revenons √† `example1` :
```python
example1 = example1.dropna()
example1
```
```
0    0
2     
dtype: object
```
Notez que cela devrait ressembler √† votre sortie de `example3[example3.notnull()]`. La diff√©rence ici est que, plut√¥t que de simplement indexer les valeurs masqu√©es, `dropna` a supprim√© ces valeurs manquantes de la `Series` `example1`.

√âtant donn√© que les `DataFrame`s ont deux dimensions, ils offrent plus d'options pour supprimer des donn√©es.

```python
example2 = pd.DataFrame([[1,      np.nan, 7], 
                         [2,      5,      8], 
                         [np.nan, 6,      9]])
example2
```
|      | 0 | 1 | 2 |
|------|---|---|---|
|0     |1.0|NaN|7  |
|1     |2.0|5.0|8  |
|2     |NaN|6.0|9  |

(Avez-vous remarqu√© que pandas a converti deux des colonnes en flottants pour accueillir les `NaN` ?)

Vous ne pouvez pas supprimer une seule valeur d'un `DataFrame`, vous devez donc supprimer des lignes ou des colonnes enti√®res. Selon ce que vous faites, vous pourriez vouloir faire l'un ou l'autre, et pandas vous offre des options pour les deux. En science des donn√©es, les colonnes repr√©sentent g√©n√©ralement des variables et les lignes des observations, vous √™tes donc plus susceptible de supprimer des lignes de donn√©es ; le param√®tre par d√©faut de `dropna()` est de supprimer toutes les lignes contenant des valeurs nulles :

```python
example2.dropna()
```
```
	0	1	2
1	2.0	5.0	8
```
Si n√©cessaire, vous pouvez supprimer les valeurs NA des colonnes. Utilisez `axis=1` pour le faire :
```python
example2.dropna(axis='columns')
```
```
	2
0	7
1	8
2	9
```
Notez que cela peut supprimer beaucoup de donn√©es que vous pourriez vouloir conserver, en particulier dans les petits ensembles de donn√©es. Que faire si vous souhaitez uniquement supprimer les lignes ou colonnes contenant plusieurs ou m√™me toutes les valeurs nulles ? Vous sp√©cifiez ces param√®tres dans `dropna` avec les param√®tres `how` et `thresh`.

Par d√©faut, `how='any'` (si vous souhaitez v√©rifier par vous-m√™me ou voir quels autres param√®tres la m√©thode poss√®de, ex√©cutez `example4.dropna?` dans une cellule de code). Vous pourriez alternativement sp√©cifier `how='all'` pour ne supprimer que les lignes ou colonnes contenant toutes des valeurs nulles. √âtendons notre exemple de `DataFrame` pour voir cela en action.

```python
example2[3] = np.nan
example2
```
|      |0  |1  |2  |3  |
|------|---|---|---|---|
|0     |1.0|NaN|7  |NaN|
|1     |2.0|5.0|8  |NaN|
|2     |NaN|6.0|9  |NaN|

Le param√®tre `thresh` vous donne un contr√¥le plus pr√©cis : vous d√©finissez le nombre de valeurs *non nulles* qu'une ligne ou colonne doit avoir pour √™tre conserv√©e :
```python
example2.dropna(axis='rows', thresh=3)
```
```
	0	1	2	3
1	2.0	5.0	8	NaN
```
Ici, la premi√®re et la derni√®re ligne ont √©t√© supprim√©es, car elles contiennent seulement deux valeurs non nulles.

- **Remplir les valeurs nulles** : Selon votre ensemble de donn√©es, il peut parfois √™tre plus logique de remplir les valeurs nulles avec des valeurs valides plut√¥t que de les supprimer. Vous pourriez utiliser `isnull` pour le faire directement, mais cela peut √™tre laborieux, en particulier si vous avez beaucoup de valeurs √† remplir. √âtant donn√© que cette t√¢che est courante en science des donn√©es, pandas propose `fillna`, qui renvoie une copie de la `Series` ou du `DataFrame` avec les valeurs manquantes remplac√©es par celles de votre choix. Cr√©ons une autre `Series` pour voir comment cela fonctionne en pratique.
```python
example3 = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))
example3
```
```
a    1.0
b    NaN
c    2.0
d    NaN
e    3.0
dtype: float64
```
Vous pouvez remplir toutes les entr√©es nulles avec une seule valeur, comme `0` :
```python
example3.fillna(0)
```
```
a    1.0
b    0.0
c    2.0
d    0.0
e    3.0
dtype: float64
```
Vous pouvez **propager vers l'avant** les valeurs nulles, c'est-√†-dire utiliser la derni√®re valeur valide pour remplir une valeur nulle :
```python
example3.fillna(method='ffill')
```
```
a    1.0
b    1.0
c    2.0
d    2.0
e    3.0
dtype: float64
```
Vous pouvez √©galement **propager vers l'arri√®re** pour utiliser la prochaine valeur valide pour remplir une valeur nulle :
```python
example3.fillna(method='bfill')
```
```
a    1.0
b    2.0
c    2.0
d    3.0
e    3.0
dtype: float64
```
Comme vous pouvez le deviner, cela fonctionne de la m√™me mani√®re avec les `DataFrame`s, mais vous pouvez √©galement sp√©cifier un `axis` le long duquel remplir les valeurs nulles. En reprenant `example2` utilis√© pr√©c√©demment :
```python
example2.fillna(method='ffill', axis=1)
```
```
	0	1	2	3
0	1.0	1.0	7.0	7.0
1	2.0	5.0	8.0	8.0
2	NaN	6.0	9.0	9.0
```
Notez que lorsqu'une valeur pr√©c√©dente n'est pas disponible pour la propagation vers l'avant, la valeur nulle reste.
> **√Ä retenir :** Il existe plusieurs fa√ßons de g√©rer les valeurs manquantes dans vos ensembles de donn√©es. La strat√©gie sp√©cifique que vous choisissez (les supprimer, les remplacer, ou m√™me la mani√®re dont vous les remplacez) doit √™tre dict√©e par les particularit√©s de ces donn√©es. Vous d√©velopperez une meilleure intuition pour traiter les valeurs manquantes √† mesure que vous manipulerez et interagirez avec des ensembles de donn√©es.
## Suppression des donn√©es dupliqu√©es

> **Objectif d'apprentissage :** √Ä la fin de cette sous-section, vous devriez √™tre √† l'aise pour identifier et supprimer les valeurs dupliqu√©es dans les DataFrames.

En plus des donn√©es manquantes, vous rencontrerez souvent des donn√©es dupliqu√©es dans les ensembles de donn√©es du monde r√©el. Heureusement, `pandas` offre un moyen simple de d√©tecter et de supprimer les entr√©es en double.

- **Identifier les doublons : `duplicated`** : Vous pouvez facilement rep√©rer les valeurs dupliqu√©es en utilisant la m√©thode `duplicated` de pandas, qui renvoie un masque bool√©en indiquant si une entr√©e dans un `DataFrame` est un doublon d'une entr√©e pr√©c√©dente. Cr√©ons un autre exemple de `DataFrame` pour voir cela en action.
```python
example4 = pd.DataFrame({'letters': ['A','B'] * 2 + ['B'],
                         'numbers': [1, 2, 1, 3, 3]})
example4
```
|      |lettres|nombres|
|------|-------|-------|
|0     |A      |1      |
|1     |B      |2      |
|2     |A      |1      |
|3     |B      |3      |
|4     |B      |3      |

```python
example4.duplicated()
```
```
0    False
1    False
2     True
3    False
4     True
dtype: bool
```
- **Supprimer les doublons : `drop_duplicates` :** renvoie simplement une copie des donn√©es pour lesquelles toutes les valeurs `duplicated` sont `False` :
```python
example4.drop_duplicates()
```
```
	letters	numbers
0	A	1
1	B	2
3	B	3
```
Les m√©thodes `duplicated` et `drop_duplicates` consid√®rent par d√©faut toutes les colonnes, mais vous pouvez sp√©cifier qu'elles examinent uniquement un sous-ensemble de colonnes dans votre `DataFrame` :
```python
example4.drop_duplicates(['letters'])
```
```
letters	numbers
0	A	1
1	B	2
```

> **√Ä retenir :** Supprimer les donn√©es dupliqu√©es est une √©tape essentielle dans presque tous les projets de science des donn√©es. Les donn√©es dupliqu√©es peuvent fausser les r√©sultats de vos analyses et produire des r√©sultats inexacts !


## üöÄ D√©fi

Tous les mat√©riaux abord√©s sont disponibles sous forme de [Jupyter Notebook](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/2-Working-With-Data/08-data-preparation/notebook.ipynb). De plus, des exercices sont propos√©s apr√®s chaque section, essayez-les !

## [Quiz post-cours](https://ff-quizzes.netlify.app/en/ds/quiz/15)



## R√©vision et auto-apprentissage

Il existe de nombreuses fa√ßons de d√©couvrir et d'aborder la pr√©paration de vos donn√©es pour l'analyse et la mod√©lisation, et le nettoyage des donn√©es est une √©tape importante qui n√©cessite une exp√©rience pratique. Essayez ces d√©fis sur Kaggle pour explorer des techniques qui n'ont pas √©t√© couvertes dans cette le√ßon.

- [D√©fi de nettoyage des donn√©es : Analyse des dates](https://www.kaggle.com/rtatman/data-cleaning-challenge-parsing-dates/)

- [D√©fi de nettoyage des donn√©es : Mise √† l'√©chelle et normalisation des donn√©es](https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data)


## Devoir

[√âvaluation des donn√©es d'un formulaire](assignment.md)

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de faire appel √† une traduction humaine professionnelle. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.