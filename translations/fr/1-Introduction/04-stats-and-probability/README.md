<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b706a07cfa87ba091cbb91e0aa775600",
  "translation_date": "2025-08-25T17:05:45+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "fr"
}
-->
# Une br√®ve introduction aux statistiques et √† la probabilit√©

|![ Sketchnote par [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| Statistiques et Probabilit√© - _Sketchnote par [@nitya](https://twitter.com/nitya)_ |

La th√©orie des statistiques et des probabilit√©s sont deux domaines des math√©matiques √©troitement li√©s et tr√®s pertinents pour la science des donn√©es. Il est possible de travailler avec des donn√©es sans une connaissance approfondie des math√©matiques, mais il est tout de m√™me pr√©f√©rable de conna√Ætre au moins quelques concepts de base. Voici une courte introduction pour vous aider √† d√©marrer.

[![Vid√©o d'introduction](../../../../translated_images/video-prob-and-stats.e4282e5efa2f2543400843ed98b1057065c9600cebfc8a728e8931b5702b2ae4.fr.png)](https://youtu.be/Z5Zy85g4Yjw)

## [Quiz avant le cours](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/6)

## Probabilit√© et variables al√©atoires

La **probabilit√©** est un nombre compris entre 0 et 1 qui exprime √† quel point un **√©v√©nement** est probable. Elle est d√©finie comme le nombre de r√©sultats positifs (qui m√®nent √† l'√©v√©nement), divis√© par le nombre total de r√©sultats, en supposant que tous les r√©sultats sont √©galement probables. Par exemple, lorsque nous lan√ßons un d√©, la probabilit√© d'obtenir un nombre pair est de 3/6 = 0,5.

Lorsque nous parlons d'√©v√©nements, nous utilisons des **variables al√©atoires**. Par exemple, la variable al√©atoire qui repr√©sente le nombre obtenu en lan√ßant un d√© prendra des valeurs de 1 √† 6. L'ensemble des nombres de 1 √† 6 est appel√© **espace d'√©chantillonnage**. Nous pouvons parler de la probabilit√© qu'une variable al√©atoire prenne une certaine valeur, par exemple P(X=3)=1/6.

La variable al√©atoire dans l'exemple pr√©c√©dent est appel√©e **discr√®te**, car elle a un espace d'√©chantillonnage d√©nombrable, c'est-√†-dire qu'il existe des valeurs distinctes qui peuvent √™tre √©num√©r√©es. Il existe des cas o√π l'espace d'√©chantillonnage est un intervalle de nombres r√©els, ou l'ensemble complet des nombres r√©els. Ces variables sont appel√©es **continues**. Un bon exemple est l'heure d'arriv√©e d'un bus.

## Distribution de probabilit√©

Dans le cas des variables al√©atoires discr√®tes, il est facile de d√©crire la probabilit√© de chaque √©v√©nement par une fonction P(X). Pour chaque valeur *s* de l'espace d'√©chantillonnage *S*, elle donnera un nombre compris entre 0 et 1, de sorte que la somme de toutes les valeurs de P(X=s) pour tous les √©v√©nements soit √©gale √† 1.

La distribution discr√®te la plus connue est la **distribution uniforme**, dans laquelle il existe un espace d'√©chantillonnage de N √©l√©ments, avec une probabilit√© √©gale de 1/N pour chacun d'eux.

Il est plus difficile de d√©crire la distribution de probabilit√© d'une variable continue, avec des valeurs tir√©es d'un intervalle [a,b], ou de l'ensemble complet des nombres r√©els ‚Ñù. Prenons l'exemple de l'heure d'arriv√©e d'un bus. En r√©alit√©, pour chaque heure d'arriv√©e exacte *t*, la probabilit√© qu'un bus arrive exactement √† cette heure est de 0 !

> Maintenant, vous savez que des √©v√©nements avec une probabilit√© de 0 se produisent, et tr√®s souvent ! Au moins chaque fois qu'un bus arrive !

Nous ne pouvons parler que de la probabilit√© qu'une variable tombe dans un intervalle donn√© de valeurs, par exemple P(t<sub>1</sub>‚â§X<t<sub>2</sub>). Dans ce cas, la distribution de probabilit√© est d√©crite par une **fonction de densit√© de probabilit√©** p(x), telle que

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../translated_images/probability-density.a8aad29f17a14afb519b407c7b6edeb9f3f9aa5f69c9e6d9445f604e5f8a2bf7.fr.png)

Un analogue continu de la distribution uniforme est appel√© **uniforme continue**, qui est d√©fini sur un intervalle fini. La probabilit√© que la valeur X tombe dans un intervalle de longueur l est proportionnelle √† l, et peut atteindre 1.

Une autre distribution importante est la **distribution normale**, dont nous parlerons plus en d√©tail ci-dessous.

## Moyenne, variance et √©cart-type

Supposons que nous tirons une s√©quence de n √©chantillons d'une variable al√©atoire X : x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. Nous pouvons d√©finir la **moyenne** (ou **moyenne arithm√©tique**) de la s√©quence de mani√®re traditionnelle comme (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n. En augmentant la taille de l'√©chantillon (c'est-√†-dire en prenant la limite avec n‚Üí‚àû), nous obtiendrons la moyenne (√©galement appel√©e **esp√©rance**) de la distribution. Nous noterons l'esp√©rance par **E**(x).

> Il peut √™tre d√©montr√© que pour toute distribution discr√®te avec des valeurs {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} et des probabilit√©s correspondantes p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, l'esp√©rance serait √©gale √† E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>.

Pour identifier √† quel point les valeurs sont dispers√©es, nous pouvons calculer la variance œÉ<sup>2</sup> = ‚àë(x<sub>i</sub> - Œº)<sup>2</sup>/n, o√π Œº est la moyenne de la s√©quence. La valeur œÉ est appel√©e **√©cart-type**, et œÉ<sup>2</sup> est appel√©e **variance**.

## Mode, m√©diane et quartiles

Parfois, la moyenne ne repr√©sente pas ad√©quatement la valeur "typique" des donn√©es. Par exemple, lorsqu'il y a quelques valeurs extr√™mes compl√®tement hors de port√©e, elles peuvent affecter la moyenne. Une autre bonne indication est la **m√©diane**, une valeur telle que la moiti√© des points de donn√©es sont inf√©rieurs √† celle-ci, et l'autre moiti√© - sup√©rieurs.

Pour mieux comprendre la distribution des donn√©es, il est utile de parler des **quartiles** :

* Le premier quartile, ou Q1, est une valeur telle que 25 % des donn√©es sont inf√©rieures √† celle-ci.
* Le troisi√®me quartile, ou Q3, est une valeur telle que 75 % des donn√©es sont inf√©rieures √† celle-ci.

Graphiquement, nous pouvons repr√©senter la relation entre la m√©diane et les quartiles dans un diagramme appel√© **bo√Æte √† moustaches** :

<img src="images/boxplot_explanation.png" width="50%"/>

Ici, nous calculons √©galement l'**√©tendue interquartile** IQR=Q3-Q1, et les **valeurs aberrantes** - des valeurs qui se situent en dehors des limites [Q1-1.5*IQR, Q3+1.5*IQR].

Pour une distribution finie contenant un petit nombre de valeurs possibles, une bonne valeur "typique" est celle qui appara√Æt le plus fr√©quemment, appel√©e **mode**. Cela s'applique souvent aux donn√©es cat√©goriques, comme les couleurs. Consid√©rons une situation o√π nous avons deux groupes de personnes - certains qui pr√©f√®rent fortement le rouge, et d'autres qui pr√©f√®rent le bleu. Si nous codons les couleurs par des nombres, la moyenne pour une couleur pr√©f√©r√©e serait quelque part dans le spectre orange-vert, ce qui ne refl√®te pas les pr√©f√©rences r√©elles d'aucun groupe. Cependant, le mode serait soit l'une des couleurs, soit les deux couleurs, si le nombre de personnes votant pour elles est √©gal (dans ce cas, nous appelons l'√©chantillon **multimodal**).

## Donn√©es du monde r√©el

Lorsque nous analysons des donn√©es du monde r√©el, elles ne sont souvent pas des variables al√©atoires √† proprement parler, dans le sens o√π nous ne r√©alisons pas d'exp√©riences avec des r√©sultats inconnus. Par exemple, consid√©rons une √©quipe de joueurs de baseball, et leurs donn√©es corporelles, telles que la taille, le poids et l'√¢ge. Ces nombres ne sont pas exactement al√©atoires, mais nous pouvons tout de m√™me appliquer les m√™mes concepts math√©matiques. Par exemple, une s√©quence de poids de personnes peut √™tre consid√©r√©e comme une s√©quence de valeurs tir√©es d'une variable al√©atoire. Voici la s√©quence des poids de joueurs de baseball r√©els de la [Major League Baseball](http://mlb.mlb.com/index.jsp), tir√©e de [ce jeu de donn√©es](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) (pour votre commodit√©, seules les 20 premi√®res valeurs sont affich√©es) :

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Note** : Pour voir un exemple de travail avec ce jeu de donn√©es, consultez le [notebook associ√©](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb). Il y a √©galement un certain nombre de d√©fis tout au long de cette le√ßon, et vous pouvez les compl√©ter en ajoutant du code √† ce notebook. Si vous ne savez pas comment manipuler les donn√©es, ne vous inqui√©tez pas - nous reviendrons sur le travail avec les donn√©es en utilisant Python plus tard. Si vous ne savez pas comment ex√©cuter du code dans un Jupyter Notebook, consultez [cet article](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

Voici le diagramme en bo√Æte montrant la moyenne, la m√©diane et les quartiles pour nos donn√©es :

![Diagramme en bo√Æte des poids](../../../../translated_images/weight-boxplot.1dbab1c03af26f8a008fff4e17680082c8ab147d6df646cbac440bbf8f5b9c42.fr.png)

Comme nos donn√©es contiennent des informations sur diff√©rents **r√¥les** de joueurs, nous pouvons √©galement r√©aliser un diagramme en bo√Æte par r√¥le - cela nous permettra de comprendre comment les valeurs des param√®tres diff√®rent selon les r√¥les. Cette fois, nous consid√©rerons la taille :

![Diagramme en bo√Æte par r√¥le](../../../../translated_images/boxplot_byrole.036b27a1c3f52d42f66fba2324ec5cde0a1bca6a01a619eeb0ce7cd054b2527b.fr.png)

Ce diagramme sugg√®re qu'en moyenne, la taille des joueurs de premi√®re base est sup√©rieure √† celle des joueurs de deuxi√®me base. Plus tard dans cette le√ßon, nous apprendrons comment tester cette hypoth√®se de mani√®re plus formelle, et comment d√©montrer que nos donn√©es sont statistiquement significatives pour le prouver.

> Lorsque nous travaillons avec des donn√©es du monde r√©el, nous supposons que tous les points de donn√©es sont des √©chantillons tir√©s d'une certaine distribution de probabilit√©. Cette hypoth√®se nous permet d'appliquer des techniques d'apprentissage automatique et de construire des mod√®les pr√©dictifs fonctionnels.

Pour voir quelle est la distribution de nos donn√©es, nous pouvons tracer un graphique appel√© **histogramme**. L'axe X contiendra un certain nombre d'intervalles de poids diff√©rents (appel√©s **bins**), et l'axe vertical montrera le nombre de fois o√π notre √©chantillon de variable al√©atoire se trouvait dans un intervalle donn√©.

![Histogramme des donn√©es r√©elles](../../../../translated_images/weight-histogram.bfd00caf7fc30b145b21e862dba7def41c75635d5280de25d840dd7f0b00545e.fr.png)

√Ä partir de cet histogramme, vous pouvez voir que toutes les valeurs sont centr√©es autour d'un certain poids moyen, et plus nous nous √©loignons de ce poids, moins il est probable de rencontrer des poids de cette valeur. Autrement dit, il est tr√®s improbable que le poids d'un joueur de baseball soit tr√®s diff√©rent du poids moyen. La variance des poids montre dans quelle mesure les poids sont susceptibles de diff√©rer de la moyenne.

> Si nous prenons les poids d'autres personnes, pas de la ligue de baseball, la distribution sera probablement diff√©rente. Cependant, la forme de la distribution restera la m√™me, mais la moyenne et la variance changeront. Ainsi, si nous entra√Ænons notre mod√®le sur des joueurs de baseball, il est probable qu'il donne des r√©sultats erron√©s lorsqu'il est appliqu√© √† des √©tudiants d'une universit√©, car la distribution sous-jacente est diff√©rente.

## Distribution normale

La distribution des poids que nous avons vue ci-dessus est tr√®s typique, et de nombreuses mesures du monde r√©el suivent le m√™me type de distribution, mais avec des moyennes et des variances diff√©rentes. Cette distribution est appel√©e **distribution normale**, et elle joue un r√¥le tr√®s important en statistiques.

Utiliser une distribution normale est une m√©thode correcte pour g√©n√©rer des poids al√©atoires de joueurs de baseball potentiels. Une fois que nous connaissons le poids moyen `mean` et l'√©cart-type `std`, nous pouvons g√©n√©rer 1000 √©chantillons de poids de la mani√®re suivante :
```python
samples = np.random.normal(mean,std,1000)
```

Si nous tra√ßons l'histogramme des √©chantillons g√©n√©r√©s, nous verrons une image tr√®s similaire √† celle montr√©e ci-dessus. Et si nous augmentons le nombre d'√©chantillons et le nombre de bins, nous pouvons g√©n√©rer une image d'une distribution normale plus proche de l'id√©al :

![Distribution normale avec moyenne=0 et √©cart-type=1](../../../../translated_images/normal-histogram.dfae0d67c202137d552d0015fb87581eca263925e512404f3c12d8885315432e.fr.png)

*Distribution normale avec moyenne=0 et √©cart-type=1*

## Intervalles de confiance

Lorsque nous parlons des poids des joueurs de baseball, nous supposons qu'il existe une certaine **variable al√©atoire W** qui correspond √† la distribution de probabilit√© id√©ale des poids de tous les joueurs de baseball (appel√©e **population**). Notre s√©quence de poids correspond √† un sous-ensemble de tous les joueurs de baseball que nous appelons **√©chantillon**. Une question int√©ressante est : pouvons-nous conna√Ætre les param√®tres de la distribution de W, c'est-√†-dire la moyenne et la variance de la population ?

La r√©ponse la plus simple serait de calculer la moyenne et la variance de notre √©chantillon. Cependant, il pourrait arriver que notre √©chantillon al√©atoire ne repr√©sente pas fid√®lement la population compl√®te. Ainsi, il est logique de parler d'**intervalle de confiance**.
> **L'intervalle de confiance** est l'estimation de la moyenne r√©elle de la population √† partir de notre √©chantillon, avec une pr√©cision selon une certaine probabilit√© (ou **niveau de confiance**).
Supposons que nous avons un √©chantillon X<sub>1</sub>, ..., X<sub>n</sub> issu de notre distribution. Chaque fois que nous tirons un √©chantillon de notre distribution, nous obtenons une valeur moyenne diff√©rente Œº. Ainsi, Œº peut √™tre consid√©r√© comme une variable al√©atoire. Un **intervalle de confiance** avec une confiance p est une paire de valeurs (L<sub>p</sub>,R<sub>p</sub>), telle que **P**(L<sub>p</sub>‚â§Œº‚â§R<sub>p</sub>) = p, c'est-√†-dire que la probabilit√© que la valeur moyenne mesur√©e tombe dans l'intervalle est √©gale √† p.

Il d√©passe le cadre de cette introduction de discuter en d√©tail comment ces intervalles de confiance sont calcul√©s. Vous pouvez trouver plus de d√©tails [sur Wikip√©dia](https://en.wikipedia.org/wiki/Confidence_interval). En r√©sum√©, nous d√©finissons la distribution de la moyenne d'√©chantillon calcul√©e par rapport √† la moyenne r√©elle de la population, appel√©e **distribution de Student**.

> **Fait int√©ressant** : La distribution de Student porte le nom du math√©maticien William Sealy Gosset, qui a publi√© son article sous le pseudonyme "Student". Il travaillait dans la brasserie Guinness et, selon une version, son employeur ne voulait pas que le grand public sache qu'ils utilisaient des tests statistiques pour d√©terminer la qualit√© des mati√®res premi√®res.

Si nous voulons estimer la moyenne Œº de notre population avec une confiance p, nous devons prendre le *percentile (1-p)/2* d'une distribution de Student A, qui peut √™tre obtenu √† partir de tables ou calcul√© √† l'aide de fonctions int√©gr√©es dans des logiciels statistiques (par exemple Python, R, etc.). Ensuite, l'intervalle pour Œº serait donn√© par X¬±A*D/‚àön, o√π X est la moyenne obtenue de l'√©chantillon, D est l'√©cart-type.

> **Note** : Nous omettons √©galement la discussion d'un concept important des [degr√©s de libert√©](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)), qui est essentiel en relation avec la distribution de Student. Vous pouvez consulter des livres plus complets sur les statistiques pour approfondir ce concept.

Un exemple de calcul d'intervalle de confiance pour les poids et les tailles est donn√© dans les [notebooks associ√©s](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb).

| p    | Moyenne du poids |
|------|------------------|
| 0.85 | 201.73¬±0.94      |
| 0.90 | 201.73¬±1.08      |
| 0.95 | 201.73¬±1.28      |

Remarquez que plus la probabilit√© de confiance est √©lev√©e, plus l'intervalle de confiance est large.

## Test d'hypoth√®se

Dans notre ensemble de donn√©es sur les joueurs de baseball, il existe diff√©rents r√¥les de joueurs, qui peuvent √™tre r√©sum√©s ci-dessous (consultez le [notebook associ√©](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) pour voir comment ce tableau peut √™tre calcul√©) :

| R√¥le               | Taille   | Poids    | Nombre |
|--------------------|----------|----------|--------|
| Receveur           | 72.723684 | 204.328947 | 76     |
| Frappeur d√©sign√©   | 74.222222 | 220.888889 | 18     |
| Premier but        | 74.000000 | 213.109091 | 55     |
| Champ ext√©rieur    | 73.010309 | 199.113402 | 194    |
| Lanceur de rel√®ve  | 74.374603 | 203.517460 | 315    |
| Deuxi√®me but       | 71.362069 | 184.344828 | 58     |
| Arr√™t-court        | 71.903846 | 182.923077 | 52     |
| Lanceur partant    | 74.719457 | 205.163636 | 221    |
| Troisi√®me but      | 73.044444 | 200.955556 | 45     |

Nous pouvons remarquer que la taille moyenne des premiers buts est sup√©rieure √† celle des deuxi√®mes buts. Ainsi, nous pourrions √™tre tent√©s de conclure que **les premiers buts sont plus grands que les deuxi√®mes buts**.

> Cette affirmation est appel√©e **une hypoth√®se**, car nous ne savons pas si le fait est r√©ellement vrai ou non.

Cependant, il n'est pas toujours √©vident de pouvoir tirer cette conclusion. D'apr√®s la discussion ci-dessus, nous savons que chaque moyenne a un intervalle de confiance associ√©, et donc cette diff√©rence peut simplement √™tre une erreur statistique. Nous avons besoin d'une m√©thode plus formelle pour tester notre hypoth√®se.

Calculons les intervalles de confiance s√©par√©ment pour les tailles des premiers et des deuxi√®mes buts :

| Confiance | Premiers buts | Deuxi√®mes buts |
|-----------|---------------|----------------|
| 0.85      | 73.62..74.38  | 71.04..71.69   |
| 0.90      | 73.56..74.44  | 70.99..71.73   |
| 0.95      | 73.47..74.53  | 70.92..71.81   |

Nous pouvons voir qu'√† aucun niveau de confiance les intervalles ne se chevauchent. Cela prouve notre hypoth√®se selon laquelle les premiers buts sont plus grands que les deuxi√®mes buts.

Plus formellement, le probl√®me que nous r√©solvons est de voir si **deux distributions de probabilit√© sont identiques**, ou du moins ont les m√™mes param√®tres. Selon la distribution, nous devons utiliser diff√©rents tests pour cela. Si nous savons que nos distributions sont normales, nous pouvons appliquer le **[test t de Student](https://en.wikipedia.org/wiki/Student%27s_t-test)**.

Dans le test t de Student, nous calculons ce qu'on appelle la **valeur t**, qui indique la diff√©rence entre les moyennes, en tenant compte de la variance. Il est d√©montr√© que la valeur t suit la **distribution de Student**, ce qui nous permet d'obtenir la valeur seuil pour un niveau de confiance donn√© **p** (cela peut √™tre calcul√© ou consult√© dans des tables num√©riques). Nous comparons ensuite la valeur t √† ce seuil pour approuver ou rejeter l'hypoth√®se.

En Python, nous pouvons utiliser le package **SciPy**, qui inclut la fonction `ttest_ind` (en plus de nombreuses autres fonctions statistiques utiles !). Elle calcule la valeur t pour nous et effectue √©galement la recherche inverse de la valeur p de confiance, afin que nous puissions simplement regarder la confiance pour tirer une conclusion.

Par exemple, notre comparaison entre les tailles des premiers et des deuxi√®mes buts nous donne les r√©sultats suivants : 
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
Dans notre cas, la valeur p est tr√®s faible, ce qui signifie qu'il existe des preuves solides soutenant que les premiers buts sont plus grands.

Il existe √©galement diff√©rents types d'hypoth√®ses que nous pourrions vouloir tester, par exemple :
* Prouver qu'un √©chantillon donn√© suit une distribution. Dans notre cas, nous avons suppos√© que les tailles sont distribu√©es normalement, mais cela n√©cessite une v√©rification statistique formelle.
* Prouver que la valeur moyenne d'un √©chantillon correspond √† une valeur pr√©d√©finie.
* Comparer les moyennes de plusieurs √©chantillons (par exemple, quelle est la diff√©rence dans les niveaux de bonheur entre diff√©rents groupes d'√¢ge).

## Loi des grands nombres et th√©or√®me central limite

L'une des raisons pour lesquelles la distribution normale est si importante est le **th√©or√®me central limite**. Supposons que nous avons un grand √©chantillon de N valeurs ind√©pendantes X<sub>1</sub>, ..., X<sub>N</sub>, √©chantillonn√©es √† partir de n'importe quelle distribution avec une moyenne Œº et une variance œÉ<sup>2</sup>. Ensuite, pour un N suffisamment grand (en d'autres termes, lorsque N‚Üí‚àû), la moyenne Œ£<sub>i</sub>X<sub>i</sub> serait distribu√©e normalement, avec une moyenne Œº et une variance œÉ<sup>2</sup>/N.

> Une autre fa√ßon d'interpr√©ter le th√©or√®me central limite est de dire que, quelle que soit la distribution, lorsque vous calculez la moyenne d'une somme de valeurs de variables al√©atoires, vous obtenez une distribution normale.

D'apr√®s le th√©or√®me central limite, il s'ensuit √©galement que, lorsque N‚Üí‚àû, la probabilit√© que la moyenne de l'√©chantillon soit √©gale √† Œº devient 1. Cela est connu sous le nom de **loi des grands nombres**.

## Covariance et corr√©lation

L'une des choses que fait la science des donn√©es est de trouver des relations entre les donn√©es. Nous disons que deux s√©quences **corr√®lent** lorsqu'elles pr√©sentent un comportement similaire au m√™me moment, c'est-√†-dire qu'elles augmentent/diminuent simultan√©ment, ou qu'une s√©quence augmente lorsque l'autre diminue et vice versa. En d'autres termes, il semble y avoir une relation entre deux s√©quences.

> La corr√©lation n'indique pas n√©cessairement une relation causale entre deux s√©quences ; parfois, les deux variables peuvent d√©pendre d'une cause externe, ou cela peut √™tre purement par hasard que les deux s√©quences corr√®lent. Cependant, une corr√©lation math√©matique forte est une bonne indication que deux variables sont d'une certaine mani√®re connect√©es.

Math√©matiquement, le concept principal qui montre la relation entre deux variables al√©atoires est la **covariance**, qui est calcul√©e comme suit : Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. Nous calculons la d√©viation des deux variables par rapport √† leurs valeurs moyennes, puis le produit de ces d√©viations. Si les deux variables d√©vient ensemble, le produit sera toujours une valeur positive, ce qui donnera une covariance positive. Si les deux variables d√©vient de mani√®re d√©synchronis√©e (c'est-√†-dire qu'une tombe en dessous de la moyenne lorsque l'autre d√©passe la moyenne), nous obtiendrons toujours des nombres n√©gatifs, ce qui donnera une covariance n√©gative. Si les d√©viations ne sont pas d√©pendantes, elles s'additionneront √† peu pr√®s √† z√©ro.

La valeur absolue de la covariance ne nous dit pas grand-chose sur l'ampleur de la corr√©lation, car elle d√©pend de la magnitude des valeurs r√©elles. Pour la normaliser, nous pouvons diviser la covariance par l'√©cart-type des deux variables, pour obtenir la **corr√©lation**. L'avantage est que la corr√©lation est toujours dans la plage [-1,1], o√π 1 indique une forte corr√©lation positive entre les valeurs, -1 une forte corr√©lation n√©gative, et 0 aucune corr√©lation (les variables sont ind√©pendantes).

**Exemple** : Nous pouvons calculer la corr√©lation entre les poids et les tailles des joueurs de baseball √† partir de l'ensemble de donn√©es mentionn√© ci-dessus :
```python
print(np.corrcoef(weights,heights))
```
En cons√©quence, nous obtenons une **matrice de corr√©lation** comme celle-ci :
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> La matrice de corr√©lation C peut √™tre calcul√©e pour n'importe quel nombre de s√©quences d'entr√©e S<sub>1</sub>, ..., S<sub>n</sub>. La valeur de C<sub>ij</sub> est la corr√©lation entre S<sub>i</sub> et S<sub>j</sub>, et les √©l√©ments diagonaux sont toujours 1 (ce qui est √©galement l'auto-corr√©lation de S<sub>i</sub>).

Dans notre cas, la valeur 0.53 indique qu'il existe une certaine corr√©lation entre le poids et la taille d'une personne. Nous pouvons √©galement r√©aliser un diagramme de dispersion d'une valeur par rapport √† l'autre pour voir la relation visuellement :

![Relation entre poids et taille](../../../../translated_images/weight-height-relationship.3f06bde4ca2aba9974182c4ef037ed602acd0fbbbbe2ca91cefd838a9e66bcf9.fr.png)

> Plus d'exemples de corr√©lation et de covariance peuvent √™tre trouv√©s dans le [notebook associ√©](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb).

## Conclusion

Dans cette section, nous avons appris :

* les propri√©t√©s statistiques de base des donn√©es, telles que la moyenne, la variance, le mode et les quartiles
* les diff√©rentes distributions de variables al√©atoires, y compris la distribution normale
* comment trouver la corr√©lation entre diff√©rentes propri√©t√©s
* comment utiliser un appareil math√©matique et statistique solide pour prouver certaines hypoth√®ses
* comment calculer des intervalles de confiance pour une variable al√©atoire donn√©e un √©chantillon de donn√©es

Bien que cette liste ne soit certainement pas exhaustive des sujets qui existent dans la probabilit√© et les statistiques, elle devrait suffire √† vous donner un bon d√©part dans ce cours.

## üöÄ D√©fi

Utilisez le code d'exemple dans le notebook pour tester d'autres hypoth√®ses :
1. Les premiers buts sont plus √¢g√©s que les deuxi√®mes buts
2. Les premiers buts sont plus grands que les troisi√®mes buts
3. Les arr√™ts-courts sont plus grands que les deuxi√®mes buts

## [Quiz post-lecture](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/7)

## R√©vision et auto-apprentissage

La probabilit√© et les statistiques sont un sujet si vaste qu'il m√©rite son propre cours. Si vous souhaitez approfondir la th√©orie, vous pouvez continuer √† lire certains des livres suivants :

1. [Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/) de l'Universit√© de New York propose d'excellentes notes de cours [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (disponibles en ligne)
1. [Peter et Andrew Bruce. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[code d'exemple en R](https://github.com/andrewgbruce/statistics-for-data-scientists)]. 
1. [James D. Miller. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[code d'exemple en R](https://github.com/PacktPublishing/Statistics-for-Data-Science)]

## Devoir

[Petite √©tude sur le diab√®te](assignment.md)

## Cr√©dits

Cette le√ßon a √©t√© r√©dig√©e avec ‚ô•Ô∏è par [Dmitry Soshnikov](http://soshnikov.com)

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction professionnelle r√©alis√©e par un humain. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.