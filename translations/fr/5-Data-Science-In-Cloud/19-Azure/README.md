<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "472d3fab1c5be50f387336e7a686dbe1",
  "translation_date": "2025-09-05T12:19:45+00:00",
  "source_file": "5-Data-Science-In-Cloud/19-Azure/README.md",
  "language_code": "fr"
}
-->
# La Science des Donn√©es dans le Cloud : La m√©thode "Azure ML SDK"

|![ Sketchnote par [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/19-DataScience-Cloud.png)|
|:---:|
| La Science des Donn√©es dans le Cloud : Azure ML SDK - _Sketchnote par [@nitya](https://twitter.com/nitya)_ |

Table des mati√®res :

- [La Science des Donn√©es dans le Cloud : La m√©thode "Azure ML SDK"](../../../../5-Data-Science-In-Cloud/19-Azure)
  - [Quiz avant le cours](../../../../5-Data-Science-In-Cloud/19-Azure)
  - [1. Introduction](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [1.1 Qu'est-ce que l'Azure ML SDK ?](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [1.2 Projet de pr√©diction d'insuffisance cardiaque et introduction au jeu de donn√©es](../../../../5-Data-Science-In-Cloud/19-Azure)
  - [2. Entra√Æner un mod√®le avec l'Azure ML SDK](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [2.1 Cr√©er un espace de travail Azure ML](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [2.2 Cr√©er une instance de calcul](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [2.3 Charger le jeu de donn√©es](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [2.4 Cr√©er des notebooks](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [2.5 Entra√Æner un mod√®le](../../../../5-Data-Science-In-Cloud/19-Azure)
      - [2.5.1 Configurer l'espace de travail, l'exp√©rience, le cluster de calcul et le jeu de donn√©es](../../../../5-Data-Science-In-Cloud/19-Azure)
      - [2.5.2 Configuration AutoML et entra√Ænement](../../../../5-Data-Science-In-Cloud/19-Azure)
  - [3. D√©ploiement du mod√®le et consommation de l'endpoint avec l'Azure ML SDK](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [3.1 Sauvegarder le meilleur mod√®le](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [3.2 D√©ploiement du mod√®le](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [3.3 Consommation de l'endpoint](../../../../5-Data-Science-In-Cloud/19-Azure)
  - [üöÄ D√©fi](../../../../5-Data-Science-In-Cloud/19-Azure)
  - [Quiz apr√®s le cours](../../../../5-Data-Science-In-Cloud/19-Azure)
  - [R√©vision et auto-apprentissage](../../../../5-Data-Science-In-Cloud/19-Azure)
  - [Devoir](../../../../5-Data-Science-In-Cloud/19-Azure)

## [Quiz avant le cours](https://ff-quizzes.netlify.app/en/ds/quiz/36)

## 1. Introduction

### 1.1 Qu'est-ce que l'Azure ML SDK ?

Les data scientists et les d√©veloppeurs en intelligence artificielle utilisent le SDK Azure Machine Learning pour cr√©er et ex√©cuter des workflows de machine learning avec le service Azure Machine Learning. Vous pouvez interagir avec le service dans n'importe quel environnement Python, y compris Jupyter Notebooks, Visual Studio Code ou votre IDE Python pr√©f√©r√©.

Les principales fonctionnalit√©s du SDK incluent :

- Explorer, pr√©parer et g√©rer le cycle de vie de vos jeux de donn√©es utilis√©s dans les exp√©riences de machine learning.
- G√©rer les ressources cloud pour surveiller, enregistrer et organiser vos exp√©riences de machine learning.
- Entra√Æner des mod√®les localement ou en utilisant des ressources cloud, y compris l'entra√Ænement acc√©l√©r√© par GPU.
- Utiliser le machine learning automatis√©, qui accepte des param√®tres de configuration et des donn√©es d'entra√Ænement. Il it√®re automatiquement sur les algorithmes et les r√©glages des hyperparam√®tres pour trouver le meilleur mod√®le pour effectuer des pr√©dictions.
- D√©ployer des services web pour transformer vos mod√®les entra√Æn√©s en services RESTful consommables dans n'importe quelle application.

[En savoir plus sur le SDK Azure Machine Learning](https://docs.microsoft.com/python/api/overview/azure/ml?WT.mc_id=academic-77958-bethanycheum&ocid=AID3041109)

Dans la [le√ßon pr√©c√©dente](../18-Low-Code/README.md), nous avons vu comment entra√Æner, d√©ployer et consommer un mod√®le de mani√®re Low code/No code. Nous avons utilis√© le jeu de donn√©es sur l'insuffisance cardiaque pour g√©n√©rer un mod√®le de pr√©diction. Dans cette le√ßon, nous allons faire exactement la m√™me chose, mais en utilisant le SDK Azure Machine Learning.

![sch√©ma-projet](../../../../5-Data-Science-In-Cloud/19-Azure/images/project-schema.PNG)

### 1.2 Projet de pr√©diction d'insuffisance cardiaque et introduction au jeu de donn√©es

Consultez [ici](../18-Low-Code/README.md) l'introduction au projet de pr√©diction d'insuffisance cardiaque et au jeu de donn√©es.

## 2. Entra√Æner un mod√®le avec l'Azure ML SDK
### 2.1 Cr√©er un espace de travail Azure ML

Pour simplifier, nous allons travailler sur un notebook Jupyter. Cela suppose que vous avez d√©j√† un espace de travail et une instance de calcul. Si vous avez d√©j√† un espace de travail, vous pouvez directement passer √† la section 2.3 Cr√©ation de notebook.

Sinon, veuillez suivre les instructions de la section **2.1 Cr√©er un espace de travail Azure ML** dans la [le√ßon pr√©c√©dente](../18-Low-Code/README.md) pour cr√©er un espace de travail.

### 2.2 Cr√©er une instance de calcul

Dans l'[espace de travail Azure ML](https://ml.azure.com/) que nous avons cr√©√© pr√©c√©demment, allez dans le menu de calcul et vous verrez les diff√©rentes ressources de calcul disponibles.

![instance-calcul-1](../../../../5-Data-Science-In-Cloud/19-Azure/images/compute-instance-1.PNG)

Cr√©ons une instance de calcul pour provisionner un notebook Jupyter. 
1. Cliquez sur le bouton + Nouveau. 
2. Donnez un nom √† votre instance de calcul.
3. Choisissez vos options : CPU ou GPU, taille de la VM et nombre de c≈ìurs.
4. Cliquez sur le bouton Cr√©er.

F√©licitations, vous venez de cr√©er une instance de calcul ! Nous utiliserons cette instance de calcul pour cr√©er un notebook dans la section [Cr√©ation de notebooks](../../../../5-Data-Science-In-Cloud/19-Azure).

### 2.3 Charger le jeu de donn√©es
Consultez la [le√ßon pr√©c√©dente](../18-Low-Code/README.md) dans la section **2.3 Charger le jeu de donn√©es** si vous n'avez pas encore t√©l√©charg√© le jeu de donn√©es.

### 2.4 Cr√©er des notebooks

> **_NOTE:_** Pour l'√©tape suivante, vous pouvez soit cr√©er un nouveau notebook √† partir de z√©ro, soit t√©l√©charger le [notebook que nous avons cr√©√©](../../../../5-Data-Science-In-Cloud/19-Azure/notebook.ipynb) dans votre Azure ML Studio. Pour le t√©l√©charger, cliquez simplement sur le menu "Notebook" et t√©l√©chargez le notebook.

Les notebooks sont une partie tr√®s importante du processus de science des donn√©es. Ils peuvent √™tre utilis√©s pour effectuer une analyse exploratoire des donn√©es (EDA), appeler un cluster de calcul pour entra√Æner un mod√®le, ou appeler un cluster d'inf√©rence pour d√©ployer un endpoint. 

Pour cr√©er un notebook, nous avons besoin d'un n≈ìud de calcul qui sert l'instance de notebook Jupyter. Retournez √† l'[espace de travail Azure ML](https://ml.azure.com/) et cliquez sur Instances de calcul. Dans la liste des instances de calcul, vous devriez voir l'[instance de calcul que nous avons cr√©√©e pr√©c√©demment](../../../../5-Data-Science-In-Cloud/19-Azure). 

1. Dans la section Applications, cliquez sur l'option Jupyter. 
2. Cochez la case "Oui, je comprends" et cliquez sur le bouton Continuer.
![notebook-1](../../../../5-Data-Science-In-Cloud/19-Azure/images/notebook-1.PNG)
3. Cela devrait ouvrir un nouvel onglet de navigateur avec votre instance de notebook Jupyter comme suit. Cliquez sur le bouton "Nouveau" pour cr√©er un notebook.

![notebook-2](../../../../5-Data-Science-In-Cloud/19-Azure/images/notebook-2.PNG)

Maintenant que nous avons un notebook, nous pouvons commencer √† entra√Æner le mod√®le avec Azure ML SDK.

### 2.5 Entra√Æner un mod√®le

Tout d'abord, si vous avez un doute, consultez la [documentation Azure ML SDK](https://docs.microsoft.com/python/api/overview/azure/ml?WT.mc_id=academic-77958-bethanycheum&ocid=AID3041109). Elle contient toutes les informations n√©cessaires pour comprendre les modules que nous allons voir dans cette le√ßon.

#### 2.5.1 Configurer l'espace de travail, l'exp√©rience, le cluster de calcul et le jeu de donn√©es

Vous devez charger l'`espace de travail` √† partir du fichier de configuration en utilisant le code suivant :

```python
from azureml.core import Workspace
ws = Workspace.from_config()
```

Cela retourne un objet de type `Workspace` qui repr√©sente l'espace de travail. Ensuite, vous devez cr√©er une `exp√©rience` en utilisant le code suivant :

```python
from azureml.core import Experiment
experiment_name = 'aml-experiment'
experiment = Experiment(ws, experiment_name)
```
Pour obtenir ou cr√©er une exp√©rience √† partir d'un espace de travail, vous demandez l'exp√©rience en utilisant son nom. Le nom de l'exp√©rience doit comporter entre 3 et 36 caract√®res, commencer par une lettre ou un chiffre, et ne contenir que des lettres, des chiffres, des underscores et des tirets. Si l'exp√©rience n'est pas trouv√©e dans l'espace de travail, une nouvelle exp√©rience est cr√©√©e.

Maintenant, vous devez cr√©er un cluster de calcul pour l'entra√Ænement en utilisant le code suivant. Notez que cette √©tape peut prendre quelques minutes. 

```python
from azureml.core.compute import AmlCompute

aml_name = "heart-f-cluster"
try:
    aml_compute = AmlCompute(ws, aml_name)
    print('Found existing AML compute context.')
except:
    print('Creating new AML compute context.')
    aml_config = AmlCompute.provisioning_configuration(vm_size = "Standard_D2_v2", min_nodes=1, max_nodes=3)
    aml_compute = AmlCompute.create(ws, name = aml_name, provisioning_configuration = aml_config)
    aml_compute.wait_for_completion(show_output = True)

cts = ws.compute_targets
compute_target = cts[aml_name]
```

Vous pouvez obtenir le jeu de donn√©es √† partir de l'espace de travail en utilisant le nom du jeu de donn√©es de la mani√®re suivante :

```python
dataset = ws.datasets['heart-failure-records']
df = dataset.to_pandas_dataframe()
df.describe()
```
#### 2.5.2 Configuration AutoML et entra√Ænement

Pour configurer AutoML, utilisez la classe [AutoMLConfig](https://docs.microsoft.com/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig(class)?WT.mc_id=academic-77958-bethanycheum&ocid=AID3041109).

Comme d√©crit dans la documentation, il existe de nombreux param√®tres avec lesquels vous pouvez jouer. Pour ce projet, nous utiliserons les param√®tres suivants :

- `experiment_timeout_minutes` : Dur√©e maximale (en minutes) pendant laquelle l'exp√©rience est autoris√©e √† s'ex√©cuter avant d'√™tre automatiquement arr√™t√©e et que les r√©sultats soient automatiquement disponibles.
- `max_concurrent_iterations` : Nombre maximal d'it√©rations d'entra√Ænement simultan√©es autoris√©es pour l'exp√©rience.
- `primary_metric` : La m√©trique principale utilis√©e pour d√©terminer l'√©tat de l'exp√©rience.
- `compute_target` : La cible de calcul Azure Machine Learning pour ex√©cuter l'exp√©rience de machine learning automatis√©.
- `task` : Type de t√¢che √† ex√©cuter. Les valeurs peuvent √™tre 'classification', 'regression' ou 'forecasting' selon le type de probl√®me de machine learning automatis√© √† r√©soudre.
- `training_data` : Les donn√©es d'entra√Ænement √† utiliser dans l'exp√©rience. Elles doivent contenir √† la fois les caract√©ristiques d'entra√Ænement et une colonne de labels (optionnellement une colonne de poids d'√©chantillon).
- `label_column_name` : Le nom de la colonne de labels.
- `path` : Le chemin complet vers le dossier du projet Azure Machine Learning.
- `enable_early_stopping` : Indique si l'arr√™t anticip√© doit √™tre activ√© si le score ne s'am√©liore pas √† court terme.
- `featurization` : Indicateur pour savoir si l'√©tape de featurisation doit √™tre effectu√©e automatiquement ou non, ou si une featurisation personnalis√©e doit √™tre utilis√©e.
- `debug_log` : Le fichier journal pour √©crire les informations de d√©bogage.

```python
from azureml.train.automl import AutoMLConfig

project_folder = './aml-project'

automl_settings = {
    "experiment_timeout_minutes": 20,
    "max_concurrent_iterations": 3,
    "primary_metric" : 'AUC_weighted'
}

automl_config = AutoMLConfig(compute_target=compute_target,
                             task = "classification",
                             training_data=dataset,
                             label_column_name="DEATH_EVENT",
                             path = project_folder,  
                             enable_early_stopping= True,
                             featurization= 'auto',
                             debug_log = "automl_errors.log",
                             **automl_settings
                            )
```
Maintenant que vous avez configur√© votre configuration, vous pouvez entra√Æner le mod√®le en utilisant le code suivant. Cette √©tape peut prendre jusqu'√† une heure selon la taille de votre cluster.

```python
remote_run = experiment.submit(automl_config)
```
Vous pouvez ex√©cuter le widget RunDetails pour afficher les diff√©rentes exp√©riences.
```python
from azureml.widgets import RunDetails
RunDetails(remote_run).show()
```
## 3. D√©ploiement du mod√®le et consommation de l'endpoint avec l'Azure ML SDK

### 3.1 Sauvegarder le meilleur mod√®le

Le `remote_run` est un objet de type [AutoMLRun](https://docs.microsoft.com/python/api/azureml-train-automl-client/azureml.train.automl.run.automlrun?WT.mc_id=academic-77958-bethanycheum&ocid=AID3041109). Cet objet contient la m√©thode `get_output()` qui retourne la meilleure ex√©cution et le mod√®le ajust√© correspondant.

```python
best_run, fitted_model = remote_run.get_output()
```
Vous pouvez voir les param√®tres utilis√©s pour le meilleur mod√®le en imprimant simplement le `fitted_model` et voir les propri√©t√©s du meilleur mod√®le en utilisant la m√©thode [get_properties()](https://docs.microsoft.com/python/api/azureml-core/azureml.core.run(class)?view=azure-ml-py#azureml_core_Run_get_properties?WT.mc_id=academic-77958-bethanycheum&ocid=AID3041109).

```python
best_run.get_properties()
```

Ensuite, enregistrez le mod√®le avec la m√©thode [register_model](https://docs.microsoft.com/python/api/azureml-train-automl-client/azureml.train.automl.run.automlrun?view=azure-ml-py#register-model-model-name-none--description-none--tags-none--iteration-none--metric-none-?WT.mc_id=academic-77958-bethanycheum&ocid=AID3041109).
```python
model_name = best_run.properties['model_name']
script_file_name = 'inference/score.py'
best_run.download_file('outputs/scoring_file_v_1_0_0.py', 'inference/score.py')
description = "aml heart failure project sdk"
model = best_run.register_model(model_name = model_name,
                                model_path = './outputs/',
                                description = description,
                                tags = None)
```
### 3.2 D√©ploiement du mod√®le

Une fois le meilleur mod√®le sauvegard√©, nous pouvons le d√©ployer avec la classe [InferenceConfig](https://docs.microsoft.com/python/api/azureml-core/azureml.core.model.inferenceconfig?view=azure-ml-py?ocid=AID3041109). InferenceConfig repr√©sente les param√®tres de configuration pour un environnement personnalis√© utilis√© pour le d√©ploiement. La classe [AciWebservice](https://docs.microsoft.com/python/api/azureml-core/azureml.core.webservice.aciwebservice?view=azure-ml-py) repr√©sente un mod√®le de machine learning d√©ploy√© en tant qu'endpoint de service web sur Azure Container Instances. Un service d√©ploy√© est cr√©√© √† partir d'un mod√®le, d'un script et de fichiers associ√©s. Le service web r√©sultant est un endpoint HTTP √©quilibr√© avec une API REST. Vous pouvez envoyer des donn√©es √† cette API et recevoir la pr√©diction retourn√©e par le mod√®le.

Le mod√®le est d√©ploy√© en utilisant la m√©thode [deploy](https://docs.microsoft.com/python/api/azureml-core/azureml.core.model(class)?view=azure-ml-py#deploy-workspace--name--models--inference-config-none--deployment-config-none--deployment-target-none--overwrite-false--show-output-false-?WT.mc_id=academic-77958-bethanycheum&ocid=AID3041109).

```python
from azureml.core.model import InferenceConfig, Model
from azureml.core.webservice import AciWebservice

inference_config = InferenceConfig(entry_script=script_file_name, environment=best_run.get_environment())

aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1,
                                               memory_gb = 1,
                                               tags = {'type': "automl-heart-failure-prediction"},
                                               description = 'Sample service for AutoML Heart Failure Prediction')

aci_service_name = 'automl-hf-sdk'
aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)
aci_service.wait_for_deployment(True)
print(aci_service.state)
```
Cette √©tape devrait prendre quelques minutes.

### 3.3 Consommation de l'endpoint

Vous consommez votre endpoint en cr√©ant un exemple d'entr√©e :

```python
data = {
    "data":
    [
        {
            'age': "60",
            'anaemia': "false",
            'creatinine_phosphokinase': "500",
            'diabetes': "false",
            'ejection_fraction': "38",
            'high_blood_pressure': "false",
            'platelets': "260000",
            'serum_creatinine': "1.40",
            'serum_sodium': "137",
            'sex': "false",
            'smoking': "false",
            'time': "130",
        },
    ],
}

test_sample = str.encode(json.dumps(data))
```
Et ensuite, vous pouvez envoyer cette entr√©e √† votre mod√®le pour obtenir une pr√©diction :
```python
response = aci_service.run(input_data=test_sample)
response
```
Cela devrait produire `'{"result": [false]}'`. Cela signifie que les donn√©es du patient que nous avons envoy√©es au point de terminaison ont g√©n√©r√© la pr√©diction `false`, ce qui indique que cette personne n'est probablement pas sujette √† une crise cardiaque.

F√©licitations ! Vous venez d'utiliser le mod√®le d√©ploy√© et entra√Æn√© sur Azure ML avec le SDK Azure ML !

> **_NOTE:_** Une fois le projet termin√©, n'oubliez pas de supprimer toutes les ressources.

## üöÄ D√©fi

Il y a beaucoup d'autres choses que vous pouvez faire avec le SDK, malheureusement, nous ne pouvons pas toutes les aborder dans cette le√ßon. Mais bonne nouvelle, apprendre √† parcourir la documentation du SDK peut vous mener loin par vous-m√™me. Consultez la documentation du SDK Azure ML et trouvez la classe `Pipeline` qui vous permet de cr√©er des pipelines. Un Pipeline est une collection d'√©tapes pouvant √™tre ex√©cut√©es comme un flux de travail.

**INDICE :** Rendez-vous sur la [documentation du SDK](https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py?WT.mc_id=academic-77958-bethanycheum&ocid=AID3041109) et tapez des mots-cl√©s dans la barre de recherche comme "Pipeline". Vous devriez voir la classe `azureml.pipeline.core.Pipeline` dans les r√©sultats de recherche.

## [Quiz apr√®s la le√ßon](https://ff-quizzes.netlify.app/en/ds/quiz/37)

## R√©vision & √âtude personnelle

Dans cette le√ßon, vous avez appris √† entra√Æner, d√©ployer et utiliser un mod√®le pour pr√©dire le risque d'insuffisance cardiaque avec le SDK Azure ML dans le cloud. Consultez cette [documentation](https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py?WT.mc_id=academic-77958-bethanycheum&ocid=AID3041109) pour plus d'informations sur le SDK Azure ML. Essayez de cr√©er votre propre mod√®le avec le SDK Azure ML.

## Devoir

[Projet Data Science avec le SDK Azure ML](assignment.md)

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de faire appel √† une traduction humaine professionnelle. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.