<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "5da2d6b3736f6d668b89de9bf3bdd31b",
  "translation_date": "2025-09-04T12:56:10+00:00",
  "source_file": "5-Data-Science-In-Cloud/19-Azure/README.md",
  "language_code": "fr"
}
-->
# La science des donn√©es dans le cloud : La m√©thode "Azure ML SDK"

|![ Sketchnote par [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/19-DataScience-Cloud.png)|
|:---:|
| Science des donn√©es dans le cloud : Azure ML SDK - _Sketchnote par [@nitya](https://twitter.com/nitya)_ |

Table des mati√®res :

- [La science des donn√©es dans le cloud : La m√©thode "Azure ML SDK"](../../../../5-Data-Science-In-Cloud/19-Azure)
  - [Quiz avant le cours](../../../../5-Data-Science-In-Cloud/19-Azure)
  - [1. Introduction](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [1.1 Qu'est-ce que l'Azure ML SDK ?](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [1.2 Pr√©sentation du projet et du jeu de donn√©es pour la pr√©diction d'insuffisance cardiaque](../../../../5-Data-Science-In-Cloud/19-Azure)
  - [2. Entra√Æner un mod√®le avec Azure ML SDK](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [2.1 Cr√©er un espace de travail Azure ML](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [2.2 Cr√©er une instance de calcul](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [2.3 Charger le jeu de donn√©es](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [2.4 Cr√©er des notebooks](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [2.5 Entra√Æner un mod√®le](../../../../5-Data-Science-In-Cloud/19-Azure)
      - [2.5.1 Configurer l'espace de travail, l'exp√©rience, le cluster de calcul et le jeu de donn√©es](../../../../5-Data-Science-In-Cloud/19-Azure)
      - [2.5.2 Configuration et entra√Ænement AutoML](../../../../5-Data-Science-In-Cloud/19-Azure)
  - [3. D√©ploiement du mod√®le et consommation de l'endpoint avec Azure ML SDK](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [3.1 Sauvegarder le meilleur mod√®le](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [3.2 D√©ploiement du mod√®le](../../../../5-Data-Science-In-Cloud/19-Azure)
    - [3.3 Consommation de l'endpoint](../../../../5-Data-Science-In-Cloud/19-Azure)
  - [üöÄ D√©fi](../../../../5-Data-Science-In-Cloud/19-Azure)
  - [Quiz apr√®s le cours](../../../../5-Data-Science-In-Cloud/19-Azure)
  - [R√©vision et auto-apprentissage](../../../../5-Data-Science-In-Cloud/19-Azure)
  - [Devoir](../../../../5-Data-Science-In-Cloud/19-Azure)

## [Quiz avant le cours](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/36)

## 1. Introduction

### 1.1 Qu'est-ce que l'Azure ML SDK ?

Les data scientists et les d√©veloppeurs en IA utilisent le SDK Azure Machine Learning pour construire et ex√©cuter des workflows de machine learning avec le service Azure Machine Learning. Vous pouvez interagir avec le service dans n'importe quel environnement Python, y compris Jupyter Notebooks, Visual Studio Code ou votre IDE Python pr√©f√©r√©.

Les domaines cl√©s du SDK incluent :

- Explorer, pr√©parer et g√©rer le cycle de vie de vos jeux de donn√©es utilis√©s dans les exp√©riences de machine learning.
- G√©rer les ressources cloud pour surveiller, journaliser et organiser vos exp√©riences de machine learning.
- Entra√Æner des mod√®les localement ou en utilisant des ressources cloud, y compris l'entra√Ænement de mod√®les acc√©l√©r√©s par GPU.
- Utiliser le machine learning automatis√©, qui accepte des param√®tres de configuration et des donn√©es d'entra√Ænement. Il it√®re automatiquement √† travers les algorithmes et les r√©glages d'hyperparam√®tres pour trouver le meilleur mod√®le pour effectuer des pr√©dictions.
- D√©ployer des services web pour transformer vos mod√®les entra√Æn√©s en services RESTful consommables dans n'importe quelle application.

[En savoir plus sur le SDK Azure Machine Learning](https://docs.microsoft.com/python/api/overview/azure/ml?WT.mc_id=academic-77958-bethanycheum&ocid=AID3041109)

Dans la [le√ßon pr√©c√©dente](../18-Low-Code/README.md), nous avons vu comment entra√Æner, d√©ployer et consommer un mod√®le de mani√®re Low code/No code. Nous avons utilis√© le jeu de donn√©es sur l'insuffisance cardiaque pour g√©n√©rer un mod√®le de pr√©diction. Dans cette le√ßon, nous allons faire exactement la m√™me chose, mais en utilisant le SDK Azure Machine Learning.

![sch√©ma-projet](../../../../translated_images/project-schema.420e56d495624541eaecf2b737f138c86fb7d8162bb1c0bf8783c350872ffc4d.fr.png)

### 1.2 Pr√©sentation du projet et du jeu de donn√©es pour la pr√©diction d'insuffisance cardiaque

Consultez [ici](../18-Low-Code/README.md) la pr√©sentation du projet et du jeu de donn√©es pour la pr√©diction d'insuffisance cardiaque.

## 2. Entra√Æner un mod√®le avec Azure ML SDK

### 2.1 Cr√©er un espace de travail Azure ML

Pour simplifier, nous allons travailler sur un notebook Jupyter. Cela suppose que vous avez d√©j√† un espace de travail et une instance de calcul. Si vous avez d√©j√† un espace de travail, vous pouvez passer directement √† la section 2.3 Cr√©ation de notebook.

Sinon, veuillez suivre les instructions de la section **2.1 Cr√©er un espace de travail Azure ML** dans la [le√ßon pr√©c√©dente](../18-Low-Code/README.md) pour cr√©er un espace de travail.

### 2.2 Cr√©er une instance de calcul

Dans l'[espace de travail Azure ML](https://ml.azure.com/) que nous avons cr√©√© pr√©c√©demment, allez dans le menu de calcul et vous verrez les diff√©rentes ressources de calcul disponibles.

![instance-calcul-1](../../../../translated_images/compute-instance-1.dba347cb199ca4996b3e3d649295ed95626ba481479d3986557b9b98e76d8816.fr.png)

Cr√©ons une instance de calcul pour provisionner un notebook Jupyter.  
1. Cliquez sur le bouton + Nouveau.  
2. Donnez un nom √† votre instance de calcul.  
3. Choisissez vos options : CPU ou GPU, taille de la machine virtuelle et nombre de c≈ìurs.  
4. Cliquez sur le bouton Cr√©er.  

F√©licitations, vous venez de cr√©er une instance de calcul ! Nous utiliserons cette instance pour cr√©er un notebook dans la [section Cr√©ation de notebooks](../../../../5-Data-Science-In-Cloud/19-Azure).

### 2.3 Charger le jeu de donn√©es

R√©f√©rez-vous √† la [le√ßon pr√©c√©dente](../18-Low-Code/README.md) dans la section **2.3 Charger le jeu de donn√©es** si vous n'avez pas encore t√©l√©charg√© le jeu de donn√©es.

### 2.4 Cr√©er des notebooks

> **_NOTE :_** Pour l'√©tape suivante, vous pouvez soit cr√©er un nouveau notebook √† partir de z√©ro, soit t√©l√©charger le [notebook que nous avons cr√©√©](notebook.ipynb) dans votre Azure ML Studio. Pour le t√©l√©charger, cliquez simplement sur le menu "Notebook" et t√©l√©chargez le fichier.

Les notebooks sont une partie essentielle du processus de science des donn√©es. Ils peuvent √™tre utilis√©s pour effectuer une analyse exploratoire des donn√©es (EDA), appeler un cluster de calcul pour entra√Æner un mod√®le, ou appeler un cluster d'inf√©rence pour d√©ployer un endpoint.

Pour cr√©er un notebook, nous avons besoin d'un n≈ìud de calcul qui h√©berge l'instance Jupyter Notebook. Retournez √† l'[espace de travail Azure ML](https://ml.azure.com/) et cliquez sur Instances de calcul. Dans la liste des instances, vous devriez voir [l'instance que nous avons cr√©√©e pr√©c√©demment](../../../../5-Data-Science-In-Cloud/19-Azure).

1. Dans la section Applications, cliquez sur l'option Jupyter.  
2. Cochez la case "Oui, je comprends" et cliquez sur le bouton Continuer.  
![notebook-1](../../../../translated_images/notebook-1.12998af7b02c83f536c11b3aeba561be16e0f05e94146600728ec64270ce1105.fr.png)  
3. Cela ouvrira un nouvel onglet de navigateur avec votre instance Jupyter Notebook. Cliquez sur le bouton "Nouveau" pour cr√©er un notebook.  

![notebook-2](../../../../translated_images/notebook-2.9a657c037e34f1cf26c0212f5ee9e2da8545b3e107c7682c55114e494167a8aa.fr.png)

Maintenant que nous avons un notebook, nous pouvons commencer √† entra√Æner le mod√®le avec Azure ML SDK.

### 2.5 Entra√Æner un mod√®le

Tout d'abord, en cas de doute, r√©f√©rez-vous √† la [documentation Azure ML SDK](https://docs.microsoft.com/python/api/overview/azure/ml?WT.mc_id=academic-77958-bethanycheum&ocid=AID3041109). Elle contient toutes les informations n√©cessaires pour comprendre les modules que nous allons utiliser dans cette le√ßon.

#### 2.5.1 Configurer l'espace de travail, l'exp√©rience, le cluster de calcul et le jeu de donn√©es

Vous devez charger l'`espace de travail` √† partir du fichier de configuration en utilisant le code suivant :

```python
from azureml.core import Workspace
ws = Workspace.from_config()
```

Cela renvoie un objet de type `Workspace` qui repr√©sente l'espace de travail. Ensuite, vous devez cr√©er une `exp√©rience` en utilisant le code suivant :

```python
from azureml.core import Experiment
experiment_name = 'aml-experiment'
experiment = Experiment(ws, experiment_name)
```

Pour obtenir ou cr√©er une exp√©rience √† partir d'un espace de travail, vous demandez l'exp√©rience en utilisant son nom. Le nom de l'exp√©rience doit comporter entre 3 et 36 caract√®res, commencer par une lettre ou un chiffre, et ne contenir que des lettres, des chiffres, des traits de soulignement et des tirets. Si l'exp√©rience n'est pas trouv√©e dans l'espace de travail, une nouvelle exp√©rience est cr√©√©e.

Ensuite, vous devez cr√©er un cluster de calcul pour l'entra√Ænement en utilisant le code suivant. Notez que cette √©tape peut prendre quelques minutes.

```python
from azureml.core.compute import AmlCompute

aml_name = "heart-f-cluster"
try:
    aml_compute = AmlCompute(ws, aml_name)
    print('Found existing AML compute context.')
except:
    print('Creating new AML compute context.')
    aml_config = AmlCompute.provisioning_configuration(vm_size = "Standard_D2_v2", min_nodes=1, max_nodes=3)
    aml_compute = AmlCompute.create(ws, name = aml_name, provisioning_configuration = aml_config)
    aml_compute.wait_for_completion(show_output = True)

cts = ws.compute_targets
compute_target = cts[aml_name]
```

Vous pouvez obtenir le jeu de donn√©es √† partir de l'espace de travail en utilisant le nom du jeu de donn√©es de la mani√®re suivante :

```python
dataset = ws.datasets['heart-failure-records']
df = dataset.to_pandas_dataframe()
df.describe()
```

#### 2.5.2 Configuration et entra√Ænement AutoML

Pour configurer AutoML, utilisez la classe [AutoMLConfig](https://docs.microsoft.com/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig(class)?WT.mc_id=academic-77958-bethanycheum&ocid=AID3041109).

Comme d√©crit dans la documentation, il existe de nombreux param√®tres avec lesquels vous pouvez jouer. Pour ce projet, nous utiliserons les param√®tres suivants :

- `experiment_timeout_minutes` : Dur√©e maximale (en minutes) pendant laquelle l'exp√©rience peut s'ex√©cuter avant d'√™tre automatiquement arr√™t√©e et que les r√©sultats soient disponibles.  
- `max_concurrent_iterations` : Nombre maximal d'it√©rations d'entra√Ænement simultan√©es autoris√©es pour l'exp√©rience.  
- `primary_metric` : M√©trique principale utilis√©e pour d√©terminer le statut de l'exp√©rience.  
- `compute_target` : Ressource de calcul Azure Machine Learning utilis√©e pour ex√©cuter l'exp√©rience AutoML.  
- `task` : Type de t√¢che √† ex√©cuter. Les valeurs possibles sont 'classification', 'regression' ou 'forecasting' selon le type de probl√®me AutoML √† r√©soudre.  
- `training_data` : Donn√©es d'entra√Ænement utilis√©es dans l'exp√©rience. Elles doivent contenir √† la fois les caract√©ristiques d'entra√Ænement et une colonne d'√©tiquettes (√©ventuellement une colonne de poids d'√©chantillon).  
- `label_column_name` : Nom de la colonne d'√©tiquettes.  
- `path` : Chemin complet vers le dossier du projet Azure Machine Learning.  
- `enable_early_stopping` : Indique si l'arr√™t anticip√© doit √™tre activ√© si le score ne s'am√©liore pas √† court terme.  
- `featurization` : Indicateur pour savoir si l'√©tape de featurisation doit √™tre effectu√©e automatiquement ou non, ou si une featurisation personnalis√©e doit √™tre utilis√©e.  
- `debug_log` : Fichier journal pour √©crire les informations de d√©bogage.  

```python
from azureml.train.automl import AutoMLConfig

project_folder = './aml-project'

automl_settings = {
    "experiment_timeout_minutes": 20,
    "max_concurrent_iterations": 3,
    "primary_metric" : 'AUC_weighted'
}

automl_config = AutoMLConfig(compute_target=compute_target,
                             task = "classification",
                             training_data=dataset,
                             label_column_name="DEATH_EVENT",
                             path = project_folder,  
                             enable_early_stopping= True,
                             featurization= 'auto',
                             debug_log = "automl_errors.log",
                             **automl_settings
                            )
```

Maintenant que votre configuration est d√©finie, vous pouvez entra√Æner le mod√®le en utilisant le code suivant. Cette √©tape peut prendre jusqu'√† une heure selon la taille de votre cluster.

```python
remote_run = experiment.submit(automl_config)
```

Vous pouvez ex√©cuter le widget RunDetails pour afficher les diff√©rentes exp√©riences.  
```python
from azureml.widgets import RunDetails
RunDetails(remote_run).show()
```

## 3. D√©ploiement du mod√®le et consommation de l'endpoint avec Azure ML SDK

### 3.1 Sauvegarder le meilleur mod√®le

L'objet `remote_run` est de type [AutoMLRun](https://docs.microsoft.com/python/api/azureml-train-automl-client/azureml.train.automl.run.automlrun?WT.mc_id=academic-77958-bethanycheum&ocid=AID3041109). Cet objet contient la m√©thode `get_output()` qui renvoie la meilleure ex√©cution et le mod√®le correspondant.

```python
best_run, fitted_model = remote_run.get_output()
```

Vous pouvez voir les param√®tres utilis√©s pour le meilleur mod√®le en imprimant simplement le `fitted_model` et consulter les propri√©t√©s du meilleur mod√®le en utilisant la m√©thode [get_properties()](https://docs.microsoft.com/python/api/azureml-core/azureml.core.run(class)?view=azure-ml-py#azureml_core_Run_get_properties?WT.mc_id=academic-77958-bethanycheum&ocid=AID3041109).

```python
best_run.get_properties()
```

Enregistrez maintenant le mod√®le avec la m√©thode [register_model](https://docs.microsoft.com/python/api/azureml-train-automl-client/azureml.train.automl.run.automlrun?view=azure-ml-py#register-model-model-name-none--description-none--tags-none--iteration-none--metric-none-?WT.mc_id=academic-77958-bethanycheum&ocid=AID3041109).  
```python
model_name = best_run.properties['model_name']
script_file_name = 'inference/score.py'
best_run.download_file('outputs/scoring_file_v_1_0_0.py', 'inference/score.py')
description = "aml heart failure project sdk"
model = best_run.register_model(model_name = model_name,
                                model_path = './outputs/',
                                description = description,
                                tags = None)
```

### 3.2 D√©ploiement du mod√®le

Une fois le meilleur mod√®le sauvegard√©, nous pouvons le d√©ployer avec la classe [InferenceConfig](https://docs.microsoft.com/python/api/azureml-core/azureml.core.model.inferenceconfig?view=azure-ml-py?ocid=AID3041109). InferenceConfig repr√©sente les param√®tres de configuration pour un environnement personnalis√© utilis√© pour le d√©ploiement. La classe [AciWebservice](https://docs.microsoft.com/python/api/azureml-core/azureml.core.webservice.aciwebservice?view=azure-ml-py) repr√©sente un mod√®le de machine learning d√©ploy√© en tant qu'endpoint de service web sur Azure Container Instances. Un service d√©ploy√© est cr√©√© √† partir d'un mod√®le, d'un script et de fichiers associ√©s. Le service web r√©sultant est un endpoint HTTP √©quilibr√© avec une API REST. Vous pouvez envoyer des donn√©es √† cette API et recevoir la pr√©diction retourn√©e par le mod√®le.

Le mod√®le est d√©ploy√© en utilisant la m√©thode [deploy](https://docs.microsoft.com/python/api/azureml-core/azureml.core.model(class)?view=azure-ml-py#deploy-workspace--name--models--inference-config-none--deployment-config-none--deployment-target-none--overwrite-false--show-output-false-?WT.mc_id=academic-77958-bethanycheum&ocid=AID3041109).

```python
from azureml.core.model import InferenceConfig, Model
from azureml.core.webservice import AciWebservice

inference_config = InferenceConfig(entry_script=script_file_name, environment=best_run.get_environment())

aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1,
                                               memory_gb = 1,
                                               tags = {'type': "automl-heart-failure-prediction"},
                                               description = 'Sample service for AutoML Heart Failure Prediction')

aci_service_name = 'automl-hf-sdk'
aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)
aci_service.wait_for_deployment(True)
print(aci_service.state)
```

Cette √©tape devrait prendre quelques minutes.

### 3.3 Consommation de l'endpoint

Vous consommez votre endpoint en cr√©ant un exemple d'entr√©e :

```python
data = {
    "data":
    [
        {
            'age': "60",
            'anaemia': "false",
            'creatinine_phosphokinase': "500",
            'diabetes': "false",
            'ejection_fraction': "38",
            'high_blood_pressure': "false",
            'platelets': "260000",
            'serum_creatinine': "1.40",
            'serum_sodium': "137",
            'sex': "false",
            'smoking': "false",
            'time': "130",
        },
    ],
}

test_sample = str.encode(json.dumps(data))
```

Ensuite, vous pouvez envoyer cette entr√©e √† votre mod√®le pour obtenir une pr√©diction :
```python
response = aci_service.run(input_data=test_sample)
response
```
Cela devrait produire `'{"result": [false]}'`. Cela signifie que les donn√©es du patient que nous avons envoy√©es √† l'endpoint ont g√©n√©r√© la pr√©diction `false`, ce qui indique que cette personne n'est probablement pas susceptible de faire une crise cardiaque.

F√©licitations ! Vous venez d'utiliser le mod√®le d√©ploy√© et entra√Æn√© sur Azure ML avec le SDK Azure ML !

> **_NOTE:_** Une fois le projet termin√©, n'oubliez pas de supprimer toutes les ressources.

## üöÄ D√©fi

Il y a beaucoup d'autres choses que vous pouvez faire avec le SDK, mais malheureusement, nous ne pouvons pas tout couvrir dans cette le√ßon. Bonne nouvelle, apprendre √† parcourir la documentation du SDK peut vous mener loin en autonomie. Consultez la documentation du SDK Azure ML et trouvez la classe `Pipeline` qui vous permet de cr√©er des pipelines. Un Pipeline est une collection d'√©tapes pouvant √™tre ex√©cut√©es comme un workflow.

**ASTUCE :** Rendez-vous sur la [documentation du SDK](https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py?WT.mc_id=academic-77958-bethanycheum&ocid=AID3041109) et tapez des mots-cl√©s dans la barre de recherche comme "Pipeline". Vous devriez trouver la classe `azureml.pipeline.core.Pipeline` dans les r√©sultats de recherche.

## [Quiz post-cours](https://ff-quizzes.netlify.app/en/ds/)

## R√©vision et auto-apprentissage

Dans cette le√ßon, vous avez appris √† entra√Æner, d√©ployer et utiliser un mod√®le pour pr√©dire le risque d'insuffisance cardiaque avec le SDK Azure ML dans le cloud. Consultez cette [documentation](https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py?WT.mc_id=academic-77958-bethanycheum&ocid=AID3041109) pour plus d'informations sur le SDK Azure ML. Essayez de cr√©er votre propre mod√®le avec le SDK Azure ML.

## Devoir

[Projet Data Science avec le SDK Azure ML](assignment.md)

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction professionnelle r√©alis√©e par un humain. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.