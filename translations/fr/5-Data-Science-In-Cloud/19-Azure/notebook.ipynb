{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Science des données dans le cloud : La méthode \"Azure ML SDK\"\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Dans ce notebook, nous allons apprendre à utiliser le SDK Azure ML pour entraîner, déployer et consommer un modèle via Azure ML.\n",
    "\n",
    "Prérequis :\n",
    "1. Vous avez créé un espace de travail Azure ML.\n",
    "2. Vous avez chargé le [jeu de données sur l'insuffisance cardiaque](https://www.kaggle.com/andrewmvd/heart-failure-clinical-data) dans Azure ML.\n",
    "3. Vous avez téléchargé ce notebook dans Azure ML Studio.\n",
    "\n",
    "Les étapes suivantes sont :\n",
    "\n",
    "1. Créer une expérience dans un espace de travail existant.\n",
    "2. Créer un cluster de calcul.\n",
    "3. Charger le jeu de données.\n",
    "4. Configurer AutoML en utilisant AutoMLConfig.\n",
    "5. Exécuter l'expérience AutoML.\n",
    "6. Explorer les résultats et obtenir le meilleur modèle.\n",
    "7. Enregistrer le meilleur modèle.\n",
    "8. Déployer le meilleur modèle.\n",
    "9. Consommer le point de terminaison.\n",
    "\n",
    "## Importations spécifiques au SDK Azure Machine Learning\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import AciWebservice"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialiser l'espace de travail\n",
    "Initialisez un objet espace de travail à partir de la configuration enregistrée. Assurez-vous que le fichier de configuration est présent à .\\config.json\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Créer une expérience Azure ML\n",
    "\n",
    "Créons une expérience nommée 'aml-experiment' dans l'espace de travail que nous venons d'initialiser.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "experiment_name = 'aml-experiment'\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "experiment"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Créer un Cluster de Calcul\n",
    "Vous devrez créer une [cible de calcul](https://docs.microsoft.com/azure/machine-learning/concept-azure-machine-learning-architecture#compute-target) pour votre exécution AutoML.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "aml_name = \"heart-f-cluster\"\n",
    "try:\n",
    "    aml_compute = AmlCompute(ws, aml_name)\n",
    "    print('Found existing AML compute context.')\n",
    "except:\n",
    "    print('Creating new AML compute context.')\n",
    "    aml_config = AmlCompute.provisioning_configuration(vm_size = \"Standard_D2_v2\", min_nodes=1, max_nodes=3)\n",
    "    aml_compute = AmlCompute.create(ws, name = aml_name, provisioning_configuration = aml_config)\n",
    "    aml_compute.wait_for_completion(show_output = True)\n",
    "\n",
    "cts = ws.compute_targets\n",
    "compute_target = cts[aml_name]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Données\n",
    "Assurez-vous d'avoir téléchargé le jeu de données sur Azure ML et que la clé porte le même nom que le jeu de données.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "key = 'heart-failure-records'\n",
    "dataset = ws.datasets[key]\n",
    "df = dataset.to_pandas_dataframe()\n",
    "df.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configuration AutoML\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\": 20,\n",
    "    \"max_concurrent_iterations\": 3,\n",
    "    \"primary_metric\" : 'AUC_weighted'\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(compute_target=compute_target,\n",
    "                             task = \"classification\",\n",
    "                             training_data=dataset,\n",
    "                             label_column_name=\"DEATH_EVENT\",\n",
    "                             enable_early_stopping= True,\n",
    "                             featurization= 'auto',\n",
    "                             debug_log = \"automl_errors.log\",\n",
    "                             **automl_settings\n",
    "                            )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exécution AutoML\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "remote_run = experiment.submit(automl_config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "RunDetails(remote_run).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_run, fitted_model = remote_run.get_output()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_run.get_properties()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_name = best_run.properties['model_name']\n",
    "script_file_name = 'inference/score.py'\n",
    "best_run.download_file('outputs/scoring_file_v_1_0_0.py', 'inference/score.py')\n",
    "description = \"aml heart failure project sdk\"\n",
    "model = best_run.register_model(model_name = model_name,\n",
    "                                description = description,\n",
    "                                tags = None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Déployer le meilleur modèle\n",
    "\n",
    "Exécutez le code suivant pour déployer le meilleur modèle. Vous pouvez consulter l'état du déploiement dans le portail Azure ML. Cette étape peut prendre quelques minutes.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "inference_config = InferenceConfig(entry_script=script_file_name, environment=best_run.get_environment())\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
    "                                               memory_gb = 1,\n",
    "                                               tags = {'type': \"automl-heart-failure-prediction\"},\n",
    "                                               description = 'Sample service for AutoML Heart Failure Prediction')\n",
    "\n",
    "aci_service_name = 'automl-hf-sdk'\n",
    "aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utiliser le point de terminaison\n",
    "Vous pouvez ajouter des entrées à l'exemple d'entrée suivant.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = {\n",
    "    \"data\":\n",
    "    [\n",
    "        {\n",
    "            'age': \"60\",\n",
    "            'anaemia': \"false\",\n",
    "            'creatinine_phosphokinase': \"500\",\n",
    "            'diabetes': \"false\",\n",
    "            'ejection_fraction': \"38\",\n",
    "            'high_blood_pressure': \"false\",\n",
    "            'platelets': \"260000\",\n",
    "            'serum_creatinine': \"1.40\",\n",
    "            'serum_sodium': \"137\",\n",
    "            'sex': \"false\",\n",
    "            'smoking': \"false\",\n",
    "            'time': \"130\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "test_sample = str.encode(json.dumps(data))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "response = aci_service.run(input_data=test_sample)\n",
    "response"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Avertissement** :  \nCe document a été traduit à l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatisées peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit être considéré comme la source faisant autorité. Pour des informations critiques, il est recommandé de recourir à une traduction professionnelle réalisée par un humain. Nous déclinons toute responsabilité en cas de malentendus ou d'interprétations erronées résultant de l'utilisation de cette traduction.\n"
   ]
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  },
  "coopTranslator": {
   "original_hash": "af42669556d5dc19fc4cc3866f7d2597",
   "translation_date": "2025-09-01T20:06:28+00:00",
   "source_file": "5-Data-Science-In-Cloud/19-Azure/notebook.ipynb",
   "language_code": "fr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}