<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1cf49f029ba1f25a54f0d5bc2fa575fc",
  "translation_date": "2025-09-05T21:51:36+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "sv"
}
-->
# En kort introduktion till statistik och sannolikhet

|![ Sketchnote av [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| Statistik och sannolikhet - _Sketchnote av [@nitya](https://twitter.com/nitya)_ |

Statistik och sannolikhetsteori √§r tv√• starkt relaterade omr√•den inom matematik som √§r mycket relevanta f√∂r datavetenskap. Det √§r m√∂jligt att arbeta med data utan djupg√•ende kunskaper i matematik, men det √§r √§nd√• b√§ttre att k√§nna till √•tminstone n√•gra grundl√§ggande begrepp. H√§r presenterar vi en kort introduktion som hj√§lper dig att komma ig√•ng.

[![Introduktionsvideo](../../../../1-Introduction/04-stats-and-probability/images/video-prob-and-stats.png)](https://youtu.be/Z5Zy85g4Yjw)

## [Quiz f√∂re f√∂rel√§sningen](https://ff-quizzes.netlify.app/en/ds/quiz/6)

## Sannolikhet och slumpm√§ssiga variabler

**Sannolikhet** √§r ett tal mellan 0 och 1 som uttrycker hur sannolikt en **h√§ndelse** √§r. Det definieras som antalet positiva utfall (som leder till h√§ndelsen), dividerat med det totala antalet utfall, givet att alla utfall √§r lika sannolika. Till exempel, n√§r vi kastar en t√§rning, √§r sannolikheten att vi f√•r ett j√§mnt tal 3/6 = 0,5.

N√§r vi pratar om h√§ndelser anv√§nder vi **slumpm√§ssiga variabler**. Till exempel, den slumpm√§ssiga variabeln som representerar ett tal som erh√•lls vid kast av en t√§rning skulle anta v√§rden fr√•n 1 till 6. M√§ngden av tal fr√•n 1 till 6 kallas **utfallsrum**. Vi kan prata om sannolikheten f√∂r att en slumpm√§ssig variabel antar ett visst v√§rde, till exempel P(X=3)=1/6.

Den slumpm√§ssiga variabeln i det tidigare exemplet kallas **diskret**, eftersom den har ett r√§kneligt utfallsrum, dvs. det finns separata v√§rden som kan numreras. Det finns fall d√§r utfallsrummet √§r ett intervall av reella tal, eller hela m√§ngden av reella tal. S√•dana variabler kallas **kontinuerliga**. Ett bra exempel √§r tiden n√§r bussen anl√§nder.

## Sannolikhetsf√∂rdelning

F√∂r diskreta slumpm√§ssiga variabler √§r det enkelt att beskriva sannolikheten f√∂r varje h√§ndelse med en funktion P(X). F√∂r varje v√§rde *s* fr√•n utfallsrummet *S* ger den ett tal mellan 0 och 1, s√• att summan av alla v√§rden av P(X=s) f√∂r alla h√§ndelser blir 1.

Den mest k√§nda diskreta f√∂rdelningen √§r **likformig f√∂rdelning**, d√§r det finns ett utfallsrum med N element, med lika sannolikhet 1/N f√∂r vart och ett av dem.

Det √§r sv√•rare att beskriva sannolikhetsf√∂rdelningen f√∂r en kontinuerlig variabel, med v√§rden fr√•n ett intervall [a,b], eller hela m√§ngden av reella tal ‚Ñù. T√§nk p√• fallet med busstider. Faktum √§r att f√∂r varje exakt ankomsttid *t* √§r sannolikheten att en buss anl√§nder exakt vid den tiden 0!

> Nu vet du att h√§ndelser med sannolikhet 0 intr√§ffar, och v√§ldigt ofta! √Ötminstone varje g√•ng bussen anl√§nder!

Vi kan bara prata om sannolikheten f√∂r att en variabel faller inom ett givet intervall av v√§rden, t.ex. P(t<sub>1</sub>‚â§X<t<sub>2</sub>). I detta fall beskrivs sannolikhetsf√∂rdelningen av en **sannolikhetst√§thetsfunktion** p(x), s√• att

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../1-Introduction/04-stats-and-probability/images/probability-density.png)

En kontinuerlig analog av likformig f√∂rdelning kallas **kontinuerlig likformig**, som definieras p√• ett √§ndligt intervall. Sannolikheten att v√§rdet X faller inom ett intervall av l√§ngd l √§r proportionell mot l och stiger upp till 1.

En annan viktig f√∂rdelning √§r **normalf√∂rdelning**, som vi kommer att prata mer om nedan.

## Medelv√§rde, varians och standardavvikelse

Anta att vi drar en sekvens av n stickprov fr√•n en slumpm√§ssig variabel X: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. Vi kan definiera **medelv√§rde** (eller **aritmetiskt medelv√§rde**) f√∂r sekvensen p√• traditionellt s√§tt som (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n. N√§r vi √∂kar storleken p√• stickprovet (dvs. tar gr√§nsen med n‚Üí‚àû), f√•r vi medelv√§rdet (√§ven kallat **f√∂rv√§ntan**) f√∂r f√∂rdelningen. Vi betecknar f√∂rv√§ntan med **E**(x).

> Det kan visas att f√∂r varje diskret f√∂rdelning med v√§rden {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} och motsvarande sannolikheter p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, skulle f√∂rv√§ntan vara E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>.

F√∂r att identifiera hur spridda v√§rdena √§r kan vi ber√§kna variansen œÉ<sup>2</sup> = ‚àë(x<sub>i</sub> - Œº)<sup>2</sup>/n, d√§r Œº √§r medelv√§rdet f√∂r sekvensen. V√§rdet œÉ kallas **standardavvikelse**, och œÉ<sup>2</sup> kallas **varians**.

## Typv√§rde, median och kvartiler

Ibland representerar medelv√§rdet inte tillr√§ckligt v√§l det "typiska" v√§rdet f√∂r data. Till exempel, n√§r det finns n√•gra extrema v√§rden som √§r helt utanf√∂r intervallet, kan de p√•verka medelv√§rdet. Ett annat bra m√•tt √§r **median**, ett v√§rde s√•dant att h√§lften av datapunkterna √§r l√§gre √§n det, och den andra h√§lften - h√∂gre.

F√∂r att hj√§lpa oss f√∂rst√• dataf√∂rdelningen √§r det anv√§ndbart att prata om **kvartiler**:

* F√∂rsta kvartilen, eller Q1, √§r ett v√§rde s√•dant att 25% av data ligger under det
* Tredje kvartilen, eller Q3, √§r ett v√§rde s√•dant att 75% av data ligger under det

Grafiskt kan vi representera f√∂rh√•llandet mellan median och kvartiler i ett diagram som kallas **l√•ddiagram**:

<img src="images/boxplot_explanation.png" width="50%"/>

H√§r ber√§knar vi ocks√• **interkvartilavst√•nd** IQR=Q3-Q1, och s√• kallade **uteliggare** - v√§rden som ligger utanf√∂r gr√§nserna [Q1-1.5*IQR,Q3+1.5*IQR].

F√∂r en √§ndlig f√∂rdelning som inneh√•ller ett litet antal m√∂jliga v√§rden √§r ett bra "typiskt" v√§rde det som f√∂rekommer oftast, vilket kallas **typv√§rde**. Det anv√§nds ofta f√∂r kategoriska data, s√•som f√§rger. T√§nk p√• en situation d√§r vi har tv√• grupper av m√§nniskor - n√•gra som starkt f√∂redrar r√∂tt, och andra som f√∂redrar bl√•tt. Om vi kodar f√§rger med siffror, skulle medelv√§rdet f√∂r en favoritf√§rg vara n√•gonstans i det orange-gr√∂na spektrumet, vilket inte indikerar den faktiska preferensen hos n√•gon av grupperna. D√§remot skulle typv√§rdet vara antingen en av f√§rgerna, eller b√•da f√§rgerna, om antalet personer som r√∂star p√• dem √§r lika (i detta fall kallar vi stickprovet **multimodalt**).

## Data fr√•n verkligheten

N√§r vi analyserar data fr√•n verkligheten √§r de ofta inte slumpm√§ssiga variabler i den meningen att vi inte utf√∂r experiment med ok√§nt resultat. Till exempel, t√§nk p√• ett lag av basebollspelare och deras kroppsliga data, s√•som l√§ngd, vikt och √•lder. Dessa siffror √§r inte exakt slumpm√§ssiga, men vi kan √§nd√• till√§mpa samma matematiska begrepp. Till exempel kan en sekvens av m√§nniskors vikter betraktas som en sekvens av v√§rden som dras fr√•n en slumpm√§ssig variabel. Nedan √§r sekvensen av vikter f√∂r faktiska basebollspelare fr√•n [Major League Baseball](http://mlb.mlb.com/index.jsp), h√§mtad fr√•n [denna dataset](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) (f√∂r din bekv√§mlighet visas endast de f√∂rsta 20 v√§rdena):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Note**: F√∂r att se ett exempel p√• hur man arbetar med denna dataset, ta en titt p√• [den medf√∂ljande notebooken](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb). Det finns ocks√• ett antal utmaningar genom hela lektionen, och du kan slutf√∂ra dem genom att l√§gga till lite kod i den notebooken. Om du inte √§r s√§ker p√• hur man arbetar med data, oroa dig inte - vi kommer tillbaka till att arbeta med data med Python vid ett senare tillf√§lle. Om du inte vet hur man k√∂r kod i Jupyter Notebook, ta en titt p√• [denna artikel](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

H√§r √§r l√•ddiagrammet som visar medelv√§rde, median och kvartiler f√∂r v√•ra data:

![Vikt l√•ddiagram](../../../../1-Introduction/04-stats-and-probability/images/weight-boxplot.png)

Eftersom v√•ra data inneh√•ller information om olika spelares **roller**, kan vi ocks√• g√∂ra ett l√•ddiagram baserat p√• roller - det l√•ter oss f√• en uppfattning om hur parametrar skiljer sig mellan roller. Den h√§r g√•ngen tittar vi p√• l√§ngd:

![L√•ddiagram baserat p√• roller](../../../../1-Introduction/04-stats-and-probability/images/boxplot_byrole.png)

Detta diagram antyder att, i genomsnitt, √§r l√§ngden p√• f√∂rsta basm√§n h√∂gre √§n l√§ngden p√• andra basm√§n. Senare i denna lektion kommer vi att l√§ra oss hur vi kan testa denna hypotes mer formellt och hur vi kan visa att v√•ra data √§r statistiskt signifikanta f√∂r att bevisa detta.

> N√§r vi arbetar med data fr√•n verkligheten antar vi att alla datapunkter √§r stickprov som dras fr√•n n√•gon sannolikhetsf√∂rdelning. Detta antagande g√∂r det m√∂jligt f√∂r oss att till√§mpa maskininl√§rningstekniker och bygga fungerande prediktiva modeller.

F√∂r att se hur f√∂rdelningen av v√•ra data ser ut kan vi rita ett diagram som kallas **histogram**. X-axeln skulle inneh√•lla ett antal olika viktintervall (s√• kallade **bins**), och den vertikala axeln skulle visa antalet g√•nger v√•rt stickprov fr√•n den slumpm√§ssiga variabeln l√•g inom ett givet intervall.

![Histogram av verkliga data](../../../../1-Introduction/04-stats-and-probability/images/weight-histogram.png)

Fr√•n detta histogram kan du se att alla v√§rden √§r centrerade kring ett visst medelv√§rde, och ju l√§ngre vi g√•r fr√•n det medelv√§rdet - desto f√§rre vikter av det v√§rdet f√∂rekommer. Dvs. det √§r mycket osannolikt att vikten av en basebollspelare skulle skilja sig mycket fr√•n medelvikten. Variansen i vikterna visar i vilken utstr√§ckning vikterna sannolikt skiljer sig fr√•n medelv√§rdet.

> Om vi tar vikter fr√•n andra m√§nniskor, inte fr√•n basebolligan, √§r f√∂rdelningen sannolikt annorlunda. Men formen p√• f√∂rdelningen kommer att vara densamma, medan medelv√§rde och varians skulle f√∂r√§ndras. S√•, om vi tr√§nar v√•r modell p√• basebollspelare, √§r det sannolikt att den ger felaktiga resultat n√§r den till√§mpas p√• universitetsstudenter, eftersom den underliggande f√∂rdelningen √§r annorlunda.

## Normalf√∂rdelning

F√∂rdelningen av vikter som vi har sett ovan √§r mycket typisk, och m√•nga m√§tningar fr√•n verkligheten f√∂ljer samma typ av f√∂rdelning, men med olika medelv√§rde och varians. Denna f√∂rdelning kallas **normalf√∂rdelning**, och den spelar en mycket viktig roll inom statistik.

Att anv√§nda normalf√∂rdelning √§r ett korrekt s√§tt att generera slumpm√§ssiga vikter f√∂r potentiella basebollspelare. N√§r vi v√§l k√§nner till medelvikten `mean` och standardavvikelsen `std`, kan vi generera 1000 viktstickprov p√• f√∂ljande s√§tt:
```python
samples = np.random.normal(mean,std,1000)
``` 

Om vi ritar histogrammet f√∂r de genererade stickproven kommer vi att se en bild som liknar den som visas ovan. Och om vi √∂kar antalet stickprov och antalet bins kan vi generera en bild av en normalf√∂rdelning som √§r n√§rmare idealet:

![Normalf√∂rdelning med medelv√§rde=0 och std.avvikelse=1](../../../../1-Introduction/04-stats-and-probability/images/normal-histogram.png)

*Normalf√∂rdelning med medelv√§rde=0 och std.avvikelse=1*

## Konfidensintervall

N√§r vi pratar om vikter av basebollspelare antar vi att det finns en viss **slumpm√§ssig variabel W** som motsvarar den ideala sannolikhetsf√∂rdelningen av vikter f√∂r alla basebollspelare (s√• kallad **population**). V√•r sekvens av vikter motsvarar en delm√§ngd av alla basebollspelare som vi kallar **stickprov**. En intressant fr√•ga √§r, kan vi veta parametrarna f√∂r f√∂rdelningen av W, dvs. medelv√§rde och varians f√∂r populationen?

Det enklaste svaret skulle vara att ber√§kna medelv√§rde och varians f√∂r v√•rt stickprov. Men det kan h√§nda att v√•rt slumpm√§ssiga stickprov inte exakt representerar hela populationen. D√§rf√∂r √§r det vettigt att prata om **konfidensintervall**.

> **Konfidensintervall** √§r uppskattningen av det sanna medelv√§rdet f√∂r populationen givet v√•rt stickprov, vilket √§r korrekt med en viss sannolikhet (eller **konfidensniv√•**).

Anta att vi har ett stickprov X

1</sub>, ..., X<sub>n</sub> fr√•n v√•r distribution. Varje g√•ng vi drar ett stickprov fr√•n v√•r distribution f√•r vi ett annat medelv√§rde Œº. D√§rf√∂r kan Œº betraktas som en slumpvariabel. Ett **konfidensintervall** med konfidens p √§r ett par v√§rden (L<sub>p</sub>,R<sub>p</sub>), s√•dant att **P**(L<sub>p</sub>‚â§Œº‚â§R<sub>p</sub>) = p, dvs. sannolikheten att det uppm√§tta medelv√§rdet faller inom intervallet √§r lika med p.

Det g√•r utanf√∂r v√•r korta introduktion att diskutera i detalj hur dessa konfidensintervall ber√§knas. Mer information finns [p√• Wikipedia](https://en.wikipedia.org/wiki/Confidence_interval). Kort sagt definierar vi f√∂rdelningen av det ber√§knade stickprovsmedelv√§rdet i f√∂rh√•llande till populationens sanna medelv√§rde, vilket kallas **studentf√∂rdelning**.

> **Intressant fakta**: Studentf√∂rdelningen √§r uppkallad efter matematikern William Sealy Gosset, som publicerade sin artikel under pseudonymen "Student". Han arbetade p√• Guinness bryggeri, och enligt en av versionerna ville hans arbetsgivare inte att allm√§nheten skulle veta att de anv√§nde statistiska tester f√∂r att best√§mma kvaliteten p√• r√•varor.

Om vi vill uppskatta medelv√§rdet Œº f√∂r v√•r population med konfidens p, beh√∂ver vi ta *(1-p)/2-percentilen* av en studentf√∂rdelning A, som antingen kan tas fr√•n tabeller eller ber√§knas med hj√§lp av inbyggda funktioner i statistisk mjukvara (t.ex. Python, R, etc.). D√• ges intervallet f√∂r Œº av X¬±A*D/‚àön, d√§r X √§r det erh√•llna medelv√§rdet f√∂r stickprovet och D √§r standardavvikelsen.

> **Notera**: Vi utel√§mnar ocks√• diskussionen om ett viktigt begrepp, [frihetsgrader](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)), som √§r relevant f√∂r studentf√∂rdelningen. Du kan h√§nvisa till mer kompletta b√∂cker om statistik f√∂r att f√∂rst√• detta begrepp djupare.

Ett exempel p√• ber√§kning av konfidensintervall f√∂r vikter och l√§ngder ges i [medf√∂ljande anteckningsb√∂cker](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb).

| p | Viktmedelv√§rde |
|-----|-----------|
| 0.85 | 201.73¬±0.94 |
| 0.90 | 201.73¬±1.08 |
| 0.95 | 201.73¬±1.28 |

Observera att ju h√∂gre konfidenssannolikheten √§r, desto bredare √§r konfidensintervallet.

## Hypotespr√∂vning

I v√•r dataset med basebollspelare finns olika spelarroller, som kan sammanfattas nedan (se [medf√∂ljande anteckningsbok](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) f√∂r att se hur denna tabell kan ber√§knas):

| Roll | L√§ngd | Vikt | Antal |
|------|--------|--------|-------|
| Catcher | 72.723684 | 204.328947 | 76 |
| Designated_Hitter | 74.222222 | 220.888889 | 18 |
| First_Baseman | 74.000000 | 213.109091 | 55 |
| Outfielder | 73.010309 | 199.113402 | 194 |
| Relief_Pitcher | 74.374603 | 203.517460 | 315 |
| Second_Baseman | 71.362069 | 184.344828 | 58 |
| Shortstop | 71.903846 | 182.923077 | 52 |
| Starting_Pitcher | 74.719457 | 205.163636 | 221 |
| Third_Baseman | 73.044444 | 200.955556 | 45 |

Vi kan notera att medell√§ngden f√∂r f√∂rstabasm√§n √§r h√∂gre √§n f√∂r andrabasm√§n. D√§rf√∂r kan vi frestas att dra slutsatsen att **f√∂rstabasm√§n √§r l√§ngre √§n andrabasm√§n**.

> Detta uttalande kallas **en hypotes**, eftersom vi inte vet om det faktiskt √§r sant eller inte.

Det √§r dock inte alltid uppenbart om vi kan dra denna slutsats. Fr√•n diskussionen ovan vet vi att varje medelv√§rde har ett associerat konfidensintervall, och d√§rf√∂r kan denna skillnad bara vara ett statistiskt fel. Vi beh√∂ver ett mer formellt s√§tt att testa v√•r hypotes.

L√•t oss ber√§kna konfidensintervall separat f√∂r l√§ngderna hos f√∂rstabasm√§n och andrabasm√§n:

| Konfidens | F√∂rstabasm√§n | Andrabasm√§n |
|------------|---------------|----------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

Vi kan se att under ingen konfidens √∂verlappar intervallen. Det bevisar v√•r hypotes att f√∂rstabasm√§n √§r l√§ngre √§n andrabasm√§n.

Mer formellt √§r problemet vi l√∂ser att se om **tv√• sannolikhetsf√∂rdelningar √§r desamma**, eller √•tminstone har samma parametrar. Beroende p√• f√∂rdelningen beh√∂ver vi anv√§nda olika tester f√∂r detta. Om vi vet att v√•ra f√∂rdelningar √§r normala kan vi anv√§nda **[Student t-test](https://en.wikipedia.org/wiki/Student%27s_t-test)**.

I Student t-test ber√§knar vi den s√• kallade **t-v√§rdet**, som indikerar skillnaden mellan medelv√§rdena med h√§nsyn till variansen. Det har visats att t-v√§rdet f√∂ljer **studentf√∂rdelningen**, vilket g√∂r att vi kan f√• tr√∂skelv√§rdet f√∂r en given konfidensniv√• **p** (detta kan ber√§knas eller hittas i numeriska tabeller). Vi j√§mf√∂r sedan t-v√§rdet med detta tr√∂skelv√§rde f√∂r att godk√§nna eller f√∂rkasta hypotesen.

I Python kan vi anv√§nda paketet **SciPy**, som inkluderar funktionen `ttest_ind` (f√∂rutom m√•nga andra anv√§ndbara statistiska funktioner!). Den ber√§knar t-v√§rdet √•t oss och g√∂r ocks√• den omv√§nda uppslagningen av konfidens p-v√§rde, s√• att vi bara kan titta p√• konfidensen f√∂r att dra slutsatsen.

Till exempel ger v√•r j√§mf√∂relse mellan l√§ngderna hos f√∂rstabasm√§n och andrabasm√§n f√∂ljande resultat:
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
I v√•rt fall √§r p-v√§rdet mycket l√•gt, vilket inneb√§r att det finns starka bevis som st√∂djer att f√∂rstabasm√§n √§r l√§ngre.

Det finns ocks√• olika andra typer av hypoteser som vi kanske vill testa, till exempel:
* Att bevisa att ett givet stickprov f√∂ljer en viss f√∂rdelning. I v√•rt fall har vi antagit att l√§ngder √§r normalf√∂rdelade, men det beh√∂ver formell statistisk verifiering.
* Att bevisa att medelv√§rdet f√∂r ett stickprov motsvarar ett f√∂rdefinierat v√§rde.
* Att j√§mf√∂ra medelv√§rden f√∂r ett antal stickprov (t.ex. vad √§r skillnaden i lyckoniv√•er mellan olika √•ldersgrupper).

## Lagen om stora tal och centrala gr√§nsv√§rdessatsen

En av anledningarna till att normalf√∂rdelningen √§r s√• viktig √§r den s√• kallade **centrala gr√§nsv√§rdessatsen**. Anta att vi har ett stort stickprov av oberoende N v√§rden X<sub>1</sub>, ..., X<sub>N</sub>, tagna fr√•n vilken f√∂rdelning som helst med medelv√§rde Œº och varians œÉ<sup>2</sup>. D√•, f√∂r tillr√§ckligt stort N (med andra ord, n√§r N‚Üí‚àû), kommer medelv√§rdet Œ£<sub>i</sub>X<sub>i</sub> att vara normalf√∂rdelat, med medelv√§rde Œº och varians œÉ<sup>2</sup>/N.

> Ett annat s√§tt att tolka den centrala gr√§nsv√§rdessatsen √§r att s√§ga att oavsett f√∂rdelning, n√§r du ber√§knar medelv√§rdet av summan av slumpm√§ssiga variabelv√§rden hamnar du med en normalf√∂rdelning.

Fr√•n den centrala gr√§nsv√§rdessatsen f√∂ljer ocks√• att, n√§r N‚Üí‚àû, blir sannolikheten f√∂r att stickprovsmedelv√§rdet √§r lika med Œº lika med 1. Detta √§r k√§nt som **lagen om stora tal**.

## Kovarians och korrelation

En av sakerna Data Science g√∂r √§r att hitta relationer mellan data. Vi s√§ger att tv√• sekvenser **korrelerar** n√§r de uppvisar liknande beteende vid samma tidpunkt, dvs. de stiger/faller samtidigt, eller en sekvens stiger n√§r en annan faller och vice versa. Med andra ord verkar det finnas n√•gon relation mellan tv√• sekvenser.

> Korrelation indikerar inte n√∂dv√§ndigtvis ett orsakssamband mellan tv√• sekvenser; ibland kan b√•da variablerna bero p√• n√•gon extern orsak, eller det kan vara ren slump att de tv√• sekvenserna korrelerar. Men stark matematisk korrelation √§r en bra indikation p√• att tv√• variabler √§r p√• n√•got s√§tt kopplade.

Matematiskt √§r det huvudsakliga begreppet som visar relationen mellan tv√• slumpvariabler **kovarians**, som ber√§knas s√• h√§r: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. Vi ber√§knar avvikelsen f√∂r b√•da variablerna fr√•n deras medelv√§rden och sedan produkten av dessa avvikelser. Om b√•da variablerna avviker tillsammans kommer produkten alltid att vara ett positivt v√§rde, vilket leder till positiv kovarians. Om b√•da variablerna avviker osynkroniserat (dvs. en faller under genomsnittet n√§r en annan stiger √∂ver genomsnittet) kommer vi alltid att f√• negativa tal, vilket leder till negativ kovarians. Om avvikelserna √§r oberoende kommer de att summera till ungef√§r noll.

Det absoluta v√§rdet av kovarians s√§ger inte mycket om hur stor korrelationen √§r, eftersom det beror p√• storleken av de faktiska v√§rdena. F√∂r att normalisera det kan vi dela kovariansen med standardavvikelsen f√∂r b√•da variablerna f√∂r att f√• **korrelation**. Det bra √§r att korrelation alltid ligger inom intervallet [-1,1], d√§r 1 indikerar stark positiv korrelation mellan v√§rden, -1 - stark negativ korrelation, och 0 - ingen korrelation alls (variablerna √§r oberoende).

**Exempel**: Vi kan ber√§kna korrelationen mellan vikter och l√§ngder hos basebollspelare fr√•n den n√§mnda dataset:
```python
print(np.corrcoef(weights,heights))
```
Som resultat f√•r vi **korrelationsmatris** som denna:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> Korrelationsmatrisen C kan ber√§knas f√∂r valfritt antal inmatningssekvenser S<sub>1</sub>, ..., S<sub>n</sub>. V√§rdet av C<sub>ij</sub> √§r korrelationen mellan S<sub>i</sub> och S<sub>j</sub>, och diagonalelementen √§r alltid 1 (vilket ocks√• √§r sj√§lvkorrelationen f√∂r S<sub>i</sub>).

I v√•rt fall indikerar v√§rdet 0.53 att det finns viss korrelation mellan en persons vikt och l√§ngd. Vi kan ocks√• g√∂ra ett spridningsdiagram av ett v√§rde mot det andra f√∂r att se relationen visuellt:

![Relation mellan vikt och l√§ngd](../../../../1-Introduction/04-stats-and-probability/images/weight-height-relationship.png)

> Fler exempel p√• korrelation och kovarians finns i [medf√∂ljande anteckningsbok](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb).

## Slutsats

I detta avsnitt har vi l√§rt oss:

* grundl√§ggande statistiska egenskaper hos data, s√•som medelv√§rde, varians, typv√§rde och kvartiler
* olika f√∂rdelningar av slumpvariabler, inklusive normalf√∂rdelning
* hur man hittar korrelation mellan olika egenskaper
* hur man anv√§nder matematiska och statistiska metoder f√∂r att bevisa vissa hypoteser
* hur man ber√§knar konfidensintervall f√∂r slumpvariabler baserat p√• stickprov

√Ñven om detta definitivt inte √§r en utt√∂mmande lista √∂ver √§mnen inom sannolikhet och statistik, b√∂r det vara tillr√§ckligt f√∂r att ge dig en bra start i denna kurs.

## üöÄ Utmaning

Anv√§nd exempelprogrammet i anteckningsboken f√∂r att testa andra hypoteser:
1. F√∂rstabasm√§n √§r √§ldre √§n andrabasm√§n
2. F√∂rstabasm√§n √§r l√§ngre √§n tredjebasm√§n
3. Shortstops √§r l√§ngre √§n andrabasm√§n

## [Quiz efter f√∂rel√§sningen](https://ff-quizzes.netlify.app/en/ds/quiz/7)

## Granskning & Sj√§lvstudier

Sannolikhet och statistik √§r ett s√• brett √§mne att det f√∂rtj√§nar sin egen kurs. Om du √§r intresserad av att g√• djupare in i teorin kan du forts√§tta l√§sa n√•gra av f√∂ljande b√∂cker:

1. [Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/) fr√•n New York University har utm√§rkta f√∂rel√§sningsanteckningar [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (tillg√§ngliga online)
1. [Peter och Andrew Bruce. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[exempelkod i R](https://github.com/andrewgbruce/statistics-for-data-scientists)].
1. [James D. Miller. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[exempelkod i R](https://github.com/PacktPublishing/Statistics-for-Data-Science)]

## Uppgift

[Small Diabetes Study](assignment.md)

## Krediter

Denna lektion har f√∂rfattats med ‚ô•Ô∏è av [Dmitry Soshnikov](http://soshnikov.com)

---

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet, b√∂r det noteras att automatiserade √∂vers√§ttningar kan inneh√•lla fel eller brister. Det ursprungliga dokumentet p√• dess originalspr√•k b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r eventuella missf√∂rst√•nd eller feltolkningar som kan uppst√• vid anv√§ndning av denna √∂vers√§ttning.