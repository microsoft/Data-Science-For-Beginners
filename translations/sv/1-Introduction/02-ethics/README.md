<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1341f6da63d434f5ba31b08ea951b02c",
  "translation_date": "2025-09-05T21:53:38+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "sv"
}
-->
# Introduktion till Dataetik

|![ Sketchnote av [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Dataetik inom Data Science - _Sketchnote av [@nitya](https://twitter.com/nitya)_ |

---

Vi 칛r alla datamedborgare som lever i en datadriven v칛rld.

Marknadstrender visar att 친r 2022 kommer 1 av 3 stora organisationer att k칬pa och s칛lja sin data via online [marknadsplatser och utbyten](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Som **apputvecklare** kommer vi att uppt칛cka att det blir enklare och billigare att integrera datadrivna insikter och algoritmstyrd automatisering i dagliga anv칛ndarupplevelser. Men n칛r AI blir alltmer utbrett m친ste vi ocks친 f칬rst친 de potentiella skador som kan orsakas av [vapenisering](https://www.youtube.com/watch?v=TQHs8SA1qpk) av s친dana algoritmer i stor skala.

Trender visar ocks친 att vi kommer att skapa och konsumera 칬ver [180 zettabyte](https://www.statista.com/statistics/871513/worldwide-data-created/) data 친r 2025. Som **dataforskare** ger detta oss enast친ende tillg친ng till personlig data. Det inneb칛r att vi kan bygga beteendeprofiler av anv칛ndare och p친verka beslutsfattande p친 s칛tt som skapar en [illusion av fri vilja](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) samtidigt som vi potentiellt styr anv칛ndare mot resultat vi f칬redrar. Det v칛cker ocks친 bredare fr친gor om datasekretess och anv칛ndarskydd.

Dataetik 칛r nu _n칬dv칛ndiga skyddsr칛cken_ f칬r dataforskning och ingenj칬rskonst, som hj칛lper oss att minimera potentiella skador och oavsiktliga konsekvenser av v친ra datadrivna handlingar. [Gartners Hype Cycle f칬r AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) identifierar relevanta trender inom digital etik, ansvarsfull AI och AI-styrning som nyckeldrivkrafter f칬r st칬rre megatrender kring _demokratisering_ och _industrialisering_ av AI.

![Gartners Hype Cycle f칬r AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

I denna lektion kommer vi att utforska det fascinerande omr친det dataetik - fr친n grundl칛ggande begrepp och utmaningar till fallstudier och till칛mpade AI-koncept som styrning - som hj칛lper till att etablera en etisk kultur i team och organisationer som arbetar med data och AI.

## [Quiz f칬re f칬rel칛sningen](https://ff-quizzes.netlify.app/en/ds/quiz/2) 游꿢

## Grundl칛ggande Definitioner

L친t oss b칬rja med att f칬rst친 den grundl칛ggande terminologin.

Ordet "etik" kommer fr친n det [grekiska ordet "ethikos"](https://en.wikipedia.org/wiki/Ethics) (och dess rot "ethos") som betyder _karakt칛r eller moralisk natur_. 

**Etik** handlar om de gemensamma v칛rderingar och moraliska principer som styr v친rt beteende i samh칛llet. Etik baseras inte p친 lagar utan p친 allm칛nt accepterade normer f칬r vad som 칛r "r칛tt kontra fel". Etiska 칬verv칛ganden kan dock p친verka f칬retagsstyrningsinitiativ och regeringsregleringar som skapar fler incitament f칬r efterlevnad.

**Dataetik** 칛r en [ny gren av etiken](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1) som "studerar och utv칛rderar moraliska problem relaterade till _data, algoritmer och motsvarande praxis_". H칛r fokuserar **"data"** p친 handlingar relaterade till generering, registrering, kurering, bearbetning, spridning, delning och anv칛ndning, **"algoritmer"** fokuserar p친 AI, agenter, maskininl칛rning och robotar, och **"praxis"** fokuserar p친 칛mnen som ansvarsfull innovation, programmering, hacking och etiska koder.

**Till칛mpad etik** 칛r den [praktiska till칛mpningen av moraliska 칬verv칛ganden](https://en.wikipedia.org/wiki/Applied_ethics). Det 칛r processen att aktivt unders칬ka etiska fr친gor i samband med _verkliga handlingar, produkter och processer_, och vidta korrigerande 친tg칛rder f칬r att s칛kerst칛lla att dessa f칬rblir i linje med v친ra definierade etiska v칛rderingar.

**Etisk kultur** handlar om [_operationalisering_ av till칛mpad etik](https://hbr.org/2019/05/how-to-design-an-ethical-organization) f칬r att s칛kerst칛lla att v친ra etiska principer och praxis antas p친 ett konsekvent och skalbart s칛tt 칬ver hela organisationen. Framg친ngsrika etiska kulturer definierar organisations칬vergripande etiska principer, tillhandah친ller meningsfulla incitament f칬r efterlevnad och f칬rst칛rker etiska normer genom att uppmuntra och f칬rst칛rka 칬nskade beteenden p친 varje niv친 i organisationen.

## Etiska Begrepp

I denna sektion kommer vi att diskutera begrepp som **gemensamma v칛rderingar** (principer) och **etiska utmaningar** (problem) f칬r dataetik - och utforska **fallstudier** som hj칛lper dig att f칬rst친 dessa begrepp i verkliga sammanhang.

### 1. Etiska Principer

Varje strategi f칬r dataetik b칬rjar med att definiera _etiska principer_ - de "gemensamma v칛rderingar" som beskriver acceptabla beteenden och styr efterlevnad i v친ra data- och AI-projekt. Du kan definiera dessa p친 individuell eller teamniv친. Men de flesta stora organisationer beskriver dessa i ett _etiskt AI_-uppdrag eller ramverk som definieras p친 f칬retagsniv친 och till칛mpas konsekvent 칬ver alla team.

**Exempel:** Microsofts [Ansvarsfull AI](https://www.microsoft.com/en-us/ai/responsible-ai) uppdrag lyder: _"Vi 칛r engagerade i att fr칛mja AI som drivs av etiska principer som s칛tter m칛nniskor f칬rst"_ - och identifierar 6 etiska principer i ramverket nedan:

![Ansvarsfull AI hos Microsoft](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

L친t oss kortfattat utforska dessa principer. _Transparens_ och _ansvar_ 칛r grundl칛ggande v칛rderingar som andra principer bygger p친 - s친 l친t oss b칬rja d칛r:

* [**Ansvar**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) g칬r ut칬vare _ansvariga_ f칬r sina data- och AI-operationer och efterlevnad av dessa etiska principer.
* [**Transparens**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) s칛kerst칛ller att data och AI-친tg칛rder 칛r _f칬rst친eliga_ (tolkbara) f칬r anv칛ndare, och f칬rklarar vad och varf칬r bakom beslut.
* [**R칛ttvisa**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - fokuserar p친 att s칛kerst칛lla att AI behandlar _alla m칛nniskor_ r칛ttvist, och adresserar eventuella systemiska eller implicita socio-tekniska f칬rdomar i data och system.
* [**Tillf칬rlitlighet och S칛kerhet**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - s칛kerst칛ller att AI beter sig _konsekvent_ med definierade v칛rderingar, och minimerar potentiella skador eller oavsiktliga konsekvenser.
* [**Sekretess och S칛kerhet**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - handlar om att f칬rst친 dataursprung och tillhandah친lla _datasekretess och relaterade skydd_ f칬r anv칛ndare.
* [**Inkludering**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - handlar om att designa AI-l칬sningar med avsikt, och anpassa dem f칬r att m칬ta ett _brett spektrum av m칛nskliga behov_ och f칬rm친gor.

> 游뚿 Fundera p친 vad ditt dataetiska uppdrag skulle kunna vara. Utforska etiska AI-ramverk fr친n andra organisationer - h칛r 칛r exempel fr친n [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles), och [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Vilka gemensamma v칛rderingar har de? Hur relaterar dessa principer till AI-produkten eller industrin de verkar inom?

### 2. Etiska Utmaningar

N칛r vi har definierat etiska principer 칛r n칛sta steg att utv칛rdera v친ra data- och AI-친tg칛rder f칬r att se om de 칬verensst칛mmer med dessa gemensamma v칛rderingar. T칛nk p친 dina 친tg칛rder i tv친 kategorier: _datainsamling_ och _algoritmdesign_. 

Vid datainsamling kommer 친tg칛rder sannolikt att involvera **personlig data** eller personligt identifierbar information (PII) f칬r identifierbara levande individer. Detta inkluderar [olika typer av icke-personlig data](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) som _tillsammans_ kan identifiera en individ. Etiska utmaningar kan relatera till _datasekretess_, _data칛gande_ och relaterade 칛mnen som _informerat samtycke_ och _immateriella r칛ttigheter_ f칬r anv칛ndare.

Vid algoritmdesign kommer 친tg칛rder att involvera insamling och kurering av **datam칛ngder**, och sedan anv칛nda dem f칬r att tr칛na och implementera **datamodeller** som f칬rutsp친r resultat eller automatiserar beslut i verkliga sammanhang. Etiska utmaningar kan uppst친 fr친n _datam칛ngdsf칬rdomar_, _datakvalitetsproblem_, _or칛ttvisa_ och _missrepresentation_ i algoritmer - inklusive vissa problem som 칛r systemiska till sin natur.

I b친da fallen belyser etiska utmaningar omr친den d칛r v친ra 친tg칛rder kan komma i konflikt med v친ra gemensamma v칛rderingar. F칬r att uppt칛cka, mildra, minimera eller eliminera dessa bekymmer m친ste vi st칛lla moraliska "ja/nej"-fr친gor relaterade till v친ra 친tg칛rder och vidta korrigerande 친tg칛rder vid behov. L친t oss titta p친 n친gra etiska utmaningar och de moraliska fr친gor de v칛cker:

#### 2.1 Data칛gande

Datainsamling involverar ofta personlig data som kan identifiera datasubjekten. [Data칛gande](https://permission.io/blog/data-ownership) handlar om _kontroll_ och [_anv칛ndarr칛ttigheter_](https://permission.io/blog/data-ownership) relaterade till skapande, bearbetning och spridning av data. 

De moraliska fr친gor vi beh칬ver st칛lla 칛r: 
 * Vem 칛ger datan? (anv칛ndare eller organisation)
 * Vilka r칛ttigheter har datasubjekten? (ex: 친tkomst, radering, portabilitet)
 * Vilka r칛ttigheter har organisationer? (ex: r칛tta skadliga anv칛ndarrecensioner)

#### 2.2 Informerat Samtycke

[Informerat samtycke](https://legaldictionary.net/informed-consent/) definierar handlingen d칛r anv칛ndare godk칛nner en 친tg칛rd (som datainsamling) med en _full f칬rst친else_ av relevanta fakta inklusive syfte, potentiella risker och alternativ. 

Fr친gor att utforska h칛r 칛r:
 * Gav anv칛ndaren (datasubjektet) tillst친nd f칬r datainsamling och anv칛ndning?
 * F칬rstod anv칛ndaren syftet med att datan samlades in?
 * F칬rstod anv칛ndaren de potentiella riskerna med sitt deltagande?

#### 2.3 Immateriella R칛ttigheter

[Immateriella r칛ttigheter](https://en.wikipedia.org/wiki/Intellectual_property) avser immateriella skapelser som resultat av m칛nskligt initiativ, som kan _ha ekonomiskt v칛rde_ f칬r individer eller f칬retag. 

Fr친gor att utforska h칛r 칛r:
 * Hade den insamlade datan ekonomiskt v칛rde f칬r en anv칛ndare eller ett f칬retag?
 * Har **anv칛ndaren** immateriella r칛ttigheter h칛r?
 * Har **organisationen** immateriella r칛ttigheter h칛r?
 * Om dessa r칛ttigheter finns, hur skyddar vi dem?

#### 2.4 Datasekretess

[Datasekretess](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) eller informationssekretess avser bevarandet av anv칛ndarsekretess och skydd av anv칛ndaridentitet med avseende p친 personligt identifierbar information. 

Fr친gor att utforska h칛r 칛r:
 * 츿r anv칛ndarnas (personliga) data s칛krad mot hack och l칛ckor?
 * 츿r anv칛ndarnas data endast tillg칛nglig f칬r auktoriserade anv칛ndare och sammanhang?
 * Bevaras anv칛ndarnas anonymitet n칛r data delas eller sprids?
 * Kan en anv칛ndare avidentifieras fr친n anonymiserade datam칛ngder?

#### 2.5 R칛tten att Bli Gl칬md

[R칛tten att bli gl칬md](https://en.wikipedia.org/wiki/Right_to_be_forgotten) eller [R칛tten till Radering](https://www.gdpreu.org/right-to-be-forgotten/) ger ytterligare skydd f칬r personlig data till anv칛ndare. Specifikt ger det anv칛ndare r칛tt att beg칛ra radering eller borttagning av personlig data fr친n internets칬kningar och andra platser, _under specifika omst칛ndigheter_ - vilket ger dem en ny start online utan att tidigare handlingar h친lls emot dem.

Fr친gor att utforska h칛r 칛r:
 * Till친ter systemet datasubjekt att beg칛ra radering?
 * B칬r 친terkallande av anv칛ndarsamtycke utl칬sa automatisk radering?
 * Samlades data in utan samtycke eller p친 olagliga s칛tt?
 * 츿r vi kompatibla med regeringsregler f칬r datasekretess?

#### 2.6 Datam칛ngdsf칬rdomar

Datam칛ngds- eller [insamlingf칬rdomar](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) handlar om att v칛lja en _icke-representativ_ delm칛ngd av data f칬r algoritmutveckling, vilket skapar potentiell or칛ttvisa i resultat f칬r olika grupper. Typer av f칬rdomar inkluderar urvals- eller provtagningsf칬rdomar, frivilligf칬rdomar och instrumentf칬rdomar. 

Fr친gor att utforska h칛r 칛r:
 * Rekryterade vi en representativ upps칛ttning datasubjekt?
 * Testade vi v친r insamlade eller kuraterade datam칛ngd f칬r olika f칬rdomar?
 * Kan vi mildra eller ta bort uppt칛ckta f칬rdomar?

#### 2.7 Datakvalitet

[Datakvalitet](https://lakefs.io/data-quality-testing/) handlar om att kontrollera validiteten hos den kuraterade datam칛ngden som anv칛nds f칬r att utveckla v친ra algoritmer, och se om funktioner och poster uppfyller kraven f칬r den niv친 av noggrannhet och konsekvens som beh칬vs f칬r v친rt AI-syfte.

Fr친gor att utforska h칛r 칛r:
 * F친ngade vi giltiga _funktioner_ f칬r v친rt anv칛ndningsfall?
 * Samlades data in _konsekvent_ 칬ver olika datak칛llor?
 * 츿r datam칛ngden _komplett_ f칬r olika f칬rh친llanden eller scenarier?
 * 츿r informationen som samlades in _korrekt_ i att 친terspegla verkligheten?

#### 2.8 Algoritmisk R칛ttvisa
[Algorithmisk r칛ttvisa](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) handlar om att unders칬ka om algoritmdesignen systematiskt diskriminerar specifika undergrupper av datainsamlade individer, vilket kan leda till [potentiella skador](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) inom _resursf칬rdelning_ (d칛r resurser nekas eller undanh친lls fr친n den gruppen) och _servicekvalitet_ (d칛r AI inte 칛r lika exakt f칬r vissa undergrupper som f칬r andra).

Fr친gor att utforska h칛r 칛r:
 * Har vi utv칛rderat modellens noggrannhet f칬r olika undergrupper och f칬rh친llanden?
 * Har vi granskat systemet f칬r potentiella skador (t.ex. stereotyper)?
 * Kan vi revidera data eller tr칛na om modeller f칬r att minska identifierade skador?

Utforska resurser som [AI Fairness checklists](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) f칬r att l칛ra dig mer.

#### 2.9 Missrepresentation

[Datamissrepresentation](https://www.sciencedirect.com/topics/computer-science/misrepresentation) handlar om att fr친ga om vi kommunicerar insikter fr친n 칛rligt rapporterad data p친 ett vilseledande s칛tt f칬r att st칬dja en 칬nskad ber칛ttelse.

Fr친gor att utforska h칛r 칛r:
 * Rapporterar vi ofullst칛ndig eller felaktig data?
 * Visualiserar vi data p친 ett s칛tt som leder till vilseledande slutsatser?
 * Anv칛nder vi selektiva statistiska tekniker f칬r att manipulera resultat?
 * Finns det alternativa f칬rklaringar som kan ge en annan slutsats?

#### 2.10 Fri vilja
[Illusionen av fri vilja](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) uppst친r n칛r systemets "valarkitekturer" anv칛nder beslutsalgoritmer f칬r att p친verka m칛nniskor att ta ett f칬redraget resultat samtidigt som det verkar ge dem alternativ och kontroll. Dessa [m칬rka m칬nster](https://www.darkpatterns.org/) kan orsaka social och ekonomisk skada f칬r anv칛ndare. Eftersom anv칛ndarens beslut p친verkar beteendeprofiler kan dessa handlingar potentiellt driva framtida val som f칬rst칛rker eller f칬rl칛nger effekten av dessa skador.

Fr친gor att utforska h칛r 칛r:
 * F칬rstod anv칛ndaren konsekvenserna av att g칬ra det valet?
 * Var anv칛ndaren medveten om (alternativa) val och f칬r- och nackdelarna med varje?
 * Kan anv칛ndaren senare 칛ndra ett automatiserat eller p친verkat val?

### 3. Fallstudier

F칬r att s칛tta dessa etiska utmaningar i verkliga sammanhang kan det vara hj칛lpsamt att titta p친 fallstudier som belyser potentiella skador och konsekvenser f칬r individer och samh칛llet n칛r s친dana etiska 칬vertr칛delser f칬rbises.

H칛r 칛r n친gra exempel:

| Etisk utmaning | Fallstudie  | 
|--- |--- |
| **Informerat samtycke** | 1972 - [Tuskegee Syfilisstudien](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - Afroamerikanska m칛n som deltog i studien lovades gratis medicinsk v친rd _men blev lurade_ av forskare som inte informerade deltagarna om deras diagnos eller om tillg칛nglig behandling. M친nga deltagare dog och deras partners eller barn p친verkades; studien p친gick i 40 친r. | 
| **Datasekretess** |  2007 - [Netflix dataprize](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) gav forskare _10M anonymiserade filmrankningar fr친n 50K kunder_ f칬r att f칬rb칛ttra rekommendationsalgoritmer. Dock kunde forskare korrelera anonymiserad data med personligt identifierbar data i _externa dataset_ (t.ex. IMDb-kommentarer) - vilket effektivt "de-anonymiserade" vissa Netflix-abonnenter.|
| **Insamlingsbias**  | 2013 - Staden Boston [utvecklade Street Bump](https://www.boston.gov/transportation/street-bump), en app som l칛t medborgare rapportera potth친l, vilket gav staden b칛ttre v칛gdata f칬r att hitta och 친tg칛rda problem. Dock hade [personer i l친ginkomstgrupper mindre tillg친ng till bilar och telefoner](https://hbr.org/2013/04/the-hidden-biases-in-big-data), vilket gjorde deras v칛gproblem osynliga i appen. Utvecklarna samarbetade med akademiker f칬r att hantera _r칛ttvis tillg친ng och digitala klyftor_. |
| **Algoritmisk r칛ttvisa**  | 2018 - MIT:s [Gender Shades Study](http://gendershades.org/overview.html) utv칛rderade noggrannheten hos AI-produkter f칬r k칬nsklassificering och avsl칬jade brister i noggrannhet f칬r kvinnor och personer med m칬rkare hudton. Ett [2019 Apple Card](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) verkade erbjuda mindre kredit till kvinnor 칛n m칛n. B친da exemplen illustrerade problem med algoritmisk bias som leder till socioekonomiska skador.|
| **Datamissrepresentation** | 2020 - [Georgia Department of Public Health sl칛ppte COVID-19-diagram](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) som verkade vilseleda medborgare om trender i bekr칛ftade fall med icke-kronologisk ordning p친 x-axeln. Detta illustrerar missrepresentation genom visualiseringstrick. |
| **Illusionen av fri vilja** | 2020 - L칛roappen [ABCmouse betalade $10M f칬r att l칬sa en FTC-klagan](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/) d칛r f칬r칛ldrar fastnade i att betala f칬r abonnemang de inte kunde avbryta. Detta illustrerar m칬rka m칬nster i valarkitekturer, d칛r anv칛ndare p친verkades att g칬ra potentiellt skadliga val. |
| **Datasekretess & anv칛ndarr칛ttigheter** | 2021 - Facebook [Data Breach](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) exponerade data fr친n 530M anv칛ndare, vilket resulterade i en $5B-uppg칬relse med FTC. Dock v칛grade f칬retaget att informera anv칛ndare om dataintr친nget, vilket br칬t mot anv칛ndarr칛ttigheter kring datatransparens och 친tkomst. |

Vill du utforska fler fallstudier? Kolla in dessa resurser:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - etiska dilemman inom olika branscher. 
* [Data Science Ethics course](https://www.coursera.org/learn/data-science-ethics#syllabus) - fallstudier som utforskas.
* [Where things have gone wrong](https://deon.drivendata.org/examples/) - deon-checklista med exempel.

> 游뚿 T칛nk p친 de fallstudier du har sett - har du upplevt eller blivit p친verkad av en liknande etisk utmaning i ditt liv? Kan du komma p친 minst en annan fallstudie som illustrerar en av de etiska utmaningarna vi har diskuterat i detta avsnitt?

## Till칛mpad etik

Vi har pratat om etiska koncept, utmaningar och fallstudier i verkliga sammanhang. Men hur b칬rjar vi _till칛mpa_ etiska principer och praxis i v친ra projekt? Och hur _operationaliserar_ vi dessa praxis f칬r b칛ttre styrning? L친t oss utforska n친gra verkliga l칬sningar:

### 1. Professionella koder

Professionella koder erbjuder ett alternativ f칬r organisationer att "motivera" medlemmar att st칬dja deras etiska principer och mission. Koder 칛r _moraliska riktlinjer_ f칬r professionellt beteende och hj칛lper anst칛llda eller medlemmar att fatta beslut som 칬verensst칛mmer med organisationens principer. De 칛r endast effektiva om medlemmarna frivilligt f칬ljer dem; dock erbjuder m친nga organisationer ytterligare bel칬ningar och straff f칬r att motivera efterlevnad.

Exempel inkluderar:

 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Code of Ethics
 * [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Code of Conduct (skapad 2013)
 * [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (sedan 1993)

> 游뚿 Tillh칬r du en professionell ingenj칬rs- eller datavetenskapsorganisation? Utforska deras webbplats f칬r att se om de definierar en professionell etisk kod. Vad s칛ger detta om deras etiska principer? Hur motiverar de medlemmar att f칬lja koden?

### 2. Etiska checklistor

Medan professionella koder definierar n칬dv칛ndigt _etiskt beteende_ fr친n praktiker, har de [k칛nda begr칛nsningar](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) i efterlevnad, s칛rskilt i storskaliga projekt. Ist칛llet f칬respr친kar m친nga datavetenskapsexperter [checklistor](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) som kan **koppla principer till praxis** p친 mer deterministiska och handlingsbara s칛tt.

Checklistor omvandlar fr친gor till "ja/nej"-uppgifter som kan operationaliseras, vilket g칬r att de kan sp친ras som en del av standardarbetsfl칬den f칬r produktlansering.

Exempel inkluderar:
 * [Deon](https://deon.drivendata.org/) - en allm칛n datavetenskaplig etisk checklista skapad fr친n [branschrekommendationer](https://deon.drivendata.org/#checklist-citations) med ett kommandoradsverktyg f칬r enkel integration.
 * [Privacy Audit Checklist](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - ger allm칛n v칛gledning f칬r informationshantering ur juridiska och sociala perspektiv.
 * [AI Fairness Checklist](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - skapad av AI-praktiker f칬r att st칬dja adoption och integration av r칛ttvisekontroller i AI-utvecklingscykler.
 * [22 fr친gor f칬r etik inom data och AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - en mer 칬ppen ram, strukturerad f칬r initial utforskning av etiska fr친gor i design, implementering och organisatoriska sammanhang.

### 3. Etiska regleringar

Etik handlar om att definiera gemensamma v칛rderingar och g칬ra det r칛tta _frivilligt_. **Efterlevnad** handlar om _att f칬lja lagen_ d칛r den 칛r definierad. **Styrning** omfattar brett alla s칛tt som organisationer arbetar f칬r att uppr칛tth친lla etiska principer och f칬lja etablerade lagar.

Idag tar styrning tv친 former inom organisationer. F칬r det f칬rsta handlar det om att definiera **etiska AI**-principer och etablera praxis f칬r att operationalisera adoption 칬ver alla AI-relaterade projekt i organisationen. F칬r det andra handlar det om att f칬lja alla statligt f칬reskrivna **dataskyddsregleringar** f칬r regioner d칛r organisationen verkar.

Exempel p친 dataskydds- och sekretessregleringar:

 * `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - reglerar _federala myndigheters_ insamling, anv칛ndning och spridning av personlig information.
 * `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - skyddar personlig h칛lsodata.
 * `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - skyddar datasekretess f칬r barn under 13 친r.
 * `2018`, [General Data Protection Regulation (GDPR)](https://gdpr-info.eu/) - ger anv칛ndarr칛ttigheter, dataskydd och sekretess.
 * `2018`, [California Consumer Privacy Act (CCPA)](https://www.oag.ca.gov/privacy/ccpa) ger konsumenter fler _r칛ttigheter_ 칬ver deras (personliga) data.
 * `2021`, Kinas [Personal Information Protection Law](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) antogs nyligen och skapar en av de starkaste regleringarna f칬r datasekretess online i v칛rlden.

> 游뚿 Europeiska unionens GDPR (General Data Protection Regulation) 칛r fortfarande en av de mest inflytelserika regleringarna f칬r datasekretess idag. Visste du att den ocks친 definierar [8 anv칛ndarr칛ttigheter](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) f칬r att skydda medborgares digitala sekretess och personliga data? L칛r dig vad dessa 칛r och varf칬r de 칛r viktiga.

### 4. Etisk kultur

Observera att det fortfarande finns en immateriell klyfta mellan _efterlevnad_ (att g칬ra tillr칛ckligt f칬r att uppfylla "lagens bokstav") och att adressera [systemiska problem](https://www.coursera.org/learn/data-science-ethics/home/week/4) (som stelhet, informationsasymmetri och or칛ttvis f칬rdelning) som kan p친skynda AI:s vapenisering.

Det senare kr칛ver [samarbetsmetoder f칬r att definiera etiska kulturer](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f) som bygger k칛nslom칛ssiga kopplingar och konsekventa gemensamma v칛rderingar _칬ver organisationer_ inom branschen. Detta kr칛ver mer [formaliserade datavetenskapliga etiska kulturer](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) i organisationer - vilket g칬r det m칬jligt f칬r _vem som helst_ att [dra Andon-sn칬ret](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (f칬r att lyfta etiska problem tidigt i processen) och g칬ra _etiska bed칬mningar_ (t.ex. vid rekrytering) till ett k칛rnkriterium f칬r teambildning i AI-projekt.

---
## [Efterf칬rel칛sningsquiz](https://ff-quizzes.netlify.app/en/ds/quiz/3) 游꿢
## Granskning & Sj칛lvstudier 

Kurser och b칬cker hj칛lper till att f칬rst친 grundl칛ggande etiska koncept och utmaningar, medan fallstudier och verktyg hj칛lper till med till칛mpad etik i verkliga sammanhang. H칛r 칛r n친gra resurser att b칬rja med.

* [Machine Learning For Beginners](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - lektion om r칛ttvisa, fr친n Microsoft.
* [Principer f칬r ansvarsfull AI](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - gratis utbildningsv칛g fr친n Microsoft Learn.
* [Etik och Data Science](https://resources.oreilly.com/examples/0636920203964) - O'Reilly EBook (M. Loukides, H. Mason m.fl.)
* [Data Science Etik](https://www.coursera.org/learn/data-science-ethics#syllabus) - onlinekurs fr친n University of Michigan.
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - fallstudier fr친n University of Texas.

# Uppgift 

[Skriv en fallstudie om dataetik](assignment.md)

---

**Ansvarsfriskrivning**:  
Detta dokument har 칬versatts med hj칛lp av AI-칬vers칛ttningstj칛nsten [Co-op Translator](https://github.com/Azure/co-op-translator). 츿ven om vi str칛var efter noggrannhet, b칬r du vara medveten om att automatiserade 칬vers칛ttningar kan inneh친lla fel eller felaktigheter. Det ursprungliga dokumentet p친 dess originalspr친k b칬r betraktas som den auktoritativa k칛llan. F칬r kritisk information rekommenderas professionell m칛nsklig 칬vers칛ttning. Vi ansvarar inte f칬r eventuella missf칬rst친nd eller feltolkningar som uppst친r vid anv칛ndning av denna 칬vers칛ttning.