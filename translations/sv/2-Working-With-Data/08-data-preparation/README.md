<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3ade580a06b5f04d57cc83a768a8fb77",
  "translation_date": "2025-08-26T20:55:54+00:00",
  "source_file": "2-Working-With-Data/08-data-preparation/README.md",
  "language_code": "sv"
}
-->
# Arbeta med data: Datapreparation

|![ Sketchnote av [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/08-DataPreparation.png)|
|:---:|
|Datapreparation - _Sketchnote av [@nitya](https://twitter.com/nitya)_ |

## [Quiz f칬re f칬rel칛sning](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/14)

Beroende p친 dess k칛lla kan r친data inneh친lla vissa inkonsekvenser som skapar utmaningar vid analys och modellering. Med andra ord kan denna data kategoriseras som "smutsig" och beh칬ver reng칬ras. Denna lektion fokuserar p친 tekniker f칬r att reng칬ra och transformera data f칬r att hantera utmaningar som saknad, felaktig eller ofullst칛ndig data. 츿mnen som tas upp i denna lektion anv칛nder Python och Pandas-biblioteket och kommer att [demonstreras i notebooken](notebook.ipynb) inom denna katalog.

## Vikten av att reng칬ra data

- **Enkel anv칛ndning och 친teranv칛ndning**: N칛r data 칛r korrekt organiserad och normaliserad blir det enklare att s칬ka, anv칛nda och dela med andra.

- **Konsistens**: Dataanalys kr칛ver ofta arbete med flera dataset, d칛r dataset fr친n olika k칛llor beh칬ver kombineras. Att s칛kerst칛lla att varje dataset har gemensam standardisering g칬r att data fortfarande 칛r anv칛ndbar n칛r de kombineras till ett dataset.

- **Modellens noggrannhet**: Rengjord data f칬rb칛ttrar noggrannheten hos modeller som 칛r beroende av den.

## Vanliga m친l och strategier f칬r datareng칬ring

- **Utforska ett dataset**: Datautforskning, som tas upp i en [senare lektion](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/4-Data-Science-Lifecycle/15-analyzing), kan hj칛lpa dig att identifiera data som beh칬ver reng칬ras. Att visuellt observera v칛rden inom ett dataset kan ge en f칬rv칛ntan om hur resten av det ser ut eller ge en id칠 om problem som kan l칬sas. Utforskning kan involvera grundl칛ggande fr친gor, visualiseringar och sampling.

- **Formatering**: Beroende p친 k칛llan kan data ha inkonsekvenser i hur den presenteras. Detta kan orsaka problem vid s칬kning och representation av v칛rden, d칛r de syns inom datasetet men inte 칛r korrekt representerade i visualiseringar eller fr친geresultat. Vanliga formateringsproblem inkluderar att l칬sa problem med blanksteg, datum och datatyper. Att l칬sa formateringsproblem 칛r vanligtvis upp till de som anv칛nder datan. Till exempel kan standarder f칬r hur datum och siffror presenteras skilja sig mellan l칛nder.

- **Dupliceringar**: Data som f칬rekommer mer 칛n en g친ng kan ge felaktiga resultat och b칬r vanligtvis tas bort. Detta 칛r vanligt n칛r man kombinerar tv친 eller fler dataset. Det finns dock tillf칛llen d친 duplicering i kombinerade dataset inneh친ller delar som kan ge ytterligare information och kan beh칬va bevaras.

- **Saknad data**: Saknad data kan orsaka felaktigheter samt svaga eller partiska resultat. Ibland kan detta l칬sas genom att "ladda om" datan, fylla i de saknade v칛rdena med ber칛kningar och kod som Python, eller helt enkelt ta bort v칛rdet och motsvarande data. Det finns m친nga anledningar till varf칬r data kan saknas, och de 친tg칛rder som vidtas f칬r att l칬sa dessa saknade v칛rden kan bero p친 hur och varf칬r de f칬rsvann.

## Utforska DataFrame-information
> **L칛randem친l:** I slutet av denna del ska du k칛nna dig bekv칛m med att hitta generell information om data som lagras i pandas DataFrames.

N칛r du har laddat din data i pandas kommer den troligen att vara i en DataFrame (se den tidigare [lektionen](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/2-Working-With-Data/07-python#dataframe) f칬r en detaljerad 칬versikt). Men om datasetet i din DataFrame har 60 000 rader och 400 kolumner, hur b칬rjar du ens f친 en k칛nsla f칬r vad du arbetar med? Lyckligtvis erbjuder [pandas](https://pandas.pydata.org/) n친gra praktiska verktyg f칬r att snabbt titta p친 칬vergripande information om en DataFrame, samt de f칬rsta och sista raderna.

F칬r att utforska denna funktionalitet kommer vi att importera Python-biblioteket scikit-learn och anv칛nda ett ikoniskt dataset: **Iris-datasetet**.

```python
import pandas as pd
from sklearn.datasets import load_iris

iris = load_iris()
iris_df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])
```
|                                        |sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|
|----------------------------------------|-----------------|----------------|-----------------|----------------|
|0                                       |5.1              |3.5             |1.4              |0.2             |
|1                                       |4.9              |3.0             |1.4              |0.2             |
|2                                       |4.7              |3.2             |1.3              |0.2             |
|3                                       |4.6              |3.1             |1.5              |0.2             |
|4                                       |5.0              |3.6             |1.4              |0.2             |

- **DataFrame.info**: F칬r att b칬rja anv칛nds metoden `info()` f칬r att skriva ut en sammanfattning av inneh친llet i en `DataFrame`. L친t oss titta p친 detta dataset f칬r att se vad vi har:
```python
iris_df.info()
```
```
RangeIndex: 150 entries, 0 to 149
Data columns (total 4 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   sepal length (cm)  150 non-null    float64
 1   sepal width (cm)   150 non-null    float64
 2   petal length (cm)  150 non-null    float64
 3   petal width (cm)   150 non-null    float64
dtypes: float64(4)
memory usage: 4.8 KB
```
Fr친n detta vet vi att *Iris*-datasetet har 150 poster i fyra kolumner utan n친gra null-poster. All data lagras som 64-bitars flyttal.

- **DataFrame.head()**: F칬r att kontrollera det faktiska inneh친llet i `DataFrame` anv칛nder vi metoden `head()`. L친t oss se hur de f칬rsta raderna i v친r `iris_df` ser ut:
```python
iris_df.head()
```
```
   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
0                5.1               3.5                1.4               0.2
1                4.9               3.0                1.4               0.2
2                4.7               3.2                1.3               0.2
3                4.6               3.1                1.5               0.2
4                5.0               3.6                1.4               0.2
```
- **DataFrame.tail()**: F칬r att kontrollera de sista raderna i `DataFrame` anv칛nder vi metoden `tail()`:
```python
iris_df.tail()
```
```
     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
145                6.7               3.0                5.2               2.3
146                6.3               2.5                5.0               1.9
147                6.5               3.0                5.2               2.0
148                6.2               3.4                5.4               2.3
149                5.9               3.0                5.1               1.8
```
> **Slutsats:** Genom att bara titta p친 metadata om informationen i en DataFrame eller de f칬rsta och sista v칛rdena kan du f친 en omedelbar uppfattning om storlek, form och inneh친ll i datan du arbetar med.

## Hantera saknad data
> **L칛randem친l:** I slutet av denna del ska du veta hur du ers칛tter eller tar bort null-v칛rden fr친n DataFrames.

Oftast har de dataset du vill anv칛nda (eller m친ste anv칛nda) saknade v칛rden. Hur saknad data hanteras inneb칛r subtila kompromisser som kan p친verka din slutliga analys och verkliga resultat.

Pandas hanterar saknade v칛rden p친 tv친 s칛tt. Det f칬rsta har du sett tidigare i tidigare avsnitt: `NaN`, eller Not a Number. Detta 칛r faktiskt ett specialv칛rde som 칛r en del av IEEE-flyttalspecifikationen och anv칛nds endast f칬r att indikera saknade flyttalsv칛rden.

F칬r saknade v칛rden ut칬ver flyttal anv칛nder pandas Python-objektet `None`. 츿ven om det kan verka f칬rvirrande att du kommer att st칬ta p친 tv친 olika typer av v칛rden som i princip s칛ger samma sak, finns det goda programmatiska sk칛l f칬r detta designval och i praktiken m칬jligg칬r detta att pandas levererar en bra kompromiss f칬r de allra flesta fall. Trots detta har b친de `None` och `NaN` begr칛nsningar som du m친ste vara medveten om n칛r det g칛ller hur de kan anv칛ndas.

L칛s mer om `NaN` och `None` fr친n [notebooken](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/4-Data-Science-Lifecycle/15-analyzing/notebook.ipynb)!

- **Uppt칛cka null-v칛rden**: I `pandas` 칛r metoderna `isnull()` och `notnull()` dina prim칛ra metoder f칬r att uppt칛cka null-data. B친da returnerar Boolean-masker 칬ver din data. Vi kommer att anv칛nda `numpy` f칬r `NaN`-v칛rden:
```python
import numpy as np

example1 = pd.Series([0, np.nan, '', None])
example1.isnull()
```
```
0    False
1     True
2    False
3     True
dtype: bool
```
Titta noga p친 utdata. 칐verraskar n친got dig? 츿ven om `0` 칛r en aritmetisk null 칛r det 칛nd친 ett heltal och pandas behandlar det som s친dant. `''` 칛r lite mer subtilt. 츿ven om vi anv칛nde det i avsnitt 1 f칬r att representera ett tomt str칛ngv칛rde, 칛r det 칛nd친 ett str칛ngobjekt och inte en representation av null enligt pandas.

Nu ska vi v칛nda p친 detta och anv칛nda dessa metoder p친 ett s칛tt som liknar hur du kommer att anv칛nda dem i praktiken. Du kan anv칛nda Boolean-masker direkt som ett ``Series`` eller ``DataFrame``-index, vilket kan vara anv칛ndbart n칛r du f칬rs칬ker arbeta med isolerade saknade (eller befintliga) v칛rden.

> **Slutsats**: B친de metoderna `isnull()` och `notnull()` ger liknande resultat n칛r du anv칛nder dem i `DataFrame`s: de visar resultaten och indexet f칬r dessa resultat, vilket kommer att hj칛lpa dig enormt n칛r du arbetar med din data.

- **Ta bort null-v칛rden**: Ut칬ver att identifiera saknade v칛rden erbjuder pandas ett bekv칛mt s칛tt att ta bort null-v칛rden fr친n `Series` och `DataFrame`s. (S칛rskilt f칬r stora dataset 칛r det ofta mer tillr친dligt att helt enkelt ta bort saknade [NA] v칛rden fr친n din analys 칛n att hantera dem p친 andra s칛tt.) F칬r att se detta i praktiken, l친t oss 친terg친 till `example1`:
```python
example1 = example1.dropna()
example1
```
```
0    0
2     
dtype: object
```
Observera att detta b칬r se ut som din utdata fr친n `example3[example3.notnull()]`. Skillnaden h칛r 칛r att ist칛llet f칬r att bara indexera p친 de maskerade v칛rdena har `dropna` tagit bort dessa saknade v칛rden fr친n `Series` `example1`.

Eftersom `DataFrame`s har tv친 dimensioner erbjuder de fler alternativ f칬r att ta bort data.

```python
example2 = pd.DataFrame([[1,      np.nan, 7], 
                         [2,      5,      8], 
                         [np.nan, 6,      9]])
example2
```
|      | 0 | 1 | 2 |
|------|---|---|---|
|0     |1.0|NaN|7  |
|1     |2.0|5.0|8  |
|2     |NaN|6.0|9  |

(Lade du m칛rke till att pandas uppgraderade tv친 av kolumnerna till flyttal f칬r att rymma `NaN`s?)

Du kan inte ta bort ett enskilt v칛rde fr친n en `DataFrame`, s친 du m친ste ta bort hela rader eller kolumner. Beroende p친 vad du g칬r kanske du vill g칬ra det ena eller det andra, och d칛rf칬r ger pandas dig alternativ f칬r b친da. Eftersom kolumner i data science generellt representerar variabler och rader representerar observationer 칛r det mer sannolikt att du tar bort rader av data; standardinst칛llningen f칬r `dropna()` 칛r att ta bort alla rader som inneh친ller n친gra null-v칛rden:

```python
example2.dropna()
```
```
	0	1	2
1	2.0	5.0	8
```
Om det beh칬vs kan du ta bort NA-v칛rden fr친n kolumner. Anv칛nd `axis=1` f칬r att g칬ra det:
```python
example2.dropna(axis='columns')
```
```
	2
0	7
1	8
2	9
```
Observera att detta kan ta bort mycket data som du kanske vill beh친lla, s칛rskilt i mindre dataset. Vad h칛nder om du bara vill ta bort rader eller kolumner som inneh친ller flera eller till och med bara alla null-v칛rden? Du specificerar dessa inst칛llningar i `dropna` med parametrarna `how` och `thresh`.

Som standard 칛r `how='any'` (om du vill kontrollera sj칛lv eller se vilka andra parametrar metoden har, k칬r `example4.dropna?` i en kodcell). Du kan alternativt specificera `how='all'` f칬r att endast ta bort rader eller kolumner som inneh친ller alla null-v칛rden. L친t oss ut칬ka v친rt exempel `DataFrame` f칬r att se detta i praktiken.

```python
example2[3] = np.nan
example2
```
|      |0  |1  |2  |3  |
|------|---|---|---|---|
|0     |1.0|NaN|7  |NaN|
|1     |2.0|5.0|8  |NaN|
|2     |NaN|6.0|9  |NaN|

Parametern `thresh` ger dig mer detaljerad kontroll: du anger antalet *icke-null* v칛rden som en rad eller kolumn beh칬ver ha f칬r att beh친llas:
```python
example2.dropna(axis='rows', thresh=3)
```
```
	0	1	2	3
1	2.0	5.0	8	NaN
```
H칛r har den f칬rsta och sista raden tagits bort eftersom de endast inneh친ller tv친 icke-null-v칛rden.

- **Fylla null-v칛rden**: Beroende p친 ditt dataset kan det ibland vara mer logiskt att fylla null-v칛rden med giltiga v칛rden ist칛llet f칬r att ta bort dem. Du kan anv칛nda `isnull` f칬r att g칬ra detta direkt, men det kan vara arbetskr칛vande, s칛rskilt om du har m친nga v칛rden att fylla. Eftersom detta 칛r en s친 vanlig uppgift inom data science erbjuder pandas `fillna`, som returnerar en kopia av `Series` eller `DataFrame` med de saknade v칛rdena ersatta med ett av ditt val. L친t oss skapa ett annat exempel `Series` f칬r att se hur detta fungerar i praktiken.
```python
example3 = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))
example3
```
```
a    1.0
b    NaN
c    2.0
d    NaN
e    3.0
dtype: float64
```
Du kan fylla alla null-poster med ett enda v칛rde, som `0`:
```python
example3.fillna(0)
```
```
a    1.0
b    0.0
c    2.0
d    0.0
e    3.0
dtype: float64
```
Du kan **fram친t-fylla** null-v칛rden, vilket inneb칛r att anv칛nda det senaste giltiga v칛rdet f칬r att fylla ett null:
```python
example3.fillna(method='ffill')
```
```
a    1.0
b    1.0
c    2.0
d    2.0
e    3.0
dtype: float64
```
Du kan ocks친 **bak친t-fylla** f칬r att sprida n칛sta giltiga v칛rde bak친t f칬r att fylla ett null:
```python
example3.fillna(method='bfill')
```
```
a    1.0
b    2.0
c    2.0
d    3.0
e    3.0
dtype: float64
```
Som du kanske gissar fungerar detta p친 samma s칛tt med `DataFrame`s, men du kan ocks친 specificera en `axis` l칛ngs vilken du fyller null-v칛rden. Genom att anv칛nda det tidigare anv칛nda `example2` igen:
```python
example2.fillna(method='ffill', axis=1)
```
```
	0	1	2	3
0	1.0	1.0	7.0	7.0
1	2.0	5.0	8.0	8.0
2	NaN	6.0	9.0	9.0
```
Observera att n칛r ett tidigare v칛rde inte 칛r tillg칛ngligt f칬r fram친t-fyllning, f칬rblir null-v칛rdet kvar.
> **Viktig insikt:** Det finns flera s칛tt att hantera saknade v칛rden i dina dataset. Den specifika strategi du anv칛nder (ta bort dem, ers칛tta dem, eller hur du ers칛tter dem) b칬r styras av detaljerna i datan. Du kommer att utveckla en b칛ttre k칛nsla f칬r hur du hanterar saknade v칛rden ju mer du arbetar med och interagerar med dataset.

## Ta bort duplicerad data

> **L칛randem친l:** Efter denna del ska du k칛nna dig bekv칛m med att identifiera och ta bort duplicerade v칛rden fr친n DataFrames.

F칬rutom saknade data kommer du ofta att st칬ta p친 duplicerad data i verkliga dataset. Lyckligtvis erbjuder `pandas` ett enkelt s칛tt att uppt칛cka och ta bort duplicerade poster.

- **Identifiera duplicat: `duplicated`**: Du kan enkelt hitta duplicerade v칛rden med metoden `duplicated` i pandas, som returnerar en Boolean-mask som indikerar om en post i en `DataFrame` 칛r en kopia av en tidigare. L친t oss skapa ett annat exempel p친 en `DataFrame` f칬r att se detta i praktiken.
```python
example4 = pd.DataFrame({'letters': ['A','B'] * 2 + ['B'],
                         'numbers': [1, 2, 1, 3, 3]})
example4
```
|      |bokst칛ver|nummer|
|------|---------|------|
|0     |A        |1     |
|1     |B        |2     |
|2     |A        |1     |
|3     |B        |3     |
|4     |B        |3     |

```python
example4.duplicated()
```
```
0    False
1    False
2     True
3    False
4     True
dtype: bool
```
- **Ta bort duplicat: `drop_duplicates`:** returnerar helt enkelt en kopia av datan d칛r alla v칛rden som 칛r `duplicated` 칛r `False`:
```python
example4.drop_duplicates()
```
```
	letters	numbers
0	A	1
1	B	2
3	B	3
```
B친de `duplicated` och `drop_duplicates` unders칬ker som standard alla kolumner, men du kan specificera att de endast ska granska en delm칛ngd av kolumnerna i din `DataFrame`:
```python
example4.drop_duplicates(['letters'])
```
```
letters	numbers
0	A	1
1	B	2
```

> **Viktig insikt:** Att ta bort duplicerad data 칛r en viktig del av n칛stan alla dataanalysprojekt. Duplicerad data kan f칬r칛ndra resultaten av dina analyser och ge dig felaktiga resultat!


## 游 Utmaning

Allt material som diskuterats finns tillg칛ngligt som en [Jupyter Notebook](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/2-Working-With-Data/08-data-preparation/notebook.ipynb). Dessutom finns det 칬vningar efter varje avsnitt, prova dem!

## [Quiz efter f칬rel칛sningen](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/15)



## Granskning & Sj칛lvstudier

Det finns m친nga s칛tt att uppt칛cka och n칛rma sig f칬rberedelse av data f칬r analys och modellering, och att reng칬ra data 칛r ett viktigt steg som kr칛ver praktisk erfarenhet. Prova dessa utmaningar fr친n Kaggle f칬r att utforska tekniker som inte t칛cktes i denna lektion.

- [Data Cleaning Challenge: Parsing Dates](https://www.kaggle.com/rtatman/data-cleaning-challenge-parsing-dates/)

- [Data Cleaning Challenge: Scale and Normalize Data](https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data)


## Uppgift

[Utv칛rdera data fr친n ett formul칛r](assignment.md)

---

**Ansvarsfriskrivning**:  
Detta dokument har 칬versatts med hj칛lp av AI-칬vers칛ttningstj칛nsten [Co-op Translator](https://github.com/Azure/co-op-translator). 츿ven om vi str칛var efter noggrannhet, b칬r det noteras att automatiserade 칬vers칛ttningar kan inneh친lla fel eller felaktigheter. Det ursprungliga dokumentet p친 dess originalspr친k b칬r betraktas som den auktoritativa k칛llan. F칬r kritisk information rekommenderas professionell m칛nsklig 칬vers칛ttning. Vi ansvarar inte f칬r eventuella missf칬rst친nd eller feltolkningar som uppst친r vid anv칛ndning av denna 칬vers칛ttning.