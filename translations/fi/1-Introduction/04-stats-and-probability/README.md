<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8bbb3fa0d4ad61384a3b4b5f7560226f",
  "translation_date": "2025-09-04T19:45:06+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "fi"
}
-->
# Tilastotieteen ja todenn√§k√∂isyyden lyhyt johdanto

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| Tilastotiede ja todenn√§k√∂isyys - _Sketchnote by [@nitya](https://twitter.com/nitya)_ |

Tilastotiede ja todenn√§k√∂isyysteoria ovat kaksi l√§heisesti toisiinsa liittyv√§√§ matematiikan osa-aluetta, jotka ovat eritt√§in t√§rkeit√§ datatieteess√§. On mahdollista k√§sitell√§ dataa ilman syv√§llist√§ matematiikan tuntemusta, mutta on silti hy√∂dyllist√§ ymm√§rt√§√§ ainakin perusk√§sitteet. T√§ss√§ esittelemme lyhyen johdannon, joka auttaa sinua p√§√§sem√§√§n alkuun.

[![Johdantovideo](../../../../translated_images/video-prob-and-stats.e4282e5efa2f2543400843ed98b1057065c9600cebfc8a728e8931b5702b2ae4.fi.png)](https://youtu.be/Z5Zy85g4Yjw)

## [Esiluentovisa](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/6)

## Todenn√§k√∂isyys ja satunnaismuuttujat

**Todenn√§k√∂isyys** on luku v√§lill√§ 0 ja 1, joka ilmaisee, kuinka todenn√§k√∂inen jokin **tapahtuma** on. Se m√§√§ritell√§√§n positiivisten lopputulosten (jotka johtavat tapahtumaan) lukum√§√§r√§n√§ jaettuna kaikkien mahdollisten lopputulosten lukum√§√§r√§ll√§, olettaen ett√§ kaikki lopputulokset ovat yht√§ todenn√§k√∂isi√§. Esimerkiksi, kun heit√§mme noppaa, todenn√§k√∂isyys saada parillinen luku on 3/6 = 0,5.

Kun puhumme tapahtumista, k√§yt√§mme **satunnaismuuttujia**. Esimerkiksi satunnaismuuttuja, joka edustaa noppaa heitett√§ess√§ saatua lukua, voi saada arvoja v√§lill√§ 1‚Äì6. Lukuja 1‚Äì6 kutsutaan **otosavaruudeksi**. Voimme puhua todenn√§k√∂isyydest√§, ett√§ satunnaismuuttuja saa tietyn arvon, esimerkiksi P(X=3)=1/6.

Edellisess√§ esimerkiss√§ oleva satunnaismuuttuja on **diskreetti**, koska sen otosavaruus on laskettavissa, eli siin√§ on erillisi√§ arvoja, jotka voidaan luetella. On my√∂s tapauksia, joissa otosavaruus on reaaliarvojen v√§li tai koko reaaliarvojen joukko. T√§llaisia muuttujia kutsutaan **jatkuviksi**. Hyv√§ esimerkki on bussin saapumisaika.

## Todenn√§k√∂isyysjakauma

Diskreettien satunnaismuuttujien tapauksessa on helppo kuvata kunkin tapahtuman todenn√§k√∂isyys funktiolla P(X). Jokaiselle otosavaruuden *S* arvolle *s* se antaa luvun v√§lill√§ 0 ja 1 siten, ett√§ kaikkien tapahtumien P(X=s) arvojen summa on 1.

Tunnetuin diskreetti jakauma on **tasajakauma**, jossa otosavaruudessa on N elementti√§, ja jokaisella niist√§ on yht√§ suuri todenn√§k√∂isyys 1/N.

Jatkuvan muuttujan todenn√§k√∂isyysjakauman kuvaaminen on vaikeampaa, kun arvot ovat per√§isin jostakin v√§list√§ [a,b] tai koko reaaliarvojen joukosta ‚Ñù. Mieti esimerkiksi bussin saapumisaikaa. Itse asiassa, jokaiselle tarkalle saapumisajalle *t* todenn√§k√∂isyys, ett√§ bussi saapuu juuri silloin, on 0!

> Nyt tied√§t, ett√§ tapahtumat, joiden todenn√§k√∂isyys on 0, tapahtuvat ‚Äì ja viel√§p√§ usein! Ainakin aina, kun bussi saapuu!

Voimme puhua vain todenn√§k√∂isyydest√§, ett√§ muuttuja osuu tietylle arvojen v√§lille, esim. P(t<sub>1</sub>‚â§X<t<sub>2</sub>). T√§ss√§ tapauksessa todenn√§k√∂isyysjakauma kuvataan **tiheysfunktiolla** p(x), siten ett√§

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../translated_images/probability-density.a8aad29f17a14afb519b407c7b6edeb9f3f9aa5f69c9e6d9445f604e5f8a2bf7.fi.png)
  
Jatkuvan tasajakauman analogia on **jatkuva tasajakauma**, joka m√§√§ritell√§√§n rajatulle v√§lille. Todenn√§k√∂isyys, ett√§ arvo X osuu v√§lin pituuteen l, on verrannollinen l:√§√§n ja kasvaa arvoon 1.

Toinen t√§rke√§ jakauma on **normaalijakauma**, josta puhumme tarkemmin my√∂hemmin.

## Keskiarvo, varianssi ja keskihajonta

Oletetaan, ett√§ otamme n n√§ytett√§ satunnaismuuttujasta X: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. Voimme m√§√§ritell√§ sarjan **keskiarvon** (tai **aritmeettisen keskiarvon**) perinteisell√§ tavalla kaavalla (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n. Kun kasvatamme otoksen kokoa (eli otamme rajan n‚Üí‚àû), saamme jakauman keskiarvon (jota kutsutaan my√∂s **odotusarvoksi**). Merkitsemme odotusarvoa **E**(x).

> On osoitettavissa, ett√§ mille tahansa diskreetille jakaumalle, jonka arvot ovat {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} ja vastaavat todenn√§k√∂isyydet p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, odotusarvo on E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>.

Arvojen hajonnan selvitt√§miseksi voimme laskea varianssin œÉ<sup>2</sup> = ‚àë(x<sub>i</sub> - Œº)<sup>2</sup>/n, miss√§ Œº on sarjan keskiarvo. Arvoa œÉ kutsutaan **keskihajonnaksi**, ja œÉ<sup>2</sup> on **varianssi**.

## Moodi, mediaani ja kvartiilit

Joskus keskiarvo ei kuvaa riitt√§v√§sti "tyypillist√§" arvoa datalle. Esimerkiksi, jos datassa on muutamia √§√§rimm√§isi√§ arvoja, ne voivat vaikuttaa keskiarvoon. Toinen hyv√§ mittari on **mediaani**, arvo, jonka alapuolella on puolet datan arvoista ja yl√§puolella toinen puoli.

Datan jakauman ymm√§rt√§miseksi on hy√∂dyllist√§ puhua **kvartiileista**:

* Ensimm√§inen kvartiili, eli Q1, on arvo, jonka alapuolella on 25 % datasta
* Kolmas kvartiili, eli Q3, on arvo, jonka alapuolella on 75 % datasta

Graafisesti voimme esitt√§√§ mediaanin ja kvartiilien suhteen diagrammissa, jota kutsutaan **laatikko- ja viiksikaavioksi**:

<img src="images/boxplot_explanation.png" width="50%"/>

T√§ss√§ laskemme my√∂s **kvartiiliv√§lin** IQR=Q3-Q1 ja niin sanotut **poikkeamat** ‚Äì arvot, jotka ovat alueen [Q1-1.5*IQR,Q3+1.5*IQR] ulkopuolella.

Pienelle diskreetille jakaumalle, jossa on vain muutamia mahdollisia arvoja, hyv√§ "tyypillinen" arvo on yleisin arvo, jota kutsutaan **moodiksi**. T√§t√§ k√§ytet√§√§n usein kategorisessa datassa, kuten v√§reiss√§. Mieti tilannetta, jossa on kaksi ryhm√§√§ ihmisi√§ ‚Äì toiset suosivat vahvasti punaista ja toiset sinist√§. Jos koodaisimme v√§rit numeroilla, suosikkiv√§rin keskiarvo olisi jossain oranssin ja vihre√§n v√§lill√§, mik√§ ei kuvaisi kummankaan ryhm√§n todellista mieltymyst√§. Moodi olisi kuitenkin jompikumpi v√§reist√§ tai molemmat, jos niiden kannattajien m√§√§r√§ on sama (t√§ss√§ tapauksessa otosta kutsutaan **monimodaaliseksi**).

## Reaaliaikainen data

Kun analysoimme tosiel√§m√§n dataa, ne eiv√§t usein ole varsinaisia satunnaismuuttujia siin√§ mieless√§, ett√§ emme suorita kokeita tuntemattomilla tuloksilla. Esimerkiksi, ajatellaan baseball-pelaajien joukkuetta ja heid√§n kehon mittojaan, kuten pituutta, painoa ja ik√§√§. N√§m√§ luvut eiv√§t ole t√§ysin satunnaisia, mutta voimme silti soveltaa samoja matemaattisia k√§sitteit√§. Esimerkiksi ihmisten painojen sarjaa voidaan pit√§√§ jonkin satunnaismuuttujan arvojen sarjana. Alla on sarja painoja oikeilta baseball-pelaajilta [Major League Baseballista](http://mlb.mlb.com/index.jsp), otettuna [t√§st√§ datasetist√§](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) (mukavuussyist√§ vain ensimm√§iset 20 arvoa on n√§ytetty):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Note**: Katso esimerkki t√§m√§n datasetin k√§sittelyst√§ [liitteen√§ olevasta muistikirjasta](notebook.ipynb). T√§ss√§ oppitunnissa on my√∂s useita haasteita, jotka voit suorittaa lis√§√§m√§ll√§ koodia muistikirjaan. Jos et ole varma, miten dataa k√§sitell√§√§n, √§l√§ huoli ‚Äì palaamme datan k√§sittelyyn Pythonilla my√∂hemmin. Jos et tied√§, miten suorittaa koodia Jupyter Notebookissa, katso [t√§m√§ artikkeli](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

T√§ss√§ on laatikko- ja viiksikaavio, joka n√§ytt√§√§ datan keskiarvon, mediaanin ja kvartiilit:

![Painon laatikkokaavio](../../../../translated_images/weight-boxplot.1dbab1c03af26f8a008fff4e17680082c8ab147d6df646cbac440bbf8f5b9c42.fi.png)

Koska datamme sis√§lt√§√§ tietoa eri pelaajien **rooleista**, voimme my√∂s tehd√§ laatikkokaavion roolin mukaan ‚Äì t√§m√§ antaa k√§sityksen siit√§, miten parametrien arvot eroavat roolien v√§lill√§. T√§ll√§ kertaa tarkastelemme pituutta:

![Laatikkokaavio roolin mukaan](../../../../translated_images/boxplot_byrole.036b27a1c3f52d42f66fba2324ec5cde0a1bca6a01a619eeb0ce7cd054b2527b.fi.png)

T√§m√§ diagrammi viittaa siihen, ett√§ keskim√§√§rin ensimm√§isen pes√§n pelaajat ovat pidempi√§ kuin toisen pes√§n pelaajat. My√∂hemmin t√§ss√§ oppitunnissa opimme, miten voimme testata t√§t√§ hypoteesia tarkemmin ja osoittaa, ett√§ datamme on tilastollisesti merkitt√§v√§√§ t√§m√§n osoittamiseksi.

> Kun ty√∂skentelemme tosiel√§m√§n datan kanssa, oletamme, ett√§ kaikki datapisteet ovat otoksia jostakin todenn√§k√∂isyysjakaumasta. T√§m√§ oletus mahdollistaa koneoppimistekniikoiden soveltamisen ja toimivien ennustemallien rakentamisen.

Jakauman hahmottamiseksi voimme piirt√§√§ **histogrammin**. X-akselilla on eri painov√§lien lukum√§√§r√§ (ns. **bin**-v√§lej√§), ja pystyakselilla n√§ytet√§√§n, kuinka monta kertaa satunnaismuuttujan otos osui tietylle v√§lille.

![Reaaliaikaisen datan histogrammi](../../../../translated_images/weight-histogram.bfd00caf7fc30b145b21e862dba7def41c75635d5280de25d840dd7f0b00545e.fi.png)

T√§st√§ histogrammista n√§et, ett√§ kaikki arvot keskittyv√§t tietyn keskipainon ymp√§rille, ja mit√§ kauemmas t√§st√§ painosta menn√§√§n, sit√§ harvemmin kyseist√§ painoa esiintyy. Toisin sanoen, on hyvin ep√§todenn√§k√∂ist√§, ett√§ baseball-pelaajan paino poikkeaisi merkitt√§v√§sti keskipainosta. Painojen varianssi osoittaa, kuinka paljon painot todenn√§k√∂isesti poikkeavat keskiarvosta.

> Jos otamme painoja muilta ihmisilt√§, jotka eiv√§t ole baseball-liigasta, jakauma on todenn√§k√∂isesti erilainen. Jakauman muoto pysyy kuitenkin samana, mutta keskiarvo ja varianssi muuttuvat. Jos siis koulutamme mallimme baseball-pelaajilla, se todenn√§k√∂isesti antaa v√§√§ri√§ tuloksia, kun sit√§ sovelletaan yliopisto-opiskelijoihin, koska taustalla oleva jakauma on erilainen.

## Normaalijakauma

Painojen jakauma, jonka n√§imme yll√§, on hyvin tyypillinen, ja monet tosiel√§m√§n mittaukset noudattavat samaa jakaumatyyppi√§, mutta eri keskiarvolla ja varianssilla. T√§t√§ jakaumaa kutsutaan **normaalijakaumaksi**, ja sill√§ on eritt√§in t√§rke√§ rooli tilastotieteess√§.

Normaalijakauman k√§ytt√§minen on oikea tapa luoda satunnaisia painoja mahdollisille baseball-pelaajille. Kun tied√§mme keskipainon `mean` ja keskihajonnan `std`, voimme luoda 1000 painon√§ytett√§ seuraavasti:
```python
samples = np.random.normal(mean,std,1000)
``` 

Jos piirr√§mme luotujen n√§ytteiden histogrammin, n√§emme kuvan, joka on hyvin samanlainen kuin yll√§ oleva. Ja jos lis√§√§mme n√§ytteiden ja binien m√§√§r√§√§, voimme luoda kuvan normaalijakaumasta, joka on l√§hemp√§n√§ ideaalia:

![Normaalijakauma, keskiarvo=0 ja keskihajonta=1](../../../../translated_images/normal-histogram.dfae0d67c202137d552d0015fb87581eca263925e512404f3c12d8885315432e.fi.png)

*Normaalijakauma, keskiarvo=0 ja keskihajonta=1*

## Luottamusv√§lit

Kun puhumme baseball-pelaajien painoista, oletamme, ett√§ on olemassa tietty **satunnaismuuttuja W**, joka vastaa ideaalista todenn√§k√∂isyysjakaumaa kaikkien baseball-pelaajien painoille (ns. **populaatio**). Painosarjamme vastaa otosta kaikista baseball-pelaajista, jota kutsumme **otokseksi**. Mielenkiintoinen kysymys on, voimmeko tiet√§√§ W:n jakauman parametrit, eli populaation keskiarvon ja varianssin?

Helpoin vastaus olisi laskea otoksen keskiarvo ja varianssi. Kuitenkin voi k√§yd√§ niin, ett√§ satunnainen otoksemme ei edusta tarkasti koko populaatiota. Siksi on j√§rkev√§√§ puhua **luottamusv√§list√§**.
> **Luottamusv√§li** on arvio populaation todellisesta keskiarvosta annetun otoksen perusteella, joka on tarkka tietyll√§ todenn√§k√∂isyydell√§ (tai **luottamustasolla**).
Oletetaan, ett√§ meill√§ on otos X<sub>1</sub>, ..., X<sub>n</sub> jakaumastamme. Joka kerta, kun otamme otoksen jakaumastamme, p√§√§dymme eri keskiarvoon Œº. N√§in ollen Œº voidaan pit√§√§ satunnaismuuttujana. **Luottamusv√§li** luottamustasolla p on arvojen pari (L<sub>p</sub>,R<sub>p</sub>), siten ett√§ **P**(L<sub>p</sub>‚â§Œº‚â§R<sub>p</sub>) = p, eli mitatun keskiarvon todenn√§k√∂isyys osua v√§lin sis√§lle on p.

Tarkempi keskustelu siit√§, miten n√§m√§ luottamusv√§lit lasketaan, menee lyhyen johdantomme ulkopuolelle. Lis√§tietoja l√∂ytyy [Wikipediasta](https://en.wikipedia.org/wiki/Confidence_interval). Lyhyesti sanottuna m√§√§rittelemme lasketun otoskeskiarvon jakauman suhteessa populaation todelliseen keskiarvoon, jota kutsutaan **Student-jakaumaksi**.

> **Mielenkiintoinen fakta**: Student-jakauma on nimetty matemaatikko William Sealy Gossetin mukaan, joka julkaisi tutkimuksensa salanimell√§ "Student". H√§n ty√∂skenteli Guinnessin panimossa, ja er√§√§n version mukaan h√§nen ty√∂nantajansa ei halunnut yleis√∂n tiet√§v√§n, ett√§ he k√§yttiv√§t tilastollisia testej√§ raaka-aineiden laadun m√§√§ritt√§miseen.

Jos haluamme arvioida populaation keskiarvon Œº luottamustasolla p, meid√§n t√§ytyy ottaa *(1-p)/2-prosenttipiste* Student-jakaumasta A, joka voidaan joko ottaa taulukoista tai laskea tilasto-ohjelmistojen sis√§√§nrakennetuilla funktioilla (esim. Python, R jne.). T√§ll√∂in Œº:n v√§li olisi X¬±A*D/‚àön, miss√§ X on otoksen saatu keskiarvo ja D on keskihajonta.

> **Huomio**: J√§t√§mme my√∂s k√§sittelem√§tt√§ t√§rke√§n k√§sitteen [vapausasteet](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)), joka on t√§rke√§ Student-jakauman yhteydess√§. Voit tutustua kattavampiin tilastotieteen kirjoihin ymm√§rt√§√§ksesi t√§m√§n k√§sitteen syv√§llisemmin.

Esimerkki painojen ja pituuksien luottamusv√§lin laskemisesta l√∂ytyy [liitteen√§ olevista muistikirjoista](notebook.ipynb).

| p | Painon keskiarvo |
|-----|----------------|
| 0.85 | 201.73¬±0.94 |
| 0.90 | 201.73¬±1.08 |
| 0.95 | 201.73¬±1.28 |

Huomaa, ett√§ mit√§ korkeampi luottamustodenn√§k√∂isyys, sit√§ laajempi luottamusv√§li.

## Hypoteesin testaus

Baseball-pelaajien datasetiss√§ on erilaisia pelaajarooleja, jotka voidaan tiivist√§√§ alla (katso [liitteen√§ oleva muistikirja](notebook.ipynb), jossa n√§ytet√§√§n, miten t√§m√§ taulukko voidaan laskea):

| Rooli | Pituus | Paino | Lukum√§√§r√§ |
|------|--------|-------|-----------|
| Catcher | 72.723684 | 204.328947 | 76 |
| Designated_Hitter | 74.222222 | 220.888889 | 18 |
| First_Baseman | 74.000000 | 213.109091 | 55 |
| Outfielder | 73.010309 | 199.113402 | 194 |
| Relief_Pitcher | 74.374603 | 203.517460 | 315 |
| Second_Baseman | 71.362069 | 184.344828 | 58 |
| Shortstop | 71.903846 | 182.923077 | 52 |
| Starting_Pitcher | 74.719457 | 205.163636 | 221 |
| Third_Baseman | 73.044444 | 200.955556 | 45 |

Voimme huomata, ett√§ ensimm√§isten basemenien keskipituus on korkeampi kuin toisten basemenien. N√§in ollen voimme olla houkuteltuja p√§√§ttelem√§√§n, ett√§ **ensimm√§iset basemenit ovat pidempi√§ kuin toiset basemenit**.

> T√§t√§ v√§itt√§m√§√§ kutsutaan **hypoteesiksi**, koska emme tied√§, onko v√§ite oikeasti totta vai ei.

Kuitenkin ei ole aina selv√§√§, voimmeko tehd√§ t√§m√§n johtop√§√§t√∂ksen. Yll√§ olevasta keskustelusta tied√§mme, ett√§ jokaisella keskiarvolla on siihen liittyv√§ luottamusv√§li, ja n√§in ollen t√§m√§ ero voi olla vain tilastollinen virhe. Tarvitsemme jonkin muodollisemman tavan testata hypoteesimme.

Lasketaan luottamusv√§lit erikseen ensimm√§isten ja toisten basemenien pituuksille:

| Luottamus | Ensimm√§iset basemenit | Toiset basemenit |
|-----------|-----------------------|------------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

Voimme n√§hd√§, ett√§ mill√§√§n luottamustasolla v√§lit eiv√§t mene p√§√§llekk√§in. T√§m√§ todistaa hypoteesimme, ett√§ ensimm√§iset basemenit ovat pidempi√§ kuin toiset basemenit.

Muodollisemmin, ongelma, jota ratkaisimme, on n√§hd√§, ovatko **kaksi todenn√§k√∂isyysjakaumaa samoja**, tai ainakin onko niill√§ samat parametrit. Riippuen jakaumasta, meid√§n t√§ytyy k√§ytt√§√§ erilaisia testej√§. Jos tied√§mme, ett√§ jakaumamme ovat normaalijakaumia, voimme soveltaa **[Studentin t-testi√§](https://en.wikipedia.org/wiki/Student%27s_t-test)**.

Studentin t-testiss√§ laskemme niin sanotun **t-arvon**, joka osoittaa keskiarvojen eron ottaen huomioon varianssin. On osoitettu, ett√§ t-arvo noudattaa **Student-jakaumaa**, mik√§ mahdollistaa kynnysarvon saamisen annetulle luottamustasolle **p** (t√§m√§ voidaan laskea tai katsoa numeerisista taulukoista). Vertailemme sitten t-arvoa t√§h√§n kynnysarvoon hyv√§ksy√§ksemme tai hyl√§t√§ksemme hypoteesin.

Pythonissa voimme k√§ytt√§√§ **SciPy**-pakettia, joka sis√§lt√§√§ `ttest_ind`-funktion (lis√§ksi monia muita hy√∂dyllisi√§ tilastollisia funktioita!). Se laskee t-arvon puolestamme ja tekee my√∂s k√§√§nteisen luottamustason p-arvon haun, jotta voimme vain katsoa luottamustasoa tehd√§ksemme johtop√§√§t√∂ksen.

Esimerkiksi vertailumme ensimm√§isten ja toisten basemenien pituuksista antaa meille seuraavat tulokset:
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
T√§ss√§ tapauksessa p-arvo on hyvin alhainen, mik√§ tarkoittaa, ett√§ on vahvaa n√§ytt√∂√§ siit√§, ett√§ ensimm√§iset basemenit ovat pidempi√§.

On my√∂s muita hypoteeseja, joita voimme testata, esimerkiksi:
* Todistaa, ett√§ annettu otos noudattaa jotain jakaumaa. Meid√§n tapauksessamme olemme olettaneet, ett√§ pituudet ovat normaalijakautuneita, mutta t√§m√§ vaatii muodollisen tilastollisen vahvistuksen.
* Todistaa, ett√§ otoksen keskiarvo vastaa jotain ennalta m√§√§ritetty√§ arvoa
* Verrata useiden otosten keskiarvoja (esim. mik√§ on onnellisuustasojen ero eri ik√§ryhmien v√§lill√§)

## Suurten lukujen laki ja keskeinen raja-arvolause

Yksi syy siihen, miksi normaalijakauma on niin t√§rke√§, on niin sanottu **keskeinen raja-arvolause**. Oletetaan, ett√§ meill√§ on suuri otos riippumattomia N arvoja X<sub>1</sub>, ..., X<sub>N</sub>, jotka on otettu mist√§ tahansa jakaumasta, jonka keskiarvo on Œº ja varianssi œÉ<sup>2</sup>. T√§ll√∂in, kun N on riitt√§v√§n suuri (toisin sanoen kun N‚Üí‚àû), keskiarvo Œ£<sub>i</sub>X<sub>i</sub> olisi normaalijakautunut, keskiarvolla Œº ja varianssilla œÉ<sup>2</sup>/N.

> Toinen tapa tulkita keskeist√§ raja-arvolausetta on sanoa, ett√§ riippumatta jakaumasta, kun lasket satunnaismuuttujien summan keskiarvon, p√§√§dyt normaalijakaumaan.

Keskeisest√§ raja-arvolauseesta seuraa my√∂s, ett√§ kun N‚Üí‚àû, otoskeskiarvon todenn√§k√∂isyys olla yht√§ suuri kuin Œº l√§hestyy 1. T√§m√§ tunnetaan nimell√§ **suurten lukujen laki**.

## Kovarianssi ja korrelaatio

Yksi asioista, joita data-analytiikka tekee, on l√∂yt√§√§ yhteyksi√§ datan v√§lill√§. Sanomme, ett√§ kaksi sarjaa **korreloivat**, kun ne k√§ytt√§ytyv√§t samankaltaisesti samaan aikaan, eli ne joko nousevat/laskevat samanaikaisesti, tai yksi sarja nousee, kun toinen laskee ja p√§invastoin. Toisin sanoen, kahden sarjan v√§lill√§ n√§ytt√§√§ olevan jokin yhteys.

> Korrelaatio ei v√§ltt√§m√§tt√§ tarkoita kausaalista yhteytt√§ kahden sarjan v√§lill√§; joskus molemmat muuttujat voivat riippua jostain ulkoisesta syyst√§, tai voi olla pelkk√§√§ sattumaa, ett√§ kaksi sarjaa korreloivat. Kuitenkin vahva matemaattinen korrelaatio on hyv√§ merkki siit√§, ett√§ kaksi muuttujaa ovat jollain tavalla yhteydess√§.

Matemaattisesti p√§√§k√§site, joka osoittaa kahden satunnaismuuttujan v√§lisen yhteyden, on **kovarianssi**, joka lasketaan n√§in: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. Laskemme molempien muuttujien poikkeaman niiden keskiarvoista ja sitten n√§iden poikkeamien tulon. Jos molemmat muuttujat poikkeavat yhdess√§, tulo on aina positiivinen arvo, joka lis√§√§ positiivista kovarianssia. Jos molemmat muuttujat poikkeavat ep√§synkronisesti (eli yksi laskee keskiarvon alapuolelle, kun toinen nousee keskiarvon yl√§puolelle), saamme aina negatiivisia lukuja, jotka lis√§√§v√§t negatiivista kovarianssia. Jos poikkeamat eiv√§t ole riippuvaisia, ne lis√§√§v√§t suunnilleen nollan.

Kovarianssin absoluuttinen arvo ei kerro paljon siit√§, kuinka suuri korrelaatio on, koska se riippuu todellisten arvojen suuruudesta. Normalisoidaksemme sen voimme jakaa kovarianssin molempien muuttujien keskihajonnalla saadaksemme **korrelaation**. Hyv√§ asia on, ett√§ korrelaatio on aina v√§lill√§ [-1,1], miss√§ 1 tarkoittaa vahvaa positiivista korrelaatiota arvojen v√§lill√§, -1 - vahvaa negatiivista korrelaatiota ja 0 - ei korrelaatiota ollenkaan (muuttujat ovat riippumattomia).

**Esimerkki**: Voimme laskea korrelaation baseball-pelaajien painojen ja pituuksien v√§lill√§ yll√§ mainitusta datasetist√§:
```python
print(np.corrcoef(weights,heights))
```
Tuloksena saamme **korrelaatiomatriisin**, joka n√§ytt√§√§ t√§lt√§:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> Korrelaatiomatriisi C voidaan laskea mille tahansa m√§√§r√§lle sy√∂tteit√§ S<sub>1</sub>, ..., S<sub>n</sub>. C<sub>ij</sub>-arvo on korrelaatio S<sub>i</sub>:n ja S<sub>j</sub>:n v√§lill√§, ja diagonaalielementit ovat aina 1 (joka on my√∂s S<sub>i</sub>:n itsekorrelaatio).

T√§ss√§ tapauksessa arvo 0.53 osoittaa, ett√§ painon ja pituuden v√§lill√§ on jonkin verran korrelaatiota. Voimme my√∂s tehd√§ hajontakaavion yhdest√§ arvosta toista vastaan n√§hd√§ksesi yhteyden visuaalisesti:

![Painon ja pituuden v√§linen yhteys](../../../../translated_images/weight-height-relationship.3f06bde4ca2aba9974182c4ef037ed602acd0fbbbbe2ca91cefd838a9e66bcf9.fi.png)

> Lis√§√§ esimerkkej√§ korrelaatiosta ja kovarianssista l√∂ytyy [liitteen√§ olevasta muistikirjasta](notebook.ipynb).

## Yhteenveto

T√§ss√§ osiossa olemme oppineet:

* datan perus tilastolliset ominaisuudet, kuten keskiarvo, varianssi, moodi ja kvartiilit
* satunnaismuuttujien eri jakaumat, mukaan lukien normaalijakauma
* kuinka l√∂yt√§√§ korrelaatio eri ominaisuuksien v√§lill√§
* kuinka k√§ytt√§√§ matematiikan ja tilastotieteen vankkaa v√§lineist√∂√§ hypoteesien todistamiseen
* kuinka laskea satunnaismuuttujan luottamusv√§li annetun otoksen perusteella

Vaikka t√§m√§ ei ole tyhjent√§v√§ lista todenn√§k√∂isyyslaskennan ja tilastotieteen aiheista, sen pit√§isi riitt√§√§ antamaan sinulle hyv√§ l√§ht√∂kohta t√§h√§n kurssiin.

## üöÄ Haaste

K√§yt√§ muistikirjan esimerkkikoodia testataksesi muita hypoteeseja:
1. Ensimm√§iset basemenit ovat vanhempia kuin toiset basemenit
2. Ensimm√§iset basemenit ovat pidempi√§ kuin kolmannet basemenit
3. Shortstopit ovat pidempi√§ kuin toiset basemenit

## [Luennon j√§lkeinen kysely](https://ff-quizzes.netlify.app/en/ds/)

## Kertaus ja itseopiskelu

Todenn√§k√∂isyyslaskenta ja tilastotiede ovat niin laajoja aiheita, ett√§ ne ansaitsevat oman kurssinsa. Jos olet kiinnostunut syventym√§√§n teoriaan, voit jatkaa lukemalla joitakin seuraavista kirjoista:

1. [Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/) New Yorkin yliopistosta on laatinut erinomaiset luentomuistiinpanot [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (saatavilla verkossa)
1. [Peter ja Andrew Bruce. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[esimerkkikoodi R:ss√§](https://github.com/andrewgbruce/statistics-for-data-scientists)].
1. [James D. Miller. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[esimerkkikoodi R:ss√§](https://github.com/PacktPublishing/Statistics-for-Data-Science)]

## Teht√§v√§

[Pieni diabetes-tutkimus](assignment.md)

## Tekij√§t

T√§m√§n oppitunnin on kirjoittanut ‚ô•Ô∏è:ll√§ [Dmitry Soshnikov](http://soshnikov.com)

---

**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ett√§ automaattiset k√§√§nn√∂kset voivat sis√§lt√§√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§ist√§ asiakirjaa sen alkuper√§isell√§ kielell√§ tulisi pit√§√§ ensisijaisena l√§hteen√§. Kriittisen tiedon osalta suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa v√§√§rink√§sityksist√§ tai virhetulkinnoista, jotka johtuvat t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§.