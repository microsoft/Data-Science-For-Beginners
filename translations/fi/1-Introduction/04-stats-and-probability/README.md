<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b706a07cfa87ba091cbb91e0aa775600",
  "translation_date": "2025-08-26T21:46:18+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "fi"
}
-->
# Lyhyt johdatus tilastotieteeseen ja todenn√§k√∂isyyksiin

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| Tilastotiede ja todenn√§k√∂isyydet - _Sketchnote by [@nitya](https://twitter.com/nitya)_ |

Tilastotiede ja todenn√§k√∂isyysteoria ovat kaksi l√§heisesti toisiinsa liittyv√§√§ matematiikan osa-aluetta, jotka ovat eritt√§in merkityksellisi√§ datatieteess√§. On mahdollista k√§sitell√§ dataa ilman syv√§llist√§ matematiikan tuntemusta, mutta on silti parempi tuntea ainakin perusk√§sitteet. T√§ss√§ esittelemme lyhyen johdannon, joka auttaa sinua p√§√§sem√§√§n alkuun.

[![Intro Video](../../../../translated_images/video-prob-and-stats.e4282e5efa2f2543400843ed98b1057065c9600cebfc8a728e8931b5702b2ae4.fi.png)](https://youtu.be/Z5Zy85g4Yjw)

## [Esiluennon kysely](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/6)

## Todenn√§k√∂isyys ja satunnaismuuttujat

**Todenn√§k√∂isyys** on luku v√§lill√§ 0 ja 1, joka ilmaisee, kuinka todenn√§k√∂inen jokin **tapahtuma** on. Se m√§√§ritell√§√§n positiivisten lopputulosten (jotka johtavat tapahtumaan) lukum√§√§r√§n√§ jaettuna kaikkien lopputulosten lukum√§√§r√§ll√§, olettaen ett√§ kaikki lopputulokset ovat yht√§ todenn√§k√∂isi√§. Esimerkiksi, kun heit√§mme noppaa, todenn√§k√∂isyys saada parillinen luku on 3/6 = 0.5.

Kun puhumme tapahtumista, k√§yt√§mme **satunnaismuuttujia**. Esimerkiksi satunnaismuuttuja, joka edustaa noppaa heitett√§ess√§ saatua lukua, voi saada arvoja v√§lill√§ 1‚Äì6. Lukuja 1‚Äì6 kutsutaan **otosavaruudeksi**. Voimme puhua satunnaismuuttujan todenn√§k√∂isyydest√§ saada tietty arvo, esimerkiksi P(X=3)=1/6.

Edellisen esimerkin satunnaismuuttujaa kutsutaan **diskreetiksi**, koska sen otosavaruus on laskettavissa, eli siin√§ on erillisi√§ arvoja, jotka voidaan luetella. On my√∂s tapauksia, joissa otosavaruus on reaaliarvojen v√§li tai koko reaaliarvojen joukko. T√§llaisia muuttujia kutsutaan **jatkuviksi**. Hyv√§ esimerkki on bussin saapumisaika.

## Todenn√§k√∂isyysjakauma

Diskreettien satunnaismuuttujien tapauksessa on helppo kuvata kunkin tapahtuman todenn√§k√∂isyys funktiolla P(X). Jokaiselle otosavaruuden *S* arvolle *s* se antaa luvun v√§lill√§ 0 ja 1 siten, ett√§ kaikkien P(X=s) arvojen summa kaikille tapahtumille on 1.

Tunnetuin diskreetti jakauma on **tasajakauma**, jossa otosavaruudessa on N elementti√§, joista jokaisen todenn√§k√∂isyys on 1/N.

Jatkuvan muuttujan todenn√§k√∂isyysjakauman kuvaaminen on vaikeampaa, kun arvot ovat per√§isin jostain v√§list√§ [a,b] tai koko reaaliarvojen joukosta ‚Ñù. Mietit√§√§n esimerkiksi bussin saapumisaikaa. Todellisuudessa jokaiselle tarkalle saapumisajalle *t* bussin saapumisen todenn√§k√∂isyys on 0!

> Nyt tied√§t, ett√§ tapahtumat, joiden todenn√§k√∂isyys on 0, tapahtuvat, ja viel√§p√§ usein! Ainakin joka kerta, kun bussi saapuu!

Voimme puhua vain muuttujan todenn√§k√∂isyydest√§ osua tiettyyn arvojen v√§liin, esim. P(t<sub>1</sub>‚â§X<t<sub>2</sub>). T√§ss√§ tapauksessa todenn√§k√∂isyysjakauma kuvataan **todenn√§k√∂isyystiheysfunktiolla** p(x), siten ett√§

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../translated_images/probability-density.a8aad29f17a14afb519b407c7b6edeb9f3f9aa5f69c9e6d9445f604e5f8a2bf7.fi.png)

Jatkuvan tasajakauman analogia on **jatkuva tasajakauma**, joka m√§√§ritell√§√§n rajallisella v√§lill√§. Todenn√§k√∂isyys, ett√§ arvo X osuu v√§lin pituuteen l, on verrannollinen l:√§√§n ja kasvaa arvoon 1.

Toinen t√§rke√§ jakauma on **normaalijakauma**, josta puhumme tarkemmin my√∂hemmin.

## Keskiarvo, varianssi ja keskihajonta

Oletetaan, ett√§ otamme n n√§ytett√§ satunnaismuuttujasta X: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. Voimme m√§√§ritell√§ **keskiarvon** (tai **aritmeettisen keskiarvon**) perinteisell√§ tavalla (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n. Kun kasvatamme otoksen kokoa (eli otamme rajan n‚Üí‚àû), saamme jakauman keskiarvon (jota kutsutaan my√∂s **odotusarvoksi**). Merkitsemme odotusarvon **E**(x).

> On osoitettavissa, ett√§ mille tahansa diskreetille jakaumalle, jonka arvot ovat {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} ja vastaavat todenn√§k√∂isyydet p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, odotusarvo on E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>.

Arvojen hajonnan tunnistamiseksi voimme laskea varianssin œÉ<sup>2</sup> = ‚àë(x<sub>i</sub> - Œº)<sup>2</sup>/n, miss√§ Œº on otoksen keskiarvo. Arvoa œÉ kutsutaan **keskihajonnaksi**, ja œÉ<sup>2</sup> kutsutaan **varianssiksi**.

## Moodi, mediaani ja kvartiilit

Joskus keskiarvo ei kuvaa riitt√§v√§n hyvin "tyypillist√§" arvoa datalle. Esimerkiksi, kun on muutama √§√§rimm√§inen arvo, jotka ovat t√§ysin poikkeavia, ne voivat vaikuttaa keskiarvoon. Toinen hyv√§ indikaattori on **mediaani**, arvo, jonka alapuolella on puolet datapisteist√§ ja yl√§puolella toinen puoli.

Datajakauman ymm√§rt√§miseksi on hy√∂dyllist√§ puhua **kvartiileista**:

* Ensimm√§inen kvartiili, eli Q1, on arvo, jonka alapuolella on 25 % datasta
* Kolmas kvartiili, eli Q3, on arvo, jonka alapuolella on 75 % datasta

Graafisesti voimme esitt√§√§ mediaanin ja kvartiilien suhteen diagrammissa, jota kutsutaan **laatikko-kaavioksi**:

<img src="images/boxplot_explanation.png" width="50%"/>

T√§ss√§ laskemme my√∂s **kvartiiliv√§lin** IQR=Q3-Q1 ja niin sanotut **poikkeamat** - arvot, jotka ovat alueen [Q1-1.5*IQR,Q3+1.5*IQR] ulkopuolella.

Pienelle mahdollisten arvojen joukolle hyv√§ "tyypillinen" arvo on se, joka esiintyy useimmin, ja sit√§ kutsutaan **moodiksi**. Sit√§ k√§ytet√§√§n usein kategorisessa datassa, kuten v√§reiss√§. Mietit√§√§n tilannetta, jossa meill√§ on kaksi ryhm√§√§ ihmisi√§ - osa, jotka suosivat vahvasti punaista, ja toiset, jotka suosivat sinist√§. Jos koodaisimme v√§rit numeroilla, suosikkiv√§rin keskiarvo olisi jossain oranssin ja vihre√§n spektriss√§, mik√§ ei kuvaisi kummankaan ryhm√§n todellista mieltymyst√§. Moodi olisi kuitenkin joko yksi v√§reist√§ tai molemmat v√§rit, jos niiden kannattajien m√§√§r√§ on sama (t√§ss√§ tapauksessa otosta kutsutaan **monimoodiseksi**).

## Reaaliaikainen data

Kun analysoimme tosiel√§m√§n dataa, ne eiv√§t usein ole satunnaismuuttujia siin√§ mieless√§, ett√§ emme tee kokeita tuntemattomalla lopputuloksella. Esimerkiksi, mietit√§√§n baseball-joukkueen pelaajia ja heid√§n kehon tietojaan, kuten pituutta, painoa ja ik√§√§. N√§m√§ luvut eiv√§t ole t√§ysin satunnaisia, mutta voimme silti soveltaa samoja matemaattisia k√§sitteit√§. Esimerkiksi ihmisten painojen sarjaa voidaan pit√§√§ satunnaismuuttujan arvojen sarjana. Alla on Major League Baseball -pelaajien painojen sarja [t√§st√§ datasetist√§](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) (mukavuuden vuoksi vain ensimm√§iset 20 arvoa n√§ytet√§√§n):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Huomio**: Katso esimerkki t√§m√§n datasetin k√§sittelyst√§ [liitteen√§ olevasta muistikirjasta](notebook.ipynb). T√§m√§n oppitunnin aikana on my√∂s useita haasteita, jotka voit suorittaa lis√§√§m√§ll√§ koodia muistikirjaan. Jos et ole varma, miten k√§sitell√§ dataa, √§l√§ huoli - palaamme datan k√§sittelyyn Pythonilla my√∂hemmin. Jos et tied√§, miten suorittaa koodia Jupyter Notebookissa, katso [t√§m√§ artikkeli](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

T√§ss√§ on laatikko-kaavio, joka n√§ytt√§√§ keskiarvon, mediaanin ja kvartiilit datallemme:

![Painon laatikko-kaavio](../../../../translated_images/weight-boxplot.1dbab1c03af26f8a008fff4e17680082c8ab147d6df646cbac440bbf8f5b9c42.fi.png)

Koska datamme sis√§lt√§√§ tietoa eri pelaajien **rooleista**, voimme my√∂s tehd√§ laatikko-kaavion roolin mukaan - t√§m√§ antaa meille k√§sityksen siit√§, miten parametrit eroavat roolien v√§lill√§. T√§ll√§ kertaa tarkastelemme pituutta:

![Laatikko-kaavio roolin mukaan](../../../../translated_images/boxplot_byrole.036b27a1c3f52d42f66fba2324ec5cde0a1bca6a01a619eeb0ce7cd054b2527b.fi.png)

T√§m√§ diagrammi viittaa siihen, ett√§ keskim√§√§rin ensimm√§isen pes√§n pelaajien pituus on suurempi kuin toisen pes√§n pelaajien pituus. My√∂hemmin t√§ss√§ oppitunnissa opimme, miten voimme testata t√§t√§ hypoteesia muodollisemmin ja miten voimme osoittaa, ett√§ datamme on tilastollisesti merkitt√§v√§√§ t√§m√§n osoittamiseksi.

> Kun ty√∂skentelemme tosiel√§m√§n datan kanssa, oletamme, ett√§ kaikki datapisteet ovat otoksia jostain todenn√§k√∂isyysjakaumasta. T√§m√§ oletus mahdollistaa koneoppimistekniikoiden soveltamisen ja toimivien ennustemallien rakentamisen.

Jotta voimme n√§hd√§, millainen datamme jakauma on, voimme piirt√§√§ diagrammin, jota kutsutaan **histogrammiksi**. X-akselilla on eri painov√§lien lukum√§√§r√§ (niin sanotut **binit**), ja pystyakseli n√§ytt√§√§, kuinka monta kertaa satunnaismuuttujan otos oli kyseisess√§ v√§liss√§.

![Tosiel√§m√§n datan histogrammi](../../../../translated_images/weight-histogram.bfd00caf7fc30b145b21e862dba7def41c75635d5280de25d840dd7f0b00545e.fi.png)

T√§st√§ histogrammista n√§et, ett√§ kaikki arvot keskittyv√§t tietyn keskim√§√§r√§isen painon ymp√§rille, ja mit√§ kauemmas keskim√§√§r√§isest√§ painosta menn√§√§n, sit√§ harvemmin kyseisen painon arvoja esiintyy. Eli on hyvin ep√§todenn√§k√∂ist√§, ett√§ baseball-pelaajan paino poikkeaisi merkitt√§v√§sti keskim√§√§r√§isest√§ painosta. Painojen varianssi osoittaa, kuinka paljon painot todenn√§k√∂isesti eroavat keskiarvosta.

> Jos otamme muiden ihmisten painoja, jotka eiv√§t ole baseball-liigasta, jakauma on todenn√§k√∂isesti erilainen. Jakauman muoto pysyy kuitenkin samana, mutta keskiarvo ja varianssi muuttuvat. Joten jos koulutamme mallimme baseball-pelaajilla, se todenn√§k√∂isesti antaa v√§√§ri√§ tuloksia, kun sit√§ sovelletaan yliopisto-opiskelijoihin, koska taustalla oleva jakauma on erilainen.

## Normaalijakauma

Painojen jakauma, jonka n√§imme yll√§, on hyvin tyypillinen, ja monet tosiel√§m√§n mittaukset noudattavat samaa tyyppist√§ jakaumaa, mutta eri keskiarvolla ja varianssilla. T√§t√§ jakaumaa kutsutaan **normaalijakaumaksi**, ja sill√§ on eritt√§in t√§rke√§ rooli tilastotieteess√§.

Normaalijakauman k√§ytt√§minen on oikea tapa luoda satunnaisia painoja potentiaalisille baseball-pelaajille. Kun tied√§mme keskim√§√§r√§isen painon `mean` ja keskihajonnan `std`, voimme luoda 1000 painon√§ytett√§ seuraavalla tavalla:
```python
samples = np.random.normal(mean,std,1000)
``` 

Jos piirr√§mme luotujen n√§ytteiden histogrammin, n√§emme kuvan, joka on hyvin samanlainen kuin yll√§ esitetty. Ja jos lis√§√§mme n√§ytteiden m√§√§r√§√§ ja binien m√§√§r√§√§, voimme luoda kuvan normaalijakaumasta, joka on l√§hemp√§n√§ ihanteellista:

![Normaalijakauma keskiarvolla=0 ja keskihajonnalla=1](../../../../translated_images/normal-histogram.dfae0d67c202137d552d0015fb87581eca263925e512404f3c12d8885315432e.fi.png)

*Normaalijakauma keskiarvolla=0 ja keskihajonnalla=1*

## Luottamusv√§lit

Kun puhumme baseball-pelaajien painoista, oletamme, ett√§ on olemassa tietty **satunnaismuuttuja W**, joka vastaa kaikkien baseball-pelaajien painojen ideaalista todenn√§k√∂isyysjakaumaa (niin sanottu **populaatio**). Painojemme sarja vastaa kaikkien baseball-pelaajien alijoukkoa, jota kutsumme **otokseksi**. Mielenkiintoinen kysymys on, voimmeko tiet√§√§ W:n jakauman parametrit, eli populaation keskiarvon ja varianssin?

Helpoin vastaus olisi laskea otoksen keskiarvo ja varianssi. Kuitenkin voi k√§yd√§ niin, ett√§ satunnainen otoksemme ei edusta tarkasti koko populaatiota. Siksi on j√§rkev√§√§ puhua **luottamusv√§list√§**.
> **Luottamusv√§li** on arvio populaation todellisesta keskiarvosta annetun otoksen perusteella, joka on tarkka tietyll√§ todenn√§k√∂isyydell√§ (tai **luottamustasolla**).
Oletetaan, ett√§ meill√§ on otos X<sub>1</sub>, ..., X<sub>n</sub> jakaumastamme. Joka kerta, kun otamme otoksen jakaumastamme, saamme eri keskiarvon Œº. N√§in ollen Œº voidaan pit√§√§ satunnaismuuttujana. **Luottamusv√§li** luottamustasolla p on arvojen pari (L<sub>p</sub>,R<sub>p</sub>), siten ett√§ **P**(L<sub>p</sub>‚â§Œº‚â§R<sub>p</sub>) = p, eli todenn√§k√∂isyys, ett√§ mitattu keskiarvo osuu v√§lin sis√§√§n, on p.

On t√§m√§n lyhyen johdannon ulkopuolella k√§sitell√§ yksityiskohtaisesti, miten n√§m√§ luottamusv√§lit lasketaan. Lis√§tietoja l√∂ytyy [Wikipediasta](https://en.wikipedia.org/wiki/Confidence_interval). Lyhyesti sanottuna m√§√§rittelemme lasketun otoskeskiarvon jakauman suhteessa populaation todelliseen keskiarvoon, jota kutsutaan **Studentin jakaumaksi**.

> **Mielenkiintoinen fakta**: Studentin jakauma on nimetty matemaatikko William Sealy Gossetin mukaan, joka julkaisi artikkelinsa salanimell√§ "Student". H√§n ty√∂skenteli Guinnessin panimossa, ja er√§√§n version mukaan h√§nen ty√∂nantajansa ei halunnut yleis√∂n tiet√§v√§n, ett√§ he k√§yttiv√§t tilastollisia testej√§ raaka-aineiden laadun m√§√§ritt√§miseen.

Jos haluamme arvioida populaation keskiarvon Œº luottamustasolla p, meid√§n t√§ytyy ottaa *(1-p)/2-prosenttipiste* Studentin jakaumasta A, joka voidaan joko hakea taulukoista tai laskea tilasto-ohjelmistojen sis√§√§nrakennetuilla funktioilla (esim. Python, R jne.). T√§ll√∂in Œº:n v√§li olisi X¬±A*D/‚àön, miss√§ X on otoksen saatu keskiarvo ja D on keskihajonta.

> **Huomio**: Emme my√∂sk√§√§n k√§sittele t√§rke√§√§ k√§sitett√§ [vapausasteet](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)), joka on merkitt√§v√§ Studentin jakauman yhteydess√§. Voit tutustua kattavampiin tilastotieteen kirjoihin ymm√§rt√§√§ksesi t√§m√§n k√§sitteen syv√§llisemmin.

Esimerkki painojen ja pituuksien luottamusv√§lin laskemisesta l√∂ytyy [liitetyist√§ muistikirjoista](notebook.ipynb).

| p    | Painon keskiarvo |
|------|------------------|
| 0.85 | 201.73¬±0.94      |
| 0.90 | 201.73¬±1.08      |
| 0.95 | 201.73¬±1.28      |

Huomaa, ett√§ mit√§ korkeampi luottamustodenn√§k√∂isyys on, sit√§ laajempi on luottamusv√§li.

## Hypoteesin testaus

Baseball-pelaajien aineistossamme on erilaisia pelaajarooleja, jotka voidaan tiivist√§√§ alla olevaan taulukkoon (katso [liitetty muistikirja](notebook.ipynb), jossa n√§ytet√§√§n, miten t√§m√§ taulukko voidaan laskea):

| Rooli             | Pituus     | Paino      | M√§√§r√§ |
|-------------------|------------|------------|-------|
| Catcher           | 72.723684  | 204.328947 | 76    |
| Designated_Hitter | 74.222222  | 220.888889 | 18    |
| First_Baseman     | 74.000000  | 213.109091 | 55    |
| Outfielder        | 73.010309  | 199.113402 | 194   |
| Relief_Pitcher    | 74.374603  | 203.517460 | 315   |
| Second_Baseman    | 71.362069  | 184.344828 | 58    |
| Shortstop         | 71.903846  | 182.923077 | 52    |
| Starting_Pitcher  | 74.719457  | 205.163636 | 221   |
| Third_Baseman     | 73.044444  | 200.955556 | 45    |

Voimme huomata, ett√§ ensimm√§isten basemenien keskipituus on suurempi kuin toisten basemenien. N√§in ollen voimme olla houkuteltuja p√§√§ttelem√§√§n, ett√§ **ensimm√§iset basemenit ovat pidempi√§ kuin toiset basemenit**.

> T√§t√§ v√§itett√§ kutsutaan **hypoteesiksi**, koska emme tied√§, onko se tosiasiallisesti totta vai ei.

Kuitenkin ei ole aina selv√§√§, voimmeko tehd√§ t√§m√§n johtop√§√§t√∂ksen. Yll√§ olevasta keskustelusta tied√§mme, ett√§ jokaisella keskiarvolla on siihen liittyv√§ luottamusv√§li, ja n√§in ollen t√§m√§ ero voi olla vain tilastollinen virhe. Tarvitsemme jonkin muodollisemman tavan testata hypoteesimme.

Lasketaan luottamusv√§lit erikseen ensimm√§isten ja toisten basemenien pituuksille:

| Luottamus | Ensimm√§iset basemenit | Toiset basemenit |
|-----------|-----------------------|------------------|
| 0.85      | 73.62..74.38          | 71.04..71.69     |
| 0.90      | 73.56..74.44          | 70.99..71.73     |
| 0.95      | 73.47..74.53          | 70.92..71.81     |

Voimme n√§hd√§, ett√§ mill√§√§n luottamustasolla v√§lit eiv√§t mene p√§√§llekk√§in. T√§m√§ todistaa hypoteesimme, ett√§ ensimm√§iset basemenit ovat pidempi√§ kuin toiset basemenit.

Muodollisemmin, ongelma, jota ratkaisemme, on n√§hd√§, ovatko **kaksi todenn√§k√∂isyysjakaumaa samat**, tai ainakin onko niill√§ samat parametrit. Riippuen jakaumasta, meid√§n t√§ytyy k√§ytt√§√§ erilaisia testej√§. Jos tied√§mme, ett√§ jakaumamme ovat normaalijakaumia, voimme soveltaa **[Studentin t-testi√§](https://en.wikipedia.org/wiki/Student%27s_t-test)**.

Studentin t-testiss√§ laskemme niin sanotun **t-arvon**, joka osoittaa keskiarvojen eron ottaen huomioon varianssin. On osoitettu, ett√§ t-arvo noudattaa **Studentin jakaumaa**, mik√§ mahdollistaa kynnysarvon saamisen annetulle luottamustasolle **p** (t√§m√§ voidaan laskea tai katsoa numeerisista taulukoista). Sitten vertaamme t-arvoa t√§h√§n kynnysarvoon hyv√§ksy√§ksemme tai hyl√§t√§ksemme hypoteesin.

Pythonissa voimme k√§ytt√§√§ **SciPy**-kirjastoa, joka sis√§lt√§√§ `ttest_ind`-funktion (monien muiden hy√∂dyllisten tilastollisten funktioiden lis√§ksi!). Se laskee t-arvon puolestamme ja tekee my√∂s k√§√§nteisen luottamustason p-arvon haun, jotta voimme vain katsoa luottamustasoa tehd√§ksemme johtop√§√§t√∂ksen.

Esimerkiksi vertailumme ensimm√§isten ja toisten basemenien pituuksista antaa seuraavat tulokset: 
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
T√§ss√§ tapauksessa p-arvo on hyvin alhainen, mik√§ tarkoittaa, ett√§ on vahvaa n√§ytt√∂√§ siit√§, ett√§ ensimm√§iset basemenit ovat pidempi√§.

On my√∂s muita hypoteeseja, joita voimme haluta testata, esimerkiksi:
* Todistaa, ett√§ annettu otos noudattaa jotain jakaumaa. Esimerkiss√§mme oletimme, ett√§ pituudet ovat normaalijakautuneita, mutta t√§m√§ vaatii muodollisen tilastollisen vahvistuksen.
* Todistaa, ett√§ otoksen keskiarvo vastaa jotain ennalta m√§√§ritelty√§ arvoa
* Verrata useiden otosten keskiarvoja (esim. mik√§ on onnellisuustasojen ero eri ik√§ryhmien v√§lill√§)

## Suurten lukujen laki ja keskeinen raja-arvolause

Yksi syy siihen, miksi normaalijakauma on niin t√§rke√§, on niin sanottu **keskeinen raja-arvolause**. Oletetaan, ett√§ meill√§ on suuri otos riippumattomia N arvoja X<sub>1</sub>, ..., X<sub>N</sub>, jotka on otettu mist√§ tahansa jakaumasta, jonka keskiarvo on Œº ja varianssi œÉ<sup>2</sup>. T√§ll√∂in, kun N on riitt√§v√§n suuri (toisin sanoen kun N‚Üí‚àû), keskiarvo Œ£<sub>i</sub>X<sub>i</sub> on normaalijakautunut, keskiarvolla Œº ja varianssilla œÉ<sup>2</sup>/N.

> Toinen tapa tulkita keskeist√§ raja-arvolausetta on sanoa, ett√§ riippumatta jakaumasta, kun lasket mink√§ tahansa satunnaismuuttujan arvojen summan keskiarvon, p√§√§dyt normaalijakaumaan.

Keskeisest√§ raja-arvolauseesta seuraa my√∂s, ett√§ kun N‚Üí‚àû, otoskeskiarvon todenn√§k√∂isyys olla yht√§ suuri kuin Œº l√§hestyy arvoa 1. T√§t√§ kutsutaan **suurten lukujen laiksi**.

## Kovaranssi ja korrelaatio

Yksi asioista, joita data-analytiikka tekee, on l√∂yt√§√§ yhteyksi√§ datan v√§lill√§. Sanomme, ett√§ kaksi jonoa **korreloivat**, kun ne k√§ytt√§ytyv√§t samankaltaisesti samaan aikaan, eli ne joko nousevat/laskevat samanaikaisesti tai toinen nousee, kun toinen laskee ja p√§invastoin. Toisin sanoen, niiden v√§lill√§ n√§ytt√§√§ olevan jokin yhteys.

> Korrelaatio ei v√§ltt√§m√§tt√§ tarkoita kausaalista suhdetta kahden jonon v√§lill√§; joskus molemmat muuttujat voivat riippua jostain ulkoisesta syyst√§, tai voi olla puhdasta sattumaa, ett√§ kaksi jonoa korreloivat. Kuitenkin vahva matemaattinen korrelaatio on hyv√§ indikaatio siit√§, ett√§ kaksi muuttujaa ovat jollain tavalla yhteydess√§.

Matemaattisesti p√§√§k√§site, joka osoittaa kahden satunnaismuuttujan v√§lisen yhteyden, on **kovarianssi**, joka lasketaan n√§in: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. Laskemme molempien muuttujien poikkeaman niiden keskiarvoista ja sitten n√§iden poikkeamien tulon. Jos molemmat muuttujat poikkeavat yhdess√§, tulo on aina positiivinen arvo, joka lis√§√§ positiivista kovarianssia. Jos molemmat muuttujat poikkeavat ep√§synkronisesti (eli toinen laskee keskiarvon alapuolelle, kun toinen nousee keskiarvon yl√§puolelle), saamme aina negatiivisia lukuja, jotka lis√§√§v√§t negatiivista kovarianssia. Jos poikkeamat eiv√§t ole riippuvaisia, ne summautuvat suunnilleen nollaan.

Kovarianssin itseisarvo ei kerro paljon siit√§, kuinka suuri korrelaatio on, koska se riippuu todellisten arvojen suuruudesta. Normalisoidaksemme sen voimme jakaa kovarianssin molempien muuttujien keskihajonnalla saadaksemme **korrelaation**. Hyv√§ puoli on, ett√§ korrelaatio on aina v√§lill√§ [-1,1], miss√§ 1 tarkoittaa vahvaa positiivista korrelaatiota arvojen v√§lill√§, -1 vahvaa negatiivista korrelaatiota ja 0 ei korrelaatiota lainkaan (muuttujat ovat riippumattomia).

**Esimerkki**: Voimme laskea korrelaation baseball-pelaajien painojen ja pituuksien v√§lill√§ yll√§ mainitusta aineistosta:
```python
print(np.corrcoef(weights,heights))
```
Tuloksena saamme **korrelaatiomatriisin**, joka n√§ytt√§√§ t√§lt√§:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> Korrelaatiomatriisi C voidaan laskea mille tahansa m√§√§r√§lle sy√∂tejonoja S<sub>1</sub>, ..., S<sub>n</sub>. Arvo C<sub>ij</sub> on korrelaatio S<sub>i</sub>:n ja S<sub>j</sub>:n v√§lill√§, ja diagonaalielementit ovat aina 1 (joka on my√∂s S<sub>i</sub>:n itsekorrelaatio).

T√§ss√§ tapauksessa arvo 0.53 osoittaa, ett√§ painon ja pituuden v√§lill√§ on jonkin verran korrelaatiota. Voimme my√∂s tehd√§ hajontakaavion yhdest√§ arvosta toista vastaan n√§hd√§ksesi suhteen visuaalisesti:

![Painon ja pituuden v√§linen suhde](../../../../translated_images/weight-height-relationship.3f06bde4ca2aba9974182c4ef037ed602acd0fbbbbe2ca91cefd838a9e66bcf9.fi.png)

> Lis√§√§ esimerkkej√§ korrelaatiosta ja kovarianssista l√∂ytyy [liitetyss√§ muistikirjassa](notebook.ipynb).

## Yhteenveto

T√§ss√§ osiossa olemme oppineet:

* datan perus tilastollisia ominaisuuksia, kuten keskiarvo, varianssi, moodi ja kvartiilit
* satunnaismuuttujien erilaisia jakaumia, mukaan lukien normaalijakauma
* kuinka l√∂yt√§√§ korrelaatio eri ominaisuuksien v√§lill√§
* kuinka k√§ytt√§√§ matematiikan ja tilastotieteen v√§lineit√§ hypoteesien todistamiseen
* kuinka laskea satunnaismuuttujan luottamusv√§lej√§ annetun otoksen perusteella

Vaikka t√§m√§ ei olekaan kattava lista todenn√§k√∂isyyslaskennan ja tilastotieteen aiheista, sen pit√§isi riitt√§√§ antamaan sinulle hyv√§ l√§ht√∂kohta t√§h√§n kurssiin.

## üöÄ Haaste

K√§yt√§ muistikirjan esimerkkikoodia testataksesi muita hypoteeseja:
1. Ensimm√§iset basemenit ovat vanhempia kuin toiset basemenit
2. Ensimm√§iset basemenit ovat pidempi√§ kuin kolmannet basemenit
3. Shortstopit ovat pidempi√§ kuin toiset basemenit

## [Luennon j√§lkeinen kysely](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/7)

## Kertaus ja itseopiskelu

Todenn√§k√∂isyyslaskenta ja tilastotiede on niin laaja aihe, ett√§ se ansaitsee oman kurssinsa. Jos olet kiinnostunut syventym√§√§n teoriaan, voit jatkaa lukemalla joitakin seuraavista kirjoista:

1. [Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/) New Yorkin yliopistosta on laatinut erinomaiset luentomuistiinpanot [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (saatavilla verkossa)
1. [Peter ja Andrew Bruce. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[esimerkkikoodi R:ss√§](https://github.com/andrewgbruce/statistics-for-data-scientists)]. 
1. [James D. Miller. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[esimerkkikoodi R:ss√§](https://github.com/PacktPublishing/Statistics-for-Data-Science)]

## Teht√§v√§

[Pieni diabetes-tutkimus](assignment.md)

## Kiitokset

T√§m√§n oppitunnin on kirjoittanut ‚ô•Ô∏è:lla [Dmitry Soshnikov](http://soshnikov.com)

---

**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ett√§ automaattiset k√§√§nn√∂kset voivat sis√§lt√§√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§inen asiakirja sen alkuper√§isell√§ kielell√§ tulisi pit√§√§ ensisijaisena l√§hteen√§. Kriittisen tiedon osalta suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa v√§√§rink√§sityksist√§ tai virhetulkinnoista, jotka johtuvat t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§.