<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ce95884566a74db72572cd51f0cb25ad",
  "translation_date": "2025-09-06T13:43:27+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "fi"
}
-->
# Tilastotiede ja todenn√§k√∂isyys: Lyhyt johdanto

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| Tilastotiede ja todenn√§k√∂isyys - _Sketchnote by [@nitya](https://twitter.com/nitya)_ |

Tilastotiede ja todenn√§k√∂isyysteoria ovat kaksi l√§heisesti liittyv√§√§ matematiikan osa-aluetta, jotka ovat eritt√§in t√§rkeit√§ datatieteess√§. Vaikka dataa voi k√§sitell√§ ilman syv√§llist√§ matematiikan tuntemusta, on silti hy√∂dyllist√§ ymm√§rt√§√§ ainakin perusk√§sitteet. T√§ss√§ esittelemme lyhyen johdannon, joka auttaa sinua p√§√§sem√§√§n alkuun.

[![Johdantovideo](../../../../translated_images/video-prob-and-stats.e4282e5efa2f2543400843ed98b1057065c9600cebfc8a728e8931b5702b2ae4.fi.png)](https://youtu.be/Z5Zy85g4Yjw)

## [Esiluentovisa](https://ff-quizzes.netlify.app/en/ds/quiz/6)

## Todenn√§k√∂isyys ja satunnaismuuttujat

**Todenn√§k√∂isyys** on luku v√§lill√§ 0 ja 1, joka ilmaisee, kuinka todenn√§k√∂inen jokin **tapahtuma** on. Se m√§√§ritell√§√§n positiivisten lopputulosten (jotka johtavat tapahtumaan) lukum√§√§r√§n√§ jaettuna kaikkien mahdollisten lopputulosten lukum√§√§r√§ll√§, olettaen ett√§ kaikki lopputulokset ovat yht√§ todenn√§k√∂isi√§. Esimerkiksi, kun heit√§mme noppaa, todenn√§k√∂isyys saada parillinen luku on 3/6 = 0,5.

Kun puhumme tapahtumista, k√§yt√§mme **satunnaismuuttujia**. Esimerkiksi satunnaismuuttuja, joka edustaa nopanheiton tulosta, voi saada arvoja 1‚Äì6. Lukuja 1‚Äì6 kutsutaan **otosavaruudeksi**. Voimme puhua todenn√§k√∂isyydest√§, ett√§ satunnaismuuttuja saa tietyn arvon, esimerkiksi P(X=3)=1/6.

Edell√§ mainittu satunnaismuuttuja on **diskreetti**, koska sen otosavaruus on laskettavissa, eli siin√§ on erillisi√§ arvoja, jotka voidaan luetella. On my√∂s tapauksia, joissa otosavaruus on reaaliarvojen v√§li tai koko reaaliarvojen joukko. T√§llaisia muuttujia kutsutaan **jatkuviksi**. Hyv√§ esimerkki on bussin saapumisaika.

## Todenn√§k√∂isyysjakauma

Diskreettien satunnaismuuttujien tapauksessa on helppo kuvata kunkin tapahtuman todenn√§k√∂isyys funktiolla P(X). Jokaiselle otosavaruuden *S* arvolle *s* se antaa luvun v√§lill√§ 0 ja 1 siten, ett√§ kaikkien tapahtumien P(X=s) arvojen summa on 1.

Tunnetuin diskreetti jakauma on **tasajakauma**, jossa otosavaruudessa on N alkiota, ja jokaisella niist√§ on yht√§ suuri todenn√§k√∂isyys 1/N.

Jatkuvan muuttujan todenn√§k√∂isyysjakauman kuvaaminen on vaikeampaa, kun arvot ovat per√§isin jostakin v√§list√§ [a,b] tai koko reaaliarvojen joukosta ‚Ñù. Mietit√§√§n esimerkiksi bussin saapumisaikaa. Itse asiassa todenn√§k√∂isyys, ett√§ bussi saapuu tarkalleen tiettyn√§ aikana *t*, on 0!

> Nyt tied√§t, ett√§ tapahtumat, joiden todenn√§k√∂isyys on 0, tapahtuvat ‚Äì ja viel√§p√§ usein! Ainakin aina, kun bussi saapuu!

Voimme puhua vain todenn√§k√∂isyydest√§, ett√§ muuttuja osuu tietylle arvojen v√§lille, esim. P(t<sub>1</sub>‚â§X<t<sub>2</sub>). T√§ss√§ tapauksessa todenn√§k√∂isyysjakauma kuvataan **tiheysfunktiolla** p(x), siten ett√§

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../translated_images/probability-density.a8aad29f17a14afb519b407c7b6edeb9f3f9aa5f69c9e6d9445f604e5f8a2bf7.fi.png)

Jatkuvan tasajakauman analogia on **jatkuva tasajakauma**, joka m√§√§ritell√§√§n √§√§relliselle v√§lille. Todenn√§k√∂isyys, ett√§ arvo X osuu pituudeltaan l olevaan v√§liin, on verrannollinen l:n pituuteen ja kasvaa arvoon 1.

Toinen t√§rke√§ jakauma on **normaalijakauma**, josta puhumme tarkemmin my√∂hemmin.

## Keskiarvo, varianssi ja keskihajonta

Oletetaan, ett√§ otamme n n√§ytett√§ satunnaismuuttujasta X: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. Voimme m√§√§ritell√§ **keskiarvon** (tai **aritmeettisen keskiarvon**) perinteisell√§ tavalla: (x<sub>1</sub>+x<sub>2</sub>+...+x<sub>n</sub>)/n. Kun kasvatamme otoksen kokoa (eli otamme rajan n‚Üí‚àû), saamme jakauman keskiarvon (jota kutsutaan my√∂s **odotusarvoksi**). Merkitsemme odotusarvoa **E**(x).

> On osoitettavissa, ett√§ mille tahansa diskreetille jakaumalle, jonka arvot ovat {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} ja vastaavat todenn√§k√∂isyydet p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, odotusarvo on E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>.

Arvojen hajonnan m√§√§ritt√§miseksi voimme laskea varianssin œÉ<sup>2</sup> = ‚àë(x<sub>i</sub> - Œº)<sup>2</sup>/n, miss√§ Œº on otoksen keskiarvo. Arvoa œÉ kutsutaan **keskihajonnaksi**, ja œÉ<sup>2</sup> on **varianssi**.

## Moodi, mediaani ja kvartiilit

Joskus keskiarvo ei kuvaa riitt√§v√§sti "tyypillist√§" arvoa datassa. Esimerkiksi, jos datassa on muutamia √§√§rimm√§isi√§ arvoja, jotka ovat t√§ysin poikkeavia, ne voivat vaikuttaa keskiarvoon. Hyv√§ vaihtoehtoinen mittari on **mediaani**, arvo, jonka alapuolella on puolet datan arvoista ja yl√§puolella toinen puoli.

Datan jakauman ymm√§rt√§miseksi on hy√∂dyllist√§ puhua **kvartiileista**:

* Ensimm√§inen kvartiili eli Q1 on arvo, jonka alapuolella on 25 % datasta
* Kolmas kvartiili eli Q3 on arvo, jonka alapuolella on 75 % datasta

Graafisesti voimme esitt√§√§ mediaanin ja kvartiilien suhteen diagrammissa, jota kutsutaan **laatikko- ja viiksikaavioksi**:

<img src="images/boxplot_explanation.png" alt="Laatikko- ja viiksikaavio" width="50%">

T√§ss√§ laskemme my√∂s **kvartiiliv√§lin** IQR=Q3-Q1 ja niin sanotut **poikkeamat** ‚Äì arvot, jotka ovat alueen [Q1-1.5*IQR, Q3+1.5*IQR] ulkopuolella.

Pienelle diskreetille jakaumalle, jossa on vain v√§h√§n mahdollisia arvoja, hyv√§ "tyypillinen" arvo on yleisin arvo, jota kutsutaan **moodiksi**. Moodia k√§ytet√§√§n usein kategorisessa datassa, kuten v√§reiss√§. Kuvitellaan tilanne, jossa on kaksi ihmisryhm√§√§ ‚Äì toiset suosivat vahvasti punaista ja toiset sinist√§. Jos koodaisimme v√§rit numeroilla, suosikkiv√§rin keskiarvo olisi jossain oranssin ja vihre√§n v√§lill√§, mik√§ ei kuvasta kummankaan ryhm√§n todellista mieltymyst√§. Moodi sen sijaan olisi joko punainen tai sininen, tai molemmat, jos molempien v√§rien kannattajia on yht√§ paljon (t√§ss√§ tapauksessa otosta kutsutaan **monimodaaliseksi**).

## Reaaliaikainen data

Kun analysoimme tosiel√§m√§n dataa, ne eiv√§t usein ole varsinaisia satunnaismuuttujia siin√§ mieless√§, ett√§ emme suorita kokeita tuntemattomilla tuloksilla. Esimerkiksi, jos tarkastelemme baseball-pelaajien joukkueen kehon mittoja, kuten pituutta, painoa ja ik√§√§, n√§m√§ luvut eiv√§t ole t√§ysin satunnaisia, mutta voimme silti soveltaa samoja matemaattisia k√§sitteit√§. Esimerkiksi ihmisten painojen sarjaa voidaan pit√§√§ satunnaismuuttujan arvojen sarjana. Alla on sarja painoja todellisilta baseball-pelaajilta [Major League Baseballista](http://mlb.mlb.com/index.jsp), otettuna [t√§st√§ datasetist√§](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) (mukavuussyist√§ vain ensimm√§iset 20 arvoa on n√§ytetty):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Huomio**: Katso esimerkki t√§m√§n datasetin k√§sittelyst√§ [liitteen√§ olevasta muistikirjasta](notebook.ipynb). T√§ss√§ oppitunnissa on my√∂s useita haasteita, jotka voit suorittaa lis√§√§m√§ll√§ koodia muistikirjaan. Jos et ole varma, miten dataa k√§sitell√§√§n, √§l√§ huoli ‚Äì palaamme datan k√§sittelyyn Pythonilla my√∂hemmin. Jos et tied√§, miten suorittaa koodia Jupyter Notebookissa, katso [t√§m√§ artikkeli](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

T√§ss√§ on laatikko- ja viiksikaavio, joka n√§ytt√§√§ datamme keskiarvon, mediaanin ja kvartiilit:

![Painon laatikko- ja viiksikaavio](../../../../translated_images/weight-boxplot.1dbab1c03af26f8a008fff4e17680082c8ab147d6df646cbac440bbf8f5b9c42.fi.png)

Koska datamme sis√§lt√§√§ tietoa eri pelaajien **rooleista**, voimme my√∂s tehd√§ laatikko- ja viiksikaavion roolin mukaan ‚Äì t√§m√§ antaa k√§sityksen siit√§, miten parametrien arvot vaihtelevat roolien v√§lill√§. T√§ll√§ kertaa tarkastelemme pituutta:

![Laatikko- ja viiksikaavio roolin mukaan](../../../../translated_images/boxplot_byrole.036b27a1c3f52d42f66fba2324ec5cde0a1bca6a01a619eeb0ce7cd054b2527b.fi.png)

T√§m√§ diagrammi viittaa siihen, ett√§ ensimm√§isen pes√§miehen keskim√§√§r√§inen pituus on suurempi kuin toisen pes√§miehen. My√∂hemmin t√§ss√§ oppitunnissa opimme, kuinka voimme testata t√§t√§ hypoteesia muodollisemmin ja osoittaa, ett√§ datamme on tilastollisesti merkitt√§v√§√§ t√§m√§n osoittamiseksi.

> Kun ty√∂skentelemme tosiel√§m√§n datan kanssa, oletamme, ett√§ kaikki datapisteet ovat otoksia jostakin todenn√§k√∂isyysjakaumasta. T√§m√§ oletus mahdollistaa koneoppimistekniikoiden soveltamisen ja toimivien ennustemallien rakentamisen.

Jotta voimme n√§hd√§, millainen datamme jakauma on, voimme piirt√§√§ kaavion, jota kutsutaan **histogrammiksi**. X-akselilla on eri painov√§lien lukum√§√§r√§ (niin sanotut **bin**-arvot), ja pystyakselilla n√§ytet√§√§n, kuinka monta kertaa satunnaismuuttujan otos osui tiettyyn v√§liin.

![Reaaliaikaisen datan histogrammi](../../../../translated_images/weight-histogram.bfd00caf7fc30b145b21e862dba7def41c75635d5280de25d840dd7f0b00545e.fi.png)

T√§st√§ histogrammista n√§et, ett√§ kaikki arvot keskittyv√§t tietyn keskipainon ymp√§rille, ja mit√§ kauemmas keskipainosta menn√§√§n, sit√§ harvemmin kyseisen painon arvoja esiintyy. Toisin sanoen on hyvin ep√§todenn√§k√∂ist√§, ett√§ baseball-pelaajan paino poikkeaisi merkitt√§v√§sti keskipainosta. Painojen varianssi osoittaa, kuinka paljon painot todenn√§k√∂isesti eroavat keskiarvosta.

> Jos ottaisimme painoja muilta ihmisilt√§, jotka eiv√§t kuulu baseball-liigaan, jakauma olisi todenn√§k√∂isesti erilainen. Jakauman muoto olisi kuitenkin sama, mutta keskiarvo ja varianssi muuttuisivat. Jos siis koulutamme mallimme baseball-pelaajilla, se todenn√§k√∂isesti antaa v√§√§ri√§ tuloksia, kun sit√§ sovelletaan esimerkiksi yliopisto-opiskelijoihin, koska taustalla oleva jakauma on erilainen.

## Normaalijakauma

Painojen jakauma, jonka n√§imme yll√§, on hyvin tyypillinen, ja monet tosiel√§m√§n mittaukset noudattavat samaa jakaumatyyppi√§, mutta eri keskiarvolla ja varianssilla. T√§t√§ jakaumaa kutsutaan **normaalijakaumaksi**, ja sill√§ on eritt√§in t√§rke√§ rooli tilastotieteess√§.

Normaalijakauman k√§ytt√§minen on oikea tapa luoda satunnaisia painoja mahdollisille baseball-pelaajille. Kun tied√§mme keskipainon `mean` ja keskihajonnan `std`, voimme luoda 1000 painon√§ytett√§ seuraavasti:
```python
samples = np.random.normal(mean,std,1000)
```

Jos piirr√§mme histogrammin luoduista n√§ytteist√§, n√§emme kuvan, joka on hyvin samanlainen kuin yll√§ oleva. Ja jos lis√§√§mme n√§ytteiden ja binien m√§√§r√§√§, voimme luoda normaalijakauman kuvan, joka on l√§hemp√§n√§ ideaalia:

![Normaalijakauma, keskiarvo=0 ja keskihajonta=1](../../../../translated_images/normal-histogram.dfae0d67c202137d552d0015fb87581eca263925e512404f3c12d8885315432e.fi.png)

*Normaalijakauma, keskiarvo=0 ja keskihajonta=1*

## Luottamusv√§lit

Kun puhumme baseball-pelaajien painoista, oletamme, ett√§ on olemassa tietty **satunnaismuuttuja W**, joka vastaa painojen ideaalista todenn√§k√∂isyysjakaumaa kaikille baseball-pelaajille (niin sanottu **populaatio**). Painojemme sarja vastaa otosta kaikista baseball-pelaajista, jota kutsumme **otokseksi**. Mielenkiintoinen kysymys on, voimmeko tiet√§√§ W:n jakauman parametrit, eli populaation keskiarvon ja varianssin?

Helpoin vastaus olisi laskea otoksen keskiarvo ja varianssi. Kuitenkin voi k√§yd√§ niin, ett√§ satunnainen otoksemme ei tarkasti edusta koko populaatiota. Siksi on j√§rkev√§√§ puhua **luottamusv√§list√§**.

> **Luottamusv√§li** on arvio populaation todellisesta keskiarvosta otoksemme perusteella, ja se on tarkka tietyll√§ todenn√§k√∂isyydell√§ (tai **luottamustasolla**).

Oletetaan, ett√§ meill√§ on otos X...

1</sub>, ..., X<sub>n</sub> otoksestamme. Joka kerta, kun otamme otoksen jakaumastamme, saamme eri keskiarvon Œº. N√§in ollen Œº voidaan pit√§√§ satunnaismuuttujana. **Luottamusv√§li** luottamustasolla p on arvojen pari (L<sub>p</sub>,R<sub>p</sub>), siten ett√§ **P**(L<sub>p</sub>‚â§Œº‚â§R<sub>p</sub>) = p, eli todenn√§k√∂isyys, ett√§ mitattu keskiarvo osuu v√§lin sis√§√§n, on p.

On t√§m√§n lyhyen johdannon ulkopuolella k√§sitell√§ yksityiskohtaisesti, miten n√§m√§ luottamusv√§lit lasketaan. Lis√§tietoja l√∂ytyy [Wikipediasta](https://en.wikipedia.org/wiki/Confidence_interval). Lyhyesti sanottuna m√§√§rittelemme lasketun otoskeskiarvon jakauman suhteessa populaation todelliseen keskiarvoon, jota kutsutaan **Studentin jakaumaksi**.

> **Mielenkiintoinen fakta**: Studentin jakauma on nimetty matemaatikko William Sealy Gossetin mukaan, joka julkaisi tutkimuksensa salanimell√§ "Student". H√§n ty√∂skenteli Guinnessin panimossa, ja er√§√§n version mukaan h√§nen ty√∂nantajansa ei halunnut yleis√∂n tiet√§v√§n, ett√§ he k√§yttiv√§t tilastollisia testej√§ raaka-aineiden laadun m√§√§ritt√§miseen.

Jos haluamme arvioida populaation keskiarvon Œº luottamustasolla p, meid√§n on otettava *(1-p)/2-prosenttipiste* Studentin jakaumasta A, joka voidaan joko hakea taulukoista tai laskea tilasto-ohjelmistojen sis√§√§nrakennetuilla funktioilla (esim. Python, R jne.). T√§ll√∂in Œº:n v√§li olisi X¬±A*D/‚àön, miss√§ X on otoksen saatu keskiarvo ja D on keskihajonta.

> **Huomio**: Ohitamme my√∂s t√§rke√§n k√§sitteen [vapausasteet](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)), joka on merkityksellinen Studentin jakauman yhteydess√§. Voit perehty√§ syv√§llisemmin t√§h√§n k√§sitteeseen t√§ydellisemmist√§ tilastotieteen kirjoista.

Esimerkki painojen ja pituuksien luottamusv√§lin laskemisesta l√∂ytyy [liitteen√§ olevista muistikirjoista](notebook.ipynb).

| p | Painon keskiarvo |
|-----|----------------|
| 0.85 | 201.73¬±0.94 |
| 0.90 | 201.73¬±1.08 |
| 0.95 | 201.73¬±1.28 |

Huomaa, ett√§ mit√§ korkeampi luottamustodenn√§k√∂isyys, sit√§ laajempi luottamusv√§li.

## Hypoteesin testaus

Baseball-pelaajien aineistossamme on erilaisia pelaajarooleja, jotka voidaan tiivist√§√§ seuraavasti (katso [liitteen√§ oleva muistikirja](notebook.ipynb), miten t√§m√§ taulukko on laskettu):

| Rooli | Pituus | Paino | Lukum√§√§r√§ |
|-------|--------|-------|-----------|
| Catcher | 72.723684 | 204.328947 | 76 |
| Designated_Hitter | 74.222222 | 220.888889 | 18 |
| First_Baseman | 74.000000 | 213.109091 | 55 |
| Outfielder | 73.010309 | 199.113402 | 194 |
| Relief_Pitcher | 74.374603 | 203.517460 | 315 |
| Second_Baseman | 71.362069 | 184.344828 | 58 |
| Shortstop | 71.903846 | 182.923077 | 52 |
| Starting_Pitcher | 74.719457 | 205.163636 | 221 |
| Third_Baseman | 73.044444 | 200.955556 | 45 |

Voimme huomata, ett√§ ensimm√§isten basemenien keskipituus on suurempi kuin toisten basemenien. N√§in ollen voimme olla taipuvaisia p√§√§ttelem√§√§n, ett√§ **ensimm√§iset basemenit ovat pidempi√§ kuin toiset basemenit**.

> T√§t√§ v√§itett√§ kutsutaan **hypoteesiksi**, koska emme tied√§, onko se tosiasiallisesti totta vai ei.

Kuitenkin ei ole aina ilmeist√§, voimmeko tehd√§ t√§m√§n johtop√§√§t√∂ksen. Kuten edell√§ keskustelimme, jokaisella keskiarvolla on siihen liittyv√§ luottamusv√§li, ja n√§in ollen t√§m√§ ero voi olla vain tilastollinen virhe. Tarvitsemme muodollisemman tavan testata hypoteesimme.

Lasketaan luottamusv√§lit erikseen ensimm√§isten ja toisten basemenien pituuksille:

| Luottamus | Ensimm√§iset basemenit | Toiset basemenit |
|-----------|-----------------------|------------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

Voimme n√§hd√§, ett√§ miss√§√§n luottamustasossa v√§lit eiv√§t mene p√§√§llekk√§in. T√§m√§ todistaa hypoteesimme, ett√§ ensimm√§iset basemenit ovat pidempi√§ kuin toiset basemenit.

Muodollisemmin, ratkaisemamme ongelma on n√§hd√§, ovatko **kaksi todenn√§k√∂isyysjakaumaa samoja**, tai ainakin onko niill√§ samat parametrit. Riippuen jakaumasta, meid√§n on k√§ytett√§v√§ erilaisia testej√§. Jos tied√§mme, ett√§ jakaumamme ovat normaalijakaumia, voimme soveltaa **[Studentin t-testi√§](https://en.wikipedia.org/wiki/Student%27s_t-test)**.

Studentin t-testiss√§ laskemme niin sanotun **t-arvon**, joka osoittaa keskiarvojen eron ottaen huomioon varianssin. On osoitettu, ett√§ t-arvo noudattaa **Studentin jakaumaa**, mik√§ mahdollistaa kynnysarvon saamisen annetulle luottamustasolle **p** (t√§m√§ voidaan laskea tai katsoa numeerisista taulukoista). Vertaillemme sitten t-arvoa t√§h√§n kynnysarvoon hypoteesin hyv√§ksymiseksi tai hylk√§√§miseksi.

Pythonissa voimme k√§ytt√§√§ **SciPy**-kirjastoa, joka sis√§lt√§√§ `ttest_ind`-funktion (sek√§ monia muita hy√∂dyllisi√§ tilastollisia funktioita!). Se laskee t-arvon puolestamme ja tekee my√∂s k√§√§nteisen luottamustason p-arvon haun, joten voimme vain tarkastella luottamustasoa johtop√§√§t√∂ksen tekemiseksi.

Esimerkiksi vertailumme ensimm√§isten ja toisten basemenien pituuksista antaa seuraavat tulokset: 
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
T√§ss√§ tapauksessa p-arvo on eritt√§in pieni, mik√§ tarkoittaa, ett√§ on vahvaa n√§ytt√∂√§ siit√§, ett√§ ensimm√§iset basemenit ovat pidempi√§.

On my√∂s muita hypoteeseja, joita voimme testata, esimerkiksi:
* Todistaa, ett√§ annettu otos noudattaa jotain jakaumaa. Esimerkiss√§mme oletimme, ett√§ pituudet ovat normaalijakautuneita, mutta t√§m√§ vaatii muodollisen tilastollisen vahvistuksen.
* Todistaa, ett√§ otoksen keskiarvo vastaa jotain ennalta m√§√§ritelty√§ arvoa.
* Verrata useiden otosten keskiarvoja (esim. mik√§ on onnellisuustasojen ero eri ik√§ryhmien v√§lill√§).

## Suurten lukujen laki ja keskeinen raja-arvolause

Yksi syy, miksi normaalijakauma on niin t√§rke√§, on niin sanottu **keskeinen raja-arvolause**. Oletetaan, ett√§ meill√§ on suuri otos riippumattomia N arvoja X<sub>1</sub>, ..., X<sub>N</sub>, jotka on otettu mist√§ tahansa jakaumasta, jonka keskiarvo on Œº ja varianssi œÉ<sup>2</sup>. T√§ll√∂in, kun N on riitt√§v√§n suuri (toisin sanoen, kun N‚Üí‚àû), keskiarvo Œ£<sub>i</sub>X<sub>i</sub> on normaalijakautunut, keskiarvolla Œº ja varianssilla œÉ<sup>2</sup>/N.

> Toinen tapa tulkita keskeist√§ raja-arvolausetta on sanoa, ett√§ riippumatta jakaumasta, kun lasket mink√§ tahansa satunnaismuuttujan arvojen summan keskiarvon, p√§√§dyt normaalijakaumaan.

Keskeisest√§ raja-arvolauseesta seuraa my√∂s, ett√§ kun N‚Üí‚àû, otoskeskiarvon todenn√§k√∂isyys olla yht√§ suuri kuin Œº l√§hestyy arvoa 1. T√§t√§ kutsutaan **suurten lukujen laiksi**.

## Kovaranssi ja korrelaatio

Yksi datatieteen teht√§vist√§ on l√∂yt√§√§ yhteyksi√§ datan v√§lill√§. Sanomme, ett√§ kaksi sarjaa **korreloivat**, kun ne k√§ytt√§ytyv√§t samankaltaisesti samaan aikaan, eli ne joko nousevat/laskevat samanaikaisesti tai toinen sarja nousee, kun toinen laskee ja p√§invastoin. Toisin sanoen, sarjojen v√§lill√§ n√§ytt√§√§ olevan jokin yhteys.

> Korrelaatio ei v√§ltt√§m√§tt√§ tarkoita kausaalista suhdetta kahden sarjan v√§lill√§; joskus molemmat muuttujat voivat riippua jostain ulkoisesta syyst√§, tai voi olla t√§ysin sattumaa, ett√§ kaksi sarjaa korreloivat. Kuitenkin vahva matemaattinen korrelaatio on hyv√§ osoitus siit√§, ett√§ kaksi muuttujaa ovat jollain tavalla yhteydess√§.

Matemaattisesti p√§√§k√§site, joka osoittaa kahden satunnaismuuttujan v√§lisen suhteen, on **kovarianssi**, joka lasketaan seuraavasti: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. Laskemme molempien muuttujien poikkeaman niiden keskiarvoista ja sitten n√§iden poikkeamien tulon. Jos molemmat muuttujat poikkeavat yhdess√§, tulo on aina positiivinen, mik√§ johtaa positiiviseen kovarianssiin. Jos molemmat muuttujat poikkeavat ep√§synkronisesti (eli toinen laskee keskiarvon alapuolelle, kun toinen nousee keskiarvon yl√§puolelle), saamme aina negatiivisia lukuja, jotka johtavat negatiiviseen kovarianssiin. Jos poikkeamat eiv√§t ole riippuvaisia, ne summautuvat suunnilleen nollaan.

Kovarianssin itseisarvo ei kerro paljon korrelaation voimakkuudesta, koska se riippuu todellisten arvojen suuruudesta. Normalisoidaksemme sen voimme jakaa kovarianssin molempien muuttujien keskihajonnalla saadaksemme **korrelaation**. Hyv√§ puoli on, ett√§ korrelaatio on aina v√§lill√§ [-1,1], miss√§ 1 tarkoittaa vahvaa positiivista korrelaatiota, -1 vahvaa negatiivista korrelaatiota ja 0 ei korrelaatiota ollenkaan (muuttujat ovat riippumattomia).

**Esimerkki**: Voimme laskea korrelaation baseball-pelaajien painojen ja pituuksien v√§lill√§ yll√§ mainitusta aineistosta:
```python
print(np.corrcoef(weights,heights))
```
Tuloksena saamme **korrelaatiomatriisin**, joka n√§ytt√§√§ t√§lt√§:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> Korrelaatiomatriisi C voidaan laskea mille tahansa m√§√§r√§lle sy√∂tteit√§ S<sub>1</sub>, ..., S<sub>n</sub>. Arvo C<sub>ij</sub> on korrelaatio S<sub>i</sub>:n ja S<sub>j</sub>:n v√§lill√§, ja diagonaalielementit ovat aina 1 (itsekorrelaatio S<sub>i</sub>:lle).

T√§ss√§ tapauksessa arvo 0.53 osoittaa, ett√§ henkil√∂n painon ja pituuden v√§lill√§ on jonkin verran korrelaatiota. Voimme my√∂s tehd√§ hajontakaavion yhdest√§ arvosta toista vastaan n√§hd√§ksesi suhteen visuaalisesti:

![Painon ja pituuden suhde](../../../../translated_images/weight-height-relationship.3f06bde4ca2aba9974182c4ef037ed602acd0fbbbbe2ca91cefd838a9e66bcf9.fi.png)

> Lis√§√§ esimerkkej√§ korrelaatiosta ja kovarianssista l√∂ytyy [liitteen√§ olevasta muistikirjasta](notebook.ipynb).

## Yhteenveto

T√§ss√§ osiossa opimme:

* datan perus tilastolliset ominaisuudet, kuten keskiarvo, varianssi, moodi ja kvartiilit
* satunnaismuuttujien erilaiset jakaumat, mukaan lukien normaalijakauma
* kuinka l√∂yt√§√§ korrelaatio eri ominaisuuksien v√§lill√§
* kuinka k√§ytt√§√§ matemaattisia ja tilastollisia menetelmi√§ hypoteesien todistamiseen
* kuinka laskea satunnaismuuttujan luottamusv√§lit annetusta otoksesta

Vaikka t√§m√§ ei olekaan tyhjent√§v√§ luettelo todenn√§k√∂isyyslaskennan ja tilastotieteen aiheista, sen pit√§isi antaa sinulle hyv√§ l√§ht√∂kohta t√§h√§n kurssiin.

## üöÄ Haaste

K√§yt√§ muistikirjan esimerkkikoodia testataksesi muita hypoteeseja:
1. Ensimm√§iset basemenit ovat vanhempia kuin toiset basemenit
2. Ensimm√§iset basemenit ovat pidempi√§ kuin kolmannet basemenit
3. Shortstopit ovat pidempi√§ kuin toiset basemenit

## [Luennon j√§lkeinen kysely](https://ff-quizzes.netlify.app/en/ds/quiz/7)

## Kertaus ja itseopiskelu

Todenn√§k√∂isyyslaskenta ja tilastotiede on niin laaja aihe, ett√§ se ansaitsee oman kurssinsa. Jos haluat syventy√§ teoriaan, voit jatkaa lukemista seuraavista kirjoista:

1. [Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/) New Yorkin yliopistosta on laatinut erinomaiset luentomuistiinpanot [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (saatavilla verkossa).
2. [Peter ja Andrew Bruce. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[esimerkkikoodi R:ll√§](https://github.com/andrewgbruce/statistics-for-data-scientists)].
3. [James D. Miller. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[esimerkkikoodi R:ll√§](https://github.com/PacktPublishing/Statistics-for-Data-Science)].

## Teht√§v√§

[Pieni diabetes-tutkimus](assignment.md)

## Kiitokset

T√§m√§n oppitunnin on laatinut ‚ô•Ô∏è:lla [Dmitry Soshnikov](http://soshnikov.com).

---

**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ett√§ automaattiset k√§√§nn√∂kset voivat sis√§lt√§√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§ist√§ asiakirjaa sen alkuper√§isell√§ kielell√§ tulee pit√§√§ ensisijaisena l√§hteen√§. Kriittisen tiedon osalta suositellaan ammattimaista ihmisk√§√§nt√§mist√§. Emme ole vastuussa v√§√§rink√§sityksist√§ tai virhetulkinnoista, jotka johtuvat t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§.