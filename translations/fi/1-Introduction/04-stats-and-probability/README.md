<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1cf49f029ba1f25a54f0d5bc2fa575fc",
  "translation_date": "2025-09-05T22:47:04+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "fi"
}
-->
# Lyhyt johdatus tilastotieteeseen ja todenn√§k√∂isyyksiin

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| Tilastotiede ja todenn√§k√∂isyydet - _Sketchnote by [@nitya](https://twitter.com/nitya)_ |

Tilastotiede ja todenn√§k√∂isyysteoria ovat kaksi l√§heisesti toisiinsa liittyv√§√§ matematiikan osa-aluetta, jotka ovat eritt√§in merkityksellisi√§ datatieteess√§. Vaikka dataa voi k√§sitell√§ ilman syv√§llist√§ matematiikan tuntemusta, on silti hy√∂dyllist√§ ymm√§rt√§√§ ainakin perusk√§sitteet. T√§ss√§ esittelemme lyhyen johdannon, joka auttaa sinua p√§√§sem√§√§n alkuun.

[![Intro Video](../../../../1-Introduction/04-stats-and-probability/images/video-prob-and-stats.png)](https://youtu.be/Z5Zy85g4Yjw)

## [Ennakkokysely ennen luentoa](https://ff-quizzes.netlify.app/en/ds/quiz/6)

## Todenn√§k√∂isyys ja satunnaismuuttujat

**Todenn√§k√∂isyys** on luku v√§lill√§ 0 ja 1, joka ilmaisee, kuinka todenn√§k√∂inen jokin **tapahtuma** on. Se m√§√§ritell√§√§n positiivisten lopputulosten (jotka johtavat tapahtumaan) lukum√§√§r√§n√§ jaettuna kaikkien lopputulosten lukum√§√§r√§ll√§, olettaen ett√§ kaikki lopputulokset ovat yht√§ todenn√§k√∂isi√§. Esimerkiksi, kun heit√§mme noppaa, todenn√§k√∂isyys saada parillinen luku on 3/6 = 0.5.

Kun puhumme tapahtumista, k√§yt√§mme **satunnaismuuttujia**. Esimerkiksi satunnaismuuttuja, joka edustaa nopanheiton tulosta, voi saada arvoja v√§lill√§ 1‚Äì6. Lukuja 1‚Äì6 kutsutaan **otosavaruudeksi**. Voimme puhua satunnaismuuttujan todenn√§k√∂isyydest√§ saada tietty arvo, esimerkiksi P(X=3)=1/6.

Edell√§ mainittu satunnaismuuttuja on **diskreetti**, koska sen otosavaruus on laskettavissa, eli siin√§ on erillisi√§ arvoja, jotka voidaan luetella. On my√∂s tapauksia, joissa otosavaruus on reaaliarvojen v√§li tai koko reaaliarvojen joukko. T√§llaisia muuttujia kutsutaan **jatkuviksi**. Hyv√§ esimerkki on bussin saapumisaika.

## Todenn√§k√∂isyysjakauma

Diskreettien satunnaismuuttujien tapauksessa on helppo kuvata kunkin tapahtuman todenn√§k√∂isyys funktiolla P(X). Jokaiselle otosavaruuden *S* arvolle *s* funktio antaa luvun v√§lill√§ 0 ja 1, siten ett√§ kaikkien P(X=s) arvojen summa on 1.

Tunnetuin diskreetti jakauma on **tasajakauma**, jossa otosavaruudessa on N elementti√§, ja jokaisen elementin todenn√§k√∂isyys on 1/N.

Jatkuvan muuttujan todenn√§k√∂isyysjakauman kuvaaminen on vaikeampaa, kun arvot ovat per√§isin jostain v√§list√§ [a,b] tai koko reaaliarvojen joukosta ‚Ñù. Mietit√§√§n esimerkiksi bussin saapumisaikaa. Todellisuudessa todenn√§k√∂isyys, ett√§ bussi saapuu t√§sm√§lleen tiettyn√§ aikana *t*, on 0!

> Nyt tied√§t, ett√§ tapahtumat, joiden todenn√§k√∂isyys on 0, tapahtuvat ‚Äì ja viel√§p√§ usein! Ainakin joka kerta, kun bussi saapuu!

Voimme puhua vain todenn√§k√∂isyydest√§, ett√§ muuttuja osuu tiettyyn arvojen v√§liin, esim. P(t<sub>1</sub>‚â§X<t<sub>2</sub>). T√§ss√§ tapauksessa todenn√§k√∂isyysjakauma kuvataan **todenn√§k√∂isyystiheysfunktiolla** p(x), siten ett√§

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../1-Introduction/04-stats-and-probability/images/probability-density.png)

Jatkuvan tasajakauman analogi on **jatkuva tasajakauma**, joka m√§√§ritell√§√§n rajallisella v√§lill√§. Todenn√§k√∂isyys, ett√§ arvo X osuu v√§liin, jonka pituus on l, on verrannollinen l:√§√§n ja kasvaa arvoon 1.

Toinen t√§rke√§ jakauma on **normaalijakauma**, josta puhumme tarkemmin my√∂hemmin.

## Keskiarvo, varianssi ja keskihajonta

Oletetaan, ett√§ otamme satunnaismuuttujasta X n n√§ytett√§: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. Voimme m√§√§ritell√§ **keskiarvon** (tai **aritmeettisen keskiarvon**) perinteisell√§ tavalla: (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n. Kun kasvatamme otoksen kokoa (eli otamme rajan n‚Üí‚àû), saamme jakauman keskiarvon (jota kutsutaan my√∂s **odotusarvoksi**). Merkitsemme odotusarvoa **E**(x).

> On osoitettu, ett√§ mille tahansa diskreetille jakaumalle, jonka arvot ovat {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} ja vastaavat todenn√§k√∂isyydet p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, odotusarvo on E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>.

Arvojen hajonnan tunnistamiseksi voimme laskea varianssin œÉ<sup>2</sup> = ‚àë(x<sub>i</sub> - Œº)<sup>2</sup>/n, miss√§ Œº on otoksen keskiarvo. Arvoa œÉ kutsutaan **keskihajonnaksi**, ja œÉ<sup>2</sup> on **varianssi**.

## Moodi, mediaani ja kvartiilit

Joskus keskiarvo ei kuvaa riitt√§v√§n hyvin "tyypillist√§" arvoa datalle. Esimerkiksi, jos datassa on muutama √§√§rimm√§inen arvo, ne voivat vaikuttaa keskiarvoon. Toinen hyv√§ indikaattori on **mediaani**, arvo, jonka alapuolella on puolet datan pisteist√§ ja yl√§puolella toinen puoli.

Datan jakauman ymm√§rt√§miseksi on hy√∂dyllist√§ puhua **kvartiileista**:

* Ensimm√§inen kvartiili, eli Q1, on arvo, jonka alapuolella on 25 % datasta
* Kolmas kvartiili, eli Q3, on arvo, jonka alapuolella on 75 % datasta

Graafisesti voimme kuvata mediaanin ja kvartiilien suhdetta diagrammilla, jota kutsutaan **laatikko-kaavioksi**:

<img src="images/boxplot_explanation.png" width="50%"/>

T√§ss√§ laskemme my√∂s **kvartiiliv√§lin** IQR=Q3-Q1 ja niin sanotut **poikkeamat** ‚Äì arvot, jotka ovat alueen [Q1-1.5*IQR,Q3+1.5*IQR] ulkopuolella.

Pienelle diskreetille jakaumalle, jossa on vain muutama mahdollinen arvo, hyv√§ "tyypillinen" arvo on se, joka esiintyy useimmin, ja sit√§ kutsutaan **moodiksi**. Moodia k√§ytet√§√§n usein kategoriselle datalle, kuten v√§reille. Mietit√§√§n tilannetta, jossa meill√§ on kaksi ryhm√§√§ ihmisi√§ ‚Äì osa suosii vahvasti punaista ja osa sinist√§. Jos koodaisimme v√§rit numeroilla, keskiarvo suosikkiv√§rille olisi jossain oranssin ja vihre√§n v√§lill√§, mik√§ ei kuvaisi kummankaan ryhm√§n todellista mieltymyst√§. Moodi sen sijaan olisi joko yksi v√§reist√§ tai molemmat, jos niiden kannattajien m√§√§r√§ on sama (t√§ss√§ tapauksessa otosta kutsutaan **multimodaaliseksi**).

## Reaaliaikainen data

Kun analysoimme tosiel√§m√§n dataa, ne eiv√§t usein ole varsinaisia satunnaismuuttujia siin√§ mieless√§, ett√§ emme tee kokeita tuntemattomalla tuloksella. Esimerkiksi, mietit√§√§n baseball-joukkueen pelaajia ja heid√§n kehon tietojaan, kuten pituutta, painoa ja ik√§√§. N√§m√§ luvut eiv√§t ole t√§ysin satunnaisia, mutta voimme silti soveltaa samoja matemaattisia k√§sitteit√§. Esimerkiksi ihmisten painojen sarjaa voidaan pit√§√§ satunnaismuuttujasta otettuna arvosarjana. Alla on Major League Baseball -pelaajien painojen sarja, joka on otettu [t√§st√§ datasetist√§](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) (mukavuuden vuoksi vain ensimm√§iset 20 arvoa n√§ytet√§√§n):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Huomio**: Katso esimerkki t√§m√§n datasetin k√§sittelyst√§ [liitteen√§ olevasta muistikirjasta](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb). T√§ss√§ oppitunnissa on my√∂s useita haasteita, jotka voit suorittaa lis√§√§m√§ll√§ koodia muistikirjaan. Jos et ole varma, miten dataa k√§sitell√§√§n, √§l√§ huoli ‚Äì palaamme datan k√§sittelyyn Pythonilla my√∂hemmin. Jos et tied√§, miten suorittaa koodia Jupyter Notebookissa, katso [t√§m√§ artikkeli](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

T√§ss√§ on laatikko-kaavio, joka n√§ytt√§√§ datan keskiarvon, mediaanin ja kvartiilit:

![Painon laatikko-kaavio](../../../../1-Introduction/04-stats-and-probability/images/weight-boxplot.png)

Koska datamme sis√§lt√§√§ tietoa eri pelaajien **rooleista**, voimme my√∂s tehd√§ laatikko-kaavion roolin mukaan ‚Äì t√§m√§ antaa meille k√§sityksen siit√§, miten parametrit eroavat roolien v√§lill√§. T√§ll√§ kertaa tarkastelemme pituutta:

![Laatikko-kaavio roolin mukaan](../../../../1-Introduction/04-stats-and-probability/images/boxplot_byrole.png)

T√§m√§ diagrammi viittaa siihen, ett√§ keskim√§√§rin ensimm√§isen pes√§n pelaajien pituus on suurempi kuin toisen pes√§n pelaajien pituus. My√∂hemmin t√§ss√§ oppitunnissa opimme, miten voimme testata t√§t√§ hypoteesia muodollisemmin ja miten voimme osoittaa, ett√§ datamme on tilastollisesti merkitt√§v√§√§ t√§m√§n osoittamiseksi.

> Kun ty√∂skentelemme tosiel√§m√§n datan kanssa, oletamme, ett√§ kaikki datapisteet ovat otoksia jostain todenn√§k√∂isyysjakaumasta. T√§m√§ oletus mahdollistaa koneoppimistekniikoiden soveltamisen ja toimivien ennustemallien rakentamisen.

Jotta voimme n√§hd√§, millainen datamme jakauma on, voimme piirt√§√§ diagrammin, jota kutsutaan **histogrammiksi**. X-akselilla on eri painov√§lien lukum√§√§r√§ (niin sanotut **binssit**), ja pystyakseli n√§ytt√§√§, kuinka monta kertaa satunnaismuuttujan otos osui tiettyyn v√§liin.

![Reaaliaikaisen datan histogrammi](../../../../1-Introduction/04-stats-and-probability/images/weight-histogram.png)

T√§st√§ histogrammista n√§et, ett√§ kaikki arvot keskittyv√§t tietyn keskim√§√§r√§isen painon ymp√§rille, ja mit√§ kauemmas keskiarvosta menn√§√§n, sit√§ harvemmin kyseist√§ painoa esiintyy. Eli on hyvin ep√§todenn√§k√∂ist√§, ett√§ baseball-pelaajan paino poikkeaisi merkitt√§v√§sti keskiarvosta. Painojen varianssi osoittaa, kuinka paljon painot todenn√§k√∂isesti eroavat keskiarvosta.

> Jos otamme muiden ihmisten painoja, jotka eiv√§t ole baseball-liigasta, jakauma on todenn√§k√∂isesti erilainen. Jakauman muoto pysyy kuitenkin samana, mutta keskiarvo ja varianssi muuttuvat. Jos siis koulutamme mallimme baseball-pelaajilla, se todenn√§k√∂isesti antaa v√§√§ri√§ tuloksia, kun sit√§ sovelletaan yliopisto-opiskelijoihin, koska taustalla oleva jakauma on erilainen.

## Normaalijakauma

Painojen jakauma, jonka n√§imme yll√§, on hyvin tyypillinen, ja monet tosiel√§m√§n mittaukset noudattavat samaa tyyppist√§ jakaumaa, mutta eri keskiarvolla ja varianssilla. T√§t√§ jakaumaa kutsutaan **normaalijakaumaksi**, ja sill√§ on eritt√§in t√§rke√§ rooli tilastotieteess√§.

Normaalijakauman k√§ytt√§minen on oikea tapa luoda satunnaisia painoja potentiaalisille baseball-pelaajille. Kun tied√§mme keskim√§√§r√§isen painon `mean` ja keskihajonnan `std`, voimme luoda 1000 painon√§ytett√§ seuraavalla tavalla:
```python
samples = np.random.normal(mean,std,1000)
``` 

Jos piirr√§mme histogrammin luoduista n√§ytteist√§, n√§emme kuvan, joka on hyvin samanlainen kuin yll√§ oleva. Ja jos lis√§√§mme n√§ytteiden m√§√§r√§√§ ja binssien m√§√§r√§√§, voimme luoda kuvan normaalijakaumasta, joka on l√§hemp√§n√§ ideaalista:

![Normaalijakauma, keskiarvo=0 ja keskihajonta=1](../../../../1-Introduction/04-stats-and-probability/images/normal-histogram.png)

*Normaalijakauma, keskiarvo=0 ja keskihajonta=1*

## Luottamusv√§lit

Kun puhumme baseball-pelaajien painoista, oletamme, ett√§ on olemassa tietty **satunnaismuuttuja W**, joka vastaa kaikkien baseball-pelaajien painojen ideaalista todenn√§k√∂isyysjakaumaa (niin sanottu **populaatio**). Painojen sarjamme vastaa kaikkien baseball-pelaajien osajoukkoa, jota kutsumme **otokseksi**. Mielenkiintoinen kysymys on, voimmeko tiet√§√§ W:n jakauman parametrit, eli populaation keskiarvon ja varianssin?

Helpoin vastaus olisi laskea otoksen keskiarvo ja varianssi. Kuitenkin voi k√§yd√§ niin, ett√§ satunnainen otoksemme ei edusta tarkasti koko populaatiota. Siksi on j√§rkev√§√§ puhua **luottamusv√§list√§**.

> **Luottamusv√§li** on arvio populaation todellisesta keskiarvosta otoksemme perusteella, joka on tietyll√§ todenn√§k√∂isyydell√§ (tai **luottamustasolla**) tarkka.

Oletetaan, ett√§ meill√§ on otos X

1</sub>, ..., X<sub>n</sub> otoksestamme. Joka kerta, kun otamme otoksen jakaumastamme, saamme eri keskiarvon Œº. N√§in ollen Œº voidaan pit√§√§ satunnaismuuttujana. **Luottamusv√§li** luottamustasolla p on arvojen pari (L<sub>p</sub>,R<sub>p</sub>), siten ett√§ **P**(L<sub>p</sub>‚â§Œº‚â§R<sub>p</sub>) = p, eli todenn√§k√∂isyys, ett√§ mitattu keskiarvo osuu v√§lin sis√§√§n, on p.

On t√§m√§n lyhyen johdannon ulkopuolella k√§sitell√§ yksityiskohtaisesti, miten n√§m√§ luottamusv√§lit lasketaan. Lis√§tietoja l√∂ytyy [Wikipediasta](https://en.wikipedia.org/wiki/Confidence_interval). Lyhyesti sanottuna m√§√§rittelemme lasketun otoskeskiarvon jakauman suhteessa populaation todelliseen keskiarvoon, jota kutsutaan **Studentin jakaumaksi**.

> **Mielenkiintoinen fakta**: Studentin jakauma on nimetty matemaatikko William Sealy Gossetin mukaan, joka julkaisi tutkimuksensa salanimell√§ "Student". H√§n ty√∂skenteli Guinnessin panimossa, ja er√§√§n version mukaan h√§nen ty√∂nantajansa ei halunnut yleis√∂n tiet√§v√§n, ett√§ he k√§yttiv√§t tilastollisia testej√§ raaka-aineiden laadun m√§√§ritt√§miseen.

Jos haluamme arvioida populaation keskiarvon Œº luottamustasolla p, meid√§n on otettava *(1-p)/2-prosenttipiste* Studentin jakaumasta A, joka voidaan joko hakea taulukoista tai laskea tilasto-ohjelmistojen sis√§√§nrakennetuilla funktioilla (esim. Python, R jne.). T√§ll√∂in Œº:n v√§li olisi X¬±A*D/‚àön, miss√§ X on otoksen saatu keskiarvo ja D on keskihajonta.

> **Huomio**: Ohitamme my√∂s t√§rke√§n k√§sitteen [vapausasteet](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)), joka on t√§rke√§ Studentin jakauman yhteydess√§. Voit perehty√§ syv√§llisemmin tilastotieteen kirjoihin ymm√§rt√§√§ksesi t√§m√§n k√§sitteen paremmin.

Esimerkki painojen ja pituuksien luottamusv√§lin laskemisesta l√∂ytyy [liitteen√§ olevista muistikirjoista](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb).

| p | Painon keskiarvo |
|-----|----------------|
| 0.85 | 201.73¬±0.94 |
| 0.90 | 201.73¬±1.08 |
| 0.95 | 201.73¬±1.28 |

Huomaa, ett√§ mit√§ korkeampi luottamustodenn√§k√∂isyys, sit√§ laajempi luottamusv√§li.

## Hypoteesin testaus

Baseball-pelaajien aineistossamme on erilaisia pelaajarooleja, jotka voidaan tiivist√§√§ alla olevaan taulukkoon (katso [liitteen√§ oleva muistikirja](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb), miten t√§m√§ taulukko on laskettu):

| Rooli | Pituus | Paino | Lukum√§√§r√§ |
|-------|--------|-------|-----------|
| Catcher | 72.723684 | 204.328947 | 76 |
| Designated_Hitter | 74.222222 | 220.888889 | 18 |
| First_Baseman | 74.000000 | 213.109091 | 55 |
| Outfielder | 73.010309 | 199.113402 | 194 |
| Relief_Pitcher | 74.374603 | 203.517460 | 315 |
| Second_Baseman | 71.362069 | 184.344828 | 58 |
| Shortstop | 71.903846 | 182.923077 | 52 |
| Starting_Pitcher | 74.719457 | 205.163636 | 221 |
| Third_Baseman | 73.044444 | 200.955556 | 45 |

Voimme huomata, ett√§ ensimm√§isten basemenien keskipituus on suurempi kuin toisten basemenien. N√§in ollen voimme olla taipuvaisia p√§√§ttelem√§√§n, ett√§ **ensimm√§iset basemenit ovat pidempi√§ kuin toiset basemenit**.

> T√§t√§ v√§itett√§ kutsutaan **hypoteesiksi**, koska emme tied√§, onko se oikeasti totta vai ei.

Kuitenkin ei ole aina ilmeist√§, voimmeko tehd√§ t√§m√§n johtop√§√§t√∂ksen. Kuten edell√§ keskustelimme, jokaisella keskiarvolla on siihen liittyv√§ luottamusv√§li, ja n√§in ollen t√§m√§ ero voi olla vain tilastollinen virhe. Tarvitsemme muodollisemman tavan testata hypoteesimme.

Lasketaan luottamusv√§lit erikseen ensimm√§isten ja toisten basemenien pituuksille:

| Luottamus | Ensimm√§iset basemenit | Toiset basemenit |
|-----------|-----------------------|------------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

Voimme n√§hd√§, ett√§ miss√§√§n luottamustasossa v√§lit eiv√§t mene p√§√§llekk√§in. T√§m√§ todistaa hypoteesimme, ett√§ ensimm√§iset basemenit ovat pidempi√§ kuin toiset basemenit.

Muodollisemmin, ratkaisemamme ongelma on n√§hd√§, ovatko **kaksi todenn√§k√∂isyysjakaumaa samat**, tai ainakin onko niill√§ samat parametrit. Riippuen jakaumasta, meid√§n on k√§ytett√§v√§ erilaisia testej√§. Jos tied√§mme, ett√§ jakaumamme ovat normaalijakaumia, voimme soveltaa **[Studentin t-testi√§](https://en.wikipedia.org/wiki/Student%27s_t-test)**.

Studentin t-testiss√§ laskemme niin sanotun **t-arvon**, joka osoittaa keskiarvojen eron ottaen huomioon varianssin. On osoitettu, ett√§ t-arvo noudattaa **Studentin jakaumaa**, mik√§ mahdollistaa kynnysarvon saamisen annetulle luottamustasolle **p** (t√§m√§ voidaan laskea tai katsoa numeerisista taulukoista). Vertaillemme sitten t-arvoa t√§h√§n kynnysarvoon hyv√§ksy√§ksemme tai hyl√§t√§ksemme hypoteesin.

Pythonissa voimme k√§ytt√§√§ **SciPy**-kirjastoa, joka sis√§lt√§√§ `ttest_ind`-funktion (monien muiden hy√∂dyllisten tilastollisten funktioiden lis√§ksi!). Se laskee t-arvon puolestamme ja tekee my√∂s k√§√§nteisen luottamustason p-arvon haun, jotta voimme vain tarkastella luottamustasoa johtop√§√§t√∂ksen tekemiseksi.

Esimerkiksi vertailumme ensimm√§isten ja toisten basemenien pituuksista antaa seuraavat tulokset: 
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
T√§ss√§ tapauksessa p-arvo on eritt√§in pieni, mik√§ tarkoittaa, ett√§ on vahvaa n√§ytt√∂√§ siit√§, ett√§ ensimm√§iset basemenit ovat pidempi√§.

On my√∂s muita hypoteeseja, joita voimme haluta testata, esimerkiksi:
* Todistaa, ett√§ annettu otos noudattaa jotain jakaumaa. Oletimme esimerkiksi, ett√§ pituudet ovat normaalijakautuneita, mutta t√§m√§ vaatii muodollisen tilastollisen vahvistuksen.
* Todistaa, ett√§ otoksen keskiarvo vastaa jotain ennalta m√§√§ritelty√§ arvoa.
* Verrata useiden otosten keskiarvoja (esim. mik√§ on ero onnellisuustasoissa eri ik√§ryhmien v√§lill√§).

## Suurten lukujen laki ja keskeinen raja-arvolause

Yksi syy, miksi normaalijakauma on niin t√§rke√§, on niin sanottu **keskeinen raja-arvolause**. Oletetaan, ett√§ meill√§ on suuri otos riippumattomia N arvoja X<sub>1</sub>, ..., X<sub>N</sub>, jotka on otettu mist√§ tahansa jakaumasta, jonka keskiarvo on Œº ja varianssi œÉ<sup>2</sup>. T√§ll√∂in, kun N on riitt√§v√§n suuri (toisin sanoen, kun N‚Üí‚àû), keskiarvo Œ£<sub>i</sub>X<sub>i</sub> on normaalijakautunut, keskiarvolla Œº ja varianssilla œÉ<sup>2</sup>/N.

> Toinen tapa tulkita keskeist√§ raja-arvolausetta on sanoa, ett√§ riippumatta jakaumasta, kun lasket mink√§ tahansa satunnaismuuttujan arvojen summan keskiarvon, p√§√§dyt normaalijakaumaan.

Keskeisest√§ raja-arvolauseesta seuraa my√∂s, ett√§ kun N‚Üí‚àû, otoskeskiarvon todenn√§k√∂isyys olla yht√§ suuri kuin Œº l√§hestyy arvoa 1. T√§t√§ kutsutaan **suurten lukujen laiksi**.

## Kovaranssi ja korrelaatio

Yksi asioista, joita data-analytiikka tekee, on l√∂yt√§√§ yhteyksi√§ datan v√§lill√§. Sanomme, ett√§ kaksi sarjaa **korreloivat**, kun ne k√§ytt√§ytyv√§t samankaltaisesti samaan aikaan, eli ne joko nousevat/laskevat samanaikaisesti tai toinen sarja nousee, kun toinen laskee ja p√§invastoin. Toisin sanoen, sarjojen v√§lill√§ n√§ytt√§√§ olevan jokin yhteys.

> Korrelaatio ei v√§ltt√§m√§tt√§ tarkoita kausaalista suhdetta kahden sarjan v√§lill√§; joskus molemmat muuttujat voivat riippua jostain ulkoisesta syyst√§, tai voi olla puhdasta sattumaa, ett√§ kaksi sarjaa korreloivat. Kuitenkin vahva matemaattinen korrelaatio on hyv√§ osoitus siit√§, ett√§ kaksi muuttujaa ovat jollain tavalla yhteydess√§.

Matemaattisesti p√§√§k√§site, joka osoittaa yhteyden kahden satunnaismuuttujan v√§lill√§, on **kovarianssi**, joka lasketaan n√§in: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. Laskemme molempien muuttujien poikkeaman niiden keskiarvoista ja sitten n√§iden poikkeamien tulon. Jos molemmat muuttujat poikkeavat yhdess√§, tulo on aina positiivinen arvo, joka lis√§√§ positiivista kovarianssia. Jos molemmat muuttujat poikkeavat ep√§synkronisesti (eli toinen laskee keskiarvon alapuolelle, kun toinen nousee keskiarvon yl√§puolelle), saamme aina negatiivisia lukuja, jotka lis√§√§v√§t negatiivista kovarianssia. Jos poikkeamat eiv√§t ole riippuvaisia, ne summautuvat suunnilleen nollaan.

Kovarianssin itseisarvo ei kerro paljon siit√§, kuinka suuri korrelaatio on, koska se riippuu todellisten arvojen suuruudesta. Normalisoidaksemme sen voimme jakaa kovarianssin molempien muuttujien keskihajonnalla saadaksemme **korrelaation**. Hyv√§ puoli on, ett√§ korrelaatio on aina v√§lill√§ [-1,1], miss√§ 1 tarkoittaa vahvaa positiivista korrelaatiota arvojen v√§lill√§, -1 vahvaa negatiivista korrelaatiota ja 0 ei korrelaatiota ollenkaan (muuttujat ovat riippumattomia).

**Esimerkki**: Voimme laskea korrelaation baseball-pelaajien painojen ja pituuksien v√§lill√§ yll√§ mainitusta aineistosta:
```python
print(np.corrcoef(weights,heights))
```
Tuloksena saamme **korrelaatiomatriisin**, joka n√§ytt√§√§ t√§lt√§:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> Korrelaatiomatriisi C voidaan laskea mille tahansa m√§√§r√§lle sy√∂tesarjoja S<sub>1</sub>, ..., S<sub>n</sub>. C<sub>ij</sub>-arvo on korrelaatio S<sub>i</sub>:n ja S<sub>j</sub>:n v√§lill√§, ja diagonaalielementit ovat aina 1 (mik√§ on my√∂s S<sub>i</sub>:n itsekorrelaatio).

T√§ss√§ tapauksessa arvo 0.53 osoittaa, ett√§ henkil√∂n painon ja pituuden v√§lill√§ on jonkin verran korrelaatiota. Voimme my√∂s tehd√§ hajontakaavion yhdest√§ arvosta toista vastaan n√§hd√§ksesi suhteen visuaalisesti:

![Painon ja pituuden v√§linen suhde](../../../../1-Introduction/04-stats-and-probability/images/weight-height-relationship.png)

> Lis√§√§ esimerkkej√§ korrelaatiosta ja kovarianssista l√∂ytyy [liitteen√§ olevasta muistikirjasta](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb).

## Yhteenveto

T√§ss√§ osiossa opimme:

* datan perus tilastolliset ominaisuudet, kuten keskiarvo, varianssi, moodi ja kvartiilit
* satunnaismuuttujien erilaiset jakaumat, mukaan lukien normaalijakauma
* kuinka l√∂yt√§√§ korrelaatio eri ominaisuuksien v√§lill√§
* kuinka k√§ytt√§√§ matemaattisia ja tilastollisia menetelmi√§ hypoteesien todistamiseen
* kuinka laskea satunnaismuuttujan luottamusv√§lej√§ otoksen perusteella

Vaikka t√§m√§ ei olekaan tyhjent√§v√§ luettelo todenn√§k√∂isyyslaskennan ja tilastotieteen aiheista, sen pit√§isi antaa sinulle hyv√§ l√§ht√∂kohta t√§h√§n kurssiin.

## üöÄ Haaste

K√§yt√§ muistikirjan esimerkkikoodia testataksesi muita hypoteeseja:
1. Ensimm√§iset basemenit ovat vanhempia kuin toiset basemenit
2. Ensimm√§iset basemenit ovat pidempi√§ kuin kolmannet basemenit
3. Shortstopit ovat pidempi√§ kuin toiset basemenit

## [Luennon j√§lkeinen kysely](https://ff-quizzes.netlify.app/en/ds/quiz/7)

## Kertaus ja itseopiskelu

Todenn√§k√∂isyyslaskenta ja tilastotiede on niin laaja aihe, ett√§ se ansaitsee oman kurssinsa. Jos haluat syventy√§ teoriaan, voit jatkaa lukemista seuraavista kirjoista:

1. [Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/) New Yorkin yliopistosta on laatinut erinomaiset luentomuistiinpanot [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (saatavilla verkossa).
1. [Peter ja Andrew Bruce. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[esimerkkikoodi R:ll√§](https://github.com/andrewgbruce/statistics-for-data-scientists)].
1. [James D. Miller. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[esimerkkikoodi R:ll√§](https://github.com/PacktPublishing/Statistics-for-Data-Science)].

## Teht√§v√§

[Small Diabetes Study](assignment.md)

## Kiitokset

T√§m√§n oppitunnin on laatinut ‚ô•Ô∏è:lla [Dmitry Soshnikov](http://soshnikov.com).

---

**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ett√§ automaattiset k√§√§nn√∂kset voivat sis√§lt√§√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§ist√§ asiakirjaa sen alkuper√§isell√§ kielell√§ tulisi pit√§√§ ensisijaisena l√§hteen√§. Kriittisen tiedon osalta suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§ johtuvista v√§√§rink√§sityksist√§ tai virhetulkinnoista.