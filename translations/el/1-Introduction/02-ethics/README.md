<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8796f41f566a0a8ebb72863a83d558ed",
  "translation_date": "2025-08-26T21:16:15+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "el"
}
-->
# Εισαγωγή στην Ηθική των Δεδομένων

|![ Σκίτσο από [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Ηθική της Επιστήμης Δεδομένων - _Σκίτσο από [@nitya](https://twitter.com/nitya)_ |

---

Είμαστε όλοι πολίτες δεδομένων που ζούμε σε έναν κόσμο γεμάτο δεδομένα.

Οι τάσεις της αγοράς μας λένε ότι μέχρι το 2022, 1 στις 3 μεγάλες οργανώσεις θα αγοράζει και θα πουλά τα δεδομένα της μέσω διαδικτυακών [Αγορών και Ανταλλακτηρίων](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Ως **Προγραμματιστές Εφαρμογών**, θα βρίσκουμε πιο εύκολο και οικονομικό να ενσωματώνουμε πληροφορίες που βασίζονται σε δεδομένα και αυτοματισμούς που βασίζονται σε αλγορίθμους στις καθημερινές εμπειρίες των χρηστών. Αλλά καθώς η Τεχνητή Νοημοσύνη (AI) γίνεται πανταχού παρούσα, θα πρέπει επίσης να κατανοήσουμε τις πιθανές βλάβες που προκαλούνται από τη [χρήση της ως όπλο](https://www.youtube.com/watch?v=TQHs8SA1qpk) σε μεγάλη κλίμακα.

Οι τάσεις δείχνουν επίσης ότι θα δημιουργήσουμε και θα καταναλώσουμε πάνω από [180 zettabytes](https://www.statista.com/statistics/871513/worldwide-data-created/) δεδομένων μέχρι το 2025. Ως **Επιστήμονες Δεδομένων**, αυτό μας δίνει πρωτοφανή επίπεδα πρόσβασης σε προσωπικά δεδομένα. Αυτό σημαίνει ότι μπορούμε να δημιουργήσουμε προφίλ συμπεριφοράς χρηστών και να επηρεάσουμε τη λήψη αποφάσεων με τρόπους που δημιουργούν μια [ψευδαίσθηση ελεύθερης επιλογής](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice), ενώ ενδεχομένως κατευθύνουμε τους χρήστες προς αποτελέσματα που προτιμούμε. Αυτό εγείρει επίσης ευρύτερα ερωτήματα σχετικά με την ιδιωτικότητα των δεδομένων και την προστασία των χρηστών.

Η ηθική των δεδομένων είναι πλέον _απαραίτητοι κανόνες ασφαλείας_ για την επιστήμη και τη μηχανική των δεδομένων, βοηθώντας μας να ελαχιστοποιήσουμε τις πιθανές βλάβες και τις ακούσιες συνέπειες από τις ενέργειές μας που βασίζονται σε δεδομένα. Ο [Κύκλος Υπερβολής της Gartner για την AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) αναγνωρίζει σχετικές τάσεις στην ψηφιακή ηθική, την υπεύθυνη AI και τη διακυβέρνηση της AI ως βασικούς παράγοντες για μεγαλύτερες τάσεις γύρω από τη _δημοκρατικοποίηση_ και τη _βιομηχανοποίηση_ της AI.

![Κύκλος Υπερβολής της Gartner για την AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

Σε αυτό το μάθημα, θα εξερευνήσουμε τον συναρπαστικό τομέα της ηθικής των δεδομένων - από βασικές έννοιες και προκλήσεις, μέχρι μελέτες περιπτώσεων και εφαρμοσμένες έννοιες AI όπως η διακυβέρνηση - που βοηθούν στη δημιουργία μιας κουλτούρας ηθικής στις ομάδες και τους οργανισμούς που εργάζονται με δεδομένα και AI.




## [Κουίζ πριν το μάθημα](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/2) 🎯

## Βασικοί Ορισμοί

Ας ξεκινήσουμε κατανοώντας τη βασική ορολογία.

Η λέξη "ηθική" προέρχεται από την [ελληνική λέξη "ηθικός"](https://en.wikipedia.org/wiki/Ethics) (και τη ρίζα της "ήθος") που σημαίνει _χαρακτήρας ή ηθική φύση_. 

**Ηθική** αφορά τις κοινές αξίες και ηθικές αρχές που διέπουν τη συμπεριφορά μας στην κοινωνία. Η ηθική δεν βασίζεται σε νόμους αλλά σε ευρέως αποδεκτούς κανόνες για το τι είναι "σωστό έναντι λάθους". Ωστόσο, οι ηθικές εκτιμήσεις μπορούν να επηρεάσουν πρωτοβουλίες εταιρικής διακυβέρνησης και κυβερνητικούς κανονισμούς που δημιουργούν περισσότερα κίνητρα για συμμόρφωση.

**Ηθική των Δεδομένων** είναι ένας [νέος κλάδος της ηθικής](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1) που "μελετά και αξιολογεί ηθικά προβλήματα που σχετίζονται με _δεδομένα, αλγορίθμους και αντίστοιχες πρακτικές_". Εδώ, **"δεδομένα"** εστιάζουν σε ενέργειες που σχετίζονται με τη δημιουργία, καταγραφή, επιμέλεια, επεξεργασία, διάδοση, κοινή χρήση και χρήση, **"αλγόριθμοι"** εστιάζουν στην AI, τους πράκτορες, τη μηχανική μάθηση και τα ρομπότ, και **"πρακτικές"** εστιάζουν σε θέματα όπως η υπεύθυνη καινοτομία, ο προγραμματισμός, το hacking και οι κώδικες ηθικής.

**Εφαρμοσμένη Ηθική** είναι η [πρακτική εφαρμογή ηθικών εκτιμήσεων](https://en.wikipedia.org/wiki/Applied_ethics). Είναι η διαδικασία ενεργής διερεύνησης ηθικών ζητημάτων στο πλαίσιο _πραγματικών ενεργειών, προϊόντων και διαδικασιών_ και η λήψη διορθωτικών μέτρων για να διασφαλιστεί ότι παραμένουν ευθυγραμμισμένα με τις καθορισμένες ηθικές μας αξίες.

**Κουλτούρα Ηθικής** αφορά την [_επιχειρησιακή εφαρμογή_ της εφαρμοσμένης ηθικής](https://hbr.org/2019/05/how-to-design-an-ethical-organization) για να διασφαλιστεί ότι οι ηθικές μας αρχές και πρακτικές υιοθετούνται με συνέπεια και κλίμακα σε ολόκληρο τον οργανισμό. Οι επιτυχημένες κουλτούρες ηθικής ορίζουν ηθικές αρχές σε επίπεδο οργανισμού, παρέχουν ουσιαστικά κίνητρα για συμμόρφωση και ενισχύουν τους κανόνες ηθικής ενθαρρύνοντας και ενισχύοντας τις επιθυμητές συμπεριφορές σε κάθε επίπεδο του οργανισμού.


## Έννοιες Ηθικής

Σε αυτή την ενότητα, θα συζητήσουμε έννοιες όπως **κοινές αξίες** (αρχές) και **ηθικές προκλήσεις** (προβλήματα) για την ηθική των δεδομένων - και θα εξερευνήσουμε **μελέτες περιπτώσεων** που σας βοηθούν να κατανοήσετε αυτές τις έννοιες σε πραγματικά πλαίσια.

### 1. Αρχές Ηθικής

Κάθε στρατηγική ηθικής δεδομένων ξεκινά με τον ορισμό των _ηθικών αρχών_ - των "κοινών αξιών" που περιγράφουν αποδεκτές συμπεριφορές και καθοδηγούν συμμορφούμενες ενέργειες στα έργα δεδομένων και AI. Μπορείτε να τις ορίσετε σε ατομικό ή ομαδικό επίπεδο. Ωστόσο, οι περισσότερες μεγάλες οργανώσεις τις περιγράφουν σε μια δήλωση αποστολής ή πλαίσιο _ηθικής AI_ που ορίζεται σε εταιρικό επίπεδο και εφαρμόζεται με συνέπεια σε όλες τις ομάδες.

**Παράδειγμα:** Η δήλωση αποστολής της Microsoft για την [Υπεύθυνη AI](https://www.microsoft.com/en-us/ai/responsible-ai) αναφέρει: _"Δεσμευόμαστε για την προώθηση της AI που καθοδηγείται από ηθικές αρχές που βάζουν τους ανθρώπους πρώτα"_ - προσδιορίζοντας 6 ηθικές αρχές στο παρακάτω πλαίσιο:

![Υπεύθυνη AI στη Microsoft](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

Ας εξερευνήσουμε σύντομα αυτές τις αρχές. _Η διαφάνεια_ και _η λογοδοσία_ είναι θεμελιώδεις αξίες πάνω στις οποίες βασίζονται οι υπόλοιπες αρχές - ας ξεκινήσουμε από εκεί:

* [**Λογοδοσία**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) καθιστά τους επαγγελματίες _υπεύθυνους_ για τις λειτουργίες δεδομένων και AI τους, καθώς και για τη συμμόρφωση με αυτές τις ηθικές αρχές.
* [**Διαφάνεια**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) διασφαλίζει ότι οι ενέργειες δεδομένων και AI είναι _κατανοητές_ (ερμηνεύσιμες) από τους χρήστες, εξηγώντας το τι και το γιατί πίσω από τις αποφάσεις.
* [**Δικαιοσύνη**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - εστιάζει στη διασφάλιση ότι η AI αντιμετωπίζει _όλους τους ανθρώπους_ δίκαια, αντιμετωπίζοντας τυχόν συστημικές ή έμφυτες κοινωνικοτεχνικές προκαταλήψεις στα δεδομένα και τα συστήματα.
* [**Αξιοπιστία & Ασφάλεια**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - διασφαλίζει ότι η AI συμπεριφέρεται _συνεπώς_ με καθορισμένες αξίες, ελαχιστοποιώντας πιθανές βλάβες ή ακούσιες συνέπειες.
* [**Ιδιωτικότητα & Ασφάλεια**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - αφορά την κατανόηση της προέλευσης των δεδομένων και την παροχή _προστασίας ιδιωτικότητας δεδομένων_ στους χρήστες.
* [**Συμπερίληψη**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - αφορά το σχεδιασμό λύσεων AI με πρόθεση, προσαρμόζοντάς τες ώστε να καλύπτουν ένα _ευρύ φάσμα ανθρώπινων αναγκών_ και δυνατοτήτων.

> 🚨 Σκεφτείτε ποια θα μπορούσε να είναι η δήλωση αποστολής σας για την ηθική των δεδομένων. Εξερευνήστε πλαίσια ηθικής AI από άλλους οργανισμούς - εδώ είναι παραδείγματα από [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles), και [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Ποιες κοινές αξίες έχουν; Πώς σχετίζονται αυτές οι αρχές με το προϊόν AI ή τη βιομηχανία στην οποία δραστηριοποιούνται;

### 2. Προκλήσεις Ηθικής

Αφού ορίσουμε τις ηθικές αρχές, το επόμενο βήμα είναι να αξιολογήσουμε τις ενέργειες δεδομένων και AI για να δούμε αν ευθυγραμμίζονται με αυτές τις κοινές αξίες. Σκεφτείτε τις ενέργειές σας σε δύο κατηγορίες: _συλλογή δεδομένων_ και _σχεδιασμός αλγορίθμων_. 

Με τη συλλογή δεδομένων, οι ενέργειες πιθανότατα θα περιλαμβάνουν **προσωπικά δεδομένα** ή προσωπικά αναγνωρίσιμες πληροφορίες (PII) για αναγνωρίσιμα ζωντανά άτομα. Αυτό περιλαμβάνει [διάφορα στοιχεία μη προσωπικών δεδομένων](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) που _συλλογικά_ αναγνωρίζουν ένα άτομο. Οι ηθικές προκλήσεις μπορεί να σχετίζονται με _ιδιωτικότητα δεδομένων_, _ιδιοκτησία δεδομένων_ και συναφή θέματα όπως η _ενημερωμένη συγκατάθεση_ και τα _δικαιώματα πνευματικής ιδιοκτησίας_ για τους χρήστες.

Με το σχεδιασμό αλγορίθμων, οι ενέργειες θα περιλαμβάνουν τη συλλογή και επιμέλεια **συνόλων δεδομένων**, και στη συνέχεια τη χρήση τους για την εκπαίδευση και ανάπτυξη **μοντέλων δεδομένων** που προβλέπουν αποτελέσματα ή αυτοματοποιούν αποφάσεις σε πραγματικά πλαίσια. Οι ηθικές προκλήσεις μπορεί να προκύψουν από _προκατάληψη συνόλου δεδομένων_, _ζητήματα ποιότητας δεδομένων_, _αδικία_ και _παραπλάνηση_ στους αλγορίθμους - συμπεριλαμβανομένων ορισμένων ζητημάτων που είναι συστημικής φύσης.

Σε αμφότερες τις περιπτώσεις, οι προκλήσεις ηθικής αναδεικνύουν περιοχές όπου οι ενέργειές μας ενδέχεται να έρχονται σε σύγκρουση με τις κοινές μας αξίες. Για να ανιχνεύσουμε, να μετριάσουμε, να ελαχιστοποιήσουμε ή να εξαλείψουμε αυτές τις ανησυχίες - πρέπει να κάνουμε ηθικές ερωτήσεις "ναι/όχι" σχετικά με τις ενέργειές μας και στη συνέχεια να λάβουμε διορθωτικές ενέργειες όπως απαιτείται. Ας δούμε μερικές ηθικές προκλήσεις και τις ηθικές ερωτήσεις που εγείρουν:


#### 2.1 Ιδιοκτησία Δεδομένων

Η συλλογή δεδομένων συχνά περιλαμβάνει προσωπικά δεδομένα που μπορούν να αναγνωρίσουν τα υποκείμενα των δεδομένων. [Η ιδιοκτησία δεδομένων](https://permission.io/blog/data-ownership) αφορά τον _έλεγχο_ και τα [_δικαιώματα χρηστών_](https://permission.io/blog/data-ownership) που σχετίζονται με τη δημιουργία, επεξεργασία και διάδοση δεδομένων. 

Οι ηθικές ερωτήσεις που πρέπει να κάνουμε είναι: 
 * Ποιος κατέχει τα δεδομένα; (χρήστης ή οργανισμός)
 * Ποια δικαιώματα έχουν τα υποκείμενα των δεδομένων; (π.χ. πρόσβαση, διαγραφή, φορητότητα)
 * Ποια δικαιώματα έχουν οι οργανισμοί; (π.χ. διόρθωση κακόβουλων κριτικών χρηστών)

#### 2.2 Ενημερωμένη Συγκατάθεση

[Η ενημερωμένη συγκατάθεση](https://legaldictionary.net/informed-consent/) ορίζει την πράξη των χρηστών να συμφωνούν σε μια ενέργεια (όπως η συλλογή δεδομένων) με _πλήρη κατανόηση_ των σχετικών γεγονότων, συμπεριλαμβανομένου του σκοπού, των πιθανών κινδύνων και των εναλλακτικών. 

Ερωτήσεις που πρέπει να εξεταστούν εδώ είναι:
 * Έδωσε ο χρήστης (υποκείμενο δεδομένων) άδεια για τη συλλογή και χρήση δεδομένων;
 * Κατάλαβε ο χρήστης τον σκοπό για τον οποίο συλλέχθηκαν τα δεδομένα;
 * Κατάλαβε ο χρήστης τους πιθανούς κινδύνους από τη συμμετοχή του;

#### 2.3 Πνευματική Ιδιοκτησία

[Η πνευματική ιδιοκτησία](https://en.wikipedia.org/wiki/Intellectual_property) αναφέρεται σε άυτες δημιουργίες που προκύπτουν από ανθρώπινη πρωτοβουλία, οι οποίες μπορεί να _έχουν οικονομική αξία_ για άτομα ή επιχειρήσεις. 

Ερωτήσεις που πρέπει να εξεταστούν εδώ είναι:
 * Είχαν τα συλλεχθέντα δεδομένα οικονομική αξία για έναν χρήστη ή μια επιχείρηση;
 * Έχει ο **χρήστης** πνευματική ιδιοκτησία εδώ;
 * Έχει ο **οργανισμός** πνευματική ιδιοκτησία εδώ;
 * Αν υπάρχουν αυτά τα δικαιώματα, πώς τα προστατεύουμε;

#### 2.4 Ιδιωτικότητα Δεδομένων

[Η ιδιωτικότητα δεδομένων](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) ή η ιδιωτικότητα πληροφοριών αναφέρεται στη διατήρηση της ιδιωτικότητας των
[Algorithm Fairness](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) ελέγχει αν ο σχεδιασμός του αλγορίθμου συστηματικά εισάγει διακρίσεις εναντίον συγκεκριμένων υποομάδων υποκειμένων δεδομένων, οδηγώντας σε [πιθανές βλάβες](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) στην _κατανομή_ (όπου πόροι αρνούνται ή παρακρατούνται από αυτήν την ομάδα) και στην _ποιότητα υπηρεσιών_ (όπου η ακρίβεια της AI δεν είναι ίδια για όλες τις υποομάδες). 

Ερωτήσεις για διερεύνηση εδώ:
 * Αξιολογήσαμε την ακρίβεια του μοντέλου για διαφορετικές υποομάδες και συνθήκες;
 * Εξετάσαμε το σύστημα για πιθανές βλάβες (π.χ., στερεότυπα);
 * Μπορούμε να αναθεωρήσουμε δεδομένα ή να επανεκπαιδεύσουμε μοντέλα για να μετριάσουμε τις εντοπισμένες βλάβες;

Εξερευνήστε πόρους όπως [AI Fairness checklists](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) για να μάθετε περισσότερα.

#### 2.9 Παραπλάνηση

[Παραπλάνηση δεδομένων](https://www.sciencedirect.com/topics/computer-science/misrepresentation) αφορά το ερώτημα αν επικοινωνούμε πληροφορίες από ειλικρινώς αναφερόμενα δεδομένα με τρόπο που παραπλανά για να υποστηρίξουμε μια επιθυμητή αφήγηση. 

Ερωτήσεις για διερεύνηση εδώ:
 * Αναφέρουμε ελλιπή ή ανακριβή δεδομένα;
 * Οπτικοποιούμε δεδομένα με τρόπο που οδηγεί σε παραπλανητικά συμπεράσματα;
 * Χρησιμοποιούμε επιλεκτικές στατιστικές τεχνικές για να χειραγωγήσουμε αποτελέσματα;
 * Υπάρχουν εναλλακτικές εξηγήσεις που μπορεί να προσφέρουν διαφορετικό συμπέρασμα;

#### 2.10 Ελεύθερη Επιλογή
Η [Ψευδαίσθηση της Ελεύθερης Επιλογής](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) συμβαίνει όταν οι "αρχιτεκτονικές επιλογών" του συστήματος χρησιμοποιούν αλγορίθμους λήψης αποφάσεων για να ωθήσουν τους ανθρώπους προς ένα προτιμώμενο αποτέλεσμα, ενώ φαίνεται ότι τους δίνουν επιλογές και έλεγχο. Αυτά τα [σκοτεινά μοτίβα](https://www.darkpatterns.org/) μπορούν να προκαλέσουν κοινωνική και οικονομική βλάβη στους χρήστες. Επειδή οι αποφάσεις των χρηστών επηρεάζουν τα προφίλ συμπεριφοράς, αυτές οι ενέργειες ενδέχεται να οδηγήσουν σε μελλοντικές επιλογές που μπορούν να ενισχύσουν ή να επεκτείνουν τον αντίκτυπο αυτών των βλαβών.

Ερωτήσεις για διερεύνηση εδώ:
 * Κατάλαβε ο χρήστης τις συνέπειες της επιλογής που έκανε;
 * Ήταν ο χρήστης ενήμερος για (εναλλακτικές) επιλογές και τα πλεονεκτήματα & μειονεκτήματα της κάθε μίας;
 * Μπορεί ο χρήστης να αναιρέσει μια αυτοματοποιημένη ή επηρεασμένη επιλογή αργότερα;

### 3. Μελέτες Περίπτωσης

Για να τοποθετήσουμε αυτές τις ηθικές προκλήσεις σε πραγματικά πλαίσια, βοηθά να εξετάσουμε μελέτες περίπτωσης που αναδεικνύουν τις πιθανές βλάβες και συνέπειες για άτομα και την κοινωνία, όταν παραβιάσεις ηθικής παραβλέπονται. 

Ακολουθούν μερικά παραδείγματα:

| Ηθική Πρόκληση | Μελέτη Περίπτωσης  | 
|--- |--- |
| **Ενημερωμένη Συναίνεση** | 1972 - [Tuskegee Syphilis Study](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - Αφροαμερικανοί άνδρες που συμμετείχαν στη μελέτη υποσχέθηκαν δωρεάν ιατρική περίθαλψη _αλλά εξαπατήθηκαν_ από ερευνητές που δεν ενημέρωσαν τους συμμετέχοντες για τη διάγνωσή τους ή για τη διαθεσιμότητα θεραπείας. Πολλοί συμμετέχοντες πέθαναν και οι σύντροφοι ή τα παιδιά τους επηρεάστηκαν. Η μελέτη διήρκεσε 40 χρόνια. | 
| **Ιδιωτικότητα Δεδομένων** |  2007 - Το [Netflix data prize](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) παρείχε στους ερευνητές _10 εκατομμύρια ανωνυμοποιημένες βαθμολογίες ταινιών από 50.000 πελάτες_ για να βοηθήσουν στη βελτίωση των αλγορίθμων συστάσεων. Ωστόσο, οι ερευνητές μπόρεσαν να συσχετίσουν ανωνυμοποιημένα δεδομένα με προσωπικά δεδομένα σε _εξωτερικές βάσεις δεδομένων_ (π.χ., σχόλια IMDb), ουσιαστικά "απο-ανωνυμοποιώντας" ορισμένους συνδρομητές του Netflix.|
| **Προκατάληψη Συλλογής Δεδομένων**  | 2013 - Η πόλη της Βοστώνης [ανέπτυξε το Street Bump](https://www.boston.gov/transportation/street-bump), μια εφαρμογή που επέτρεπε στους πολίτες να αναφέρουν λακκούβες, παρέχοντας στην πόλη καλύτερα δεδομένα για τους δρόμους. Ωστόσο, [άτομα με χαμηλότερα εισοδήματα είχαν λιγότερη πρόσβαση σε αυτοκίνητα και τηλέφωνα](https://hbr.org/2013/04/the-hidden-biases-in-big-data), καθιστώντας τα προβλήματα των δρόμων τους αόρατα στην εφαρμογή. Οι προγραμματιστές συνεργάστηκαν με ακαδημαϊκούς για να αντιμετωπίσουν ζητήματα _ισότιμης πρόσβασης και ψηφιακών αποκλεισμών_ για δικαιοσύνη. |
| **Δικαιοσύνη Αλγορίθμων**  | 2018 - Η MIT [Gender Shades Study](http://gendershades.org/overview.html) αξιολόγησε την ακρίβεια των προϊόντων AI ταξινόμησης φύλου, αποκαλύπτοντας κενά στην ακρίβεια για γυναίκες και άτομα με χρώμα. Μια [2019 Apple Card](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) φάνηκε να προσφέρει λιγότερη πίστωση στις γυναίκες από ό,τι στους άνδρες. Και τα δύο παραδείγματα ανέδειξαν ζητήματα προκατάληψης αλγορίθμων που οδηγούν σε κοινωνικοοικονομικές βλάβες.|
| **Παραπλάνηση Δεδομένων** | 2020 - Το [Georgia Department of Public Health κυκλοφόρησε γραφήματα COVID-19](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) που φαινόταν να παραπλανούν τους πολίτες σχετικά με τις τάσεις των επιβεβαιωμένων κρουσμάτων με μη χρονολογική ταξινόμηση στον άξονα x. Αυτό δείχνει παραπλάνηση μέσω τεχνασμάτων οπτικοποίησης. |
| **Ψευδαίσθηση Ελεύθερης Επιλογής** | 2020 - Η εκπαιδευτική εφαρμογή [ABCmouse πλήρωσε $10M για να διευθετήσει καταγγελία της FTC](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/) όπου οι γονείς παγιδεύτηκαν να πληρώνουν για συνδρομές που δεν μπορούσαν να ακυρώσουν. Αυτό δείχνει σκοτεινά μοτίβα στις αρχιτεκτονικές επιλογών, όπου οι χρήστες ωθήθηκαν σε δυνητικά επιβλαβείς επιλογές. |
| **Ιδιωτικότητα Δεδομένων & Δικαιώματα Χρηστών** | 2021 - Η [Διαρροή Δεδομένων του Facebook](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) αποκάλυψε δεδομένα από 530 εκατομμύρια χρήστες, οδηγώντας σε διακανονισμό $5B με την FTC. Ωστόσο, αρνήθηκε να ειδοποιήσει τους χρήστες για τη διαρροή, παραβιάζοντας τα δικαιώματα των χρηστών σχετικά με τη διαφάνεια και την πρόσβαση στα δεδομένα. |

Θέλετε να εξερευνήσετε περισσότερες μελέτες περίπτωσης; Δείτε αυτούς τους πόρους:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - ηθικά διλήμματα σε διάφορες βιομηχανίες. 
* [Data Science Ethics course](https://www.coursera.org/learn/data-science-ethics#syllabus) - μελέτες περίπτωσης ορόσημα.
* [Where things have gone wrong](https://deon.drivendata.org/examples/) - λίστα ελέγχου deon με παραδείγματα.


> 🚨 Σκεφτείτε τις μελέτες περίπτωσης που έχετε δει - έχετε βιώσει ή επηρεαστεί από μια παρόμοια ηθική πρόκληση στη ζωή σας; Μπορείτε να σκεφτείτε τουλάχιστον μία άλλη μελέτη περίπτωσης που να απεικονίζει μία από τις ηθικές προκλήσεις που συζητήσαμε σε αυτήν την ενότητα;

## Εφαρμοσμένη Ηθική

Μιλήσαμε για έννοιες ηθικής, προκλήσεις και μελέτες περίπτωσης σε πραγματικά πλαίσια. Αλλά πώς ξεκινάμε να _εφαρμόζουμε_ ηθικές αρχές και πρακτικές στα έργα μας; Και πώς _επιχειρησιακοποιούμε_ αυτές τις πρακτικές για καλύτερη διακυβέρνηση; Ας εξερευνήσουμε μερικές λύσεις πραγματικού κόσμου: 

### 1. Επαγγελματικοί Κώδικες

Οι Επαγγελματικοί Κώδικες προσφέρουν μια επιλογή για οργανισμούς να "ενθαρρύνουν" τα μέλη να υποστηρίξουν τις ηθικές αρχές και τη δήλωση αποστολής τους. Οι κώδικες είναι _ηθικές κατευθυντήριες γραμμές_ για επαγγελματική συμπεριφορά, βοηθώντας τους υπαλλήλους ή τα μέλη να λαμβάνουν αποφάσεις που ευθυγραμμίζονται με τις αρχές του οργανισμού τους. Είναι τόσο καλοί όσο η εθελοντική συμμόρφωση από τα μέλη. Ωστόσο, πολλοί οργανισμοί προσφέρουν πρόσθετες ανταμοιβές και ποινές για να παρακινήσουν τη συμμόρφωση από τα μέλη.

Παραδείγματα περιλαμβάνουν:

 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Κώδικας Ηθικής
 * [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Κώδικας Συμπεριφοράς (δημιουργήθηκε το 2013)
 * [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (από το 1993)

> 🚨 Ανήκετε σε έναν επαγγελματικό οργανισμό μηχανικής ή επιστήμης δεδομένων; Εξερευνήστε τον ιστότοπό τους για να δείτε αν ορίζουν έναν επαγγελματικό κώδικα ηθικής. Τι λέει αυτό για τις ηθικές τους αρχές; Πώς "ενθαρρύνουν" τα μέλη να ακολουθήσουν τον κώδικα;

### 2. Λίστες Ελέγχου Ηθικής

Ενώ οι επαγγελματικοί κώδικες ορίζουν την απαιτούμενη _ηθική συμπεριφορά_ από τους επαγγελματίες, [έχουν γνωστούς περιορισμούς](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) στην επιβολή, ιδιαίτερα σε μεγάλης κλίμακας έργα. Αντίθετα, πολλοί ειδικοί στην επιστήμη δεδομένων [υποστηρίζουν λίστες ελέγχου](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), που μπορούν να **συνδέσουν τις αρχές με τις πρακτικές** με πιο καθοριστικούς και εφαρμόσιμους τρόπους. 

Οι λίστες ελέγχου μετατρέπουν ερωτήσεις σε "ναι/όχι" εργασίες που μπορούν να επιχειρησιακοποιηθούν, επιτρέποντάς τους να παρακολουθούνται ως μέρος των τυπικών ροών εργασίας κυκλοφορίας προϊόντων. 

Παραδείγματα περιλαμβάνουν:
 * [Deon](https://deon.drivendata.org/) - μια γενικής χρήσης λίστα ελέγχου ηθικής δεδομένων που δημιουργήθηκε από [συστάσεις της βιομηχανίας](https://deon.drivendata.org/#checklist-citations) με ένα εργαλείο γραμμής εντολών για εύκολη ενσωμάτωση.
 * [Privacy Audit Checklist](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - παρέχει γενικές οδηγίες για πρακτικές χειρισμού πληροφοριών από νομικές και κοινωνικές προοπτικές έκθεσης.
 * [AI Fairness Checklist](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - δημιουργήθηκε από επαγγελματίες AI για να υποστηρίξει την υιοθέτηση και ενσωμάτωση ελέγχων δικαιοσύνης στους κύκλους ανάπτυξης AI.
 * [22 ερωτήσεις για την ηθική στα δεδομένα και την AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - πιο ανοιχτό πλαίσιο, δομημένο για αρχική εξερεύνηση ηθικών ζητημάτων στο σχεδιασμό, την υλοποίηση και τα οργανωτικά πλαίσια.

### 3. Κανονισμοί Ηθικής

Η ηθική αφορά τον ορισμό κοινών αξιών και την εθελοντική σωστή πράξη. **Συμμόρφωση** αφορά την _τήρηση του νόμου_ όπου και αν ορίζεται. **Διακυβέρνηση** καλύπτει γενικά όλους τους τρόπους με τους οποίους οι οργανισμοί λειτουργούν για να επιβάλλουν ηθικές αρχές και να συμμορφώνονται με καθορισμένους νόμους.

Σήμερα, η διακυβέρνηση λαμβάνει δύο μορφές εντός οργανισμών. Πρώτον, αφορά τον ορισμό **ηθικών αρχών AI** και την καθιέρωση πρακτικών για την επιχειρησιακοποίηση της υιοθέτησης σε όλα τα έργα που σχετίζονται με AI στον οργανισμό. Δεύτερον, αφορά τη συμμόρφωση με όλους τους κυβερνητικά καθορισμένους **κανονισμούς προστασίας δεδομένων** για τις περιοχές στις οποίες λειτουργεί.

Παραδείγματα κανονισμών προστασίας δεδομένων και ιδιωτικότητας:

 * `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - ρυθμίζει τη _συλλογή, χρήση και αποκάλυψη_ προσωπικών πληροφοριών από την ομοσπονδιακή κυβέρνηση.
 * `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - προστατεύει προσωπικά δεδομένα υγείας.
 * `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - προστατεύει την ιδιωτικότητα δεδομένων παιδιών κάτω των 13 ετών.
 * `2018`, [General Data Protection Regulation (GDPR)](https://gdpr-info.eu/) - παρέχει δικαιώματα χρηστών, προστασία δεδομένων και ιδιωτικότητα.
 * `2018`, [California Consumer Privacy Act (CCPA)](https://www.oag.ca.gov/privacy/ccpa) δίνει στους καταναλωτές περισσότερα _δικαιώματα_ για τα (προσωπικά) δεδομένα τους.
 * `2021`, Η Κίνα [Personal Information Protection Law](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) μόλις πέρασε, δημιουργώντας έναν από τους ισχυρότερους κανονισμούς ιδιωτικότητας δεδομένων παγκοσμίως.

> 🚨 Η Ευρωπαϊ
* [Αρχές Υπεύθυνης Τεχνητής Νοημοσύνης](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - δωρεάν εκπαιδευτική διαδρομή από το Microsoft Learn.  
* [Ηθική και Επιστήμη Δεδομένων](https://resources.oreilly.com/examples/0636920203964) - EBook από την O'Reilly (M. Loukides, H. Mason κ.ά.)  
* [Ηθική στην Επιστήμη Δεδομένων](https://www.coursera.org/learn/data-science-ethics#syllabus) - διαδικτυακό μάθημα από το Πανεπιστήμιο του Μίσιγκαν.  
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - μελέτες περιπτώσεων από το Πανεπιστήμιο του Τέξας.  

# Εργασία  

[Γράψτε Μια Μελέτη Περίπτωσης Ηθικής Δεδομένων](assignment.md)  

---

**Αποποίηση ευθύνης**:  
Αυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία αυτόματης μετάφρασης [Co-op Translator](https://github.com/Azure/co-op-translator). Παρόλο που καταβάλλουμε προσπάθειες για ακρίβεια, παρακαλούμε να έχετε υπόψη ότι οι αυτοματοποιημένες μεταφράσεις ενδέχεται να περιέχουν λάθη ή ανακρίβειες. Το πρωτότυπο έγγραφο στη μητρική του γλώσσα θα πρέπει να θεωρείται η αυθεντική πηγή. Για κρίσιμες πληροφορίες, συνιστάται επαγγελματική ανθρώπινη μετάφραση. Δεν φέρουμε ευθύνη για τυχόν παρεξηγήσεις ή εσφαλμένες ερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.