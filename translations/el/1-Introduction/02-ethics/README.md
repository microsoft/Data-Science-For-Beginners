<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1341f6da63d434f5ba31b08ea951b02c",
  "translation_date": "2025-09-05T21:20:49+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "el"
}
-->
# Εισαγωγή στην Ηθική των Δεδομένων

|![ Σκίτσο από [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Ηθική της Επιστήμης Δεδομένων - _Σκίτσο από [@nitya](https://twitter.com/nitya)_ |

---

Είμαστε όλοι πολίτες δεδομένων που ζούμε σε έναν κόσμο γεμάτο δεδομένα.

Οι τάσεις της αγοράς δείχνουν ότι μέχρι το 2022, 1 στους 3 μεγάλους οργανισμούς θα αγοράζει και θα πουλάει δεδομένα μέσω διαδικτυακών [Αγορών και Ανταλλακτηρίων](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Ως **Προγραμματιστές Εφαρμογών**, θα βρούμε πιο εύκολο και οικονομικό να ενσωματώσουμε πληροφορίες που βασίζονται σε δεδομένα και αυτοματισμούς που βασίζονται σε αλγόριθμους στις καθημερινές εμπειρίες των χρηστών. Αλλά καθώς η Τεχνητή Νοημοσύνη γίνεται πανταχού παρούσα, θα χρειαστεί επίσης να κατανοήσουμε τις πιθανές βλάβες που προκαλούνται από τη [χρήση ως όπλο](https://www.youtube.com/watch?v=TQHs8SA1qpk) τέτοιων αλγορίθμων σε μεγάλη κλίμακα.

Οι τάσεις δείχνουν επίσης ότι θα δημιουργήσουμε και θα καταναλώσουμε πάνω από [180 zettabytes](https://www.statista.com/statistics/871513/worldwide-data-created/) δεδομένων μέχρι το 2025. Ως **Επιστήμονες Δεδομένων**, αυτό μας δίνει πρωτοφανή επίπεδα πρόσβασης σε προσωπικά δεδομένα. Αυτό σημαίνει ότι μπορούμε να δημιουργήσουμε προφίλ συμπεριφοράς χρηστών και να επηρεάσουμε τη λήψη αποφάσεων με τρόπους που δημιουργούν μια [ψευδαίσθηση ελεύθερης επιλογής](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice), ενώ ενδεχομένως καθοδηγούμε τους χρήστες προς αποτελέσματα που προτιμούμε. Αυτό εγείρει επίσης ευρύτερα ερωτήματα σχετικά με την ιδιωτικότητα των δεδομένων και την προστασία των χρηστών.

Η ηθική των δεδομένων είναι πλέον _απαραίτητα προστατευτικά μέτρα_ για την επιστήμη και τη μηχανική των δεδομένων, βοηθώντας μας να ελαχιστοποιήσουμε τις πιθανές βλάβες και τις ακούσιες συνέπειες από τις ενέργειές μας που βασίζονται σε δεδομένα. Ο [Κύκλος Υπερβολής της Gartner για την Τεχνητή Νοημοσύνη](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) εντοπίζει σχετικές τάσεις στην ψηφιακή ηθική, την υπεύθυνη ΤΝ και τη διακυβέρνηση ΤΝ ως βασικούς παράγοντες για μεγαλύτερες τάσεις γύρω από τη _δημοκρατικοποίηση_ και τη _βιομηχανοποίηση_ της ΤΝ.

![Κύκλος Υπερβολής της Gartner για την ΤΝ - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

Σε αυτό το μάθημα, θα εξερευνήσουμε τον συναρπαστικό τομέα της ηθικής των δεδομένων - από βασικές έννοιες και προκλήσεις, μέχρι μελέτες περιπτώσεων και εφαρμοσμένες έννοιες ΤΝ όπως η διακυβέρνηση - που βοηθούν στη δημιουργία μιας κουλτούρας ηθικής σε ομάδες και οργανισμούς που εργάζονται με δεδομένα και ΤΝ.




## [Κουίζ πριν το μάθημα](https://ff-quizzes.netlify.app/en/ds/quiz/2) 🎯

## Βασικοί Ορισμοί

Ας ξεκινήσουμε κατανοώντας τη βασική ορολογία.

Η λέξη "ηθική" προέρχεται από την [ελληνική λέξη "ηθικός"](https://en.wikipedia.org/wiki/Ethics) (και τη ρίζα της "ήθος") που σημαίνει _χαρακτήρας ή ηθική φύση_. 

**Ηθική** αφορά τις κοινές αξίες και τις ηθικές αρχές που διέπουν τη συμπεριφορά μας στην κοινωνία. Η ηθική βασίζεται όχι σε νόμους αλλά σε ευρέως αποδεκτούς κανόνες για το τι είναι "σωστό έναντι λάθους". Ωστόσο, οι ηθικές σκέψεις μπορούν να επηρεάσουν πρωτοβουλίες εταιρικής διακυβέρνησης και κυβερνητικούς κανονισμούς που δημιουργούν περισσότερα κίνητρα για συμμόρφωση.

**Ηθική των Δεδομένων** είναι ένας [νέος κλάδος της ηθικής](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1) που "μελετά και αξιολογεί ηθικά προβλήματα που σχετίζονται με _δεδομένα, αλγόριθμους και αντίστοιχες πρακτικές_". Εδώ, **"δεδομένα"** εστιάζουν σε ενέργειες που σχετίζονται με τη δημιουργία, την καταγραφή, τη φροντίδα, την επεξεργασία, τη διάδοση, την κοινή χρήση και τη χρήση, **"αλγόριθμοι"** εστιάζουν στην ΤΝ, τους πράκτορες, τη μηχανική μάθηση και τα ρομπότ, και **"πρακτικές"** εστιάζουν σε θέματα όπως η υπεύθυνη καινοτομία, ο προγραμματισμός, το hacking και οι κώδικες ηθικής.

**Εφαρμοσμένη Ηθική** είναι η [πρακτική εφαρμογή ηθικών σκέψεων](https://en.wikipedia.org/wiki/Applied_ethics). Είναι η διαδικασία ενεργής διερεύνησης ηθικών ζητημάτων στο πλαίσιο _πραγματικών ενεργειών, προϊόντων και διαδικασιών_, και λήψης διορθωτικών μέτρων για να διασφαλιστεί ότι αυτά παραμένουν ευθυγραμμισμένα με τις καθορισμένες ηθικές αξίες μας.

**Κουλτούρα Ηθικής** αφορά την [_επιχειρησιακή εφαρμογή_ της εφαρμοσμένης ηθικής](https://hbr.org/2019/05/how-to-design-an-ethical-organization) για να διασφαλιστεί ότι οι ηθικές μας αρχές και πρακτικές υιοθετούνται με συνεπή και επεκτάσιμο τρόπο σε ολόκληρο τον οργανισμό. Οι επιτυχημένες κουλτούρες ηθικής ορίζουν ηθικές αρχές σε επίπεδο οργανισμού, παρέχουν ουσιαστικά κίνητρα για συμμόρφωση και ενισχύουν τους κανόνες ηθικής ενθαρρύνοντας και ενισχύοντας τις επιθυμητές συμπεριφορές σε κάθε επίπεδο του οργανισμού.


## Έννοιες Ηθικής

Σε αυτή την ενότητα, θα συζητήσουμε έννοιες όπως **κοινές αξίες** (αρχές) και **ηθικές προκλήσεις** (προβλήματα) για την ηθική των δεδομένων - και θα εξερευνήσουμε **μελέτες περιπτώσεων** που σας βοηθούν να κατανοήσετε αυτές τις έννοιες σε πραγματικά πλαίσια.

### 1. Αρχές Ηθικής

Κάθε στρατηγική ηθικής δεδομένων ξεκινά με τον ορισμό _ηθικών αρχών_ - των "κοινών αξιών" που περιγράφουν αποδεκτές συμπεριφορές και καθοδηγούν συμμορφούμενες ενέργειες στα έργα μας με δεδομένα και ΤΝ. Μπορείτε να τις ορίσετε σε ατομικό ή ομαδικό επίπεδο. Ωστόσο, οι περισσότεροι μεγάλοι οργανισμοί τις περιγράφουν σε μια δήλωση αποστολής ή πλαίσιο _ηθικής ΤΝ_ που ορίζεται σε εταιρικό επίπεδο και εφαρμόζεται με συνέπεια σε όλες τις ομάδες.

**Παράδειγμα:** Η δήλωση αποστολής της [Υπεύθυνης ΤΝ της Microsoft](https://www.microsoft.com/en-us/ai/responsible-ai) αναφέρει: _"Δεσμευόμαστε για την προώθηση της ΤΝ που καθοδηγείται από ηθικές αρχές που βάζουν τους ανθρώπους πρώτα"_ - προσδιορίζοντας 6 ηθικές αρχές στο παρακάτω πλαίσιο:

![Υπεύθυνη ΤΝ στη Microsoft](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

Ας εξερευνήσουμε σύντομα αυτές τις αρχές. _Η διαφάνεια_ και _η λογοδοσία_ είναι θεμελιώδεις αξίες πάνω στις οποίες χτίζονται οι άλλες αρχές - ας ξεκινήσουμε από εκεί:

* [**Λογοδοσία**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) καθιστά τους επαγγελματίες _υπεύθυνους_ για τις λειτουργίες τους με δεδομένα και ΤΝ, και τη συμμόρφωση με αυτές τις ηθικές αρχές.
* [**Διαφάνεια**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) διασφαλίζει ότι οι ενέργειες με δεδομένα και ΤΝ είναι _κατανοητές_ (ερμηνεύσιμες) στους χρήστες, εξηγώντας το τι και το γιατί πίσω από τις αποφάσεις.
* [**Δικαιοσύνη**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - εστιάζει στη διασφάλιση ότι η ΤΝ αντιμετωπίζει _όλους τους ανθρώπους_ δίκαια, αντιμετωπίζοντας τυχόν συστημικές ή έμμεσες κοινωνικο-τεχνικές προκαταλήψεις στα δεδομένα και τα συστήματα.
* [**Αξιοπιστία & Ασφάλεια**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - διασφαλίζει ότι η ΤΝ συμπεριφέρεται _συνεπώς_ με καθορισμένες αξίες, ελαχιστοποιώντας πιθανές βλάβες ή ακούσιες συνέπειες.
* [**Ιδιωτικότητα & Ασφάλεια**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - αφορά την κατανόηση της προέλευσης των δεδομένων και την παροχή _προστασίας ιδιωτικότητας δεδομένων_ στους χρήστες.
* [**Συμπερίληψη**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - αφορά το σχεδιασμό λύσεων ΤΝ με πρόθεση, προσαρμόζοντάς τες για να καλύψουν ένα _ευρύ φάσμα ανθρώπινων αναγκών_ και δυνατοτήτων.

> 🚨 Σκεφτείτε ποια θα μπορούσε να είναι η δήλωση αποστολής σας για την ηθική των δεδομένων. Εξερευνήστε πλαίσια ηθικής ΤΝ από άλλους οργανισμούς - εδώ είναι παραδείγματα από [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles), και [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Ποιες κοινές αξίες έχουν; Πώς σχετίζονται αυτές οι αρχές με το προϊόν ΤΝ ή τη βιομηχανία στην οποία δραστηριοποιούνται;

### 2. Προκλήσεις Ηθικής

Αφού ορίσουμε τις ηθικές αρχές, το επόμενο βήμα είναι να αξιολογήσουμε τις ενέργειές μας με δεδομένα και ΤΝ για να δούμε αν ευθυγραμμίζονται με αυτές τις κοινές αξίες. Σκεφτείτε τις ενέργειές σας σε δύο κατηγορίες: _συλλογή δεδομένων_ και _σχεδιασμός αλγορίθμων_. 

Με τη συλλογή δεδομένων, οι ενέργειες πιθανότατα θα περιλαμβάνουν **προσωπικά δεδομένα** ή προσωπικά αναγνωρίσιμες πληροφορίες (PII) για αναγνωρίσιμα ζωντανά άτομα. Αυτό περιλαμβάνει [διάφορα στοιχεία μη προσωπικών δεδομένων](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) που _συλλογικά_ αναγνωρίζουν ένα άτομο. Οι ηθικές προκλήσεις μπορεί να σχετίζονται με _ιδιωτικότητα δεδομένων_, _ιδιοκτησία δεδομένων_, και συναφή θέματα όπως _ενημερωμένη συναίνεση_ και _δικαιώματα πνευματικής ιδιοκτησίας_ για τους χρήστες.

Με το σχεδιασμό αλγορίθμων, οι ενέργειες θα περιλαμβάνουν τη συλλογή και την επιμέλεια **συνόλων δεδομένων**, και στη συνέχεια τη χρήση τους για την εκπαίδευση και την ανάπτυξη **μοντέλων δεδομένων** που προβλέπουν αποτελέσματα ή αυτοματοποιούν αποφάσεις σε πραγματικά πλαίσια. Οι ηθικές προκλήσεις μπορεί να προκύψουν από _προκατάληψη συνόλου δεδομένων_, _προβλήματα ποιότητας δεδομένων_, _αδικία_ και _παραπλάνηση_ στους αλγορίθμους - συμπεριλαμβανομένων ορισμένων ζητημάτων που είναι συστημικά στη φύση.

Και στις δύο περιπτώσεις, οι ηθικές προκλήσεις υπογραμμίζουν περιοχές όπου οι ενέργειές μας μπορεί να έρθουν σε σύγκρουση με τις κοινές αξίες μας. Για να ανιχνεύσουμε, να μετριάσουμε, να ελαχιστοποιήσουμε ή να εξαλείψουμε αυτές τις ανησυχίες - πρέπει να θέσουμε ηθικά ερωτήματα "ναι/όχι" σχετικά με τις ενέργειές μας και να λάβουμε διορθωτικά μέτρα όπως απαιτείται. Ας δούμε μερικές ηθικές προκλήσεις και τα ηθικά ερωτήματα που εγείρουν:


#### 2.1 Ιδιοκτησία Δεδομένων

Η συλλογή δεδομένων συχνά περιλαμβάνει προσωπικά δεδομένα που μπορούν να αναγνωρίσουν τα υποκείμενα των δεδομένων. [Η ιδιοκτησία δεδομένων](https://permission.io/blog/data-ownership) αφορά τον _έλεγχο_ και [_τα δικαιώματα των χρηστών_](https://permission.io/blog/data-ownership) σχετικά με τη δημιουργία, την επεξεργασία και τη διάδοση δεδομένων. 

Τα ηθικά ερωτήματα που πρέπει να θέσουμε είναι: 
 * Ποιος κατέχει τα δεδομένα; (χρήστης ή οργανισμός)
 * Ποια δικαιώματα έχουν τα υποκείμενα των δεδομένων; (π.χ. πρόσβαση, διαγραφή, φορητότητα)
 * Ποια δικαιώματα έχουν οι οργανισμοί; (π.χ. διόρθωση κακόβουλων κριτικών χρηστών)

#### 2.2 Ενημερωμένη Συναίνεση

[Η ενημερωμένη συναίνεση](https://legaldictionary.net/informed-consent/) ορίζει την πράξη των χρηστών να συμφωνούν σε μια ενέργεια (όπως η συλλογή δεδομένων) με _πλήρη κατανόηση_ των σχετικών γεγονότων, συμπεριλαμβανομένου του σκοπού, των πιθανών κινδύνων και των εναλλακτικών. 

Ερωτήματα προς διερεύνηση εδώ είναι:
 * Έδωσε ο χρήστης (υποκείμενο δεδομένων) άδεια για τη συλλογή και χρήση δεδομένων;
 * Κατάλαβε ο χρήστης τον σκοπό για τον οποίο συλλέχθηκαν τα δεδομένα;
 * Κατάλαβε ο χρήστης τους πιθανούς κινδύνους από τη συμμετοχή του;

#### 2.3 Πνευματική Ιδιοκτησία

[Η πνευματική ιδιοκτησία](https://en.wikipedia.org/wiki/Intellectual_property) αναφέρεται σε άυλες δημιουργίες που προκύπτουν από την ανθρώπινη πρωτοβουλία, οι οποίες μπορεί να _έχουν οικονομική αξία_ για άτομα ή επιχειρήσεις. 

Ερωτήματα προς διερεύνηση εδώ είναι:
 * Είχαν τα συλλεχθέντα δεδομένα οικονομική αξία για έναν χρήστη ή μια επιχείρηση;
 * Έχει ο **χρήστης** πνευματική ιδιοκτησία εδώ;
 * Έχει ο **οργανισμός** πνευματική ιδιοκτησία εδώ;
 * Εάν υπάρχουν αυτά τα δικαιώματα, πώς τα προστατεύουμε;

#### 2.4 Ιδιωτικότητα Δεδομένων

[Η ιδιωτικότητα δεδομένων](https://www.northeastern.edu/graduate/blog/what
[Algorithm Fairness](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) ελέγχει αν ο σχεδιασμός του αλγορίθμου συστηματικά εισάγει διακρίσεις εναντίον συγκεκριμένων υποομάδων υποκειμένων δεδομένων, οδηγώντας σε [πιθανούς κινδύνους](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) στην _κατανομή_ (όπου πόροι αρνούνται ή παρακρατούνται από αυτή την ομάδα) και στην _ποιότητα υπηρεσιών_ (όπου η ακρίβεια της AI δεν είναι ίδια για όλες τις υποομάδες). 

Ερωτήσεις για διερεύνηση εδώ:
 * Αξιολογήσαμε την ακρίβεια του μοντέλου για διαφορετικές υποομάδες και συνθήκες;
 * Εξετάσαμε το σύστημα για πιθανούς κινδύνους (π.χ., στερεοτυπικές αντιλήψεις);
 * Μπορούμε να αναθεωρήσουμε δεδομένα ή να επανεκπαιδεύσουμε μοντέλα για να μειώσουμε τους εντοπισμένους κινδύνους;

Εξερευνήστε πόρους όπως [AI Fairness checklists](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) για να μάθετε περισσότερα.

#### 2.9 Παραπλάνηση

[Παραπλάνηση δεδομένων](https://www.sciencedirect.com/topics/computer-science/misrepresentation) αφορά το ερώτημα αν επικοινωνούμε ευρήματα από ειλικρινώς αναφερόμενα δεδομένα με τρόπο που παραπλανά για να υποστηρίξουμε μια επιθυμητή αφήγηση. 

Ερωτήσεις για διερεύνηση εδώ:
 * Αναφέρουμε ελλιπή ή ανακριβή δεδομένα;
 * Οπτικοποιούμε δεδομένα με τρόπο που οδηγεί σε παραπλανητικά συμπεράσματα;
 * Χρησιμοποιούμε επιλεκτικές στατιστικές τεχνικές για να χειραγωγήσουμε αποτελέσματα;
 * Υπάρχουν εναλλακτικές εξηγήσεις που μπορεί να προσφέρουν διαφορετικό συμπέρασμα;

#### 2.10 Ελεύθερη Επιλογή
Η [Ψευδαίσθηση της Ελεύθερης Επιλογής](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) συμβαίνει όταν οι "αρχιτεκτονικές επιλογών" του συστήματος χρησιμοποιούν αλγορίθμους λήψης αποφάσεων για να ωθήσουν τους ανθρώπους προς ένα προτιμώμενο αποτέλεσμα, ενώ φαίνεται ότι τους δίνουν επιλογές και έλεγχο. Αυτά τα [σκοτεινά μοτίβα](https://www.darkpatterns.org/) μπορούν να προκαλέσουν κοινωνική και οικονομική βλάβη στους χρήστες. Επειδή οι αποφάσεις των χρηστών επηρεάζουν τα προφίλ συμπεριφοράς, αυτές οι ενέργειες ενδέχεται να οδηγήσουν σε μελλοντικές επιλογές που μπορούν να ενισχύσουν ή να επεκτείνουν τον αντίκτυπο αυτών των βλαβών.

Ερωτήσεις για διερεύνηση εδώ:
 * Κατάλαβε ο χρήστης τις συνέπειες της επιλογής που έκανε;
 * Ήταν ο χρήστης ενήμερος για (εναλλακτικές) επιλογές και τα πλεονεκτήματα & μειονεκτήματα της κάθε μίας;
 * Μπορεί ο χρήστης να αναιρέσει μια αυτοματοποιημένη ή επηρεασμένη επιλογή αργότερα;

### 3. Μελέτες Περίπτωσης

Για να τοποθετήσουμε αυτές τις ηθικές προκλήσεις σε πραγματικά πλαίσια, βοηθά να εξετάσουμε μελέτες περίπτωσης που αναδεικνύουν τους πιθανούς κινδύνους και τις συνέπειες για άτομα και την κοινωνία, όταν παραβιάσεις ηθικής παραβλέπονται. 

Ακολουθούν μερικά παραδείγματα:

| Ηθική Πρόκληση | Μελέτη Περίπτωσης  | 
|--- |--- |
| **Ενημερωμένη Συναίνεση** | 1972 - [Tuskegee Syphilis Study](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - Αφροαμερικανοί άνδρες που συμμετείχαν στη μελέτη υποσχέθηκαν δωρεάν ιατρική φροντίδα _αλλά εξαπατήθηκαν_ από ερευνητές που δεν ενημέρωσαν τους συμμετέχοντες για τη διάγνωσή τους ή για τη διαθεσιμότητα θεραπείας. Πολλοί συμμετέχοντες πέθαναν και οι σύντροφοι ή τα παιδιά τους επηρεάστηκαν. Η μελέτη διήρκεσε 40 χρόνια. | 
| **Ιδιωτικότητα Δεδομένων** |  2007 - Το [Netflix data prize](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) παρείχε στους ερευνητές _10 εκατομμύρια ανωνυμοποιημένες βαθμολογίες ταινιών από 50.000 πελάτες_ για να βοηθήσουν στη βελτίωση των αλγορίθμων συστάσεων. Ωστόσο, οι ερευνητές μπόρεσαν να συσχετίσουν ανωνυμοποιημένα δεδομένα με προσωπικά αναγνωρίσιμα δεδομένα σε _εξωτερικά σύνολα δεδομένων_ (π.χ., σχόλια IMDb) - ουσιαστικά "απο-ανωνυμοποιώντας" ορισμένους συνδρομητές του Netflix.|
| **Προκατάληψη Συλλογής Δεδομένων**  | 2013 - Η πόλη της Βοστώνης [ανέπτυξε το Street Bump](https://www.boston.gov/transportation/street-bump), μια εφαρμογή που επέτρεπε στους πολίτες να αναφέρουν λακκούβες, παρέχοντας στην πόλη καλύτερα δεδομένα για τους δρόμους. Ωστόσο, [άτομα με χαμηλότερα εισοδήματα είχαν λιγότερη πρόσβαση σε αυτοκίνητα και τηλέφωνα](https://hbr.org/2013/04/the-hidden-biases-in-big-data), καθιστώντας τα προβλήματα των δρόμων τους αόρατα στην εφαρμογή. Οι προγραμματιστές συνεργάστηκαν με ακαδημαϊκούς για να αντιμετωπίσουν ζητήματα _ισότιμης πρόσβασης και ψηφιακών αποκλεισμών_ για δικαιοσύνη. |
| **Δικαιοσύνη Αλγορίθμων**  | 2018 - Η MIT [Gender Shades Study](http://gendershades.org/overview.html) αξιολόγησε την ακρίβεια προϊόντων AI για ταξινόμηση φύλου, αποκαλύπτοντας κενά στην ακρίβεια για γυναίκες και άτομα με χρώμα. Μια [2019 Apple Card](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) φάνηκε να προσφέρει λιγότερη πίστωση στις γυναίκες από ό,τι στους άνδρες. Και τα δύο ανέδειξαν ζητήματα προκατάληψης αλγορίθμων που οδηγούν σε κοινωνικοοικονομικές βλάβες.|
| **Παραπλάνηση Δεδομένων** | 2020 - Το [Georgia Department of Public Health κυκλοφόρησε γραφήματα COVID-19](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) που φαινόταν να παραπλανούν τους πολίτες σχετικά με τις τάσεις των επιβεβαιωμένων κρουσμάτων με μη χρονολογική ταξινόμηση στον άξονα x. Αυτό δείχνει παραπλάνηση μέσω τεχνικών οπτικοποίησης. |
| **Ψευδαίσθηση Ελεύθερης Επιλογής** | 2020 - Η εφαρμογή μάθησης [ABCmouse πλήρωσε $10M για να διευθετήσει καταγγελία της FTC](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/) όπου οι γονείς παγιδεύτηκαν να πληρώνουν για συνδρομές που δεν μπορούσαν να ακυρώσουν. Αυτό δείχνει σκοτεινά μοτίβα στις αρχιτεκτονικές επιλογών, όπου οι χρήστες ωθήθηκαν σε δυνητικά επιβλαβείς επιλογές. |
| **Ιδιωτικότητα Δεδομένων & Δικαιώματα Χρηστών** | 2021 - Το Facebook [Data Breach](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) αποκάλυψε δεδομένα από 530 εκατομμύρια χρήστες, οδηγώντας σε διακανονισμό $5B με την FTC. Ωστόσο, αρνήθηκε να ειδοποιήσει τους χρήστες για την παραβίαση, παραβιάζοντας τα δικαιώματα των χρηστών σχετικά με τη διαφάνεια και την πρόσβαση στα δεδομένα. |

Θέλετε να εξερευνήσετε περισσότερες μελέτες περίπτωσης; Δείτε αυτούς τους πόρους:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - ηθικά διλήμματα σε διάφορες βιομηχανίες. 
* [Data Science Ethics course](https://www.coursera.org/learn/data-science-ethics#syllabus) - μελέτες περίπτωσης ορόσημα.
* [Where things have gone wrong](https://deon.drivendata.org/examples/) - λίστα ελέγχου deon με παραδείγματα.


> 🚨 Σκεφτείτε τις μελέτες περίπτωσης που έχετε δει - έχετε βιώσει ή επηρεαστεί από μια παρόμοια ηθική πρόκληση στη ζωή σας; Μπορείτε να σκεφτείτε τουλάχιστον μία άλλη μελέτη περίπτωσης που να απεικονίζει μία από τις ηθικές προκλήσεις που συζητήσαμε σε αυτή την ενότητα;

## Εφαρμοσμένη Ηθική

Μιλήσαμε για έννοιες ηθικής, προκλήσεις και μελέτες περίπτωσης σε πραγματικά πλαίσια. Αλλά πώς ξεκινάμε να _εφαρμόζουμε_ ηθικές αρχές και πρακτικές στα έργα μας; Και πώς _επιχειρησιακοποιούμε_ αυτές τις πρακτικές για καλύτερη διακυβέρνηση; Ας εξερευνήσουμε μερικές λύσεις πραγματικού κόσμου: 

### 1. Επαγγελματικοί Κώδικες

Οι Επαγγελματικοί Κώδικες προσφέρουν μια επιλογή για οργανισμούς να "ενθαρρύνουν" τα μέλη τους να υποστηρίξουν τις ηθικές αρχές και τη δήλωση αποστολής τους. Οι κώδικες είναι _ηθικές κατευθυντήριες γραμμές_ για επαγγελματική συμπεριφορά, βοηθώντας τους υπαλλήλους ή τα μέλη να λαμβάνουν αποφάσεις που ευθυγραμμίζονται με τις αρχές του οργανισμού τους. Είναι τόσο καλοί όσο η εθελοντική συμμόρφωση από τα μέλη. Ωστόσο, πολλοί οργανισμοί προσφέρουν πρόσθετες ανταμοιβές και ποινές για να παρακινήσουν τη συμμόρφωση από τα μέλη.

Παραδείγματα περιλαμβάνουν:

 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Κώδικας Ηθικής
 * [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Κώδικας Συμπεριφοράς (δημιουργήθηκε το 2013)
 * [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (από το 1993)

> 🚨 Ανήκετε σε έναν επαγγελματικό οργανισμό μηχανικών ή επιστήμης δεδομένων; Εξερευνήστε τον ιστότοπό τους για να δείτε αν ορίζουν έναν επαγγελματικό κώδικα ηθικής. Τι λέει αυτό για τις ηθικές τους αρχές; Πώς "ενθαρρύνουν" τα μέλη να ακολουθήσουν τον κώδικα;

### 2. Λίστες Ελέγχου Ηθικής

Ενώ οι επαγγελματικοί κώδικες ορίζουν την απαιτούμενη _ηθική συμπεριφορά_ από τους επαγγελματίες, [έχουν γνωστούς περιορισμούς](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) στην επιβολή, ιδιαίτερα σε μεγάλης κλίμακας έργα. Αντίθετα, πολλοί ειδικοί στην επιστήμη δεδομένων [υποστηρίζουν λίστες ελέγχου](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), που μπορούν να **συνδέσουν τις αρχές με τις πρακτικές** με πιο καθοριστικούς και εφαρμόσιμους τρόπους. 

Οι λίστες ελέγχου μετατρέπουν ερωτήσεις σε "ναι/όχι" εργασίες που μπορούν να επιχειρησιακοποιηθούν, επιτρέποντάς τους να παρακολουθούνται ως μέρος των τυπικών ροών εργασίας κυκλοφορίας προϊόντων. 

Παραδείγματα περιλαμβάνουν:
 * [Deon](https://deon.drivendata.org/) - μια γενικής χρήσης λίστα ελέγχου ηθικής δεδομένων που δημιουργήθηκε από [συστάσεις της βιομηχανίας](https://deon.drivendata.org/#checklist-citations) με ένα εργαλείο γραμμής εντολών για εύκολη ενσωμάτωση.
 * [Privacy Audit Checklist](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - παρέχει γενικές οδηγίες για πρακτικές χειρισμού πληροφοριών από νομικές και κοινωνικές προοπτικές έκθεσης.
 * [AI Fairness Checklist](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - δημιουργήθηκε από επαγγελματίες AI για να υποστηρίξει την υιοθέτηση και ενσωμάτωση ελέγχων δικαιοσύνης στους κύκλους ανάπτυξης AI.
 * [22 ερωτήσεις για την ηθική στα δεδομένα και την AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - πιο ανοιχτό πλαίσιο, δομημένο για αρχική διερεύνηση ηθικών ζητημάτων στο σχεδιασμό, την υλοποίηση και τα οργανωτικά πλαίσια.

### 3. Κανονισμοί Ηθικής

Η ηθική αφορά τον ορισμό κοινών αξιών και την εθελοντική σωστή πράξη. **Συμμόρφωση** αφορά την _τήρηση του νόμου_ όπου και αν ορίζεται. **Διακυβέρνηση** καλύπτει ευρύτερα όλους τους τρόπους με τους οποίους οι οργανισμοί λειτουργούν για να επιβάλλουν ηθικές αρχές και να συμμορφώνονται με καθορισμένους νόμους.

Σήμερα, η διακυβέρνηση λαμβάνει δύο μορφές εντός οργανισμών. Πρώτον, αφορά τον ορισμό **ηθικών αρχών AI** και την καθιέρωση πρακτικών για την επιχειρησιακοποίηση της υιοθέτησης σε όλα τα έργα AI του οργανισμού. Δεύτερον, αφορά τη συμμόρφωση με όλους τους κυβερνητικά καθορισμένους **κανονισμούς προστασίας δεδομένων** για τις περιοχές στις οποίες δραστηριοποιείται.

Παραδείγματα κανονισμών προστασίας δεδομένων και ιδιωτικότητας:

 * `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - ρυθμίζει τη συλλογή, χρήση και αποκάλυψη προσωπικών πληροφοριών από την _ομοσπονδιακή κυβέρνηση_.
 * `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - προστατεύει προσωπικά δεδομένα υγείας.
 * `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - προστατεύει την ιδιωτικότητα δεδομένων παιδιών κάτω των 13 ετών.
 * `2018`, [General Data Protection Regulation (GDPR)](https://gdpr-info.eu/) - παρέχει δικαιώματα χρηστών, προστασία δεδομένων και ιδιωτικότητα.
 * `2018`, [California Consumer Privacy Act (CCPA)](https://www.oag.ca.gov/privacy/ccpa) δίνει στους καταναλωτές περισσότερα _δικαιώματα_ για τα (προσωπικά) δεδομένα τους.
 * `2021`, Η Κίνα [Personal Information Protection Law](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) μόλις πέρασε, δημιουργώντας έναν από τους ισχυρότερους κανονισμούς ιδιωτικότητας δεδομένων παγκοσμίως.

>
* [Αρχές Υπεύθυνης Τεχνητής Νοημοσύνης](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - δωρεάν εκπαιδευτική διαδρομή από το Microsoft Learn.  
* [Ηθική και Επιστήμη Δεδομένων](https://resources.oreilly.com/examples/0636920203964) - EBook από την O'Reilly (M. Loukides, H. Mason κ.ά.)  
* [Ηθική στην Επιστήμη Δεδομένων](https://www.coursera.org/learn/data-science-ethics#syllabus) - διαδικτυακό μάθημα από το Πανεπιστήμιο του Μίσιγκαν.  
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - μελέτες περιπτώσεων από το Πανεπιστήμιο του Τέξας.  

# Εργασία  

[Γράψτε Μια Μελέτη Περίπτωσης Ηθικής Δεδομένων](assignment.md)  

---

**Αποποίηση Ευθύνης**:  
Αυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία αυτόματης μετάφρασης AI [Co-op Translator](https://github.com/Azure/co-op-translator). Παρόλο που καταβάλλουμε προσπάθειες για ακρίβεια, παρακαλούμε να έχετε υπόψη ότι οι αυτόματες μεταφράσεις ενδέχεται να περιέχουν σφάλματα ή ανακρίβειες. Το πρωτότυπο έγγραφο στη μητρική του γλώσσα θα πρέπει να θεωρείται η αυθεντική πηγή. Για κρίσιμες πληροφορίες, συνιστάται επαγγελματική ανθρώπινη μετάφραση. Δεν φέρουμε ευθύνη για τυχόν παρεξηγήσεις ή εσφαλμένες ερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.