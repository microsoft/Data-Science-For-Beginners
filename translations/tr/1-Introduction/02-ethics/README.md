<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3a34157cc63516eba97c89a0b2f8c3e6",
  "translation_date": "2025-09-03T21:20:39+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "tr"
}
-->
# Veri EtiÄŸine GiriÅŸ

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Veri Bilimi EtiÄŸi - _Sketchnote by [@nitya](https://twitter.com/nitya)_ |

---

Hepimiz veriyle dolu bir dÃ¼nyada yaÅŸayan veri vatandaÅŸlarÄ±yÄ±z.

Pazar trendleri, 2022 yÄ±lÄ± itibarÄ±yla bÃ¼yÃ¼k organizasyonlarÄ±n Ã¼Ã§te birinin verilerini Ã§evrimiÃ§i [Pazar Yerleri ve Borsalar](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/) aracÄ±lÄ±ÄŸÄ±yla alÄ±p satacaÄŸÄ±nÄ± gÃ¶steriyor. **Uygulama GeliÅŸtiricileri** olarak, veri odaklÄ± iÃ§gÃ¶rÃ¼leri ve algoritma tabanlÄ± otomasyonu gÃ¼nlÃ¼k kullanÄ±cÄ± deneyimlerine entegre etmenin daha kolay ve ucuz hale geldiÄŸini gÃ¶receÄŸiz. Ancak yapay zeka yaygÄ±nlaÅŸtÄ±kÃ§a, bu tÃ¼r algoritmalarÄ±n [silah haline getirilmesi](https://www.youtube.com/watch?v=TQHs8SA1qpk) sonucu ortaya Ã§Ä±kabilecek potansiyel zararlarÄ± da anlamamÄ±z gerekecek.

Trendler ayrÄ±ca 2025 yÄ±lÄ±na kadar [180 zettabayt](https://www.statista.com/statistics/871513/worldwide-data-created/) veri Ã¼reteceÄŸimizi ve tÃ¼keteceÄŸimizi gÃ¶steriyor. **Veri Bilimcileri** olarak, bu durum bize kiÅŸisel verilere benzeri gÃ¶rÃ¼lmemiÅŸ bir eriÅŸim saÄŸlÄ±yor. Bu, kullanÄ±cÄ±larÄ±n davranÄ±ÅŸ profillerini oluÅŸturabileceÄŸimiz ve karar alma sÃ¼reÃ§lerini, kullanÄ±cÄ±larÄ± tercih ettiÄŸimiz sonuÃ§lara yÃ¶nlendirebilecek ÅŸekilde etkileyebileceÄŸimiz anlamÄ±na geliyor. AynÄ± zamanda veri gizliliÄŸi ve kullanÄ±cÄ± korumalarÄ± gibi daha geniÅŸ sorularÄ± da gÃ¼ndeme getiriyor.

Veri etiÄŸi, veri bilimi ve mÃ¼hendisliÄŸi iÃ§in artÄ±k _gerekli koruma Ã¶nlemleri_ haline geldi ve veri odaklÄ± eylemlerimizden kaynaklanabilecek potansiyel zararlarÄ± ve istenmeyen sonuÃ§larÄ± en aza indirmemize yardÄ±mcÄ± oluyor. [Gartner'Ä±n Yapay Zeka Hype DÃ¶ngÃ¼sÃ¼](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/), dijital etik, sorumlu yapay zeka ve yapay zeka yÃ¶netimi gibi ilgili trendleri, yapay zekanÄ±n _demokratikleÅŸmesi_ ve _endÃ¼strileÅŸmesi_ gibi daha bÃ¼yÃ¼k megatrendlerin anahtar itici gÃ¼Ã§leri olarak tanÄ±mlÄ±yor.

![Gartner'Ä±n Yapay Zeka Hype DÃ¶ngÃ¼sÃ¼ - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

Bu derste, veri etiÄŸi alanÄ±nÄ± keÅŸfedeceÄŸiz - temel kavramlardan ve zorluklardan, vaka Ã§alÄ±ÅŸmalarÄ±na ve yÃ¶netiÅŸim gibi uygulamalÄ± yapay zeka kavramlarÄ±na kadar - veri ve yapay zeka ile Ã§alÄ±ÅŸan ekiplerde ve organizasyonlarda bir etik kÃ¼ltÃ¼rÃ¼ oluÅŸturulmasÄ±na yardÄ±mcÄ± olan konularÄ± ele alacaÄŸÄ±z.

## [Ders Ã–ncesi Test](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/2) ğŸ¯

## Temel TanÄ±mlar

Ã–ncelikle temel terminolojiyi anlamakla baÅŸlayalÄ±m.

"Etik" kelimesi, _karakter veya ahlaki doÄŸa_ anlamÄ±na gelen [Yunanca "ethikos"](https://en.wikipedia.org/wiki/Ethics) (ve kÃ¶kÃ¼ "ethos") kelimesinden gelir.

**Etik**, toplumdaki davranÄ±ÅŸlarÄ±mÄ±zÄ± yÃ¶neten ortak deÄŸerler ve ahlaki prensiplerle ilgilidir. Etik, yasalara deÄŸil, "doÄŸru ve yanlÄ±ÅŸ" olarak kabul edilen normlara dayanÄ±r. Ancak etik dÃ¼ÅŸÃ¼nceler, uyum iÃ§in daha fazla teÅŸvik yaratan kurumsal yÃ¶netim giriÅŸimlerini ve hÃ¼kÃ¼met dÃ¼zenlemelerini etkileyebilir.

**Veri EtiÄŸi**, "_veriler, algoritmalar ve ilgili uygulamalarla_ ilgili ahlaki sorunlarÄ± inceleyen ve deÄŸerlendiren" [etik alanÄ±nda yeni bir dal](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1) olarak tanÄ±mlanÄ±r. Burada, **"veri"** veri Ã¼retimi, kaydÄ±, kÃ¼rasyonu, iÅŸlenmesi, yayÄ±lmasÄ±, paylaÅŸÄ±mÄ± ve kullanÄ±mÄ± ile ilgili eylemlere odaklanÄ±r; **"algoritmalar"** yapay zeka, ajanlar, makine Ã¶ÄŸrenimi ve robotlara odaklanÄ±r; ve **"uygulamalar"** sorumlu yenilik, programlama, hackleme ve etik kodlar gibi konulara odaklanÄ±r.

**UygulamalÄ± Etik**, [_ahlaki dÃ¼ÅŸÃ¼ncelerin pratik uygulamasÄ±_](https://en.wikipedia.org/wiki/Applied_ethics) ile ilgilidir. Bu, _gerÃ§ek dÃ¼nya eylemleri, Ã¼rÃ¼nleri ve sÃ¼reÃ§leri_ baÄŸlamÄ±nda etik sorunlarÄ± aktif olarak araÅŸtÄ±rma ve bu sorunlarÄ±n tanÄ±mlÄ± etik deÄŸerlerimizle uyumlu kalmasÄ±nÄ± saÄŸlamak iÃ§in dÃ¼zeltici Ã¶nlemler alma sÃ¼recidir.

**Etik KÃ¼ltÃ¼rÃ¼**, [_uygulamalÄ± etiÄŸi_](https://hbr.org/2019/05/how-to-design-an-ethical-organization) operasyonel hale getirmekle ilgilidir; bÃ¶ylece etik prensiplerimizin ve uygulamalarÄ±mÄ±zÄ±n tÃ¼m organizasyon genelinde tutarlÄ± ve Ã¶lÃ§eklenebilir bir ÅŸekilde benimsenmesini saÄŸlar. BaÅŸarÄ±lÄ± etik kÃ¼ltÃ¼rleri, organizasyon genelinde etik prensipler tanÄ±mlar, uyum iÃ§in anlamlÄ± teÅŸvikler saÄŸlar ve istenen davranÄ±ÅŸlarÄ± her seviyede teÅŸvik ederek ve gÃ¼Ã§lendirerek etik normlarÄ± pekiÅŸtirir.

## Etik KavramlarÄ±

Bu bÃ¶lÃ¼mde, veri etiÄŸi iÃ§in **ortak deÄŸerler** (prensipler) ve **etik zorluklar** (sorunlar) gibi kavramlarÄ± tartÄ±ÅŸacaÄŸÄ±z - ve bu kavramlarÄ± gerÃ§ek dÃ¼nya baÄŸlamlarÄ±nda anlamanÄ±za yardÄ±mcÄ± olacak **vaka Ã§alÄ±ÅŸmalarÄ±** inceleyeceÄŸiz.

### 1. Etik Prensipler

Her veri etiÄŸi stratejisi, veri ve yapay zeka projelerimizde kabul edilebilir davranÄ±ÅŸlarÄ± tanÄ±mlayan ve uyumlu eylemleri yÃ¶nlendiren _etik prensipleri_ tanÄ±mlamakla baÅŸlar. BunlarÄ± bireysel veya ekip dÃ¼zeyinde tanÄ±mlayabilirsiniz. Ancak, Ã§oÄŸu bÃ¼yÃ¼k organizasyon, bunlarÄ± kurumsal dÃ¼zeyde tanÄ±mlanan ve tÃ¼m ekiplerde tutarlÄ± bir ÅŸekilde uygulanan bir _etik yapay zeka_ misyon bildirimi veya Ã§erÃ§evesinde belirtir.

**Ã–rnek:** Microsoft'un [Sorumlu Yapay Zeka](https://www.microsoft.com/en-us/ai/responsible-ai) misyon bildirimi ÅŸu ÅŸekilde ifade edilir: _"Ä°nsanlarÄ± Ã¶nceliklendiren etik prensiplerle yÃ¶nlendirilen yapay zekanÄ±n ilerlemesine baÄŸlÄ±yÄ±z"_ - aÅŸaÄŸÄ±daki Ã§erÃ§evede 6 etik prensibi tanÄ±mlÄ±yor:

![Microsoft'ta Sorumlu Yapay Zeka](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

Bu prensipleri kÄ±saca inceleyelim. _ÅeffaflÄ±k_ ve _hesap verebilirlik_, diÄŸer prensiplerin Ã¼zerine inÅŸa edildiÄŸi temel deÄŸerlerdir - bu yÃ¼zden buradan baÅŸlayalÄ±m:

* [**Hesap Verebilirlik**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6), uygulayÄ±cÄ±larÄ± veri ve yapay zeka operasyonlarÄ± ve bu etik prensiplere uyum konusunda _sorumlu_ kÄ±lar.
* [**ÅeffaflÄ±k**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6), veri ve yapay zeka eylemlerinin kullanÄ±cÄ±lar iÃ§in _anlaÅŸÄ±lÄ±r_ (yorumlanabilir) olmasÄ±nÄ± saÄŸlar, kararlarÄ±n arkasÄ±ndaki ne ve nedenleri aÃ§Ä±klar.
* [**Adalet**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6), yapay zekanÄ±n _tÃ¼m insanlara_ adil davranmasÄ±nÄ± saÄŸlamaya odaklanÄ±r, veri ve sistemlerdeki sistemik veya Ã¶rtÃ¼k sosyo-teknik Ã¶nyargÄ±larÄ± ele alÄ±r.
* [**GÃ¼venilirlik ve GÃ¼venlik**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6), yapay zekanÄ±n tanÄ±mlÄ± deÄŸerlere _tutarlÄ±_ bir ÅŸekilde davranmasÄ±nÄ± saÄŸlar, potansiyel zararlarÄ± veya istenmeyen sonuÃ§larÄ± en aza indirir.
* [**Gizlilik ve GÃ¼venlik**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6), veri kÃ¶kenini anlamak ve kullanÄ±cÄ±lara _veri gizliliÄŸi ve ilgili korumalar_ saÄŸlamakla ilgilidir.
* [**KapsayÄ±cÄ±lÄ±k**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6), yapay zeka Ã§Ã¶zÃ¼mlerini niyetle tasarlamak ve onlarÄ± _geniÅŸ bir insan ihtiyaÃ§larÄ± ve yetenekleri yelpazesine_ uyarlamakla ilgilidir.

> ğŸš¨ Veri etiÄŸi misyon bildiriminizin ne olabileceÄŸini dÃ¼ÅŸÃ¼nÃ¼n. DiÄŸer organizasyonlarÄ±n etik yapay zeka Ã§erÃ§evelerini keÅŸfedin - iÅŸte [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles) ve [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/) Ã¶rnekleri. Ortak deÄŸerleri nelerdir? Bu prensipler, faaliyet gÃ¶sterdikleri yapay zeka Ã¼rÃ¼nÃ¼ veya endÃ¼stri ile nasÄ±l iliÅŸkilidir?

### 2. Etik Zorluklar

Etik prensiplerimizi tanÄ±mladÄ±ktan sonra, bir sonraki adÄ±m, veri ve yapay zeka eylemlerimizin bu ortak deÄŸerlerle uyumlu olup olmadÄ±ÄŸÄ±nÄ± deÄŸerlendirmektir. Eylemlerinizi iki kategoriye ayÄ±rarak dÃ¼ÅŸÃ¼nÃ¼n: _veri toplama_ ve _algoritma tasarÄ±mÄ±_.

Veri toplama ile ilgili eylemler, muhtemelen **kiÅŸisel veri** veya yaÅŸayan bireyler iÃ§in kiÅŸisel olarak tanÄ±mlanabilir bilgiler (PII) iÃ§erecektir. Bu, bir bireyi _toplu olarak_ tanÄ±mlayan [Ã§eÅŸitli kiÅŸisel olmayan veri Ã¶ÄŸelerini](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) iÃ§erir. Etik zorluklar, _veri gizliliÄŸi_, _veri sahipliÄŸi_ ve _bilgilendirilmiÅŸ onay_ gibi ilgili konularla baÄŸlantÄ±lÄ± olabilir.

Algoritma tasarÄ±mÄ± ile ilgili eylemler, **veri setleri** toplama ve kÃ¼ratÃ¶rlÃ¼ÄŸÃ¼nÃ¼ yapmayÄ±, ardÄ±ndan bunlarÄ± gerÃ§ek dÃ¼nya baÄŸlamlarÄ±nda sonuÃ§larÄ± tahmin eden veya kararlarÄ± otomatikleÅŸtiren **veri modelleri** eÄŸitmek ve daÄŸÄ±tmak iÃ§in kullanmayÄ± iÃ§erecektir. Etik zorluklar, _veri seti Ã¶nyargÄ±sÄ±_, _veri kalitesi_ sorunlarÄ±, _adaletsizlik_ ve algoritmalardaki _yanlÄ±ÅŸ temsil_ gibi konulardan kaynaklanabilir - bazÄ±larÄ± sistemik nitelikte olabilir.

Her iki durumda da, etik zorluklar, eylemlerimizin ortak deÄŸerlerimizle Ã§atÄ±ÅŸabileceÄŸi alanlarÄ± vurgular. Bu endiÅŸeleri tespit etmek, hafifletmek, en aza indirmek veya ortadan kaldÄ±rmak iÃ§in, eylemlerimizle ilgili ahlaki "evet/hayÄ±r" sorularÄ± sormamÄ±z ve gerektiÄŸinde dÃ¼zeltici eylemler almamÄ±z gerekir. Åimdi bazÄ± etik zorluklara ve bunlarÄ±n ortaya Ã§Ä±kardÄ±ÄŸÄ± ahlaki sorulara bakalÄ±m:

#### 2.1 Veri SahipliÄŸi

Veri toplama genellikle veri konularÄ±nÄ± tanÄ±mlayabilecek kiÅŸisel verileri iÃ§erir. [Veri sahipliÄŸi](https://permission.io/blog/data-ownership), verilerin oluÅŸturulmasÄ±, iÅŸlenmesi ve yayÄ±lmasÄ± ile ilgili _kontrol_ ve [_kullanÄ±cÄ± haklarÄ±_](https://permission.io/blog/data-ownership) ile ilgilidir.

SormamÄ±z gereken ahlaki sorular ÅŸunlardÄ±r:
 * Verinin sahibi kimdir? (kullanÄ±cÄ± mÄ± organizasyon mu)
 * Veri konularÄ±nÄ±n hangi haklarÄ± vardÄ±r? (Ã¶rneÄŸin: eriÅŸim, silme, taÅŸÄ±nabilirlik)
 * OrganizasyonlarÄ±n hangi haklarÄ± vardÄ±r? (Ã¶rneÄŸin: kÃ¶tÃ¼ niyetli kullanÄ±cÄ± yorumlarÄ±nÄ± dÃ¼zeltme)

#### 2.2 BilgilendirilmiÅŸ Onay

[BilgilendirilmiÅŸ onay](https://legaldictionary.net/informed-consent/), kullanÄ±cÄ±larÄ±n (veri konularÄ±) bir eylemi (Ã¶rneÄŸin veri toplama) _ilgili gerÃ§eklerin tam olarak anlaÅŸÄ±lmasÄ±yla_ kabul etmesini tanÄ±mlar; buna amaÃ§, potansiyel riskler ve alternatifler dahildir.

Burada keÅŸfedilecek sorular ÅŸunlardÄ±r:
 * KullanÄ±cÄ± (veri konusu) veri yakalama ve kullanÄ±mÄ± iÃ§in izin verdi mi?
 * KullanÄ±cÄ±, verinin yakalandÄ±ÄŸÄ± amacÄ± anladÄ± mÄ±?
 * KullanÄ±cÄ±, katÄ±lÄ±mÄ±ndan kaynaklanabilecek potansiyel riskleri anladÄ± mÄ±?

#### 2.3 Fikri MÃ¼lkiyet

[Fikri mÃ¼lkiyet](https://en.wikipedia.org/wiki/Intellectual_property), bireyler veya iÅŸletmeler iÃ§in _ekonomik deÄŸeri_ olabilecek insan giriÅŸiminden kaynaklanan soyut yaratÄ±mlarÄ± ifade eder.

Burada keÅŸfedilecek sorular ÅŸunlardÄ±r:
 * Toplanan veriler bir kullanÄ±cÄ± veya iÅŸletme iÃ§in ekonomik deÄŸere sahip miydi?
 * Burada **kullanÄ±cÄ±nÄ±n** fikri mÃ¼lkiyeti var mÄ±?
 * Burada **organizasyonun** fikri mÃ¼lkiyeti var mÄ±?
 * Bu haklar varsa, onlarÄ± nasÄ±l koruyoruz?

#### 2.4 Veri GizliliÄŸi

[Veri gizliliÄŸi](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) veya bilgi gizliliÄŸi, kullanÄ±cÄ± kimliÄŸinin korunmasÄ± ve kiÅŸisel olarak tanÄ±mlanabilir bilgilerin korunmasÄ± ile ilgilidir.

Burada keÅŸfedilecek sorular ÅŸunlardÄ±r:
 * KullanÄ±cÄ±larÄ±n (kiÅŸisel) verileri hacklere ve sÄ±zÄ±ntÄ±lara karÅŸÄ± gÃ¼venli mi?
 * KullanÄ±cÄ±larÄ±n verileri yalnÄ±zca yetkili kullanÄ±cÄ±lar ve baÄŸlamlar iÃ§in eriÅŸilebilir mi?
 * Veri paylaÅŸÄ±ldÄ±ÄŸÄ±nda veya yayÄ±ldÄ±ÄŸÄ±nda kullanÄ±cÄ±larÄ±n anonimliÄŸi korunuyor mu?
 * KullanÄ±cÄ± anonimleÅŸtirilmiÅŸ veri setlerinden kimliksizleÅŸtirilebilir mi?

#### 2.5 Unutulma HakkÄ±

[Unutulma HakkÄ±](https://en.wikipedia.org/wiki/Right_to_be_forgotten) veya [Silinme HakkÄ±](https://www.gdpreu.org/right-to-be-forgotten/), kullanÄ±cÄ±lara ek kiÅŸisel veri korumasÄ± saÄŸlar. Ã–zellikle, kullanÄ±cÄ±lara Ä°nternet aramalarÄ±ndan ve diÄŸer konumlardan kiÅŸisel verilerin silinmesini veya kaldÄ±rÄ±lmasÄ±nÄ± talep etme hakkÄ± verir, _belirli koÅŸullar altÄ±nda_ - geÃ§miÅŸ eylemlerin kendilerine karÅŸÄ± kullanÄ±lmamasÄ± iÃ§in Ã§evrimiÃ§i olarak yeni bir baÅŸlangÄ±Ã§ yapmalarÄ±na olanak tanÄ±r.

Burada keÅŸfedilecek sorular ÅŸunlardÄ±r:
 * Sistem, veri konularÄ±nÄ±n silme talebinde bulunmasÄ±na izin veriyor mu?
 * KullanÄ±cÄ± onayÄ±nÄ±n geri Ã§ekilmesi otomatik silmeyi tetiklemeli mi?
 * Veri, kullanÄ±cÄ± onayÄ± olmadan veya yasa dÄ±ÅŸÄ± yollarla mÄ± toplandÄ±?
 * Veri gizliliÄŸi iÃ§in hÃ¼kÃ¼met dÃ¼zenlemelerine uyuyor muyuz?

#### 2.6 Veri Seti Ã–nyargÄ±sÄ±

Veri seti veya [Toplama Ã–nyargÄ±sÄ±](http://researcharticles.com/index.php/bias-in-data-collection-in-research/), algoritma geliÅŸtirme iÃ§in _temsil edici olmayan_ bir veri alt kÃ¼mesi seÃ§mekle ilgilidir ve bu durum, Ã§eÅŸitli gruplar iÃ§in sonuÃ§larÄ±n adaletsiz olmasÄ±na neden olabilir. Ã–nyargÄ± tÃ¼rleri arasÄ±nda seÃ§im veya Ã¶rnekleme Ã¶nyargÄ±sÄ±, gÃ¶nÃ¼llÃ¼ Ã¶nyargÄ±sÄ± ve araÃ§ Ã¶nyargÄ±sÄ± bulunur.

Burada keÅŸfedilecek sorular ÅŸunlardÄ±r:
 * Temsil edici bir veri konusu seti mi topladÄ±k?
 * Toplanan veya kÃ¼ratÃ¶rlÃ¼ÄŸÃ¼ yapÄ±lan veri setimizi Ã§eÅŸitli Ã¶nyargÄ±lar aÃ§Ä±sÄ±ndan test ettik mi?
 * KeÅŸfedilen Ã¶nyargÄ±larÄ± hafifletebilir veya ortadan kaldÄ±rabilir miyiz?

#### 2.7 Veri Kalitesi

[Veri Kalitesi](https://lakefs.io/data-quality-testing/), algoritmalarÄ±mÄ±zÄ± geliÅŸtirmek iÃ§in kullanÄ±lan kÃ¼ratÃ¶rlÃ¼ÄŸÃ¼ yapÄ±lmÄ±ÅŸ veri setinin geÃ§erliliÄŸini inceler ve Ã¶zelliklerin ve kayÄ±tlarÄ±n yapay zeka amacÄ±mÄ±z iÃ§in gereken doÄŸruluk ve tutarlÄ±lÄ±k dÃ¼zeyini karÅŸÄ±layÄ±p karÅŸÄ±lamadÄ±ÄŸÄ±nÄ± kontrol eder.

Burada keÅŸfedilecek sorular ÅŸunlardÄ±r:
 * KullanÄ±m senaryomuz iÃ§in geÃ§erli _Ã¶zellikler_ yakaladÄ±k mÄ±?
 * Ã‡eÅŸitli veri kaynaklarÄ± arasÄ±nda veri _tutarlÄ±_ bir ÅŸekilde mi yakalandÄ±?
 * Veri seti, Ã§eÅŸitli koÅŸullar veya senaryolar iÃ§in _tam_ mÄ±?
 * Bilgiler, gerÃ§ekliÄŸi yansÄ±tacak ÅŸekilde _doÄŸru_ bir ÅŸekilde mi yakalandÄ±?

#### 2.8 Algoritma Adaleti
[Algoritma Adaleti](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f), algoritma tasarÄ±mÄ±nÄ±n belirli veri gruplarÄ±na sistematik olarak ayrÄ±mcÄ±lÄ±k yapÄ±p yapmadÄ±ÄŸÄ±nÄ± ve bunun sonucunda _daÄŸÄ±tÄ±m_ (kaynaklarÄ±n o gruptan esirgenmesi veya reddedilmesi) ve _hizmet kalitesi_ (Yapay Zeka'nÄ±n bazÄ± alt gruplar iÃ§in diÄŸerlerine kÄ±yasla daha az doÄŸru olmasÄ±) gibi [potansiyel zararlar](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) yaratÄ±p yaratmadÄ±ÄŸÄ±nÄ± kontrol eder.

Burada incelenmesi gereken sorular ÅŸunlardÄ±r:
 * Model doÄŸruluÄŸunu farklÄ± alt gruplar ve koÅŸullar iÃ§in deÄŸerlendirdik mi?
 * Sistemi potansiyel zararlar (Ã¶rneÄŸin, stereotipleme) aÃ§Ä±sÄ±ndan inceledik mi?
 * Belirlenen zararlarÄ± azaltmak iÃ§in verileri yeniden dÃ¼zenleyebilir veya modelleri yeniden eÄŸitebilir miyiz?

Daha fazla bilgi edinmek iÃ§in [Yapay Zeka Adaleti kontrol listeleri](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) gibi kaynaklarÄ± keÅŸfedin.

#### 2.9 YanÄ±ltÄ±cÄ± Bilgi

[Veri YanÄ±ltÄ±cÄ±lÄ±ÄŸÄ±](https://www.sciencedirect.com/topics/computer-science/misrepresentation), dÃ¼rÃ¼stÃ§e raporlanan verilerden elde edilen iÃ§gÃ¶rÃ¼lerin, istenen bir anlatÄ±yÄ± desteklemek iÃ§in yanÄ±ltÄ±cÄ± bir ÅŸekilde sunulup sunulmadÄ±ÄŸÄ±nÄ± sorgular.

Burada incelenmesi gereken sorular ÅŸunlardÄ±r:
 * Eksik veya yanlÄ±ÅŸ veri mi raporluyoruz?
 * Verileri yanÄ±ltÄ±cÄ± sonuÃ§lara yÃ¶nlendirecek ÅŸekilde mi gÃ¶rselleÅŸtiriyoruz?
 * SonuÃ§larÄ± manipÃ¼le etmek iÃ§in seÃ§ici istatistiksel teknikler mi kullanÄ±yoruz?
 * FarklÄ± bir sonuca gÃ¶tÃ¼rebilecek alternatif aÃ§Ä±klamalar var mÄ±?

#### 2.10 Ã–zgÃ¼r SeÃ§im

[Ã–zgÃ¼r SeÃ§im YanÄ±lsamasÄ±](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice), sistemin "seÃ§im mimarilerinin" karar verme algoritmalarÄ±nÄ± kullanarak insanlarÄ± tercih edilen bir sonuca yÃ¶nlendirdiÄŸi, ancak onlara seÃ§enekler ve kontrol sunduÄŸu izlenimini verdiÄŸi durumlarda ortaya Ã§Ä±kar. Bu tÃ¼r [karanlÄ±k desenler](https://www.darkpatterns.org/), kullanÄ±cÄ±lar iÃ§in sosyal ve ekonomik zararlara yol aÃ§abilir. KullanÄ±cÄ± kararlarÄ± davranÄ±ÅŸ profillerini etkilediÄŸinden, bu eylemler potansiyel olarak bu zararlarÄ±n etkisini artÄ±rabilir veya uzatabilir.

Burada incelenmesi gereken sorular ÅŸunlardÄ±r:
 * KullanÄ±cÄ±, bu seÃ§imi yapmanÄ±n sonuÃ§larÄ±nÄ± anladÄ± mÄ±?
 * KullanÄ±cÄ±, (alternatif) seÃ§eneklerin ve her birinin artÄ± ve eksilerinin farkÄ±nda mÄ±ydÄ±?
 * KullanÄ±cÄ±, otomatikleÅŸtirilmiÅŸ veya etkilenmiÅŸ bir seÃ§imi daha sonra geri alabilir mi?

### 3. Vaka Ã‡alÄ±ÅŸmalarÄ±

Bu etik zorluklarÄ± gerÃ§ek dÃ¼nya baÄŸlamlarÄ±na yerleÅŸtirmek iÃ§in, bu tÃ¼r etik ihlallerin gÃ¶z ardÄ± edilmesi durumunda bireyler ve toplum Ã¼zerindeki potansiyel zararlarÄ± ve sonuÃ§larÄ± vurgulayan vaka Ã§alÄ±ÅŸmalarÄ±na bakmak faydalÄ± olur.

Ä°ÅŸte birkaÃ§ Ã¶rnek:

| Etik ZorluÄŸu | Vaka Ã‡alÄ±ÅŸmasÄ±  | 
|--- |--- |
| **BilgilendirilmiÅŸ Onay** | 1972 - [Tuskegee Frengi Ã‡alÄ±ÅŸmasÄ±](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - Ã‡alÄ±ÅŸmaya katÄ±lan AfrikalÄ± AmerikalÄ± erkeklere Ã¼cretsiz tÄ±bbi bakÄ±m vaat edildi, _ancak_ araÅŸtÄ±rmacÄ±lar teÅŸhislerini veya tedavi seÃ§eneklerini aÃ§Ä±klamadÄ±. BirÃ§ok katÄ±lÄ±mcÄ± Ã¶ldÃ¼ ve eÅŸleri veya Ã§ocuklarÄ± etkilendi; Ã§alÄ±ÅŸma 40 yÄ±l sÃ¼rdÃ¼. | 
| **Veri GizliliÄŸi** | 2007 - [Netflix veri Ã¶dÃ¼lÃ¼](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/), araÅŸtÄ±rmacÄ±lara _50K mÃ¼ÅŸteriden 10M anonimleÅŸtirilmiÅŸ film derecelendirmesi_ saÄŸladÄ±. Ancak, araÅŸtÄ±rmacÄ±lar anonimleÅŸtirilmiÅŸ verileri _harici veri setlerindeki_ (Ã¶rneÄŸin, IMDb yorumlarÄ±) kiÅŸisel olarak tanÄ±mlanabilir verilerle iliÅŸkilendirebildi - bazÄ± Netflix abonelerini "de-anonimleÅŸtirdi".|
| **Toplama YanlÄ±lÄ±ÄŸÄ±** | 2013 - Boston Åehri, vatandaÅŸlarÄ±n Ã§ukurlarÄ± bildirmesine olanak tanÄ±yan [Street Bump](https://www.boston.gov/transportation/street-bump) adlÄ± bir uygulama geliÅŸtirdi. Ancak, [dÃ¼ÅŸÃ¼k gelirli gruplarÄ±n araba ve telefonlara daha az eriÅŸimi vardÄ±](https://hbr.org/2013/04/the-hidden-biases-in-big-data), bu da onlarÄ±n yol sorunlarÄ±nÄ± bu uygulamada gÃ¶rÃ¼nmez hale getirdi. GeliÅŸtiriciler, adalet iÃ§in _eÅŸit eriÅŸim ve dijital uÃ§urumlar_ sorunlarÄ±nÄ± Ã§Ã¶zmek Ã¼zere akademisyenlerle Ã§alÄ±ÅŸtÄ±. |
| **Algoritmik Adalet** | 2018 - MIT [Gender Shades Ã‡alÄ±ÅŸmasÄ±](http://gendershades.org/overview.html), cinsiyet sÄ±nÄ±flandÄ±rma yapay zeka Ã¼rÃ¼nlerinin doÄŸruluÄŸunu deÄŸerlendirdi ve kadÄ±nlar ve renkli insanlar iÃ§in doÄŸrulukta boÅŸluklar olduÄŸunu ortaya Ã§Ä±kardÄ±. Bir [2019 Apple Card](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/), kadÄ±nlara erkeklere kÄ±yasla daha az kredi sunuyor gibi gÃ¶rÃ¼nÃ¼yordu. Her ikisi de sosyo-ekonomik zararlara yol aÃ§an algoritmik Ã¶nyargÄ± sorunlarÄ±nÄ± gÃ¶sterdi.|
| **Veri YanÄ±ltÄ±cÄ±lÄ±ÄŸÄ±** | 2020 - [Georgia Halk SaÄŸlÄ±ÄŸÄ± DepartmanÄ±, COVID-19 grafiklerini](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) yayÄ±nladÄ± ve x ekseninde kronolojik olmayan sÄ±ralama ile vatandaÅŸlarÄ± doÄŸrulanmÄ±ÅŸ vaka eÄŸilimleri hakkÄ±nda yanÄ±ltÄ±yor gibi gÃ¶rÃ¼ndÃ¼. Bu, gÃ¶rselleÅŸtirme hileleriyle yanÄ±ltÄ±cÄ±lÄ±ÄŸÄ± gÃ¶sterir. |
| **Ã–zgÃ¼r SeÃ§im YanÄ±lsamasÄ±** | 2020 - Ã–ÄŸrenme uygulamasÄ± [ABCmouse, FTC ÅŸikayetini Ã§Ã¶zmek iÃ§in 10M $ Ã¶dedi](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/). Bu, kullanÄ±cÄ±larÄ±n potansiyel olarak zararlÄ± seÃ§imlere yÃ¶nlendirildiÄŸi seÃ§im mimarilerindeki karanlÄ±k desenleri gÃ¶sterir. |
| **Veri GizliliÄŸi ve KullanÄ±cÄ± HaklarÄ±** | 2021 - Facebook [Veri Ä°hlali](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users), 530M kullanÄ±cÄ±nÄ±n verilerini aÃ§Ä±ÄŸa Ã§Ä±kardÄ± ve FTC'ye 5B $'lÄ±k bir anlaÅŸma ile sonuÃ§landÄ±. Ancak, kullanÄ±cÄ±larÄ± ihlal hakkÄ±nda bilgilendirmeyi reddetti ve veri ÅŸeffaflÄ±ÄŸÄ± ve eriÅŸimi konusundaki kullanÄ±cÄ± haklarÄ±nÄ± ihlal etti. |

Daha fazla vaka Ã§alÄ±ÅŸmasÄ± keÅŸfetmek ister misiniz? Bu kaynaklara gÃ¶z atÄ±n:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - Ã§eÅŸitli sektÃ¶rlerde etik ikilemler.
* [Veri Bilimi EtiÄŸi kursu](https://www.coursera.org/learn/data-science-ethics#syllabus) - Ã¶nemli vaka Ã§alÄ±ÅŸmalarÄ± inceleniyor.
* [YanlÄ±ÅŸ giden Ã¶rnekler](https://deon.drivendata.org/examples/) - deon kontrol listesi Ã¶rnekleriyle.

> ğŸš¨ GÃ¶rdÃ¼ÄŸÃ¼nÃ¼z vaka Ã§alÄ±ÅŸmalarÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼n - hayatÄ±nÄ±zda benzer bir etik zorluk yaÅŸadÄ±nÄ±z mÄ± veya etkilendiniz mi? Bu bÃ¶lÃ¼mde tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z etik zorluklardan birini gÃ¶steren baÅŸka bir vaka Ã§alÄ±ÅŸmasÄ± dÃ¼ÅŸÃ¼nebilir misiniz?

## UygulamalÄ± Etik

Etik kavramlarÄ±, zorluklarÄ± ve vaka Ã§alÄ±ÅŸmalarÄ±nÄ± gerÃ§ek dÃ¼nya baÄŸlamlarÄ±nda ele aldÄ±k. Ancak, projelerimizde etik ilkeleri ve uygulamalarÄ± _uygulamaya_ nasÄ±l baÅŸlarÄ±z? Ve bu uygulamalarÄ± daha iyi yÃ¶netiÅŸim iÃ§in nasÄ±l _operasyonelleÅŸtiririz_? GerÃ§ek dÃ¼nya Ã§Ã¶zÃ¼mlerini keÅŸfedelim:

### 1. Mesleki Kodlar

Mesleki Kodlar, kuruluÅŸlarÄ±n Ã¼yelerini etik ilkelerini ve misyon beyanlarÄ±nÄ± desteklemeye "teÅŸvik etmek" iÃ§in bir seÃ§enek sunar. Kodlar, profesyonel davranÄ±ÅŸ iÃ§in _ahlaki kÄ±lavuzlardÄ±r_ ve Ã§alÄ±ÅŸanlarÄ±n veya Ã¼yelerin kuruluÅŸlarÄ±nÄ±n ilkelerine uygun kararlar almasÄ±na yardÄ±mcÄ± olur. Ancak, Ã¼yelerin gÃ¶nÃ¼llÃ¼ uyumu kadar etkilidir; birÃ§ok kuruluÅŸ, Ã¼yelerin uyumunu motive etmek iÃ§in ek Ã¶dÃ¼ller ve cezalar sunar.

Ã–rnekler:
 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Etik Kodu
 * [Veri Bilimi DerneÄŸi](http://datascienceassn.org/code-of-conduct.html) DavranÄ±ÅŸ KurallarÄ± (2013'te oluÅŸturuldu)
 * [ACM Etik ve Profesyonel DavranÄ±ÅŸ Kodu](https://www.acm.org/code-of-ethics) (1993'ten beri)

> ğŸš¨ Bir mÃ¼hendislik veya veri bilimi meslek kuruluÅŸuna Ã¼ye misiniz? Sitelerini inceleyerek bir mesleki etik kodu tanÄ±mlayÄ±p tanÄ±mlamadÄ±klarÄ±nÄ± gÃ¶rÃ¼n. Bu, etik ilkeleri hakkÄ±nda ne sÃ¶ylÃ¼yor? Ãœyeleri kodu takip etmeye nasÄ±l "teÅŸvik ediyorlar"?

### 2. Etik Kontrol Listeleri

Mesleki kodlar, uygulayÄ±cÄ±lardan beklenen _etik davranÄ±ÅŸÄ±_ tanÄ±mlarken, [bÃ¼yÃ¼k Ã¶lÃ§ekli projelerde](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) uygulanabilirlik aÃ§Ä±sÄ±ndan bilinen sÄ±nÄ±rlamalara sahiptir. Bunun yerine, birÃ§ok veri bilimi uzmanÄ±, ilkeleri daha belirleyici ve uygulanabilir yollarla **uygulamalara baÄŸlayabilen** [kontrol listelerini](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) savunur.

Kontrol listeleri, sorularÄ± "evet/hayÄ±r" gÃ¶revlerine dÃ¶nÃ¼ÅŸtÃ¼rerek operasyonelleÅŸtirilebilir ve standart Ã¼rÃ¼n sÃ¼rÃ¼m iÅŸ akÄ±ÅŸlarÄ±nÄ±n bir parÃ§asÄ± olarak izlenebilir hale getirir.

Ã–rnekler:
 * [Deon](https://deon.drivendata.org/) - [sektÃ¶r Ã¶nerilerinden](https://deon.drivendata.org/#checklist-citations) oluÅŸturulmuÅŸ genel amaÃ§lÄ± bir veri etiÄŸi kontrol listesi ve kolay entegrasyon iÃ§in bir komut satÄ±rÄ± aracÄ±.
 * [Gizlilik Denetim Kontrol Listesi](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - yasal ve sosyal maruz kalma perspektiflerinden bilgi iÅŸleme uygulamalarÄ± iÃ§in genel rehberlik saÄŸlar.
 * [Yapay Zeka Adaleti Kontrol Listesi](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - adalet kontrollerinin yapay zeka geliÅŸtirme dÃ¶ngÃ¼lerine entegrasyonunu desteklemek iÃ§in yapay zeka uygulayÄ±cÄ±larÄ± tarafÄ±ndan oluÅŸturulmuÅŸtur.
 * [Veri ve Yapay Zekada Etik iÃ§in 22 Soru](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - tasarÄ±m, uygulama ve organizasyonel baÄŸlamlarda etik sorunlarÄ±n ilk keÅŸfi iÃ§in yapÄ±landÄ±rÄ±lmÄ±ÅŸ daha aÃ§Ä±k uÃ§lu bir Ã§erÃ§eve.

### 3. Etik DÃ¼zenlemeler

Etik, paylaÅŸÄ±lan deÄŸerleri tanÄ±mlamak ve _gÃ¶nÃ¼llÃ¼ olarak_ doÄŸru olanÄ± yapmakla ilgilidir. **Uyum**, tanÄ±mlandÄ±ÄŸÄ± takdirde _yasalara uymakla_ ilgilidir. **YÃ¶netiÅŸim**, kuruluÅŸlarÄ±n etik ilkeleri uygulamak ve belirlenmiÅŸ yasalara uymak iÃ§in faaliyet gÃ¶sterdiÄŸi tÃ¼m yollarÄ± kapsar.

BugÃ¼n yÃ¶netiÅŸim, kuruluÅŸlar iÃ§inde iki ÅŸekilde gerÃ§ekleÅŸir. Ä°lk olarak, **etik yapay zeka** ilkelerini tanÄ±mlamak ve kuruluÅŸun tÃ¼m yapay zeka ile ilgili projelerinde benimsenmesini saÄŸlamak iÃ§in uygulamalar oluÅŸturmaktÄ±r. Ä°kincisi, faaliyet gÃ¶sterdiÄŸi bÃ¶lgelerdeki tÃ¼m hÃ¼kÃ¼met tarafÄ±ndan belirlenen **veri koruma dÃ¼zenlemelerine** uymaktÄ±r.

Veri koruma ve gizlilik dÃ¼zenlemelerine Ã¶rnekler:

 * `1974`, [ABD Gizlilik YasasÄ±](https://www.justice.gov/opcl/privacy-act-1974) - _federal hÃ¼kÃ¼metin_ kiÅŸisel bilgileri toplamasÄ±nÄ±, kullanmasÄ±nÄ± ve ifÅŸa etmesini dÃ¼zenler.
 * `1996`, [ABD SaÄŸlÄ±k SigortasÄ± TaÅŸÄ±nabilirlik ve Sorumluluk YasasÄ± (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - kiÅŸisel saÄŸlÄ±k verilerini korur.
 * `1998`, [ABD Ã‡ocuklarÄ±n Ã‡evrimiÃ§i GizliliÄŸini Koruma YasasÄ± (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - 13 yaÅŸ altÄ±ndaki Ã§ocuklarÄ±n veri gizliliÄŸini korur.
 * `2018`, [Genel Veri Koruma YÃ¶netmeliÄŸi (GDPR)](https://gdpr-info.eu/) - kullanÄ±cÄ± haklarÄ±, veri koruma ve gizlilik saÄŸlar.
 * `2018`, [Kaliforniya TÃ¼ketici GizliliÄŸi YasasÄ± (CCPA)](https://www.oag.ca.gov/privacy/ccpa) - tÃ¼keticilere (kiÅŸisel) verileri Ã¼zerinde daha fazla _hak_ verir.
 * `2021`, Ã‡in'in [KiÅŸisel Bilgi Koruma YasasÄ±](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) yeni geÃ§ti ve dÃ¼nya Ã§apÄ±nda en gÃ¼Ã§lÃ¼ Ã§evrimiÃ§i veri gizliliÄŸi dÃ¼zenlemelerinden birini oluÅŸturdu.

> ğŸš¨ Avrupa BirliÄŸi tarafÄ±ndan tanÄ±mlanan GDPR (Genel Veri Koruma YÃ¶netmeliÄŸi), bugÃ¼n en etkili veri gizliliÄŸi dÃ¼zenlemelerinden biri olmaya devam ediyor. AyrÄ±ca vatandaÅŸlarÄ±n dijital gizliliÄŸini ve kiÅŸisel verilerini korumak iÃ§in [8 kullanÄ±cÄ± hakkÄ±](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) tanÄ±mladÄ±ÄŸÄ±nÄ± biliyor muydunuz? BunlarÄ±n ne olduÄŸunu ve neden Ã¶nemli olduklarÄ±nÄ± Ã¶ÄŸrenin.

### 4. Etik KÃ¼ltÃ¼rÃ¼

Not edin ki, _uyum_ (yasanÄ±n "harfine" uygun hareket etmek) ile [sistemik sorunlarÄ±](https://www.coursera.org/learn/data-science-ethics/home/week/4) ele almak (Ã¶rneÄŸin, katÄ±laÅŸma, bilgi asimetrisi ve daÄŸÄ±tÄ±m adaletsizliÄŸi) arasÄ±nda soyut bir boÅŸluk vardÄ±r. Bu tÃ¼r sorunlar, yapay zekanÄ±n silah haline getirilmesini hÄ±zlandÄ±rabilir.

Ä°kincisi, [etik kÃ¼ltÃ¼rlerini tanÄ±mlamak iÃ§in iÅŸbirlikÃ§i yaklaÅŸÄ±mlar](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f) gerektirir. Bu, duygusal baÄŸlar kurmayÄ± ve sektÃ¶rdeki kuruluÅŸlar arasÄ±nda tutarlÄ± ortak deÄŸerler oluÅŸturmayÄ± iÃ§erir. Bu, kuruluÅŸlarda daha [resmileÅŸtirilmiÅŸ veri etiÄŸi kÃ¼ltÃ¼rleri](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) oluÅŸturmayÄ± gerektirir - _herkesin_ (sÃ¼reÃ§te erken aÅŸamada etik kaygÄ±larÄ± dile getirmek iÃ§in) [Andon ipini Ã§ekmesine](https://en.wikipedia.org/wiki/Andon_(manufacturing)) olanak tanÄ±r ve yapay zeka projelerinde ekip oluÅŸturmanÄ±n temel kriteri olarak _etik deÄŸerlendirmeleri_ (Ã¶rneÄŸin, iÅŸe alÄ±mda) yapar.

---
## [Ders sonrasÄ± sÄ±nav](https://ff-quizzes.netlify.app/en/ds/) ğŸ¯
## GÃ¶zden GeÃ§irme ve Kendi Kendine Ã‡alÄ±ÅŸma

Kurslar ve kitaplar, temel etik kavramlarÄ±nÄ± ve zorluklarÄ±nÄ± anlamaya yardÄ±mcÄ± olurken, vaka Ã§alÄ±ÅŸmalarÄ± ve araÃ§lar, gerÃ§ek dÃ¼nya baÄŸlamlarÄ±nda uygulamalÄ± etik uygulamalarÄ±na yardÄ±mcÄ± olur. BaÅŸlamak iÃ§in birkaÃ§ kaynak:

* [BaÅŸlangÄ±Ã§ Seviyesi iÃ§in Makine Ã–ÄŸrenimi](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - Microsoft'tan Adalet Ã¼zerine bir ders.
* [Sorumlu Yapay Zeka Ä°lkeleri](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - Microsoft Learn'den Ã¼cretsiz Ã¶ÄŸrenim yolu.
* [Etik ve Veri Bilimi](https://resources.oreilly.com/examples/0636920203964) - O'Reilly EKitap (M. Loukides, H. Mason ve diÄŸerleri)
* [Veri Bilimi EtiÄŸi](https://www.coursera.org/learn/data-science-ethics#syllabus) - Michigan Ãœniversitesi'nden Ã§evrimiÃ§i kurs.
* [Etik AÃ§Ä±klanÄ±yor](https://ethicsunwrapped.utexas.edu/case-studies) - Texas Ãœniversitesi'nden vaka Ã§alÄ±ÅŸmalarÄ±.

# Ã–dev 

[Bir Veri EtiÄŸi Vaka Ã‡alÄ±ÅŸmasÄ± YazÄ±n](assignment.md)

---

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluÄŸu saÄŸlamak iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±k iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalardan sorumlu deÄŸiliz.