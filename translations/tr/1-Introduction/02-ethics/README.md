<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1341f6da63d434f5ba31b08ea951b02c",
  "translation_date": "2025-09-06T09:06:31+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "tr"
}
-->
# Veri EtiÄŸine GiriÅŸ

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Veri Bilimi EtiÄŸi - _Sketchnote by [@nitya](https://twitter.com/nitya)_ |

---

Hepimiz veriyle dolu bir dÃ¼nyada yaÅŸayan veri vatandaÅŸlarÄ±yÄ±z.

Pazar trendleri, 2022 yÄ±lÄ± itibarÄ±yla bÃ¼yÃ¼k organizasyonlarÄ±n Ã¼Ã§te birinin verilerini Ã§evrimiÃ§i [Pazar Yerleri ve Borsalar](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/) aracÄ±lÄ±ÄŸÄ±yla alÄ±p satacaÄŸÄ±nÄ± gÃ¶steriyor. **Uygulama GeliÅŸtiricileri** olarak, veri odaklÄ± iÃ§gÃ¶rÃ¼leri ve algoritma tabanlÄ± otomasyonu gÃ¼nlÃ¼k kullanÄ±cÄ± deneyimlerine entegre etmenin daha kolay ve ucuz hale geldiÄŸini gÃ¶receÄŸiz. Ancak yapay zeka yaygÄ±nlaÅŸtÄ±kÃ§a, bu tÃ¼r algoritmalarÄ±n [silah haline getirilmesi](https://www.youtube.com/watch?v=TQHs8SA1qpk) durumunda ortaya Ã§Ä±kabilecek potansiyel zararlarÄ± da anlamamÄ±z gerekecek.

Trendler ayrÄ±ca 2025 yÄ±lÄ±na kadar [180 zettabayt](https://www.statista.com/statistics/871513/worldwide-data-created/) veri oluÅŸturup tÃ¼keteceÄŸimizi gÃ¶steriyor. **Veri Bilimcileri** olarak, bu durum bize kiÅŸisel verilere benzeri gÃ¶rÃ¼lmemiÅŸ bir eriÅŸim seviyesi saÄŸlÄ±yor. Bu, kullanÄ±cÄ±larÄ±n davranÄ±ÅŸ profillerini oluÅŸturabileceÄŸimiz ve karar alma sÃ¼reÃ§lerini, kullanÄ±cÄ±larÄ± tercih ettiÄŸimiz sonuÃ§lara yÃ¶nlendirebilecek ÅŸekilde etkileyebileceÄŸimiz anlamÄ±na geliyor. AynÄ± zamanda veri gizliliÄŸi ve kullanÄ±cÄ± korumalarÄ± gibi daha geniÅŸ sorularÄ± da gÃ¼ndeme getiriyor.

Veri etiÄŸi, veri bilimi ve mÃ¼hendisliÄŸi iÃ§in artÄ±k _gerekli koruma Ã¶nlemleri_ haline geldi ve veri odaklÄ± eylemlerimizden kaynaklanabilecek potansiyel zararlarÄ± ve istenmeyen sonuÃ§larÄ± en aza indirmemize yardÄ±mcÄ± oluyor. [Gartner'Ä±n Yapay Zeka Hype DÃ¶ngÃ¼sÃ¼](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) dijital etik, sorumlu yapay zeka ve yapay zeka yÃ¶netimi gibi ilgili trendleri, yapay zekanÄ±n _demokratikleÅŸmesi_ ve _endÃ¼strileÅŸmesi_ etrafÄ±ndaki daha bÃ¼yÃ¼k megatrendlerin anahtar itici gÃ¼Ã§leri olarak tanÄ±mlÄ±yor.

![Gartner'Ä±n Yapay Zeka Hype DÃ¶ngÃ¼sÃ¼ - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

Bu derste, veri etiÄŸi alanÄ±nÄ± keÅŸfedeceÄŸiz - temel kavramlardan ve zorluklardan, vaka Ã§alÄ±ÅŸmalarÄ±na ve yÃ¶netiÅŸim gibi uygulamalÄ± yapay zeka kavramlarÄ±na kadar - veri ve yapay zeka ile Ã§alÄ±ÅŸan ekiplerde ve organizasyonlarda bir etik kÃ¼ltÃ¼rÃ¼ oluÅŸturulmasÄ±na yardÄ±mcÄ± olan konularÄ± ele alacaÄŸÄ±z.

## [Ders Ã–ncesi Test](https://ff-quizzes.netlify.app/en/ds/quiz/2) ğŸ¯

## Temel TanÄ±mlar

Ã–ncelikle temel terminolojiyi anlamakla baÅŸlayalÄ±m.

"Etik" kelimesi, [Yunanca "ethikos"](https://en.wikipedia.org/wiki/Ethics) (ve kÃ¶kÃ¼ "ethos") kelimesinden gelir ve _karakter veya ahlaki doÄŸa_ anlamÄ±na gelir.

**Etik**, toplumdaki davranÄ±ÅŸlarÄ±mÄ±zÄ± yÃ¶neten ortak deÄŸerler ve ahlaki ilkelerdir. Etik, yasalara deÄŸil, "doÄŸru ile yanlÄ±ÅŸ" arasÄ±ndaki yaygÄ±n olarak kabul edilen normlara dayanÄ±r. Ancak etik dÃ¼ÅŸÃ¼nceler, kurumsal yÃ¶netim giriÅŸimlerini ve uyum iÃ§in daha fazla teÅŸvik yaratan hÃ¼kÃ¼met dÃ¼zenlemelerini etkileyebilir.

**Veri EtiÄŸi**, "_veri, algoritmalar ve ilgili uygulamalarla_ ilgili ahlaki sorunlarÄ± inceleyen ve deÄŸerlendiren" [yeni bir etik dalÄ±dÄ±r](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1). Burada, **"veri"** oluÅŸturma, kaydetme, kÃ¼rasyon, iÅŸleme, yayma, paylaÅŸma ve kullanÄ±m ile ilgili eylemlere odaklanÄ±r, **"algoritmalar"** yapay zeka, ajanlar, makine Ã¶ÄŸrenimi ve robotlara odaklanÄ±r ve **"uygulamalar"** sorumlu yenilik, programlama, hackleme ve etik kodlar gibi konulara odaklanÄ±r.

**UygulamalÄ± Etik**, [ahlaki dÃ¼ÅŸÃ¼ncelerin pratik uygulamasÄ±dÄ±r](https://en.wikipedia.org/wiki/Applied_ethics). Bu, _gerÃ§ek dÃ¼nya eylemleri, Ã¼rÃ¼nleri ve sÃ¼reÃ§leri_ baÄŸlamÄ±nda etik sorunlarÄ± aktif olarak araÅŸtÄ±rma ve bunlarÄ±n tanÄ±mlÄ± etik deÄŸerlerimizle uyumlu kalmasÄ±nÄ± saÄŸlamak iÃ§in dÃ¼zeltici Ã¶nlemler alma sÃ¼recidir.

**Etik KÃ¼ltÃ¼rÃ¼**, [_uygulamalÄ± etiÄŸi_ operasyonelleÅŸtirmek](https://hbr.org/2019/05/how-to-design-an-ethical-organization) ile ilgilidir; etik ilkelerimizin ve uygulamalarÄ±mÄ±zÄ±n tÃ¼m organizasyon genelinde tutarlÄ± ve Ã¶lÃ§eklenebilir bir ÅŸekilde benimsenmesini saÄŸlamak. BaÅŸarÄ±lÄ± etik kÃ¼ltÃ¼rleri, organizasyon genelinde etik ilkeler tanÄ±mlar, uyum iÃ§in anlamlÄ± teÅŸvikler saÄŸlar ve istenen davranÄ±ÅŸlarÄ± her seviyede teÅŸvik ederek ve gÃ¼Ã§lendirerek etik normlarÄ± pekiÅŸtirir.

## Etik KavramlarÄ±

Bu bÃ¶lÃ¼mde, veri etiÄŸi iÃ§in **ortak deÄŸerler** (ilkeler) ve **etik zorluklar** (sorunlar) gibi kavramlarÄ± tartÄ±ÅŸacaÄŸÄ±z - ve bu kavramlarÄ± gerÃ§ek dÃ¼nya baÄŸlamlarÄ±nda anlamanÄ±za yardÄ±mcÄ± olacak **vaka Ã§alÄ±ÅŸmalarÄ±** inceleyeceÄŸiz.

### 1. Etik Ä°lkeleri

Her veri etiÄŸi stratejisi, _etik ilkeler_ tanÄ±mlayarak baÅŸlar - veri ve yapay zeka projelerimizde kabul edilebilir davranÄ±ÅŸlarÄ± tanÄ±mlayan ve uyumlu eylemleri yÃ¶nlendiren "ortak deÄŸerler". BunlarÄ± bireysel veya ekip dÃ¼zeyinde tanÄ±mlayabilirsiniz. Ancak, Ã§oÄŸu bÃ¼yÃ¼k organizasyon bunlarÄ± kurumsal dÃ¼zeyde tanÄ±mlanan ve tÃ¼m ekiplerde tutarlÄ± bir ÅŸekilde uygulanan bir _etik yapay zeka_ misyon bildirimi veya Ã§erÃ§evesinde belirtir.

**Ã–rnek:** Microsoft'un [Sorumlu Yapay Zeka](https://www.microsoft.com/en-us/ai/responsible-ai) misyon bildirimi ÅŸu ÅŸekilde ifade edilir: _"Ä°nsanlarÄ± Ã¶n planda tutan etik ilkelerle yÃ¶nlendirilen yapay zekanÄ±n ilerlemesine baÄŸlÄ±yÄ±z"_ - aÅŸaÄŸÄ±daki Ã§erÃ§evede 6 etik ilkeyi tanÄ±mlÄ±yor:

![Microsoft'ta Sorumlu Yapay Zeka](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

Bu ilkeleri kÄ±saca inceleyelim. _ÅeffaflÄ±k_ ve _hesap verebilirlik_ diÄŸer ilkelerin Ã¼zerine inÅŸa edildiÄŸi temel deÄŸerlerdir - bu yÃ¼zden buradan baÅŸlayalÄ±m:

* [**Hesap Verebilirlik**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6), uygulayÄ±cÄ±larÄ± veri ve yapay zeka operasyonlarÄ±ndan ve bu etik ilkelere uyumdan _sorumlu_ kÄ±lar.
* [**ÅeffaflÄ±k**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6), veri ve yapay zeka eylemlerinin kullanÄ±cÄ±lar iÃ§in _anlaÅŸÄ±lÄ±r_ (yorumlanabilir) olmasÄ±nÄ± saÄŸlar, kararlarÄ±n arkasÄ±ndaki ne ve nedenleri aÃ§Ä±klar.
* [**Adalet**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6), yapay zekanÄ±n _tÃ¼m insanlara_ adil davranmasÄ±nÄ± saÄŸlamaya odaklanÄ±r, veri ve sistemlerdeki sistemik veya Ã¶rtÃ¼k sosyo-teknik Ã¶nyargÄ±larÄ± ele alÄ±r.
* [**GÃ¼venilirlik ve GÃ¼venlik**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6), yapay zekanÄ±n tanÄ±mlÄ± deÄŸerlere _tutarlÄ±_ bir ÅŸekilde davranmasÄ±nÄ± saÄŸlar, potansiyel zararlarÄ± veya istenmeyen sonuÃ§larÄ± en aza indirir.
* [**Gizlilik ve GÃ¼venlik**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6), veri kÃ¶kenini anlamak ve kullanÄ±cÄ±lara _veri gizliliÄŸi ve ilgili korumalar_ saÄŸlamakla ilgilidir.
* [**KapsayÄ±cÄ±lÄ±k**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6), yapay zeka Ã§Ã¶zÃ¼mlerini niyetle tasarlamak, onlarÄ± _geniÅŸ bir insan ihtiyaÃ§larÄ± ve yetenekleri yelpazesine_ uyarlamakla ilgilidir.

> ğŸš¨ Veri etiÄŸi misyon bildiriminizin ne olabileceÄŸini dÃ¼ÅŸÃ¼nÃ¼n. DiÄŸer organizasyonlarÄ±n etik yapay zeka Ã§erÃ§evelerini keÅŸfedin - iÅŸte [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles) ve [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/) Ã¶rnekleri. Ortak deÄŸerleri nelerdir? Bu ilkeler, Ã§alÄ±ÅŸtÄ±klarÄ± yapay zeka Ã¼rÃ¼nÃ¼ veya endÃ¼strisiyle nasÄ±l iliÅŸkilidir?

### 2. Etik Zorluklar

Etik ilkeleri tanÄ±mladÄ±ktan sonra, bir sonraki adÄ±m veri ve yapay zeka eylemlerimizi bu ortak deÄŸerlerle uyumlu olup olmadÄ±ÄŸÄ±nÄ± deÄŸerlendirmektir. Eylemlerinizi iki kategoriye ayÄ±rmayÄ± dÃ¼ÅŸÃ¼nÃ¼n: _veri toplama_ ve _algoritma tasarÄ±mÄ±_.

Veri toplama ile ilgili eylemler, bÃ¼yÃ¼k olasÄ±lÄ±kla **kiÅŸisel veri** veya tanÄ±mlanabilir yaÅŸayan bireyler iÃ§in kiÅŸisel olarak tanÄ±mlanabilir bilgiler (PII) iÃ§erecektir. Bu, bir bireyi _toplu olarak_ tanÄ±mlayan [Ã§eÅŸitli kiÅŸisel olmayan veri Ã¶ÄŸelerini](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) iÃ§erir. Etik zorluklar, _veri gizliliÄŸi_, _veri sahipliÄŸi_ ve kullanÄ±cÄ±lar iÃ§in _bilgilendirilmiÅŸ onay_ ve _fikri mÃ¼lkiyet haklarÄ±_ gibi ilgili konularla ilgili olabilir.

Algoritma tasarÄ±mÄ± ile ilgili eylemler, **veri setleri** toplama ve kÃ¼rasyon yapmayÄ±, ardÄ±ndan bunlarÄ± gerÃ§ek dÃ¼nya baÄŸlamlarÄ±nda sonuÃ§larÄ± tahmin eden veya kararlarÄ± otomatikleÅŸtiren **veri modelleri** eÄŸitmek ve daÄŸÄ±tmak iÃ§in kullanmayÄ± iÃ§erecektir. Etik zorluklar, _veri seti Ã¶nyargÄ±sÄ±_, _veri kalitesi_ sorunlarÄ±, _adaletsizlik_ ve algoritmalardaki _yanlÄ±ÅŸ temsil_ gibi konulardan kaynaklanabilir - bunlar arasÄ±nda bazÄ±larÄ± sistemik olabilir.

Her iki durumda da, etik zorluklar eylemlerimizin ortak deÄŸerlerimizle Ã§atÄ±ÅŸabileceÄŸi alanlarÄ± vurgular. Bu endiÅŸeleri tespit etmek, hafifletmek, en aza indirmek veya ortadan kaldÄ±rmak iÃ§in, eylemlerimizle ilgili ahlaki "evet/hayÄ±r" sorularÄ± sormamÄ±z ve gerektiÄŸinde dÃ¼zeltici Ã¶nlemler almamÄ±z gerekir. Åimdi bazÄ± etik zorluklara ve bunlarÄ±n ortaya Ã§Ä±kardÄ±ÄŸÄ± ahlaki sorulara bakalÄ±m:

#### 2.1 Veri SahipliÄŸi

Veri toplama genellikle veri konularÄ±nÄ± tanÄ±mlayabilecek kiÅŸisel verileri iÃ§erir. [Veri sahipliÄŸi](https://permission.io/blog/data-ownership), verilerin oluÅŸturulmasÄ±, iÅŸlenmesi ve yayÄ±lmasÄ± ile ilgili _kontrol_ ve [_kullanÄ±cÄ± haklarÄ±_](https://permission.io/blog/data-ownership) ile ilgilidir.

SormamÄ±z gereken ahlaki sorular ÅŸunlardÄ±r:
 * Verinin sahibi kimdir? (kullanÄ±cÄ± mÄ± yoksa organizasyon mu?)
 * Veri konularÄ±nÄ±n hangi haklarÄ± vardÄ±r? (Ã¶rneÄŸin: eriÅŸim, silme, taÅŸÄ±nabilirlik)
 * OrganizasyonlarÄ±n hangi haklarÄ± vardÄ±r? (Ã¶rneÄŸin: kÃ¶tÃ¼ niyetli kullanÄ±cÄ± yorumlarÄ±nÄ± dÃ¼zeltme)

#### 2.2 BilgilendirilmiÅŸ Onay

[BilgilendirilmiÅŸ onay](https://legaldictionary.net/informed-consent/), kullanÄ±cÄ±larÄ±n (veri toplama gibi) bir eylemi, amacÄ±nÄ±, potansiyel risklerini ve alternatiflerini _tam olarak anlayarak_ kabul etmesi eylemini tanÄ±mlar.

Burada keÅŸfedilecek sorular ÅŸunlardÄ±r:
 * KullanÄ±cÄ± (veri konusu) veri yakalama ve kullanÄ±mÄ± iÃ§in izin verdi mi?
 * KullanÄ±cÄ±, verinin yakalandÄ±ÄŸÄ± amacÄ± anladÄ± mÄ±?
 * KullanÄ±cÄ±, katÄ±lÄ±mÄ±ndan kaynaklanabilecek potansiyel riskleri anladÄ± mÄ±?

#### 2.3 Fikri MÃ¼lkiyet

[Fikri mÃ¼lkiyet](https://en.wikipedia.org/wiki/Intellectual_property), insan giriÅŸiminden kaynaklanan, bireyler veya iÅŸletmeler iÃ§in _ekonomik deÄŸeri_ olabilecek soyut yaratÄ±mlarÄ± ifade eder.

Burada keÅŸfedilecek sorular ÅŸunlardÄ±r:
 * Toplanan veriler bir kullanÄ±cÄ± veya iÅŸletme iÃ§in ekonomik deÄŸere sahip miydi?
 * Burada **kullanÄ±cÄ±nÄ±n** fikri mÃ¼lkiyeti var mÄ±?
 * Burada **organizasyonun** fikri mÃ¼lkiyeti var mÄ±?
 * Bu haklar varsa, onlarÄ± nasÄ±l koruyoruz?

#### 2.4 Veri GizliliÄŸi

[Veri gizliliÄŸi](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) veya bilgi gizliliÄŸi, kullanÄ±cÄ± gizliliÄŸinin korunmasÄ± ve kullanÄ±cÄ± kimliÄŸinin kiÅŸisel olarak tanÄ±mlanabilir bilgilerle ilgili olarak korunmasÄ± anlamÄ±na gelir.

Burada keÅŸfedilecek sorular ÅŸunlardÄ±r:
 * KullanÄ±cÄ±larÄ±n (kiÅŸisel) verileri hacklere ve sÄ±zÄ±ntÄ±lara karÅŸÄ± gÃ¼venli mi?
 * KullanÄ±cÄ±larÄ±n verileri yalnÄ±zca yetkili kullanÄ±cÄ±lar ve baÄŸlamlar iÃ§in eriÅŸilebilir mi?
 * KullanÄ±cÄ±larÄ±n anonimliÄŸi veri paylaÅŸÄ±ldÄ±ÄŸÄ±nda veya yayÄ±ldÄ±ÄŸÄ±nda korunuyor mu?
 * KullanÄ±cÄ± anonimleÅŸtirilmiÅŸ veri setlerinden kimliksizleÅŸtirilebilir mi?

#### 2.5 Unutulma HakkÄ±

[Unutulma HakkÄ±](https://en.wikipedia.org/wiki/Right_to_be_forgotten) veya [Silme HakkÄ±](https://www.gdpreu.org/right-to-be-forgotten/), kullanÄ±cÄ±lara ek kiÅŸisel veri korumasÄ± saÄŸlar. Ã–zellikle, kullanÄ±cÄ±lara Ä°nternet aramalarÄ±ndan ve diÄŸer konumlardan kiÅŸisel verilerin silinmesini veya kaldÄ±rÄ±lmasÄ±nÄ± talep etme hakkÄ± verir, _belirli koÅŸullar altÄ±nda_ - geÃ§miÅŸ eylemlerin kendilerine karÅŸÄ± kullanÄ±lmamasÄ± iÃ§in Ã§evrimiÃ§i olarak yeni bir baÅŸlangÄ±Ã§ yapmalarÄ±na olanak tanÄ±r.

Burada keÅŸfedilecek sorular ÅŸunlardÄ±r:
 * Sistem, veri konularÄ±nÄ±n silme talebinde bulunmasÄ±na izin veriyor mu?
 * KullanÄ±cÄ± onayÄ±nÄ±n geri Ã§ekilmesi otomatik silmeyi tetiklemeli mi?
 * Veri, kullanÄ±cÄ± onayÄ± olmadan veya yasa dÄ±ÅŸÄ± yollarla mÄ± toplandÄ±?
 * Veri gizliliÄŸi iÃ§in hÃ¼kÃ¼met dÃ¼zenlemelerine uyuyor muyuz?

#### 2.6 Veri Seti Ã–nyargÄ±sÄ±

Veri seti veya [Toplama Ã–nyargÄ±sÄ±](http://researcharticles.com/index.php/bias-in-data-collection-in-research/), algoritma geliÅŸtirme iÃ§in _temsil edici olmayan_ bir veri alt kÃ¼mesi seÃ§mekle ilgilidir ve bu durum Ã§eÅŸitli gruplar iÃ§in sonuÃ§larÄ±n adaletsiz olmasÄ±na neden olabilir. Ã–nyargÄ± tÃ¼rleri arasÄ±nda seÃ§im veya Ã¶rnekleme Ã¶nyargÄ±sÄ±, gÃ¶nÃ¼llÃ¼ Ã¶nyargÄ±sÄ± ve araÃ§ Ã¶nyargÄ±sÄ± bulunur.

Burada keÅŸfedilecek sorular ÅŸunlardÄ±r:
 * Temsil edici bir veri konusu seti mi topladÄ±k?
 * Toplanan veya kÃ¼ratÃ¶rlÃ¼ÄŸÃ¼ yapÄ±lan veri setimizi Ã§eÅŸitli Ã¶nyargÄ±lar aÃ§Ä±sÄ±ndan test ettik mi?
 * KeÅŸfedilen Ã¶nyargÄ±larÄ± hafifletebilir veya ortadan kaldÄ±rabilir miyiz?

#### 2.7 Veri Kalitesi

[Veri Kalitesi](https://lakefs.io/data-quality-testing/), algoritmalarÄ±mÄ±zÄ± geliÅŸtirmek iÃ§in kullanÄ±lan kÃ¼ratÃ¶rlÃ¼ÄŸÃ¼ yapÄ±lmÄ±ÅŸ veri setinin geÃ§erliliÄŸini inceler ve Ã¶zelliklerin ve kayÄ±tlarÄ±n yapay zeka amacÄ±mÄ±z iÃ§in gereken doÄŸruluk ve tutarlÄ±lÄ±k dÃ¼zeyini karÅŸÄ±layÄ±p karÅŸÄ±lamadÄ±ÄŸÄ±nÄ± kontrol eder.

Burada keÅŸfedilecek sorular ÅŸunlardÄ±r:
 * KullanÄ±m durumumuz iÃ§in geÃ§erli _Ã¶zellikleri_ yakaladÄ±k mÄ±?
 * Ã‡eÅŸitli veri kaynaklarÄ± arasÄ±nda veri _tutarlÄ±_ bir ÅŸekilde mi yakalandÄ±?
 * Veri seti Ã§eÅŸitli koÅŸullar veya senaryolar iÃ§in _tam_ mÄ±?
 * Bilgiler gerÃ§ekliÄŸi yansÄ±tacak ÅŸekilde _doÄŸru_ bir ÅŸekilde mi yakalandÄ±?

#### 2.8 Algoritma Adaleti
[Algorithm Adaleti](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f), algoritma tasarÄ±mÄ±nÄ±n belirli veri gruplarÄ±na sistematik olarak ayrÄ±mcÄ±lÄ±k yapÄ±p yapmadÄ±ÄŸÄ±nÄ± ve bunun sonucunda _kaynak tahsisi_ (kaynaklarÄ±n o gruptan esirgenmesi veya reddedilmesi) ve _hizmet kalitesi_ (AI'nin bazÄ± gruplar iÃ§in diÄŸerlerine gÃ¶re daha az doÄŸru olmasÄ±) gibi [potansiyel zararlar](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) oluÅŸturup oluÅŸturmadÄ±ÄŸÄ±nÄ± kontrol eder.

Burada araÅŸtÄ±rÄ±lmasÄ± gereken sorular:
 * Model doÄŸruluÄŸunu farklÄ± gruplar ve koÅŸullar iÃ§in deÄŸerlendirdik mi?
 * Sistemi potansiyel zararlar (Ã¶rneÄŸin, stereotipleme) aÃ§Ä±sÄ±ndan inceledik mi?
 * Belirlenen zararlarÄ± azaltmak iÃ§in verileri revize edebilir veya modelleri yeniden eÄŸitebilir miyiz?

Daha fazla bilgi edinmek iÃ§in [AI Adalet kontrol listeleri](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) gibi kaynaklarÄ± keÅŸfedin.

#### 2.9 YanÄ±ltÄ±cÄ± Temsil

[Veri YanÄ±ltÄ±cÄ± Temsili](https://www.sciencedirect.com/topics/computer-science/misrepresentation), dÃ¼rÃ¼stÃ§e raporlanan verilerden elde edilen iÃ§gÃ¶rÃ¼lerin, istenen bir anlatÄ±yÄ± desteklemek iÃ§in aldatÄ±cÄ± bir ÅŸekilde iletilip iletilmediÄŸini sorgular.

Burada araÅŸtÄ±rÄ±lmasÄ± gereken sorular:
 * Eksik veya yanlÄ±ÅŸ veri mi raporluyoruz?
 * Verileri yanÄ±ltÄ±cÄ± sonuÃ§lar Ã§Ä±karacak ÅŸekilde mi gÃ¶rselleÅŸtiriyoruz?
 * SonuÃ§larÄ± manipÃ¼le etmek iÃ§in seÃ§ici istatistiksel teknikler mi kullanÄ±yoruz?
 * FarklÄ± bir sonuca yol aÃ§abilecek alternatif aÃ§Ä±klamalar var mÄ±?

#### 2.10 Ã–zgÃ¼r SeÃ§im

[Ã–zgÃ¼r SeÃ§im YanÄ±lsamasÄ±](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice), sistemin "seÃ§im mimarilerinin" karar verme algoritmalarÄ±nÄ± kullanarak insanlarÄ± tercih edilen bir sonuca yÃ¶nlendirdiÄŸi, ancak onlara seÃ§enekler ve kontrol sunduÄŸu izlenimini verdiÄŸi durumlarda ortaya Ã§Ä±kar. Bu [karanlÄ±k desenler](https://www.darkpatterns.org/) kullanÄ±cÄ±lar iÃ§in sosyal ve ekonomik zararlar yaratabilir. KullanÄ±cÄ± kararlarÄ± davranÄ±ÅŸ profillerini etkilediÄŸinden, bu eylemler potansiyel olarak bu zararlarÄ±n etkisini artÄ±rabilir veya uzatabilir.

Burada araÅŸtÄ±rÄ±lmasÄ± gereken sorular:
 * KullanÄ±cÄ±, o seÃ§imi yapmanÄ±n sonuÃ§larÄ±nÄ± anladÄ± mÄ±?
 * KullanÄ±cÄ±, (alternatif) seÃ§eneklerin ve her birinin artÄ±larÄ± ve eksilerinin farkÄ±nda mÄ±ydÄ±?
 * KullanÄ±cÄ±, otomatik veya etkilenmiÅŸ bir seÃ§imi daha sonra geri alabilir mi?

### 3. Vaka Ã‡alÄ±ÅŸmalarÄ±

Bu etik zorluklarÄ± gerÃ§ek dÃ¼nya baÄŸlamlarÄ±nda ele almak iÃ§in, bu tÃ¼r etik ihlallerin gÃ¶z ardÄ± edildiÄŸinde bireyler ve toplum Ã¼zerindeki potansiyel zararlarÄ± ve sonuÃ§larÄ±nÄ± vurgulayan vaka Ã§alÄ±ÅŸmalarÄ±na bakmak faydalÄ± olur.

Ä°ÅŸte birkaÃ§ Ã¶rnek:

| Etik Zorluk | Vaka Ã‡alÄ±ÅŸmasÄ±  | 
|--- |--- |
| **BilgilendirilmiÅŸ Onay** | 1972 - [Tuskegee Frengi Ã‡alÄ±ÅŸmasÄ±](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - Ã‡alÄ±ÅŸmaya katÄ±lan AfrikalÄ± AmerikalÄ± erkeklere Ã¼cretsiz tÄ±bbi bakÄ±m vaat edildi, ancak araÅŸtÄ±rmacÄ±lar tarafÄ±ndan teÅŸhisleri veya tedavi seÃ§enekleri hakkÄ±nda bilgilendirilmediler. BirÃ§ok katÄ±lÄ±mcÄ± Ã¶ldÃ¼ ve eÅŸleri veya Ã§ocuklarÄ± etkilendi; Ã§alÄ±ÅŸma 40 yÄ±l sÃ¼rdÃ¼. | 
| **Veri GizliliÄŸi** |  2007 - [Netflix veri Ã¶dÃ¼lÃ¼](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) araÅŸtÄ±rmacÄ±lara _50K mÃ¼ÅŸteriden 10M anonimleÅŸtirilmiÅŸ film derecelendirmesi_ saÄŸladÄ±. Ancak, araÅŸtÄ±rmacÄ±lar anonimleÅŸtirilmiÅŸ verileri _harici veri setlerindeki_ (Ã¶rneÄŸin, IMDb yorumlarÄ±) kiÅŸisel olarak tanÄ±mlanabilir verilerle iliÅŸkilendirebildi - bazÄ± Netflix abonelerini "de-anonimleÅŸtirdi".|
| **Veri Toplama YanlÄ±lÄ±ÄŸÄ±**  | 2013 - Boston Åehri [Street Bump uygulamasÄ±nÄ± geliÅŸtirdi](https://www.boston.gov/transportation/street-bump), vatandaÅŸlarÄ±n Ã§ukurlarÄ± bildirmesine olanak tanÄ±yarak ÅŸehre yol sorunlarÄ±nÄ± bulmak ve dÃ¼zeltmek iÃ§in daha iyi veriler saÄŸladÄ±. Ancak, [dÃ¼ÅŸÃ¼k gelir gruplarÄ±ndaki insanlarÄ±n araba ve telefonlara eriÅŸimi daha azdÄ±](https://hbr.org/2013/04/the-hidden-biases-in-big-data), bu da onlarÄ±n yol sorunlarÄ±nÄ± bu uygulamada gÃ¶rÃ¼nmez hale getirdi. GeliÅŸtiriciler, adalet iÃ§in _eÅŸit eriÅŸim ve dijital bÃ¶lÃ¼nmeler_ sorunlarÄ± Ã¼zerinde akademisyenlerle Ã§alÄ±ÅŸtÄ±. |
| **Algoritmik Adalet**  | 2018 - MIT [Gender Shades Ã‡alÄ±ÅŸmasÄ±](http://gendershades.org/overview.html), cinsiyet sÄ±nÄ±flandÄ±rma AI Ã¼rÃ¼nlerinin doÄŸruluÄŸunu deÄŸerlendirerek kadÄ±nlar ve renkli kiÅŸiler iÃ§in doÄŸrulukta boÅŸluklar olduÄŸunu ortaya Ã§Ä±kardÄ±. Bir [2019 Apple Card](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) kadÄ±nlara erkeklere gÃ¶re daha az kredi sunmuÅŸ gibi gÃ¶rÃ¼ndÃ¼. Her ikisi de algoritmik yanlÄ±lÄ±ÄŸÄ±n sosyo-ekonomik zararlara yol aÃ§tÄ±ÄŸÄ±nÄ± gÃ¶sterdi.|
| **Veri YanÄ±ltÄ±cÄ± Temsili** | 2020 - [Georgia Halk SaÄŸlÄ±ÄŸÄ± DepartmanÄ± COVID-19 grafiklerini yayÄ±nladÄ±](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) ve x ekseninde kronolojik olmayan sÄ±ralama ile vatandaÅŸlarÄ± doÄŸrulanmÄ±ÅŸ vakalardaki eÄŸilimler hakkÄ±nda yanÄ±ltmÄ±ÅŸ gibi gÃ¶rÃ¼ndÃ¼. Bu, gÃ¶rselleÅŸtirme hileleriyle yanÄ±ltÄ±cÄ± temsili Ã¶rnekler. |
| **Ã–zgÃ¼r SeÃ§im YanÄ±lsamasÄ±** | 2020 - Ã–ÄŸrenme uygulamasÄ± [ABCmouse, FTC ÅŸikayetini Ã§Ã¶zmek iÃ§in $10M Ã¶dedi](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/) ve ebeveynler iptal edemedikleri abonelikler iÃ§in Ã¶deme yapmaya zorlandÄ±. Bu, kullanÄ±cÄ±larÄ±n potansiyel olarak zararlÄ± seÃ§imlere yÃ¶nlendirildiÄŸi seÃ§im mimarilerindeki karanlÄ±k desenleri gÃ¶sterir. |
| **Veri GizliliÄŸi ve KullanÄ±cÄ± HaklarÄ±** | 2021 - Facebook [Veri Ä°hlali](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) 530M kullanÄ±cÄ±nÄ±n verilerini ifÅŸa etti ve FTC'ye $5B Ã¶deme yaptÄ±. Ancak, kullanÄ±cÄ±larÄ± ihlal hakkÄ±nda bilgilendirmeyi reddetti ve veri ÅŸeffaflÄ±ÄŸÄ± ve eriÅŸimi konusundaki kullanÄ±cÄ± haklarÄ±nÄ± ihlal etti. |

Daha fazla vaka Ã§alÄ±ÅŸmasÄ± keÅŸfetmek ister misiniz? Bu kaynaklara gÃ¶z atÄ±n:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - Ã§eÅŸitli endÃ¼strilerde etik ikilemler. 
* [Data Science Ethics course](https://www.coursera.org/learn/data-science-ethics#syllabus) - Ã¶nemli vaka Ã§alÄ±ÅŸmalarÄ± inceleniyor.
* [Where things have gone wrong](https://deon.drivendata.org/examples/) - deon kontrol listesi ve Ã¶rnekler.

> ğŸš¨ GÃ¶rdÃ¼ÄŸÃ¼nÃ¼z vaka Ã§alÄ±ÅŸmalarÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼n - hayatÄ±nÄ±zda benzer bir etik zorlukla karÅŸÄ±laÅŸtÄ±nÄ±z mÄ± veya etkilendiniz mi? Bu bÃ¶lÃ¼mde tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z etik zorluklardan birini gÃ¶steren en az bir baÅŸka vaka Ã§alÄ±ÅŸmasÄ± dÃ¼ÅŸÃ¼nebilir misiniz?

## UygulamalÄ± Etik

Etik kavramlarÄ±, zorluklarÄ± ve gerÃ§ek dÃ¼nya baÄŸlamlarÄ±nda vaka Ã§alÄ±ÅŸmalarÄ±nÄ± konuÅŸtuk. Peki, projelerimizde etik ilkeleri ve uygulamalarÄ± nasÄ±l _uygularÄ±z_? Ve bu uygulamalarÄ± daha iyi yÃ¶netim iÃ§in nasÄ±l _operasyonelleÅŸtiririz_? GerÃ§ek dÃ¼nya Ã§Ã¶zÃ¼mlerini keÅŸfedelim:

### 1. Profesyonel Kodlar

Profesyonel Kodlar, organizasyonlarÄ±n Ã¼yelerini etik ilkelerini ve misyon beyanlarÄ±nÄ± desteklemeye "teÅŸvik etmek" iÃ§in bir seÃ§enek sunar. Kodlar, profesyonel davranÄ±ÅŸ iÃ§in _ahlaki yÃ¶nergeler_ olup, Ã§alÄ±ÅŸanlarÄ±n veya Ã¼yelerin organizasyonlarÄ±nÄ±n ilkelerine uygun kararlar almasÄ±na yardÄ±mcÄ± olur. Ancak, Ã¼yelerin gÃ¶nÃ¼llÃ¼ uyumu kadar iyidirler; birÃ§ok organizasyon, Ã¼yelerin uyumunu motive etmek iÃ§in ek Ã¶dÃ¼ller ve cezalar sunar.

Ã–rnekler:
 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Etik Kodu
 * [Data Science Association](http://datascienceassn.org/code-of-conduct.html) DavranÄ±ÅŸ KurallarÄ± (2013'te oluÅŸturuldu)
 * [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (1993'ten beri)

> ğŸš¨ Profesyonel bir mÃ¼hendislik veya veri bilimi organizasyonuna Ã¼ye misiniz? Sitelerini inceleyerek profesyonel bir etik kodu tanÄ±mlayÄ±p tanÄ±mlamadÄ±klarÄ±nÄ± gÃ¶rÃ¼n. Bu, etik ilkeleri hakkÄ±nda ne sÃ¶ylÃ¼yor? Ãœyeleri kodu takip etmeye nasÄ±l "teÅŸvik ediyorlar"?

### 2. Etik Kontrol Listeleri

Profesyonel kodlar, uygulayÄ±cÄ±lardan beklenen _etik davranÄ±ÅŸÄ±_ tanÄ±mlarken, [bilinen sÄ±nÄ±rlamalarÄ±](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) vardÄ±r, Ã¶zellikle bÃ¼yÃ¼k Ã¶lÃ§ekli projelerde. Bunun yerine, birÃ§ok veri bilimi uzmanÄ± [kontrol listelerini](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) savunur, bu da **ilkeleri uygulamalara** daha belirleyici ve uygulanabilir yollarla baÄŸlayabilir.

Kontrol listeleri, sorularÄ± "evet/hayÄ±r" gÃ¶revlerine dÃ¶nÃ¼ÅŸtÃ¼rerek operasyonelleÅŸtirilebilir ve standart Ã¼rÃ¼n sÃ¼rÃ¼m iÅŸ akÄ±ÅŸlarÄ±nÄ±n bir parÃ§asÄ± olarak izlenebilir hale getirir.

Ã–rnekler:
 * [Deon](https://deon.drivendata.org/) - [endÃ¼stri Ã¶nerilerinden](https://deon.drivendata.org/#checklist-citations) oluÅŸturulmuÅŸ genel amaÃ§lÄ± bir veri etik kontrol listesi ve kolay entegrasyon iÃ§in bir komut satÄ±rÄ± aracÄ±.
 * [Gizlilik Denetim Kontrol Listesi](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - yasal ve sosyal maruz kalma perspektiflerinden bilgi iÅŸleme uygulamalarÄ± iÃ§in genel rehberlik saÄŸlar.
 * [AI Adalet Kontrol Listesi](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - AI geliÅŸtirme dÃ¶ngÃ¼lerine adalet kontrollerinin benimsenmesini ve entegrasyonunu desteklemek iÃ§in AI uygulayÄ±cÄ±larÄ± tarafÄ±ndan oluÅŸturuldu.
 * [Veri ve AI'da etik iÃ§in 22 soru](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - tasarÄ±m, uygulama ve organizasyonel baÄŸlamlarda etik sorunlarÄ±n ilk keÅŸfi iÃ§in daha aÃ§Ä±k uÃ§lu bir Ã§erÃ§eve.

### 3. Etik DÃ¼zenlemeler

Etik, paylaÅŸÄ±lan deÄŸerleri tanÄ±mlamak ve doÄŸru olanÄ± _gÃ¶nÃ¼llÃ¼ olarak_ yapmakla ilgilidir. **Uyum**, tanÄ±mlanmÄ±ÅŸsa ve nerede tanÄ±mlanmÄ±ÅŸsa _yasalara uymak_ ile ilgilidir. **YÃ¶netim**, organizasyonlarÄ±n etik ilkeleri uygulamak ve belirlenmiÅŸ yasalara uymak iÃ§in Ã§alÄ±ÅŸtÄ±ÄŸÄ± tÃ¼m yollarÄ± kapsar.

BugÃ¼n, yÃ¶netim organizasyonlar iÃ§inde iki ÅŸekilde gerÃ§ekleÅŸir. Ä°lk olarak, **etik AI** ilkelerini tanÄ±mlamak ve organizasyondaki tÃ¼m AI ile ilgili projelerde benimsenmeyi operasyonelleÅŸtirmekle ilgilidir. Ä°kincisi, faaliyet gÃ¶sterdiÄŸi bÃ¶lgeler iÃ§in tÃ¼m hÃ¼kÃ¼met tarafÄ±ndan belirlenmiÅŸ **veri koruma dÃ¼zenlemelerine** uymakla ilgilidir.

Veri koruma ve gizlilik dÃ¼zenlemeleri Ã¶rnekleri:

 * `1974`, [ABD Gizlilik YasasÄ±](https://www.justice.gov/opcl/privacy-act-1974) - _federal hÃ¼kÃ¼metin_ kiÅŸisel bilgilerin toplanmasÄ±nÄ±, kullanÄ±lmasÄ±nÄ± ve aÃ§Ä±klanmasÄ±nÄ± dÃ¼zenler.
 * `1996`, [ABD SaÄŸlÄ±k SigortasÄ± TaÅŸÄ±nabilirlik ve Hesap Verebilirlik YasasÄ± (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - kiÅŸisel saÄŸlÄ±k verilerini korur.
 * `1998`, [ABD Ã‡ocuklarÄ±n Ã‡evrimiÃ§i GizliliÄŸini Koruma YasasÄ± (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - 13 yaÅŸ altÄ±ndaki Ã§ocuklarÄ±n veri gizliliÄŸini korur.
 * `2018`, [Genel Veri Koruma YÃ¶netmeliÄŸi (GDPR)](https://gdpr-info.eu/) - kullanÄ±cÄ± haklarÄ±, veri koruma ve gizlilik saÄŸlar.
 * `2018`, [California TÃ¼ketici GizliliÄŸi YasasÄ± (CCPA)](https://www.oag.ca.gov/privacy/ccpa) tÃ¼keticilere (kiÅŸisel) verileri Ã¼zerinde daha fazla _hak_ verir.
 * `2021`, Ã‡in'in [KiÅŸisel Bilgi Koruma YasasÄ±](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) yeni geÃ§ti ve dÃ¼nya Ã§apÄ±nda en gÃ¼Ã§lÃ¼ Ã§evrimiÃ§i veri gizliliÄŸi dÃ¼zenlemelerinden birini oluÅŸturdu.

> ğŸš¨ Avrupa BirliÄŸi tarafÄ±ndan tanÄ±mlanan GDPR (Genel Veri Koruma YÃ¶netmeliÄŸi), bugÃ¼n en etkili veri gizliliÄŸi dÃ¼zenlemelerinden biri olmaya devam ediyor. AyrÄ±ca vatandaÅŸlarÄ±n dijital gizliliÄŸini ve kiÅŸisel verilerini korumak iÃ§in [8 kullanÄ±cÄ± hakkÄ±](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) tanÄ±mladÄ±ÄŸÄ±nÄ± biliyor muydunuz? BunlarÄ±n ne olduÄŸunu ve neden Ã¶nemli olduklarÄ±nÄ± Ã¶ÄŸrenin.

### 4. Etik KÃ¼ltÃ¼rÃ¼

Uyum (yasanÄ±n "harfini" yerine getirmek iÃ§in yeterince yapmak) ile [sistemik sorunlarÄ±](https://www.coursera.org/learn/data-science-ethics/home/week/4) ele almak (Ã¶rneÄŸin, katÄ±laÅŸma, bilgi asimetrisi ve daÄŸÄ±tÄ±m adaletsizliÄŸi) arasÄ±nda hala elle tutulamayan bir boÅŸluk olduÄŸunu unutmayÄ±n. 

Ä°kincisi, [etik kÃ¼ltÃ¼rleri tanÄ±mlamak iÃ§in iÅŸbirlikÃ§i yaklaÅŸÄ±mlar](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f) gerektirir ve bu, organizasyonlar arasÄ±nda duygusal baÄŸlar ve tutarlÄ± paylaÅŸÄ±lan deÄŸerler oluÅŸturur. Bu, organizasyonlarda daha [resmileÅŸtirilmiÅŸ veri etik kÃ¼ltÃ¼rleri](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) oluÅŸturmayÄ± gerektirir - _herkesin_ (etik endiÅŸeleri sÃ¼recin erken aÅŸamalarÄ±nda dile getirmek iÃ§in) [Andon ipini Ã§ekmesine](https://en.wikipedia.org/wiki/Andon_(manufacturing)) olanak tanÄ±r ve _etik deÄŸerlendirmeleri_ (Ã¶rneÄŸin, iÅŸe alÄ±mda) AI projelerinde ekip oluÅŸturmanÄ±n temel kriteri haline getirir.

---
## [Ders sonrasÄ± test](https://ff-quizzes.netlify.app/en/ds/quiz/3) ğŸ¯
## GÃ¶zden GeÃ§irme ve Kendi Kendine Ã‡alÄ±ÅŸma 

Kurslar ve kitaplar, temel etik kavramlarÄ±nÄ± ve zorluklarÄ±nÄ± anlamaya yardÄ±mcÄ± olurken, vaka Ã§alÄ±ÅŸmalarÄ± ve araÃ§lar gerÃ§ek dÃ¼nya baÄŸlamlarÄ±nda uygulamalÄ± etik uygulamalarÄ±na yardÄ±mcÄ± olur. Ä°ÅŸte baÅŸlamak iÃ§in birkaÃ§ kaynak.

* [Machine Learning For Beginners](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - Microsoft'tan Adalet Ã¼zerine bir ders.
* [Sorumlu Yapay Zeka Ä°lkeleri](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - Microsoft Learn'den Ã¼cretsiz Ã¶ÄŸrenim yolu.
* [Etik ve Veri Bilimi](https://resources.oreilly.com/examples/0636920203964) - O'Reilly EKitap (M. Loukides, H. Mason ve diÄŸerleri)
* [Veri Bilimi EtiÄŸi](https://www.coursera.org/learn/data-science-ethics#syllabus) - Michigan Ãœniversitesi'nden Ã§evrimiÃ§i kurs.
* [Etik AÃ§Ä±klanÄ±yor](https://ethicsunwrapped.utexas.edu/case-studies) - Texas Ãœniversitesi'nden vaka Ã§alÄ±ÅŸmalarÄ±.

# Ã–dev 

[Bir Veri EtiÄŸi Vaka Ã‡alÄ±ÅŸmasÄ± YazÄ±n](assignment.md)

---

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dilindeki hali, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalar iÃ§in sorumluluk kabul etmiyoruz.