<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "58860ce9a4b8a564003d2752f7c72851",
  "translation_date": "2025-10-03T16:29:37+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "tr"
}
-->
# Veri EtiÄŸine GiriÅŸ

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Veri Bilimi EtiÄŸi - _Sketchnote by [@nitya](https://twitter.com/nitya)_ |

---

Hepimiz veriyle dolu bir dÃ¼nyada yaÅŸayan veri vatandaÅŸlarÄ±yÄ±z.

Pazar trendleri, 2022 yÄ±lÄ± itibarÄ±yla bÃ¼yÃ¼k organizasyonlarÄ±n Ã¼Ã§te birinin verilerini Ã§evrimiÃ§i [Pazar Yerleri ve Borsalar](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/) aracÄ±lÄ±ÄŸÄ±yla alÄ±p satacaÄŸÄ±nÄ± gÃ¶steriyor. **Uygulama GeliÅŸtiricileri** olarak, veri odaklÄ± iÃ§gÃ¶rÃ¼leri ve algoritma tabanlÄ± otomasyonu gÃ¼nlÃ¼k kullanÄ±cÄ± deneyimlerine entegre etmenin daha kolay ve ucuz hale geldiÄŸini gÃ¶receÄŸiz. Ancak yapay zeka yaygÄ±nlaÅŸtÄ±kÃ§a, bu tÃ¼r algoritmalarÄ±n [silah haline getirilmesi](https://www.youtube.com/watch?v=TQHs8SA1qpk) durumunda ortaya Ã§Ä±kabilecek zararlarÄ± da anlamamÄ±z gerekecek.

Trendler, 2025 yÄ±lÄ±na kadar [180 zettabayt](https://www.statista.com/statistics/871513/worldwide-data-created/) veri Ã¼reteceÄŸimizi ve tÃ¼keteceÄŸimizi Ã¶ngÃ¶rÃ¼yor. **Veri Bilimcileri** iÃ§in bu bilgi patlamasÄ±, kiÅŸisel ve davranÄ±ÅŸsal verilere benzeri gÃ¶rÃ¼lmemiÅŸ bir eriÅŸim saÄŸlÄ±yor. Bu durum, ayrÄ±ntÄ±lÄ± kullanÄ±cÄ± profilleri oluÅŸturma ve karar verme sÃ¼reÃ§lerini ince bir ÅŸekilde etkileme gÃ¼cÃ¼nÃ¼ beraberinde getiriyorâ€”Ã§oÄŸu zaman [Ã¶zgÃ¼r seÃ§im yanÄ±lsamasÄ±](https://www.datasciencecentral.com/the-pareto-set-and-the-paradox-of-choice/) yaratacak ÅŸekilde. Bu, kullanÄ±cÄ±larÄ± tercih edilen sonuÃ§lara yÃ¶nlendirmek iÃ§in kullanÄ±labilirken, aynÄ± zamanda veri gizliliÄŸi, Ã¶zerklik ve algoritmik etkilerin etik sÄ±nÄ±rlarÄ± hakkÄ±nda kritik sorularÄ± gÃ¼ndeme getiriyor.

Veri etiÄŸi, veri bilimi ve mÃ¼hendisliÄŸi iÃ§in artÄ±k _gerekli koruma Ã¶nlemleri_ haline geldi ve veri odaklÄ± eylemlerimizden kaynaklanabilecek potansiyel zararlarÄ± ve istenmeyen sonuÃ§larÄ± en aza indirmemize yardÄ±mcÄ± oluyor. [Gartner'Ä±n Yapay Zeka Hype DÃ¶ngÃ¼sÃ¼](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/), dijital etik, sorumlu yapay zeka ve yapay zeka yÃ¶netimi gibi ilgili trendleri, yapay zekanÄ±n _demokratikleÅŸmesi_ ve _endÃ¼strileÅŸmesi_ gibi daha bÃ¼yÃ¼k megatrendlerin anahtar itici gÃ¼Ã§leri olarak tanÄ±mlÄ±yor.

![Gartner'Ä±n Yapay Zeka Hype DÃ¶ngÃ¼sÃ¼ - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

Bu derste, veri etiÄŸi alanÄ±nÄ± keÅŸfedeceÄŸizâ€”temel kavramlardan ve zorluklardan, vaka Ã§alÄ±ÅŸmalarÄ±na ve yÃ¶netiÅŸim gibi uygulamalÄ± yapay zeka kavramlarÄ±na kadarâ€”veri ve yapay zeka ile Ã§alÄ±ÅŸan ekiplerde ve organizasyonlarda bir etik kÃ¼ltÃ¼rÃ¼ oluÅŸturmayÄ± destekleyen unsurlarÄ± inceleyeceÄŸiz.

## [Ders Ã–ncesi Test](https://ff-quizzes.netlify.app/en/ds/quiz/2) ğŸ¯

## Temel TanÄ±mlar

Ã–ncelikle temel terminolojiyi anlamakla baÅŸlayalÄ±m.

"Etik" kelimesi, [Yunanca "ethikos"](https://en.wikipedia.org/wiki/Ethics) (ve kÃ¶kÃ¼ "ethos") kelimesinden gelir ve _karakter veya ahlaki doÄŸa_ anlamÄ±na gelir.

**Etik**, toplumdaki davranÄ±ÅŸlarÄ±mÄ±zÄ± yÃ¶neten ortak deÄŸerler ve ahlaki prensiplerle ilgilidir. Etik, yasalara deÄŸil, "doÄŸru ve yanlÄ±ÅŸ" olarak kabul edilen normlara dayanÄ±r. Ancak etik dÃ¼ÅŸÃ¼nceler, kurumsal yÃ¶netim giriÅŸimlerini ve uyum iÃ§in daha fazla teÅŸvik yaratan hÃ¼kÃ¼met dÃ¼zenlemelerini etkileyebilir.

**Veri EtiÄŸi**, "_veri, algoritmalar ve ilgili uygulamalarla_ ilgili ahlaki sorunlarÄ± inceleyen ve deÄŸerlendiren" [yeni bir etik dalÄ±dÄ±r](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1). Burada, **"veri"**, Ã¼retim, kayÄ±t, kÃ¼rasyon, iÅŸleme, yayma, paylaÅŸÄ±m ve kullanÄ±m ile ilgili eylemlere odaklanÄ±r; **"algoritmalar"**, yapay zeka, ajanlar, makine Ã¶ÄŸrenimi ve robotlara odaklanÄ±r; ve **"uygulamalar"**, sorumlu yenilik, programlama, hackleme ve etik kodlar gibi konulara odaklanÄ±r.

**UygulamalÄ± Etik**, [ahlaki dÃ¼ÅŸÃ¼ncelerin pratik uygulamasÄ±dÄ±r](https://en.wikipedia.org/wiki/Applied_ethics). GerÃ§ek dÃ¼nya eylemleri, Ã¼rÃ¼nleri ve sÃ¼reÃ§leri baÄŸlamÄ±nda etik sorunlarÄ± aktif olarak araÅŸtÄ±rma ve bu sorunlarÄ±n tanÄ±mlÄ± etik deÄŸerlerimizle uyumlu kalmasÄ±nÄ± saÄŸlamak iÃ§in dÃ¼zeltici Ã¶nlemler alma sÃ¼recidir.

**Etik KÃ¼ltÃ¼rÃ¼**, [_uygulamalÄ± etiÄŸi_ operasyonelleÅŸtirmek](https://hbr.org/2019/05/how-to-design-an-ethical-organization) ile ilgilidir; bÃ¶ylece etik prensiplerimizin ve uygulamalarÄ±mÄ±zÄ±n organizasyon genelinde tutarlÄ± ve Ã¶lÃ§eklenebilir bir ÅŸekilde benimsenmesini saÄŸlar. BaÅŸarÄ±lÄ± etik kÃ¼ltÃ¼rleri, organizasyon genelinde etik prensipler tanÄ±mlar, uyum iÃ§in anlamlÄ± teÅŸvikler sunar ve istenen davranÄ±ÅŸlarÄ± her seviyede teÅŸvik ederek ve gÃ¼Ã§lendirerek etik normlarÄ± pekiÅŸtirir.

## Etik KavramlarÄ±

Bu bÃ¶lÃ¼mde, veri etiÄŸi iÃ§in **ortak deÄŸerler** (prensipler) ve **etik zorluklar** (sorunlar) gibi kavramlarÄ± tartÄ±ÅŸacaÄŸÄ±z ve bu kavramlarÄ± gerÃ§ek dÃ¼nya baÄŸlamlarÄ±nda anlamanÄ±za yardÄ±mcÄ± olacak **vaka Ã§alÄ±ÅŸmalarÄ±** inceleyeceÄŸiz.

### 1. Etik Prensipler

Her veri etiÄŸi stratejisi, _etik prensipleri_ tanÄ±mlayarak baÅŸlarâ€”veri ve yapay zeka projelerimizde kabul edilebilir davranÄ±ÅŸlarÄ± tanÄ±mlayan ve uyumlu eylemleri yÃ¶nlendiren "ortak deÄŸerler". BunlarÄ± bireysel veya ekip dÃ¼zeyinde tanÄ±mlayabilirsiniz. Ancak, Ã§oÄŸu bÃ¼yÃ¼k organizasyon, bunlarÄ± kurumsal dÃ¼zeyde tanÄ±mlanan ve tÃ¼m ekiplerde tutarlÄ± bir ÅŸekilde uygulanan bir _etik yapay zeka_ misyon bildirimi veya Ã§erÃ§evesinde belirtir.

**Ã–rnek:** Microsoft'un [Sorumlu Yapay Zeka](https://www.microsoft.com/en-us/ai/responsible-ai) misyon bildirimi ÅŸu ÅŸekilde ifade edilir: _"Ä°nsanlarÄ± Ã¶nceliklendiren etik prensiplerle yÃ¶nlendirilen yapay zekanÄ±n ilerlemesine baÄŸlÄ±yÄ±z"_â€”aÅŸaÄŸÄ±daki Ã§erÃ§evede 6 etik prensip tanÄ±mlanmÄ±ÅŸtÄ±r:

![Microsoft'ta Sorumlu Yapay Zeka](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

Bu prensipleri kÄ±saca inceleyelim. _ÅeffaflÄ±k_ ve _hesap verebilirlik_, diÄŸer prensiplerin Ã¼zerine inÅŸa edildiÄŸi temel deÄŸerlerdirâ€”bu yÃ¼zden buradan baÅŸlayalÄ±m:

* [**Hesap Verebilirlik**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6), uygulayÄ±cÄ±larÄ± veri ve yapay zeka operasyonlarÄ±ndan ve bu etik prensiplere uyumdan _sorumlu_ kÄ±lar.
* [**ÅeffaflÄ±k**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6), veri ve yapay zeka eylemlerinin kullanÄ±cÄ±lar tarafÄ±ndan _anlaÅŸÄ±labilir_ (yorumlanabilir) olmasÄ±nÄ± saÄŸlar ve kararlarÄ±n arkasÄ±ndaki ne ve nedenleri aÃ§Ä±klar.
* [**Adalet**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6), yapay zekanÄ±n _tÃ¼m insanlara_ adil davranmasÄ±nÄ± saÄŸlar ve veri ve sistemlerdeki sistematik veya Ã¶rtÃ¼k sosyo-teknik Ã¶nyargÄ±larÄ± ele alÄ±r.
* [**GÃ¼venilirlik ve GÃ¼venlik**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6), yapay zekanÄ±n tanÄ±mlÄ± deÄŸerlere _tutarlÄ±_ bir ÅŸekilde davranmasÄ±nÄ± saÄŸlar ve potansiyel zararlarÄ± veya istenmeyen sonuÃ§larÄ± en aza indirir.
* [**Gizlilik ve GÃ¼venlik**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6), veri kÃ¶kenini anlamak ve kullanÄ±cÄ±lara _veri gizliliÄŸi ve ilgili korumalar_ saÄŸlamakla ilgilidir.
* [**KapsayÄ±cÄ±lÄ±k**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6), yapay zeka Ã§Ã¶zÃ¼mlerini niyetle tasarlamak ve onlarÄ± _geniÅŸ bir insan ihtiyaÃ§larÄ± ve yetenekleri yelpazesine_ uyarlamakla ilgilidir.

> ğŸš¨ Veri etiÄŸi misyon bildiriminizin ne olabileceÄŸini dÃ¼ÅŸÃ¼nÃ¼n. DiÄŸer organizasyonlarÄ±n etik yapay zeka Ã§erÃ§evelerini keÅŸfedinâ€”iÅŸte [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles) ve [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/) Ã¶rnekleri. Ortak deÄŸerleri nelerdir? Bu prensipler, Ã§alÄ±ÅŸtÄ±klarÄ± yapay zeka Ã¼rÃ¼nÃ¼ veya endÃ¼stri ile nasÄ±l iliÅŸkilidir?

### 2. Etik Zorluklar

Etik prensipler tanÄ±mlandÄ±ktan sonra, bir sonraki adÄ±m, veri ve yapay zeka eylemlerimizin bu ortak deÄŸerlerle uyumlu olup olmadÄ±ÄŸÄ±nÄ± deÄŸerlendirmektir. Eylemlerinizi iki kategoriye ayÄ±rarak dÃ¼ÅŸÃ¼nÃ¼n: _veri toplama_ ve _algoritma tasarÄ±mÄ±_.

Veri toplama ile ilgili eylemler, bÃ¼yÃ¼k olasÄ±lÄ±kla **kiÅŸisel veri** veya yaÅŸayan bireyleri tanÄ±mlanabilir kÄ±lan kiÅŸisel olarak tanÄ±mlanabilir bilgiler (PII) iÃ§erecektir. Bu, [Ã§eÅŸitli kiÅŸisel olmayan veri Ã¶ÄŸelerini](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) iÃ§erir ve _birlikte_ bir bireyi tanÄ±mlar. Etik zorluklar, _veri gizliliÄŸi_, _veri sahipliÄŸi_ ve _bilgilendirilmiÅŸ onay_ ve kullanÄ±cÄ±lar iÃ§in _fikri mÃ¼lkiyet haklarÄ±_ gibi ilgili konularla ilgili olabilir.

Algoritma tasarÄ±mÄ± ile ilgili eylemler, **veri setleri** toplama ve dÃ¼zenleme, ardÄ±ndan bunlarÄ± gerÃ§ek dÃ¼nya baÄŸlamlarÄ±nda sonuÃ§larÄ± tahmin eden veya kararlarÄ± otomatikleÅŸtiren **veri modelleri** oluÅŸturmak ve daÄŸÄ±tmak iÃ§in kullanmayÄ± iÃ§erecektir. Etik zorluklar, _veri seti Ã¶nyargÄ±sÄ±_, _veri kalitesi_ sorunlarÄ±, _adaletsizlik_ ve algoritmalardaki _yanlÄ±ÅŸ temsil_ gibi konulardan kaynaklanabilirâ€”bunlar arasÄ±nda bazÄ±larÄ± sistematik olabilir.

Her iki durumda da, etik zorluklar, eylemlerimizin ortak deÄŸerlerle Ã§atÄ±ÅŸabileceÄŸi alanlarÄ± vurgular. Bu endiÅŸeleri tespit etmek, hafifletmek, en aza indirmek veya ortadan kaldÄ±rmak iÃ§in, eylemlerimizle ilgili ahlaki "evet/hayÄ±r" sorularÄ± sormamÄ±z ve gerektiÄŸinde dÃ¼zeltici eylemler almamÄ±z gerekir. Ä°ÅŸte bazÄ± etik zorluklar ve bunlarÄ±n ortaya Ã§Ä±kardÄ±ÄŸÄ± ahlaki sorular:

#### 2.1 Veri SahipliÄŸi

Veri toplama genellikle veri konularÄ±nÄ± tanÄ±mlayabilen kiÅŸisel verileri iÃ§erir. [Veri sahipliÄŸi](https://permission.io/blog/data-ownership), verilerin oluÅŸturulmasÄ±, iÅŸlenmesi ve yayÄ±lmasÄ± ile ilgili _kontrol_ ve [_kullanÄ±cÄ± haklarÄ±_](https://permission.io/blog/data-ownership) ile ilgilidir.

SormamÄ±z gereken ahlaki sorular:
 * Verinin sahibi kimdir? (kullanÄ±cÄ± mÄ± organizasyon mu)
 * Veri konularÄ±nÄ±n hangi haklarÄ± vardÄ±r? (Ã¶rneÄŸin: eriÅŸim, silme, taÅŸÄ±nabilirlik)
 * OrganizasyonlarÄ±n hangi haklarÄ± vardÄ±r? (Ã¶rneÄŸin: kÃ¶tÃ¼ niyetli kullanÄ±cÄ± yorumlarÄ±nÄ± dÃ¼zeltme)

#### 2.2 BilgilendirilmiÅŸ Onay

[BilgilendirilmiÅŸ onay](https://legaldictionary.net/informed-consent/), kullanÄ±cÄ±larÄ±n (veri toplama gibi) bir eylemi, amacÄ±nÄ±, potansiyel risklerini ve alternatiflerini iÃ§eren _ilgili gerÃ§eklerin tam bir anlayÄ±ÅŸÄ±yla_ kabul etmesini tanÄ±mlar.

Burada keÅŸfedilecek sorular:
 * KullanÄ±cÄ± (veri konusu) veri toplama ve kullanÄ±m iÃ§in izin verdi mi?
 * KullanÄ±cÄ±, bu verinin toplandÄ±ÄŸÄ± amacÄ± anladÄ± mÄ±?
 * KullanÄ±cÄ±, katÄ±lÄ±mÄ±ndan kaynaklanabilecek potansiyel riskleri anladÄ± mÄ±?

#### 2.3 Fikri MÃ¼lkiyet

[Fikri mÃ¼lkiyet](https://en.wikipedia.org/wiki/Intellectual_property), insan giriÅŸiminden kaynaklanan ve bireyler veya iÅŸletmeler iÃ§in _ekonomik deÄŸeri_ olabilecek soyut yaratÄ±mlarÄ± ifade eder.

Burada keÅŸfedilecek sorular:
 * Toplanan veriler bir kullanÄ±cÄ± veya iÅŸletme iÃ§in ekonomik deÄŸere sahip miydi?
 * Burada **kullanÄ±cÄ±nÄ±n** fikri mÃ¼lkiyeti var mÄ±?
 * Burada **organizasyonun** fikri mÃ¼lkiyeti var mÄ±?
 * Bu haklar varsa, onlarÄ± nasÄ±l koruyoruz?

#### 2.4 Veri GizliliÄŸi

[Veri gizliliÄŸi](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) veya bilgi gizliliÄŸi, kullanÄ±cÄ± gizliliÄŸinin korunmasÄ± ve kullanÄ±cÄ± kimliÄŸinin kiÅŸisel olarak tanÄ±mlanabilir bilgilerle ilgili olarak korunmasÄ± anlamÄ±na gelir.

Burada keÅŸfedilecek sorular:
 * KullanÄ±cÄ±larÄ±n (kiÅŸisel) verileri hacklere ve sÄ±zÄ±ntÄ±lara karÅŸÄ± gÃ¼venli mi?
 * KullanÄ±cÄ±larÄ±n verileri yalnÄ±zca yetkili kullanÄ±cÄ±lar ve baÄŸlamlar tarafÄ±ndan eriÅŸilebilir mi?
 * Veri paylaÅŸÄ±ldÄ±ÄŸÄ±nda veya yayÄ±ldÄ±ÄŸÄ±nda kullanÄ±cÄ±larÄ±n anonimliÄŸi korunuyor mu?
 * KullanÄ±cÄ± anonimleÅŸtirilmiÅŸ veri setlerinden kimliksizleÅŸtirilebilir mi?

#### 2.5 Unutulma HakkÄ±

[Unutulma HakkÄ±](https://en.wikipedia.org/wiki/Right_to_be_forgotten) veya [Silme HakkÄ±](https://www.gdpreu.org/right-to-be-forgotten/), kullanÄ±cÄ±lara ek kiÅŸisel veri korumasÄ± saÄŸlar. Ã–zellikle, kullanÄ±cÄ±lara Ä°nternet aramalarÄ±ndan ve diÄŸer yerlerden kiÅŸisel verilerin silinmesini veya kaldÄ±rÄ±lmasÄ±nÄ± talep etme hakkÄ± verir, _belirli koÅŸullar altÄ±nda_â€”onlara geÃ§miÅŸ eylemlerinin kendilerine karÅŸÄ± kullanÄ±lmadÄ±ÄŸÄ± Ã§evrimiÃ§i yeni bir baÅŸlangÄ±Ã§ saÄŸlar.

Burada keÅŸfedilecek sorular:
 * Sistem, veri konularÄ±nÄ±n silme talebinde bulunmasÄ±na izin veriyor mu?
 * KullanÄ±cÄ± onayÄ±nÄ±n geri Ã§ekilmesi otomatik silmeyi tetiklemeli mi?
 * Veri, kullanÄ±cÄ± onayÄ± olmadan veya yasa dÄ±ÅŸÄ± yollarla mÄ± toplandÄ±?
 * Veri gizliliÄŸi iÃ§in hÃ¼kÃ¼met dÃ¼zenlemelerine uyuyor muyuz?

#### 2.6 Veri Seti Ã–nyargÄ±sÄ±

Veri seti veya [Toplama Ã–nyargÄ±sÄ±](http://researcharticles.com/index.php/bias-in-data-collection-in-research/), algoritma geliÅŸtirme iÃ§in _temsil edici olmayan_ bir veri alt kÃ¼mesi seÃ§mekle ilgilidir ve Ã§eÅŸitli gruplar iÃ§in sonuÃ§larda potansiyel adaletsizlik yaratÄ±r. Ã–nyargÄ± tÃ¼rleri arasÄ±nda seÃ§im veya Ã¶rnekleme Ã¶nyargÄ±sÄ±, gÃ¶nÃ¼llÃ¼ Ã¶nyargÄ± ve araÃ§ Ã¶nyargÄ±sÄ± bulunur.

Burada keÅŸfedilecek sorular:
 * Temsil edici bir veri konusu seti mi topladÄ±k?
 * Toplanan veya dÃ¼zenlenen veri setimizi Ã§eÅŸitli Ã¶nyargÄ±lar aÃ§Ä±sÄ±ndan test ettik mi?
 * Bulunan Ã¶nyargÄ±larÄ± hafifletebilir veya ortadan kaldÄ±rabilir miyiz?

#### 2.7 Veri Kalitesi

[Veri Kalitesi](https://lakefs.io/data-quality-testing/), algoritmalarÄ±mÄ±zÄ± geliÅŸtirmek iÃ§in kullanÄ±lan dÃ¼zenlenmiÅŸ veri setinin geÃ§erliliÄŸine bakar ve Ã¶zelliklerin ve kayÄ±tlarÄ±n yapay zeka amacÄ±mÄ±z iÃ§in gereken doÄŸruluk ve tutarlÄ±lÄ±k dÃ¼zeyini karÅŸÄ±layÄ±p karÅŸÄ±lamadÄ±ÄŸÄ±nÄ± kontrol eder.

Burada keÅŸfedilecek sorular:
 * KullanÄ±m senaryomuz iÃ§in geÃ§erli _Ã¶zellikler_ yakaladÄ±k mÄ±?
 * Ã‡eÅŸitli veri kaynaklarÄ± arasÄ±nda veri _tutarlÄ±_ bir ÅŸekilde mi toplandÄ±?
 * Veri seti, Ã§eÅŸitli koÅŸullar veya senaryolar iÃ§in _tam_ mÄ±?
* Bilgiler _gerÃ§ekliÄŸi doÄŸru bir ÅŸekilde_ yansÄ±tÄ±yor mu?

#### 2.8 Algoritma Adaleti

[Algoritma Adaleti](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f), algoritma tasarÄ±mÄ±nÄ±n belirli veri gruplarÄ±na sistematik olarak ayrÄ±mcÄ±lÄ±k yapÄ±p yapmadÄ±ÄŸÄ±nÄ± ve bunun sonucunda _kaynak tahsisi_ (kaynaklarÄ±n o gruptan esirgenmesi veya geri Ã§ekilmesi) ve _hizmet kalitesi_ (AI'nin bazÄ± gruplar iÃ§in diÄŸerlerine gÃ¶re daha az doÄŸru olmasÄ±) gibi [potansiyel zararlar](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) oluÅŸturup oluÅŸturmadÄ±ÄŸÄ±nÄ± kontrol eder.

Burada sorulmasÄ± gereken sorular ÅŸunlardÄ±r:
* Model doÄŸruluÄŸunu farklÄ± gruplar ve koÅŸullar iÃ§in deÄŸerlendirdik mi?
* Sistemi potansiyel zararlar (Ã¶rneÄŸin, stereotipleme) aÃ§Ä±sÄ±ndan inceledik mi?
* Belirlenen zararlarÄ± azaltmak iÃ§in verileri revize edebilir veya modelleri yeniden eÄŸitebilir miyiz?

Daha fazla bilgi edinmek iÃ§in [AI Adalet kontrol listeleri](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) gibi kaynaklarÄ± inceleyin.

#### 2.9 YanÄ±ltÄ±cÄ± Bilgi

[Veri YanÄ±ltÄ±cÄ±lÄ±ÄŸÄ±](https://www.sciencedirect.com/topics/computer-science/misrepresentation), dÃ¼rÃ¼stÃ§e raporlanmÄ±ÅŸ verilerden elde edilen iÃ§gÃ¶rÃ¼lerin, istenen bir anlatÄ±yÄ± desteklemek iÃ§in aldatÄ±cÄ± bir ÅŸekilde iletilip iletilmediÄŸini sorgular.

Burada sorulmasÄ± gereken sorular ÅŸunlardÄ±r:
* Eksik veya yanlÄ±ÅŸ verileri mi raporluyoruz?
* Verileri yanÄ±ltÄ±cÄ± sonuÃ§lar Ã§Ä±karacak ÅŸekilde mi gÃ¶rselleÅŸtiriyoruz?
* SonuÃ§larÄ± manipÃ¼le etmek iÃ§in seÃ§ici istatistiksel teknikler mi kullanÄ±yoruz?
* FarklÄ± bir sonuca yol aÃ§abilecek alternatif aÃ§Ä±klamalar var mÄ±?

#### 2.10 Ã–zgÃ¼r SeÃ§im

[Ã–zgÃ¼r SeÃ§im Ä°llÃ¼zyonu](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice), sistem "seÃ§im mimarilerinin" insanlarÄ± tercih edilen bir sonuca yÃ¶nlendirmek iÃ§in karar verme algoritmalarÄ±nÄ± kullanÄ±rken onlara seÃ§enek ve kontrol sunuyormuÅŸ gibi gÃ¶rÃ¼nmesi durumunda ortaya Ã§Ä±kar. Bu [karanlÄ±k desenler](https://www.darkpatterns.org/) kullanÄ±cÄ±lar iÃ§in sosyal ve ekonomik zararlara yol aÃ§abilir. KullanÄ±cÄ± kararlarÄ± davranÄ±ÅŸ profillerini etkilediÄŸinden, bu eylemler gelecekteki seÃ§imleri yÃ¶nlendirebilir ve bu zararlarÄ±n etkisini artÄ±rabilir veya geniÅŸletebilir.

Burada sorulmasÄ± gereken sorular ÅŸunlardÄ±r:
* KullanÄ±cÄ±, o seÃ§imi yapmanÄ±n sonuÃ§larÄ±nÄ± anladÄ± mÄ±?
* KullanÄ±cÄ±, (alternatif) seÃ§eneklerin ve her birinin artÄ±larÄ± ve eksilerinin farkÄ±nda mÄ±ydÄ±?
* KullanÄ±cÄ±, otomatik veya etkilenmiÅŸ bir seÃ§imi daha sonra geri alabilir mi?

### 3. Vaka Ã‡alÄ±ÅŸmalarÄ±

Bu etik zorluklarÄ± gerÃ§ek dÃ¼nya baÄŸlamlarÄ±nda ele almak iÃ§in, bu tÃ¼r etik ihlallerin gÃ¶z ardÄ± edildiÄŸinde bireyler ve toplum Ã¼zerindeki potansiyel zararlarÄ± ve sonuÃ§larÄ±nÄ± vurgulayan vaka Ã§alÄ±ÅŸmalarÄ±na bakmak faydalÄ± olur.

Ä°ÅŸte birkaÃ§ Ã¶rnek:

| Etik Zorluk | Vaka Ã‡alÄ±ÅŸmasÄ± | 
|--- |--- |
| **BilgilendirilmiÅŸ Onay** | 1972 - [Tuskegee Frengi Ã‡alÄ±ÅŸmasÄ±](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - Ã‡alÄ±ÅŸmaya katÄ±lan AfrikalÄ± AmerikalÄ± erkeklere Ã¼cretsiz tÄ±bbi bakÄ±m vaat edildi, ancak araÅŸtÄ±rmacÄ±lar teÅŸhislerini veya tedavi seÃ§eneklerini aÃ§Ä±klamayarak onlarÄ± _aldattÄ±_. BirÃ§ok katÄ±lÄ±mcÄ± Ã¶ldÃ¼ ve eÅŸleri veya Ã§ocuklarÄ± etkilendi; Ã§alÄ±ÅŸma 40 yÄ±l sÃ¼rdÃ¼. | 
| **Veri GizliliÄŸi** | 2007 - [Netflix veri Ã¶dÃ¼lÃ¼](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) araÅŸtÄ±rmacÄ±lara _50K mÃ¼ÅŸteriden 10M anonimleÅŸtirilmiÅŸ film derecelendirmesi_ saÄŸladÄ±. Ancak, araÅŸtÄ±rmacÄ±lar anonimleÅŸtirilmiÅŸ verileri _harici veri setlerindeki_ (Ã¶rneÄŸin, IMDb yorumlarÄ±) kiÅŸisel olarak tanÄ±mlanabilir verilerle iliÅŸkilendirebildi - bazÄ± Netflix abonelerini "de-anonimleÅŸtirdi".|
| **Toplama YanlÄ±lÄ±ÄŸÄ±** | 2013 - Boston Åehri [Street Bump uygulamasÄ±nÄ± geliÅŸtirdi](https://www.boston.gov/transportation/street-bump), vatandaÅŸlarÄ±n Ã§ukurlarÄ± bildirmesine olanak tanÄ±yarak ÅŸehre yol sorunlarÄ±nÄ± bulmak ve dÃ¼zeltmek iÃ§in daha iyi veriler saÄŸladÄ±. Ancak, [dÃ¼ÅŸÃ¼k gelir gruplarÄ±ndaki insanlarÄ±n araba ve telefon eriÅŸimi daha azdÄ±](https://hbr.org/2013/04/the-hidden-biases-in-big-data), bu da onlarÄ±n yol sorunlarÄ±nÄ± bu uygulamada gÃ¶rÃ¼nmez hale getirdi. GeliÅŸtiriciler, adalet iÃ§in _eÅŸit eriÅŸim ve dijital bÃ¶lÃ¼nmeler_ sorunlarÄ± Ã¼zerinde akademisyenlerle Ã§alÄ±ÅŸtÄ±. |
| **Algoritmik Adalet** | 2018 - MIT [Gender Shades Ã‡alÄ±ÅŸmasÄ±](http://gendershades.org/overview.html), cinsiyet sÄ±nÄ±flandÄ±rma AI Ã¼rÃ¼nlerinin doÄŸruluÄŸunu deÄŸerlendirdi ve kadÄ±nlar ve renkli kiÅŸiler iÃ§in doÄŸrulukta boÅŸluklar olduÄŸunu ortaya Ã§Ä±kardÄ±. Bir [2019 Apple Card](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) kadÄ±nlara erkeklere gÃ¶re daha az kredi sunmuÅŸ gibi gÃ¶rÃ¼ndÃ¼. Her ikisi de algoritmik yanlÄ±lÄ±ÄŸÄ±n sosyo-ekonomik zararlara yol aÃ§tÄ±ÄŸÄ±nÄ± gÃ¶sterdi.|
| **Veri YanÄ±ltÄ±cÄ±lÄ±ÄŸÄ±** | 2020 - [Georgia Halk SaÄŸlÄ±ÄŸÄ± DepartmanÄ± COVID-19 grafiklerini](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) yayÄ±nladÄ± ve x ekseninde kronolojik olmayan sÄ±ralama ile vatandaÅŸlarÄ± doÄŸrulanmÄ±ÅŸ vakalardaki eÄŸilimler hakkÄ±nda yanÄ±ltmÄ±ÅŸ gibi gÃ¶rÃ¼ndÃ¼. Bu, gÃ¶rselleÅŸtirme hileleriyle yanÄ±ltmayÄ± gÃ¶sterir. |
| **Ã–zgÃ¼r SeÃ§im Ä°llÃ¼zyonu** | 2020 - Ã–ÄŸrenme uygulamasÄ± [ABCmouse, FTC ÅŸikayetini Ã§Ã¶zmek iÃ§in 10M$ Ã¶dedi](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/) ve ebeveynlerin iptal edemedikleri abonelikler iÃ§in Ã¶deme yapmaya zorlandÄ±ÄŸÄ± bir durum ortaya Ã§Ä±ktÄ±. Bu, kullanÄ±cÄ±larÄ±n potansiyel olarak zararlÄ± seÃ§imlere yÃ¶nlendirildiÄŸi seÃ§im mimarilerindeki karanlÄ±k desenleri gÃ¶sterir. |
| **Veri GizliliÄŸi ve KullanÄ±cÄ± HaklarÄ±** | 2021 - Facebook [Veri Ä°hlali](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) 530M kullanÄ±cÄ±nÄ±n verilerini ifÅŸa etti ve FTC'ye 5B$ Ã¶deme yaptÄ±. Ancak, ihlal hakkÄ±nda kullanÄ±cÄ±larÄ± bilgilendirmeyi reddetti ve veri ÅŸeffaflÄ±ÄŸÄ± ve eriÅŸimi ile ilgili kullanÄ±cÄ± haklarÄ±nÄ± ihlal etti. |

Daha fazla vaka Ã§alÄ±ÅŸmasÄ± mÄ± incelemek istiyorsunuz? Bu kaynaklara gÃ¶z atÄ±n:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - Ã§eÅŸitli endÃ¼strilerde etik ikilemler.
* [Data Science Ethics kursu](https://www.coursera.org/learn/data-science-ethics#syllabus) - Ã¶nemli vaka Ã§alÄ±ÅŸmalarÄ± inceleniyor.
* [Nerede yanlÄ±ÅŸ yapÄ±ldÄ±](https://deon.drivendata.org/examples/) - deon kontrol listesi ve Ã¶rnekler.

> ğŸš¨ GÃ¶rdÃ¼ÄŸÃ¼nÃ¼z vaka Ã§alÄ±ÅŸmalarÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼n - hayatÄ±nÄ±zda benzer bir etik zorlukla karÅŸÄ±laÅŸtÄ±nÄ±z mÄ± veya etkilendiniz mi? Bu bÃ¶lÃ¼mde tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z etik zorluklardan birini gÃ¶steren en az bir baÅŸka vaka Ã§alÄ±ÅŸmasÄ± dÃ¼ÅŸÃ¼nebilir misiniz?

## UygulamalÄ± Etik

Etik kavramlarÄ±, zorluklarÄ± ve gerÃ§ek dÃ¼nya baÄŸlamlarÄ±nda vaka Ã§alÄ±ÅŸmalarÄ±nÄ± ele aldÄ±k. Peki projelerimizde etik ilkeleri ve uygulamalarÄ± _uygulamaya_ nasÄ±l baÅŸlayabiliriz? Ve bu uygulamalarÄ± daha iyi yÃ¶netim iÃ§in nasÄ±l _operasyonelleÅŸtirebiliriz_? GerÃ§ek dÃ¼nya Ã§Ã¶zÃ¼mlerini inceleyelim:

### 1. Mesleki Kodlar

Mesleki Kodlar, kuruluÅŸlarÄ±n etik ilkelerini ve misyon bildirimlerini desteklemek iÃ§in Ã¼yelerini "teÅŸvik etmesi" iÃ§in bir seÃ§enek sunar. Kodlar, profesyonel davranÄ±ÅŸ iÃ§in _ahlaki yÃ¶nergeler_ olup, Ã§alÄ±ÅŸanlarÄ±n veya Ã¼yelerin kuruluÅŸlarÄ±nÄ±n ilkelerine uygun kararlar almasÄ±na yardÄ±mcÄ± olur. Ãœyelerin gÃ¶nÃ¼llÃ¼ uyumu kadar iyidirler; ancak birÃ§ok kuruluÅŸ, Ã¼yelerin uyumunu teÅŸvik etmek iÃ§in ek Ã¶dÃ¼ller ve cezalar sunar.

Ã–rnekler:
* [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Etik KodlarÄ±
* [Data Science Association](http://datascienceassn.org/code-of-conduct.html) DavranÄ±ÅŸ KurallarÄ± (2013'te oluÅŸturuldu)
* [ACM Etik ve Profesyonel DavranÄ±ÅŸ KurallarÄ±](https://www.acm.org/code-of-ethics) (1993'ten beri)

> ğŸš¨ Bir profesyonel mÃ¼hendislik veya veri bilimi organizasyonuna Ã¼ye misiniz? Web sitelerini inceleyerek bir mesleki etik kodu tanÄ±mlayÄ±p tanÄ±mlamadÄ±klarÄ±nÄ± Ã¶ÄŸrenin. Bu, etik ilkeleri hakkÄ±nda ne sÃ¶ylÃ¼yor? Ãœyeleri kodu takip etmeye nasÄ±l "teÅŸvik ediyorlar"?

### 2. Etik Kontrol Listeleri

Mesleki kodlar, uygulayÄ±cÄ±lardan beklenen _etik davranÄ±ÅŸÄ±_ tanÄ±mlarken, [bilinen sÄ±nÄ±rlamalarÄ±](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) vardÄ±r, Ã¶zellikle bÃ¼yÃ¼k Ã¶lÃ§ekli projelerde. Bunun yerine, birÃ§ok veri bilimi uzmanÄ± [kontrol listelerini](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) savunur, bu da **ilkeleri uygulamalara** daha belirleyici ve uygulanabilir yollarla baÄŸlayabilir.

Kontrol listeleri, sorularÄ± "evet/hayÄ±r" gÃ¶revlerine dÃ¶nÃ¼ÅŸtÃ¼rerek operasyonelleÅŸtirilebilir ve standart Ã¼rÃ¼n sÃ¼rÃ¼m iÅŸ akÄ±ÅŸlarÄ±nÄ±n bir parÃ§asÄ± olarak izlenebilir hale getirir.

Ã–rnekler:
* [Deon](https://deon.drivendata.org/) - [endÃ¼stri Ã¶nerilerinden](https://deon.drivendata.org/#checklist-citations) oluÅŸturulmuÅŸ genel amaÃ§lÄ± bir veri etik kontrol listesi ve kolay entegrasyon iÃ§in bir komut satÄ±rÄ± aracÄ±.
* [Gizlilik Denetim Kontrol Listesi](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - yasal ve sosyal maruz kalma perspektiflerinden bilgi iÅŸleme uygulamalarÄ± iÃ§in genel rehberlik saÄŸlar.
* [AI Adalet Kontrol Listesi](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - AI geliÅŸtirme dÃ¶ngÃ¼lerine adalet kontrollerinin benimsenmesini ve entegrasyonunu desteklemek iÃ§in AI uygulayÄ±cÄ±larÄ± tarafÄ±ndan oluÅŸturulmuÅŸtur.
* [Veri ve AI'da etik iÃ§in 22 soru](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - tasarÄ±m, uygulama ve organizasyonel baÄŸlamlarda etik sorunlarÄ±n ilk keÅŸfi iÃ§in yapÄ±landÄ±rÄ±lmÄ±ÅŸ daha aÃ§Ä±k uÃ§lu bir Ã§erÃ§eve.

### 3. Etik DÃ¼zenlemeler

Etik, ortak deÄŸerleri tanÄ±mlamak ve _gÃ¶nÃ¼llÃ¼ olarak_ doÄŸru olanÄ± yapmakla ilgilidir. **Uyum**, tanÄ±mlanmÄ±ÅŸsa ve nerede tanÄ±mlanmÄ±ÅŸsa _yasalara uymak_ ile ilgilidir. **YÃ¶netim**, kuruluÅŸlarÄ±n etik ilkeleri uygulamak ve belirlenmiÅŸ yasalara uymak iÃ§in Ã§alÄ±ÅŸtÄ±ÄŸÄ± tÃ¼m yollarÄ± kapsar.

BugÃ¼n, yÃ¶netim kuruluÅŸlar iÃ§inde iki ÅŸekilde gerÃ§ekleÅŸir. Ä°lk olarak, **etik AI** ilkelerini tanÄ±mlamak ve kuruluÅŸ iÃ§indeki tÃ¼m AI ile ilgili projelerde benimsenmeyi operasyonelleÅŸtirmekle ilgilidir. Ä°kincisi, faaliyet gÃ¶sterdiÄŸi bÃ¶lgeler iÃ§in tÃ¼m hÃ¼kÃ¼met tarafÄ±ndan belirlenmiÅŸ **veri koruma dÃ¼zenlemelerine** uymakla ilgilidir.

Veri koruma ve gizlilik dÃ¼zenlemeleri Ã¶rnekleri:
* `1974`, [ABD Gizlilik YasasÄ±](https://www.justice.gov/opcl/privacy-act-1974) - _federal hÃ¼kÃ¼metin_ kiÅŸisel bilgileri toplamasÄ±nÄ±, kullanmasÄ±nÄ± ve ifÅŸa etmesini dÃ¼zenler.
* `1996`, [ABD SaÄŸlÄ±k SigortasÄ± TaÅŸÄ±nabilirlik ve Hesap Verebilirlik YasasÄ± (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - kiÅŸisel saÄŸlÄ±k verilerini korur.
* `1998`, [ABD Ã‡ocuklarÄ±n Ã‡evrimiÃ§i GizliliÄŸini Koruma YasasÄ± (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - 13 yaÅŸ altÄ±ndaki Ã§ocuklarÄ±n veri gizliliÄŸini korur.
* `2018`, [Genel Veri Koruma YÃ¶netmeliÄŸi (GDPR)](https://gdpr-info.eu/) - kullanÄ±cÄ± haklarÄ±, veri koruma ve gizlilik saÄŸlar.
* `2018`, [California TÃ¼ketici GizliliÄŸi YasasÄ± (CCPA)](https://www.oag.ca.gov/privacy/ccpa) tÃ¼keticilere (kiÅŸisel) verileri Ã¼zerinde daha fazla _hak_ verir.
* `2021`, Ã‡in'in [KiÅŸisel Bilgi Koruma YasasÄ±](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) yeni geÃ§ti ve dÃ¼nya Ã§apÄ±nda en gÃ¼Ã§lÃ¼ Ã§evrimiÃ§i veri gizliliÄŸi dÃ¼zenlemelerinden birini oluÅŸturdu.

> ğŸš¨ Avrupa BirliÄŸi tarafÄ±ndan tanÄ±mlanan GDPR (Genel Veri Koruma YÃ¶netmeliÄŸi), bugÃ¼n en etkili veri gizliliÄŸi dÃ¼zenlemelerinden biri olmaya devam ediyor. AyrÄ±ca vatandaÅŸlarÄ±n dijital gizliliÄŸini ve kiÅŸisel verilerini korumak iÃ§in [8 kullanÄ±cÄ± hakkÄ±](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) tanÄ±mladÄ±ÄŸÄ±nÄ± biliyor muydunuz? BunlarÄ±n ne olduÄŸunu ve neden Ã¶nemli olduklarÄ±nÄ± Ã¶ÄŸrenin.

### 4. Etik KÃ¼ltÃ¼rÃ¼

Uyum (yasanÄ±n "harfini" yerine getirmek iÃ§in yeterince yapmak) ile [sistemik sorunlarÄ±](https://www.coursera.org/learn/data-science-ethics/home/week/4) ele almak (Ã¶rneÄŸin, katÄ±laÅŸma, bilgi asimetrisi ve daÄŸÄ±tÄ±msal adaletsizlik) arasÄ±nda hala elle tutulamayan bir boÅŸluk olduÄŸunu unutmayÄ±n. 

Ä°kincisi, [etik kÃ¼ltÃ¼rleri tanÄ±mlamak iÃ§in iÅŸbirlikÃ§i yaklaÅŸÄ±mlar](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f) gerektirir ve bu, endÃ¼stride _kuruluÅŸlar arasÄ±nda_ duygusal baÄŸlar ve tutarlÄ± ortak deÄŸerler oluÅŸturur. Bu, kuruluÅŸlarda daha [resmileÅŸtirilmiÅŸ veri etik kÃ¼ltÃ¼rleri](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) Ã§aÄŸrÄ±sÄ± yapar - _herkesin_ (sÃ¼recin erken aÅŸamalarÄ±nda etik endiÅŸeleri dile getirmek iÃ§in) [Andon ipini Ã§ekmesine](https://en.wikipedia.org/wiki/Andon_(manufacturing)) olanak tanÄ±r ve AI projelerinde ekip oluÅŸturma iÃ§in _etik deÄŸerlendirmeleri_ (Ã¶rneÄŸin, iÅŸe alÄ±mda) temel bir kriter haline getirir.

---
## [Ders sonrasÄ± test](https://ff-quizzes.netlify.app/en/ds/quiz/3) ğŸ¯
## GÃ¶zden GeÃ§irme ve Kendi Kendine Ã‡alÄ±ÅŸma

Kurslar ve kitaplar, temel etik kavramlarÄ±nÄ± ve zorluklarÄ±nÄ± anlamaya yardÄ±mcÄ± olurken, vaka Ã§alÄ±ÅŸmalarÄ± ve araÃ§lar gerÃ§ek dÃ¼nya baÄŸlamlarÄ±nda uygulamalÄ± etik uygulamalarÄ±na yardÄ±mcÄ± olur. Ä°ÅŸte baÅŸlamak iÃ§in birkaÃ§ kaynak.
* [Makine Ã–ÄŸrenimi iÃ§in BaÅŸlangÄ±Ã§ Rehberi](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - Microsoft'tan Adalet Ã¼zerine bir ders.
* [Sorumlu Yapay Zeka Ä°lkeleri](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - Microsoft Learn'den Ã¼cretsiz bir Ã¶ÄŸrenim yolu.
* [Etik ve Veri Bilimi](https://resources.oreilly.com/examples/0636920203964) - O'Reilly EKitabÄ± (M. Loukides, H. Mason ve diÄŸerleri)
* [Veri Bilimi EtiÄŸi](https://www.coursera.org/learn/data-science-ethics#syllabus) - Michigan Ãœniversitesi'nden Ã§evrimiÃ§i bir kurs.
* [Etik AÃ§Ä±klanÄ±yor](https://ethicsunwrapped.utexas.edu/case-studies) - Teksas Ãœniversitesi'nden vaka Ã§alÄ±ÅŸmalarÄ±.

# Ã–dev 

[Bir Veri EtiÄŸi Vaka Ã‡alÄ±ÅŸmasÄ± YazÄ±n](assignment.md)

---

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluÄŸu saÄŸlamak iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalar iÃ§in sorumluluk kabul edilmemektedir.