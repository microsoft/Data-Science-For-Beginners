{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inleiding tot Kansrekening en Statistiek\n",
    "In dit notitieboek gaan we experimenteren met enkele van de concepten die we eerder hebben besproken. Veel concepten uit de kansrekening en statistiek zijn goed vertegenwoordigd in belangrijke bibliotheken voor gegevensverwerking in Python, zoals `numpy` en `pandas`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Willekeurige variabelen en verdelingen\n",
    "Laten we beginnen met het trekken van een steekproef van 30 waarden uit een uniforme verdeling van 0 tot 9. We zullen ook het gemiddelde en de variantie berekenen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [ random.randint(0,10) for _ in range(30) ]\n",
    "print(f\"Sample: {sample}\")\n",
    "print(f\"Mean = {np.mean(sample)}\")\n",
    "print(f\"Variance = {np.var(sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om visueel in te schatten hoeveel verschillende waarden er in de steekproef zijn, kunnen we de **histogram** plotten:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyseren van echte gegevens\n",
    "\n",
    "Gemiddelde en variantie zijn zeer belangrijk bij het analyseren van gegevens uit de echte wereld. Laten we de gegevens over honkbalspelers laden van [SOCR MLB Height/Weight Data](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/SOCR_MLB.tsv\",sep='\\t', header=None, names=['Name','Team','Role','Weight','Height','Age'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We gebruiken hier een package genaamd [**Pandas**](https://pandas.pydata.org/) voor data-analyse. We zullen later in deze cursus meer praten over Pandas en werken met data in Python.\n",
    "\n",
    "Laten we gemiddelde waarden berekenen voor leeftijd, lengte en gewicht:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Age','Height','Weight']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laten we ons nu richten op de lengte, en standaarddeviatie en variantie berekenen:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df['Height'])[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df['Height'].mean()\n",
    "var = df['Height'].var()\n",
    "std = df['Height'].std()\n",
    "print(f\"Mean = {mean}\\nVariance = {var}\\nStandard Deviation = {std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naast het gemiddelde is het zinvol om ook naar de mediaan en kwartielen te kijken. Deze kunnen worden weergegeven met een **boxplot**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2))\n",
    "plt.boxplot(df['Height'].ffill(), vert=False, showmeans=True)\n",
    "plt.grid(color='gray', linestyle='dotted')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kunnen ook doosdiagrammen maken van subsets van onze dataset, bijvoorbeeld gegroepeerd op spelersrol.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='Height', by='Role', figsize=(10,8))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Opmerking**: Dit diagram suggereert dat gemiddeld de lengtes van eerst base-spelers hoger zijn dan de lengtes van tweede base-spelers. Later zullen we leren hoe we deze hypothese formeler kunnen testen en hoe we kunnen aantonen dat onze gegevens statistisch significant zijn om dit te laten zien.  \n",
    "\n",
    "Leeftijd, lengte en gewicht zijn allemaal continue stochastische variabelen. Wat denk je dat hun verdeling is? Een goede manier om dat te achterhalen is het plotten van het histogram van de waarden: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weight'].hist(bins=15, figsize=(10,6))\n",
    "plt.suptitle('Weight distribution of MLB Players')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normale Verdeling\n",
    "\n",
    "Laten we een kunstmatige steekproef van gewichten maken die een normale verdeling volgt met dezelfde gemiddelde en variantie als onze echte gegevens:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = np.random.normal(mean, std, 1000)\n",
    "generated[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(generated, bins=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(np.random.normal(0,1,50000), bins=300)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aangezien de meeste waarden in het echte leven normaal verdeeld zijn, zouden we geen uniforme willekeurige getallengenerator moeten gebruiken om steekproefgegevens te genereren. Dit is wat er gebeurt als we proberen gewichten te genereren met een uniforme verdeling (gegenereerd door `np.random.rand`):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_sample = np.random.rand(1000)*2*std+mean-std\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(wrong_sample)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Betrouwbaarheidsintervallen\n",
    "\n",
    "Laten we nu betrouwbaarheidsintervallen berekenen voor het gewicht en de lengte van honkbalspelers. We zullen de code gebruiken [uit deze stackoverflow-discussie](https://stackoverflow.com/questions/15033511/compute-a-confidence-interval-from-sample-data):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, h\n",
    "\n",
    "for p in [0.85, 0.9, 0.95]:\n",
    "    m, h = mean_confidence_interval(df['Weight'].fillna(method='pad'),p)\n",
    "    print(f\"p={p:.2f}, mean = {m:.2f} ± {h:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesetoetsing\n",
    "\n",
    "Laten we verschillende posities in onze honkbalspelersdataset verkennen:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Role').agg({ 'Weight' : 'mean', 'Height' : 'mean', 'Age' : 'count'}).rename(columns={ 'Age' : 'Count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laten we de hypothese testen dat eerste honkmannen langer zijn dan tweede honkmannen. De eenvoudigste manier om dit te doen is door de betrouwbaarheidsintervallen te testen:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [0.85,0.9,0.95]:\n",
    "    m1, h1 = mean_confidence_interval(df.loc[df['Role']=='First_Baseman',['Height']],p)\n",
    "    m2, h2 = mean_confidence_interval(df.loc[df['Role']=='Second_Baseman',['Height']],p)\n",
    "    print(f'Conf={p:.2f}, 1st basemen height: {m1-h1[0]:.2f}..{m1+h1[0]:.2f}, 2nd basemen height: {m2-h2[0]:.2f}..{m2+h2[0]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kunnen zien dat de intervallen niet overlappen.\n",
    "\n",
    "Een statistisch correctere manier om de hypothese te bewijzen is het gebruik van een **Student t-toets**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Second_Baseman',['Height']],equal_var=False)\n",
    "print(f\"T-value = {tval[0]:.2f}\\nP-value: {pval[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De twee waarden die worden geretourneerd door de `ttest_ind` functie zijn:\n",
    "* p-waarde kan worden beschouwd als de waarschijnlijkheid dat twee verdelingen dezelfde gemiddelde waarde hebben. In ons geval is deze zeer laag, wat betekent dat er sterk bewijs is dat eerste honkverdedigers langer zijn.\n",
    "* t-waarde is de tussenliggende waarde van genormaliseerd verschil tussen gemiddelden die wordt gebruikt in de t-toets, en deze wordt vergeleken met een drempelwaarde voor een gegeven betrouwbaarheidswaarde.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Een normale verdeling simuleren met de centrale limietstelling\n",
    "\n",
    "De pseudowillekeurige generator in Python is ontworpen om ons een uniforme verdeling te geven. Als we een generator voor een normale verdeling willen maken, kunnen we de centrale limietstelling gebruiken. Om een normaal verdeelde waarde te krijgen, berekenen we gewoon het gemiddelde van een uniform gegenereerde steekproef.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_random(sample_size=100):\n",
    "    sample = [random.uniform(0,1) for _ in range(sample_size) ]\n",
    "    return sum(sample)/sample_size\n",
    "\n",
    "sample = [normal_random() for _ in range(100)]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(sample)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlatie en Evil Baseball Corp\n",
    "\n",
    "Correlatie stelt ons in staat relaties tussen datareeksen te vinden. In ons voorbeeld met speelgoed doen we alsof er een boosaardige honkbalmaatschappij is die haar spelers betaalt op basis van hun lengte - hoe langer de speler is, hoe meer geld hij/zij krijgt. Stel dat er een basissalaris van $1000 is, en een extra bonus van $0 tot $100, afhankelijk van de lengte. We nemen de echte spelers van de MLB en berekenen hun denkbeeldige salarissen:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = df['Height'].fillna(method='pad')\n",
    "salaries = 1000+(heights-heights.min())/(heights.max()-heights.mean())*100\n",
    "print(list(zip(heights, salaries))[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laten we nu de covariantie en correlatie van die reeksen berekenen. `np.cov` geeft ons een zogenaamde **covariantiematrix**, wat een uitbreiding is van covariantie naar meerdere variabelen. Het element $M_{ij}$ van de covariantiematrix $M$ is een correlatie tussen invoervariabelen $X_i$ en $X_j$, en diagonale waarden $M_{ii}$ zijn de variantie van $X_{i}$. Op dezelfde manier geeft `np.corrcoef` ons de **correlatiematrix**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Covariance matrix:\\n{np.cov(heights, salaries)}\")\n",
    "print(f\"Covariance = {np.cov(heights, salaries)[0,1]}\")\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een correlatie gelijk aan 1 betekent dat er een sterke **lineaire relatie** is tussen twee variabelen. We kunnen de lineaire relatie visueel zien door de ene waarde uit te zetten tegen de andere:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(heights,salaries)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laten we eens kijken wat er gebeurt als de relatie niet lineair is. Stel dat ons bedrijf heeft besloten de voor de hand liggende lineaire afhankelijkheid tussen lengtes en salarissen te verbergen, en wat niet-lineariteit in de formule heeft geïntroduceerd, zoals `sin`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = 1000+np.sin((heights-heights.min())/(heights.max()-heights.mean()))*100\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dit geval is de correlatie iets kleiner, maar nog steeds behoorlijk hoog. Nu, om de relatie nog minder duidelijk te maken, willen we misschien wat extra willekeur toevoegen door een willekeurige variabele aan het salaris toe te voegen. Laten we eens kijken wat er gebeurt:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = 1000+np.sin((heights-heights.min())/(heights.max()-heights.mean()))*100+np.random.random(size=len(heights))*20-10\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(heights, salaries)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Kun je raden waarom de stippen zo recht onder elkaar komen te staan in verticale lijnen?\n",
    "\n",
    "We hebben de correlatie waargenomen tussen een kunstmatig geconstrueerd concept zoals salaris en de waargenomen variabele *lengte*. Laten we ook kijken of de twee waargenomen variabelen, zoals lengte en gewicht, ook correleren:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df['Height'].ffill(),df['Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helaas hebben we geen resultaten gekregen - alleen enkele vreemde `nan` waarden. Dit komt doordat sommige van de waarden in onze reeks niet gedefinieerd zijn, weergegeven als `nan`, wat ertoe leidt dat het resultaat van de bewerking ook niet gedefinieerd is. Door naar de matrix te kijken, zien we dat `Weight` de problematische kolom is, omdat zelfcorrelatie tussen `Height` waarden is berekend.\n",
    "\n",
    "> Dit voorbeeld toont het belang aan van **gegevensvoorbereiding** en **schoonmaak**. Zonder juiste gegevens kunnen we niets berekenen.\n",
    "\n",
    "Laten we de methode `fillna` gebruiken om de ontbrekende waarden in te vullen, en de correlatie berekenen: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df['Height'].fillna(method='pad'), df['Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er is inderdaad een correlatie, maar niet zo sterk als in ons kunstmatige voorbeeld. Inderdaad, als we naar de spreidingsdiagram van de ene waarde tegen de andere kijken, zou de relatie veel minder duidelijk zijn:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(df['Weight'],df['Height'])\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Height')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusie\n",
    "\n",
    "In dit notitieboek hebben we geleerd hoe we basisbewerkingen op gegevens kunnen uitvoeren om statistische functies te berekenen. We weten nu hoe we een degelijk apparaat van wiskunde en statistiek kunnen gebruiken om enkele hypotheses te bewijzen, en hoe we betrouwbaarheidsintervallen voor willekeurige variabelen kunnen berekenen op basis van een gegevensmonster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Disclaimer**:\nDit document is vertaald met behulp van de AI-vertalingsservice [Co-op Translator](https://github.com/Azure/co-op-translator). Hoewel we streven naar nauwkeurigheid, dient u er rekening mee te houden dat geautomatiseerde vertalingen fouten of onnauwkeurigheden kunnen bevatten. Het oorspronkelijke document in de oorspronkelijke taal moet als de gezaghebbende bron worden beschouwd. Voor belangrijke informatie wordt professionele menselijke vertaling aanbevolen. Wij zijn niet aansprakelijk voor eventuele misverstanden of verkeerd geïnterpreteerde informatie die voortvloeit uit het gebruik van deze vertaling.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86193a1ab0ba47eac1c69c1756090baa3b420b3eea7d4aafab8b85f8b312f0c5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "coopTranslator": {
   "original_hash": "0f899e3c5019f948e7c787b22f3b2304",
   "translation_date": "2026-01-16T16:42:54+00:00",
   "source_file": "1-Introduction/04-stats-and-probability/notebook.ipynb",
   "language_code": "nl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}