<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1341f6da63d434f5ba31b08ea951b02c",
  "translation_date": "2025-09-05T23:27:49+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "he"
}
-->
# מבוא לאתיקה של נתונים

|![ סקיצה מאת [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| אתיקה במדעי הנתונים - _סקיצה מאת [@nitya](https://twitter.com/nitya)_ |

---

כולנו אזרחים של נתונים החיים בעולם מבוסס נתונים.

מגמות השוק מראות שעד שנת 2022, אחת מתוך שלוש ארגונים גדולים תקנה ותמכור את הנתונים שלה דרך [שווקים ומרכזי מסחר](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/) מקוונים. בתור **מפתחי אפליקציות**, יהיה לנו קל וזול יותר לשלב תובנות מבוססות נתונים ואוטומציה מבוססת אלגוריתמים בחוויות היומיום של המשתמשים. אך ככל שהבינה המלאכותית הופכת לנפוצה, נצטרך גם להבין את הנזקים הפוטנציאליים הנגרמים מ[שימוש לרעה](https://www.youtube.com/watch?v=TQHs8SA1qpk) באלגוריתמים כאלה בקנה מידה רחב.

מגמות נוספות מצביעות על כך שניצור ונצרוך מעל [180 זטה-בייטים](https://www.statista.com/statistics/871513/worldwide-data-created/) של נתונים עד שנת 2025. בתור **מדעני נתונים**, זה מעניק לנו רמות חסרות תקדים של גישה לנתונים אישיים. המשמעות היא שנוכל לבנות פרופילים התנהגותיים של משתמשים ולהשפיע על קבלת ההחלטות בדרכים שיוצרות [אשליה של בחירה חופשית](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice), תוך כדי דחיפת המשתמשים לתוצאות שאנחנו מעדיפים. זה גם מעלה שאלות רחבות יותר על פרטיות נתונים והגנה על משתמשים.

אתיקה של נתונים היא כיום _מעקה בטיחות הכרחי_ למדעי הנתונים וההנדסה, המסייעת לנו למזער נזקים פוטנציאליים ותוצאות בלתי צפויות מפעולות מבוססות נתונים. [מעגל ההייפ של גרטנר עבור AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) מזהה מגמות רלוונטיות באתיקה דיגיטלית, AI אחראי, וממשל AI כגורמים מרכזיים למגמות רחבות יותר סביב _דמוקרטיזציה_ ו_תיעוש_ של AI.

![מעגל ההייפ של גרטנר עבור AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

בשיעור זה, נחקור את התחום המרתק של אתיקה של נתונים - החל ממושגים ואתגרים מרכזיים, דרך מחקרי מקרה ועד מושגים יישומיים כמו ממשל AI - המסייעים לבסס תרבות אתית בצוותים ובארגונים העובדים עם נתונים ו-AI.

## [שאלון לפני השיעור](https://ff-quizzes.netlify.app/en/ds/quiz/2) 🎯

## הגדרות בסיסיות

נתחיל בהבנת המונחים הבסיסיים.

המילה "אתיקה" מגיעה מהמילה היוונית ["ethikos"](https://en.wikipedia.org/wiki/Ethics) (ושורשה "ethos") שמשמעותה _אופי או טבע מוסרי_.

**אתיקה** עוסקת בערכים משותפים ועקרונות מוסריים שמנחים את ההתנהגות שלנו בחברה. אתיקה מבוססת לא על חוקים אלא על נורמות מקובלות של מה "נכון מול לא נכון". עם זאת, שיקולים אתיים יכולים להשפיע על יוזמות ממשל תאגידי ורגולציות ממשלתיות שיוצרות תמריצים נוספים לציות.

**אתיקה של נתונים** היא [ענף חדש של אתיקה](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1) שחוקר ומעריך בעיות מוסריות הקשורות ל_נתונים, אלגוריתמים ופרקטיקות נלוות_. כאן, **"נתונים"** מתמקדים בפעולות הקשורות ליצירה, רישום, אצירה, עיבוד, הפצה, שיתוף ושימוש; **"אלגוריתמים"** מתמקדים ב-AI, סוכנים, למידת מכונה ורובוטים; ו**"פרקטיקות"** מתמקדות בנושאים כמו חדשנות אחראית, תכנות, פריצה וקודי אתיקה.

**אתיקה יישומית** היא [יישום מעשי של שיקולים מוסריים](https://en.wikipedia.org/wiki/Applied_ethics). זהו תהליך של חקירה פעילה של סוגיות אתיות בהקשר של _פעולות, מוצרים ותהליכים בעולם האמיתי_, ולקיחת צעדים מתקנים כדי להבטיח שהם נשארים מיושרים עם הערכים האתיים שהוגדרו.

**תרבות אתית** עוסקת ב[_הפעלה_ של אתיקה יישומית](https://hbr.org/2019/05/how-to-design-an-ethical-organization) כדי להבטיח שהעקרונות והפרקטיקות האתיים שלנו יאומצו באופן עקבי וניתן להרחבה בכל רחבי הארגון. תרבויות אתיות מצליחות מגדירות עקרונות אתיים ברמת הארגון, מספקות תמריצים משמעותיים לציות, ומחזקות נורמות אתיות על ידי עידוד והגברת התנהגויות רצויות בכל רמות הארגון.

## מושגי אתיקה

בקטע זה נדון במושגים כמו **ערכים משותפים** (עקרונות) ו**אתגרים אתיים** (בעיות) באתיקה של נתונים - ונחקור **מחקרי מקרה** שיעזרו לכם להבין את המושגים הללו בהקשרים של העולם האמיתי.

### 1. עקרונות אתיים

כל אסטרטגיה של אתיקה של נתונים מתחילה בהגדרת _עקרונות אתיים_ - "ערכים משותפים" שמתארים התנהגויות מקובלות ומנחים פעולות תואמות בפרויקטים של נתונים ו-AI. ניתן להגדיר אותם ברמה אישית או צוותית. עם זאת, רוב הארגונים הגדולים מגדירים אותם בהצהרת משימה או מסגרת של _AI אתי_ ברמת הארגון, ומיישמים אותם באופן עקבי בכל הצוותים.

**דוגמה:** הצהרת המשימה של [AI אחראי](https://www.microsoft.com/en-us/ai/responsible-ai) של מיקרוסופט אומרת: _"אנחנו מחויבים לקידום AI המונע על ידי עקרונות אתיים שמעמידים את האנשים במרכז"_ - ומזהה 6 עקרונות אתיים במסגרת הבאה:

![AI אחראי במיקרוסופט](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

בואו נחקור בקצרה את העקרונות הללו. _שקיפות_ ו_אחריות_ הם ערכים יסודיים שעליהם נבנים עקרונות אחרים - אז נתחיל שם:

* [**אחריות**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) הופכת את העוסקים בתחום ל_אחראים_ על פעולותיהם בתחום הנתונים וה-AI, ועל הציות לעקרונות האתיים הללו.
* [**שקיפות**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) מבטיחה שפעולות הנתונים וה-AI יהיו _מובנות_ (ניתנות לפרשנות) למשתמשים, ומסבירה את ה"מה" וה"למה" מאחורי ההחלטות.
* [**הוגנות**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - מתמקדת בהבטחת AI שמתייחס _לכל האנשים_ באופן הוגן, תוך התמודדות עם הטיות חברתיות-טכניות מערכתיות או סמיות בנתונים ובמערכות.
* [**אמינות ובטיחות**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - מבטיחה ש-AI מתנהג _בעקביות_ עם ערכים מוגדרים, וממזערת נזקים פוטנציאליים או תוצאות בלתי צפויות.
* [**פרטיות ואבטחה**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - עוסקת בהבנת שושלת הנתונים ובמתן _הגנות על פרטיות נתונים_ למשתמשים.
* [**הכללה**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - עוסקת בתכנון פתרונות AI בכוונה, והתאמתם למגוון רחב של _צרכים ויכולות אנושיות_.

> 🚨 חשבו על מה יכולה להיות הצהרת המשימה של אתיקה של נתונים שלכם. חקרו מסגרות AI אתיות מארגונים אחרים - הנה דוגמאות מ-[IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles), ו-[Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). אילו ערכים משותפים יש להם במשותף? כיצד עקרונות אלה קשורים למוצרי AI או לתעשייה שבה הם פועלים?

### 2. אתגרים אתיים

לאחר שהגדרנו עקרונות אתיים, השלב הבא הוא להעריך את פעולות הנתונים וה-AI שלנו כדי לראות אם הן מתיישרות עם הערכים המשותפים הללו. חשבו על הפעולות שלכם בשתי קטגוריות: _איסוף נתונים_ ו_עיצוב אלגוריתמים_.

באיסוף נתונים, הפעולות יכללו ככל הנראה **נתונים אישיים** או מידע אישי מזהה (PII) עבור אנשים מזוהים. זה כולל [פריטים מגוונים של נתונים לא אישיים](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) שמזהים _ביחד_ אדם. אתגרים אתיים יכולים להיות קשורים ל_פרטיות נתונים_, _בעלות על נתונים_, ונושאים קשורים כמו _הסכמה מדעת_ ו_זכויות קניין רוחני_ של משתמשים.

בעיצוב אלגוריתמים, הפעולות יכללו איסוף ואצירה של **מאגרי נתונים**, ואז שימוש בהם לאימון ופריסה של **מודלים נתונים** שמנבאים תוצאות או מבצעים אוטומציה של החלטות בהקשרים של העולם האמיתי. אתגרים אתיים יכולים לנבוע מ_הטיות במאגרי נתונים_, _בעיות איכות נתונים_, _חוסר הוגנות_, ו_ייצוג שגוי_ באלגוריתמים - כולל כמה בעיות שהן מערכתיות בטבען.

בשני המקרים, אתגרים אתיים מדגישים אזורים שבהם הפעולות שלנו עשויות להתנגש עם הערכים המשותפים שלנו. כדי לזהות, למזער, למנוע או להסיר את החששות הללו - עלינו לשאול שאלות מוסריות "כן/לא" הקשורות לפעולות שלנו, ואז לנקוט צעדים מתקנים לפי הצורך. בואו נבחן כמה אתגרים אתיים והשאלות המוסריות שהם מעלים:

#### 2.1 בעלות על נתונים

איסוף נתונים כולל לעיתים קרובות נתונים אישיים שיכולים לזהות את נושאי הנתונים. [בעלות על נתונים](https://permission.io/blog/data-ownership) עוסקת ב_שליטה_ ו[זכויות משתמש](https://permission.io/blog/data-ownership) הקשורות ליצירה, עיבוד והפצה של נתונים.

השאלות המוסריות שעלינו לשאול הן:
* מי הבעלים של הנתונים? (משתמש או ארגון)
* אילו זכויות יש לנושאי הנתונים? (לדוגמה: גישה, מחיקה, ניידות)
* אילו זכויות יש לארגונים? (לדוגמה: תיקון ביקורות משתמשים מזיקות)

#### 2.2 הסכמה מדעת

[הסכמה מדעת](https://legaldictionary.net/informed-consent/) מגדירה את פעולת המשתמשים בהסכמה לפעולה (כמו איסוף נתונים) עם _הבנה מלאה_ של העובדות הרלוונטיות כולל המטרה, הסיכונים הפוטנציאליים והחלופות.

שאלות לחקור כאן הן:
* האם המשתמש (נושא הנתונים) נתן רשות ללכידת נתונים ושימוש בהם?
* האם המשתמש הבין את המטרה שלשמה הנתונים נלכדו?
* האם המשתמש הבין את הסיכונים הפוטנציאליים מהשתתפותו?

#### 2.3 קניין רוחני

[קניין רוחני](https://en.wikipedia.org/wiki/Intellectual_property) מתייחס ליצירות בלתי מוחשיות הנובעות מיוזמה אנושית, שעשויות _להיות בעלות ערך כלכלי_ לאנשים או עסקים.

שאלות לחקור כאן הן:
* האם הנתונים שנאספו היו בעלי ערך כלכלי למשתמש או לעסק?
* האם ל**משתמש** יש קניין רוחני כאן?
* האם ל**ארגון** יש קניין רוחני כאן?
* אם זכויות אלו קיימות, כיצד אנו מגנים עליהן?

#### 2.4 פרטיות נתונים

[פרטיות נתונים](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) או פרטיות מידע מתייחסת לשימור פרטיות המשתמש והגנה על זהותו ביחס למידע אישי מזהה.

שאלות לחקור כאן הן:
* האם הנתונים האישיים של המשתמשים מאובטחים מפני פריצות ודליפות?
* האם הנתונים של המשתמשים נגישים רק למשתמשים מורשים ולהקשרים מורשים?
* האם האנונימיות של המשתמשים נשמרת כאשר הנתונים משותפים או מופצים?
* האם ניתן להסיר זיהוי של משתמש ממאגרי נתונים אנונימיים?

#### 2.5 הזכות להישכח

[הזכות להישכח](https://en.wikipedia.org/wiki/Right_to_be_forgotten) או [הזכות למחיקה](https://www.gdpreu.org/right-to-be-forgotten/) מספקת הגנה נוספת על נתונים אישיים למשתמשים. באופן ספציפי, היא מעניקה למשתמשים את הזכות לבקש מחיקה או הסרה של נתונים אישיים מחיפושים באינטרנט וממקומות אחרים, _בתנאים מסוימים_ - ומאפשרת להם התחלה חדשה באינטרנט מבלי שפעולות עבר יעמדו נגדם.

שאלות לחקור כאן הן:
* האם המערכת מאפשרת לנושאי נתונים לבקש מחיקה?
* האם ביטול הסכמת המשתמש צריך להפעיל מחיקה אוטומטית?
* האם נתונים נאספו ללא הסכמה או באמצעים בלתי חוקיים?
* האם אנו עומדים בתקנות ממשלתיות לפרטיות נתונים?

#### 2.6 הטיות במאגרי נתונים

הטיות במאגרי נתונים או [הטיות באיסוף](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) עוסקות בבחירת תת-קבוצה _לא מייצגת_ של נתונים לפיתוח אלגוריתמים, מה שיוצר פוטנציאל לחוסר הוגנות בתוצאות עבור קבוצות מגוונות. סוגי הטיות כוללים הטיות בבחירה או דגימה, הטיות מתנדבים והטיות מכשירים.

שאלות לחקור כאן הן:
* האם גייסנו קבוצה מייצגת של נושאי נתונים?
* האם בדקנו את מאגר הנתונים שנאסף או נאצר עבור הטיות שונות?
* האם אנו יכולים למזער או להסיר הטיות שהתגלו?

#### 2.7 איכות נתונים

[איכות נתונים](https://lakefs.io/data-quality-testing/) בוחנת את תקפות מאגר הנתונים שנאצר לפיתוח האלגוריתמים שלנו, ובודקת אם התכונות והרשומות עומדות בדרישות לרמת דיוק ועקביות הנדרשת למטרת ה-AI שלנו.

שאלות לחקור כאן הן:
* האם לכדנו תכונות _תקפות_ למקרה השימוש שלנו?
* האם נתונים נלכדו _בעקביות_ ממקורות נתונים מגוונים?
* האם מאגר הנתונים _שלם_ עבור תנאים או תרחישים מגוונים?
* האם מידע שנלכד _מדויק_ ומשקף את המציאות?
[Algorithm Fairness](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) בודק האם עיצוב האלגוריתם מפלה באופן שיטתי נגד קבוצות מסוימות של נבדקים, מה שעלול להוביל ל[נזקים פוטנציאליים](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) בהקצאה (כאשר משאבים נשללים או נמנעים מקבוצה זו) ובאיכות השירות (כאשר הבינה המלאכותית אינה מדויקת באותה מידה עבור תת-קבוצות מסוימות כמו עבור אחרות).

שאלות שכדאי לבחון כאן:
 * האם הערכנו את דיוק המודל עבור תת-קבוצות ותנאים מגוונים?
 * האם בדקנו את המערכת לנזקים פוטנציאליים (למשל, סטריאוטיפים)?
 * האם ניתן לעדכן נתונים או לאמן מחדש מודלים כדי לצמצם נזקים שזוהו?

חקור משאבים כמו [AI Fairness checklists](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) כדי ללמוד עוד.

#### 2.9 הצגת נתונים מטעה

[הצגת נתונים מטעה](https://www.sciencedirect.com/topics/computer-science/misrepresentation) עוסקת בשאלה האם אנו מציגים תובנות מתוך נתונים מדווחים באופן כנה בצורה מטעה כדי לתמוך בנרטיב רצוי.

שאלות שכדאי לבחון כאן:
 * האם אנו מדווחים נתונים לא שלמים או לא מדויקים?
 * האם אנו מציגים נתונים בצורה שמובילה למסקנות מטעות?
 * האם אנו משתמשים בטכניקות סטטיסטיות סלקטיביות כדי לעוות תוצאות?
 * האם קיימות הסברים חלופיים שיכולים להוביל למסקנה שונה?

#### 2.10 אשליית הבחירה החופשית

[אשליית הבחירה החופשית](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) מתרחשת כאשר "ארכיטקטורות בחירה" של מערכת משתמשות באלגוריתמים לקבלת החלטות כדי להניע אנשים לבחור בתוצאה מועדפת, תוך יצירת רושם שהם מקבלים אפשרויות ושליטה. [דפוסים אפלים](https://www.darkpatterns.org/) אלו עלולים לגרום לנזקים חברתיים וכלכליים למשתמשים. מכיוון שהחלטות משתמשים משפיעות על פרופילי התנהגות, פעולות אלו עשויות להניע בחירות עתידיות ולהעצים או להרחיב את השפעת הנזקים.

שאלות שכדאי לבחון כאן:
 * האם המשתמש הבין את ההשלכות של הבחירה שעשה?
 * האם המשתמש היה מודע לאפשרויות (חלופיות) וליתרונות והחסרונות של כל אחת מהן?
 * האם המשתמש יכול לבטל בחירה אוטומטית או מושפעת מאוחר יותר?

### 3. מקרי בוחן

כדי לשים את האתגרים האתיים הללו בהקשרים של העולם האמיתי, כדאי לבחון מקרי בוחן המדגישים את הנזקים וההשלכות האפשריים על יחידים וחברה, כאשר מתעלמים מהפרות אתיות כאלה.

להלן מספר דוגמאות:

| אתגר אתי | מקרה בוחן | 
|--- |--- |
| **הסכמה מדעת** | 1972 - [מחקר העגבת בטסקיגי](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - גברים אפרו-אמריקאים שהשתתפו במחקר הובטחה להם טיפול רפואי חינם _אך הוטעו_ על ידי חוקרים שלא יידעו אותם על האבחנה שלהם או על זמינות הטיפול. רבים מהנבדקים מתו, ושותפים או ילדים נפגעו; המחקר נמשך 40 שנה. | 
| **פרטיות נתונים** | 2007 - [פרס הנתונים של נטפליקס](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) סיפק לחוקרים _10 מיליון דירוגי סרטים אנונימיים מ-50 אלף לקוחות_ כדי לשפר אלגוריתמי המלצה. עם זאת, חוקרים הצליחו לקשר נתונים אנונימיים לנתונים מזהים אישית ב_מאגרי נתונים חיצוניים_ (למשל, תגובות ב-IMDb) - ובכך "לחשוף" חלק ממנויי נטפליקס.|
| **הטיית איסוף נתונים** | 2013 - עיריית בוסטון [פיתחה את Street Bump](https://www.boston.gov/transportation/street-bump), אפליקציה שאפשרה לתושבים לדווח על בורות בכביש, מה שסיפק לעיר נתונים טובים יותר על מצב הדרכים. עם זאת, [לאנשים בקבוצות הכנסה נמוכה הייתה פחות גישה למכוניות וטלפונים](https://hbr.org/2013/04/the-hidden-biases-in-big-data), מה שהפך את הבעיות בדרכים שלהם לבלתי נראות באפליקציה זו. המפתחים עבדו עם אקדמאים כדי לטפל בבעיות של _נגישות שוויונית ופערים דיגיטליים_ למען הוגנות. |
| **הוגנות אלגוריתמית** | 2018 - [מחקר Gender Shades של MIT](http://gendershades.org/overview.html) העריך את דיוק מוצרי AI לסיווג מגדר, וחשף פערים בדיוק עבור נשים ואנשים בעלי צבע עור כהה. [כרטיס האשראי של אפל ב-2019](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) נראה שהציע פחות אשראי לנשים מאשר לגברים. שני המקרים הדגישו בעיות של הטיה אלגוריתמית שהובילה לנזקים חברתיים-כלכליים.|
| **הצגת נתונים מטעה** | 2020 - [מחלקת הבריאות של ג'ורג'יה פרסמה גרפים של מקרי COVID-19](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) שנראה כי הטעו אזרחים לגבי מגמות במקרי הקורונה המאומתים באמצעות סדר לא כרונולוגי בציר ה-x. זה מדגים הצגת נתונים מטעה באמצעות טריקים ויזואליים. |
| **אשליית הבחירה החופשית** | 2020 - אפליקציית הלמידה [ABCmouse שילמה 10 מיליון דולר כדי ליישב תלונה של ה-FTC](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/) שבה הורים נלכדו בתשלומים על מנויים שלא יכלו לבטל. זה מדגים דפוסים אפלים בארכיטקטורות בחירה, שבהן משתמשים הונעו לעבר בחירות שעלולות להזיק. |
| **פרטיות נתונים וזכויות משתמשים** | 2021 - [פרצת נתונים בפייסבוק](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) חשפה נתונים של 530 מיליון משתמשים, מה שהוביל להסדר של 5 מיליארד דולר עם ה-FTC. עם זאת, החברה סירבה להודיע למשתמשים על הפרצה, ובכך הפרה זכויות משתמשים בנוגע לשקיפות וגישה לנתונים. |

רוצה לחקור עוד מקרי בוחן? עיין במשאבים הבאים:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - דילמות אתיות בתעשיות מגוונות. 
* [קורס אתיקה במדעי הנתונים](https://www.coursera.org/learn/data-science-ethics#syllabus) - מקרי בוחן מרכזיים נידונים.
* [מקרים שבהם דברים השתבשו](https://deon.drivendata.org/examples/) - רשימת בדיקה של Deon עם דוגמאות.

> 🚨 חשוב על מקרי הבוחן שראית - האם חווית או הושפעת מאתגר אתי דומה בחייך? האם תוכל לחשוב על מקרה בוחן נוסף שממחיש אחד מהאתגרים האתיים שדנו בהם בסעיף זה?

## אתיקה יישומית

דיברנו על מושגי אתיקה, אתגרים ומקרי בוחן בהקשרים של העולם האמיתי. אבל איך מתחילים _ליישם_ עקרונות ואתיקה בפרויקטים שלנו? ואיך _מפעילים_ את העקרונות הללו למען ממשל טוב יותר? בואו נחקור כמה פתרונות מעשיים:

### 1. קודים מקצועיים

קודים מקצועיים מציעים אפשרות לארגונים "לתמרץ" חברים לתמוך בעקרונות האתיקה ובאמנת הארגון. קודים אלו הם _הנחיות מוסריות_ להתנהגות מקצועית, המסייעות לעובדים או חברים לקבל החלטות שמתיישרות עם עקרונות הארגון. הם טובים רק כמו הציות הוולונטרי של החברים; עם זאת, ארגונים רבים מציעים תגמולים ועונשים נוספים כדי להניע ציות.

דוגמאות כוללות:

 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) קוד אתיקה
 * [Data Science Association](http://datascienceassn.org/code-of-conduct.html) קוד התנהגות (נוצר ב-2013)
 * [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (מאז 1993)

> 🚨 האם אתה חבר בארגון מקצועי להנדסה או מדעי הנתונים? חקור את האתר שלהם כדי לראות אם הם מגדירים קוד אתיקה מקצועי. מה זה אומר על עקרונות האתיקה שלהם? איך הם "מתמרצים" חברים לציית לקוד?

### 2. רשימות בדיקה אתיות

בעוד שקודים מקצועיים מגדירים התנהגות אתית נדרשת, הם [מוגבלים באכיפה](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), במיוחד בפרויקטים רחבי היקף. במקום זאת, מומחים רבים במדעי הנתונים [תומכים ברשימות בדיקה](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), שיכולות **לחבר עקרונות לפרקטיקות** בדרכים דטרמיניסטיות וברות ביצוע.

רשימות בדיקה ממירות שאלות למשימות "כן/לא" שניתן להפעיל, ומאפשרות מעקב כחלק מזרימות עבודה סטנדרטיות לשחרור מוצרים.

דוגמאות כוללות:
 * [Deon](https://deon.drivendata.org/) - רשימת בדיקה כללית לאתיקה במדעי הנתונים שנוצרה מתוך [המלצות תעשייה](https://deon.drivendata.org/#checklist-citations) עם כלי שורת פקודה לשילוב קל.
 * [Privacy Audit Checklist](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - מספקת הנחיות כלליות לטיפול במידע מנקודות מבט משפטיות וחברתיות.
 * [AI Fairness Checklist](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - נוצרה על ידי מומחי AI לתמיכה באימוץ ובשילוב בדיקות הוגנות במחזורי פיתוח AI.
 * [22 שאלות לאתיקה בנתונים ובינה מלאכותית](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - מסגרת פתוחה יותר, מובנית לחקירה ראשונית של סוגיות אתיות בעיצוב, יישום והקשרים ארגוניים.

### 3. רגולציות אתיות

אתיקה עוסקת בהגדרת ערכים משותפים ועשיית הדבר הנכון _מרצון_. **ציות** עוסק ב_עמידה בחוק_ אם וכאשר הוא מוגדר. **ממשל** מכסה באופן רחב את כל הדרכים שבהן ארגונים פועלים כדי לאכוף עקרונות אתיים ולעמוד בחוקים שנקבעו.

כיום, ממשל לוקח שתי צורות בארגונים. ראשית, מדובר בהגדרת עקרונות **AI אתיים** וביסוס פרקטיקות להפעלת אימוץ בכל הפרויקטים הקשורים ל-AI בארגון. שנית, מדובר בעמידה בכל **תקנות הגנת נתונים** שממשלות מגדירות באזורים שבהם הארגון פועל.

דוגמאות לתקנות הגנת נתונים ופרטיות:
 
 * `1974`, [חוק הפרטיות האמריקאי](https://www.justice.gov/opcl/privacy-act-1974) - מסדיר את איסוף, שימוש וחשיפת מידע אישי על ידי _הממשלה הפדרלית_.
 * `1996`, [חוק הניידות והאחריות של ביטוח בריאות (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - מגן על נתוני בריאות אישיים.
 * `1998`, [חוק הגנת פרטיות ילדים באינטרנט (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - מגן על פרטיות נתונים של ילדים מתחת לגיל 13.
 * `2018`, [תקנת הגנת המידע הכללית (GDPR)](https://gdpr-info.eu/) - מספקת זכויות משתמש, הגנת נתונים ופרטיות.
 * `2018`, [חוק פרטיות הצרכן בקליפורניה (CCPA)](https://www.oag.ca.gov/privacy/ccpa) - מעניק לצרכנים יותר _זכויות_ על הנתונים האישיים שלהם.
 * `2021`, [חוק הגנת המידע האישי של סין](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) - יצר אחת מתקנות הפרטיות המקוונות החזקות ביותר בעולם.

> 🚨 תקנת GDPR (General Data Protection Regulation) שהוגדרה על ידי האיחוד האירופי נחשבת לאחת מתקנות הפרטיות המשפיעות ביותר כיום. האם ידעת שהיא גם מגדירה [8 זכויות משתמש](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) כדי להגן על פרטיות דיגיטלית ונתונים אישיים של אזרחים? למד מהן הזכויות הללו ולמה הן חשובות.

### 4. תרבות אתית

שימו לב כי קיים פער בלתי מוחשי בין _ציות_ (לעשות מספיק כדי לעמוד ב"אות החוק") לבין טיפול ב[בעיות מערכתיות](https://www.coursera.org/learn/data-science-ethics/home/week/4) (כמו קיפאון, אסימטריה במידע, ואי-שוויון חלוקתי) שיכולות להאיץ את השימוש לרעה ב-AI.

האחרון דורש [גישות שיתופיות להגדרת תרבויות אתיות](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f) שבונות קשרים רגשיים וערכים משותפים עקביים _בין ארגונים_ בתעשייה. זה קורא ל[תרבויות אתיקה פורמליות יותר](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) בארגונים - המאפשרות _לכל אחד_ [למשוך את חוט האנדון](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (כדי להעלות חששות אתיים מוקדם בתהליך) והופכות _הערכות אתיות_ (למשל, בגיוס עובדים) לקריטריון מרכזי בהרכבת צוותים בפרויקטים של AI.

---
## [חידון לאחר ההרצאה](https://ff-quizzes.netlify.app/en/ds/quiz/3) 🎯
## סקירה ולמידה עצמית

קורסים וספרים עוזרים להבין מושגי אתיקה ואתגרים מרכזיים, בעוד שמקרי בוחן וכלים מסייעים בפרקטיקות אתיקה יישומיות בהקשרים של העולם האמיתי. הנה כמה משאבים להתחלה:

* [Machine Learning For Beginners](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - שיעור על הוגנות, ממיקרוסופט.
* [עקרונות הבינה המלאכותית האחראית](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - מסלול למידה חינמי מ-Microsoft Learn.  
* [אתיקה ומדע הנתונים](https://resources.oreilly.com/examples/0636920203964) - ספר אלקטרוני של O'Reilly (מ. לוקידס, ה. מייסון ואחרים).  
* [אתיקה במדע הנתונים](https://www.coursera.org/learn/data-science-ethics#syllabus) - קורס מקוון מאוניברסיטת מישיגן.  
* [אתיקה ללא כיסוי](https://ethicsunwrapped.utexas.edu/case-studies) - מקרי בוחן מאוניברסיטת טקסס.  

# משימה  

[כתיבת מקרה בוחן על אתיקה בנתונים](assignment.md)  

---

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). בעוד שאנו שואפים לדיוק, יש לקחת בחשבון שתרגומים אוטומטיים עשויים להכיל שגיאות או אי-דיוקים. המסמך המקורי בשפתו המקורית נחשב למקור הסמכותי. למידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי בני אדם. איננו נושאים באחריות לכל אי-הבנה או פרשנות שגויה הנובעת משימוש בתרגום זה.