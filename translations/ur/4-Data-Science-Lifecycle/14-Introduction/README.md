<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "07478c2092203a69087b9c76b1f4dd56",
  "translation_date": "2025-09-06T06:40:38+00:00",
  "source_file": "4-Data-Science-Lifecycle/14-Introduction/README.md",
  "language_code": "ur"
}
-->
# ڈیٹا سائنس لائف سائیکل کا تعارف

|![ [(@sketchthedocs)](https://sketchthedocs.dev) کی اسکیچ نوٹ ](../../sketchnotes/14-DataScience-Lifecycle.png)|
|:---:|
| ڈیٹا سائنس لائف سائیکل کا تعارف - _[@nitya](https://twitter.com/nitya) کی اسکیچ نوٹ_ |

## [لیکچر سے پہلے کا کوئز](https://ff-quizzes.netlify.app/en/ds/quiz/26)

اس مرحلے پر آپ نے شاید یہ سمجھ لیا ہوگا کہ ڈیٹا سائنس ایک عمل ہے۔ اس عمل کو پانچ مراحل میں تقسیم کیا جا سکتا ہے:

- ڈیٹا حاصل کرنا
- پراسیسنگ
- تجزیہ
- مواصلات
- دیکھ بھال

یہ سبق لائف سائیکل کے تین حصوں پر مرکوز ہے: ڈیٹا حاصل کرنا، پراسیسنگ اور دیکھ بھال۔

![ڈیٹا سائنس لائف سائیکل کا خاکہ](../../../../4-Data-Science-Lifecycle/14-Introduction/images/data-science-lifecycle.jpg)
> تصویر [Berkeley School of Information](https://ischoolonline.berkeley.edu/data-science/what-is-data-science/) کی جانب سے

## ڈیٹا حاصل کرنا

لائف سائیکل کا پہلا مرحلہ بہت اہم ہے کیونکہ اگلے مراحل اس پر منحصر ہیں۔ یہ عملی طور پر دو مراحل کو ایک میں جوڑتا ہے: ڈیٹا حاصل کرنا اور مقصد اور مسائل کی وضاحت کرنا جنہیں حل کرنے کی ضرورت ہے۔  
پروجیکٹ کے اہداف کی وضاحت کے لیے مسئلے یا سوال کے بارے میں گہری تفہیم کی ضرورت ہوگی۔ سب سے پہلے، ہمیں ان لوگوں کی شناخت اور حصول کرنا ہوگا جنہیں ان کا مسئلہ حل کرنے کی ضرورت ہے۔ یہ کاروبار میں اسٹیک ہولڈرز یا پروجیکٹ کے اسپانسرز ہو سکتے ہیں، جو یہ شناخت کرنے میں مدد کر سکتے ہیں کہ کون یا کیا اس پروجیکٹ سے فائدہ اٹھائے گا اور انہیں کیا اور کیوں ضرورت ہے۔ ایک اچھی طرح سے وضاحت شدہ مقصد قابل پیمائش اور مقداری ہونا چاہیے تاکہ ایک قابل قبول نتیجہ کی وضاحت کی جا سکے۔

ڈیٹا سائنسدان درج ذیل سوالات پوچھ سکتے ہیں:
- کیا اس مسئلے کو پہلے حل کرنے کی کوشش کی گئی ہے؟ کیا دریافت ہوا؟
- کیا مقصد اور ہدف تمام متعلقہ افراد کے لیے واضح ہے؟
- کیا کوئی ابہام ہے اور اسے کیسے کم کیا جا سکتا ہے؟
- کیا پابندیاں ہیں؟
- ممکنہ طور پر آخری نتیجہ کیسا نظر آئے گا؟
- کتنے وسائل (وقت، افراد، کمپیوٹیشنل) دستیاب ہیں؟

اگلا مرحلہ ڈیٹا کی شناخت، جمع کرنا اور پھر اس کی جانچ کرنا ہے جو ان وضاحت شدہ اہداف کو حاصل کرنے کے لیے ضروری ہے۔ اس حصول کے مرحلے پر، ڈیٹا سائنسدانوں کو ڈیٹا کی مقدار اور معیار کا بھی جائزہ لینا ہوگا۔ اس کے لیے کچھ ڈیٹا کی جانچ پڑتال کی ضرورت ہوگی تاکہ تصدیق کی جا سکے کہ جو حاصل کیا گیا ہے وہ مطلوبہ نتیجہ تک پہنچنے میں مدد کرے گا۔

ڈیٹا کے بارے میں ڈیٹا سائنسدان درج ذیل سوالات پوچھ سکتے ہیں:
- میرے پاس پہلے سے کون سا ڈیٹا دستیاب ہے؟
- اس ڈیٹا کا مالک کون ہے؟
- پرائیویسی کے کیا خدشات ہیں؟
- کیا میرے پاس اس مسئلے کو حل کرنے کے لیے کافی ڈیٹا ہے؟
- کیا یہ ڈیٹا اس مسئلے کے لیے قابل قبول معیار کا ہے؟
- اگر میں اس ڈیٹا کے ذریعے اضافی معلومات دریافت کروں، تو کیا ہمیں اہداف کو تبدیل یا دوبارہ وضاحت کرنے پر غور کرنا چاہیے؟

## پراسیسنگ

لائف سائیکل کا پراسیسنگ مرحلہ ڈیٹا میں پیٹرنز دریافت کرنے اور ماڈلنگ پر مرکوز ہے۔ اس مرحلے میں استعمال ہونے والی کچھ تکنیکوں کو پیٹرنز کو ظاہر کرنے کے لیے شماریاتی طریقوں کی ضرورت ہوتی ہے۔ عام طور پر، یہ ایک انسان کے لیے بڑے ڈیٹا سیٹ کے ساتھ کرنے کے لیے ایک تھکا دینے والا کام ہوگا اور اس عمل کو تیز کرنے کے لیے کمپیوٹرز پر انحصار کیا جائے گا۔ یہ وہ مرحلہ بھی ہے جہاں ڈیٹا سائنس اور مشین لرننگ آپس میں ملتے ہیں۔ جیسا کہ آپ نے پہلے سبق میں سیکھا، مشین لرننگ ڈیٹا کو سمجھنے کے لیے ماڈلز بنانے کا عمل ہے۔ ماڈلز ڈیٹا میں متغیرات کے درمیان تعلقات کی نمائندگی کرتے ہیں جو نتائج کی پیش گوئی کرنے میں مدد کرتے ہیں۔

اس مرحلے میں استعمال ہونے والی عام تکنیکیں ML for Beginners کے نصاب میں شامل ہیں۔ مزید جاننے کے لیے لنکس پر عمل کریں:

- [Classification](https://github.com/microsoft/ML-For-Beginners/tree/main/4-Classification): ڈیٹا کو زیادہ مؤثر استعمال کے لیے زمروں میں ترتیب دینا۔
- [Clustering](https://github.com/microsoft/ML-For-Beginners/tree/main/5-Clustering): ڈیٹا کو ایک جیسے گروپس میں تقسیم کرنا۔
- [Regression](https://github.com/microsoft/ML-For-Beginners/tree/main/2-Regression): متغیرات کے درمیان تعلقات کا تعین کرنا تاکہ اقدار کی پیش گوئی یا پیشن گوئی کی جا سکے۔

## دیکھ بھال

لائف سائیکل کے خاکے میں، آپ نے دیکھا ہوگا کہ دیکھ بھال ڈیٹا حاصل کرنے اور پراسیسنگ کے درمیان موجود ہے۔ دیکھ بھال ایک جاری عمل ہے جس میں پروجیکٹ کے دوران ڈیٹا کا انتظام، ذخیرہ اور تحفظ شامل ہے اور اسے پورے پروجیکٹ کے دوران مدنظر رکھا جانا چاہیے۔

### ڈیٹا ذخیرہ کرنا

ڈیٹا کو کیسے اور کہاں ذخیرہ کیا جائے، اس کے بارے میں غور و فکر اس کے ذخیرہ کرنے کی لاگت اور ڈیٹا تک رسائی کی رفتار کو متاثر کر سکتا ہے۔ ایسے فیصلے ممکنہ طور پر صرف ڈیٹا سائنسدان کے ذریعے نہیں کیے جاتے لیکن وہ ڈیٹا کے ساتھ کام کرنے کے طریقے پر انتخاب کر سکتے ہیں، اس بنیاد پر کہ ڈیٹا کیسے ذخیرہ کیا گیا ہے۔

جدید ڈیٹا اسٹوریج سسٹمز کے کچھ پہلو جو ان انتخاب کو متاثر کر سکتے ہیں:

**آن پریمیس بمقابلہ آف پریمیس بمقابلہ پبلک یا پرائیویٹ کلاؤڈ**

آن پریمیس کا مطلب ہے کہ ڈیٹا کو اپنے آلات پر میزبانی اور انتظام کرنا، جیسے کہ سرور کے مالک ہونا جس میں ڈیٹا ذخیرہ کیا جاتا ہے، جبکہ آف پریمیس ایسے آلات پر انحصار کرتا ہے جو آپ کے مالک نہیں ہیں، جیسے کہ ڈیٹا سینٹر۔ پبلک کلاؤڈ ڈیٹا ذخیرہ کرنے کے لیے ایک مقبول انتخاب ہے جس کے لیے یہ جاننے کی ضرورت نہیں ہوتی کہ ڈیٹا کیسے یا کہاں ذخیرہ کیا گیا ہے، جہاں پبلک کا مطلب ہے کہ بنیادی انفراسٹرکچر تمام کلاؤڈ استعمال کرنے والوں کے لیے مشترکہ ہے۔ کچھ تنظیموں کی سخت سیکیورٹی پالیسیاں ہوتی ہیں جو اس بات کی ضرورت ہوتی ہیں کہ وہ اس سامان تک مکمل رسائی حاصل کریں جہاں ڈیٹا میزبانی کیا گیا ہے اور وہ پرائیویٹ کلاؤڈ پر انحصار کریں گے جو اپنی کلاؤڈ سروسز فراہم کرتا ہے۔ آپ کلاؤڈ میں ڈیٹا کے بارے میں مزید جانیں گے [بعد کے اسباق](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/5-Data-Science-In-Cloud) میں۔

**کولڈ بمقابلہ ہاٹ ڈیٹا**

جب آپ اپنے ماڈلز کو تربیت دے رہے ہوں، تو آپ کو زیادہ تربیتی ڈیٹا کی ضرورت ہو سکتی ہے۔ اگر آپ اپنے ماڈل سے مطمئن ہیں، تو مزید ڈیٹا ماڈل کو اس کے مقصد کے لیے کام کرنے کے لیے آئے گا۔ کسی بھی صورت میں، جیسے جیسے آپ زیادہ ڈیٹا جمع کرتے ہیں، اس کے ذخیرہ کرنے اور اس تک رسائی کی لاگت بڑھ جائے گی۔ شاذ و نادر استعمال ہونے والے ڈیٹا، جسے کولڈ ڈیٹا کہا جاتا ہے، کو اکثر استعمال ہونے والے ہاٹ ڈیٹا سے الگ کرنا ہارڈویئر یا سافٹ ویئر سروسز کے ذریعے سستا ڈیٹا اسٹوریج آپشن ہو سکتا ہے۔ اگر کولڈ ڈیٹا تک رسائی کی ضرورت ہو، تو اسے ہاٹ ڈیٹا کے مقابلے میں حاصل کرنے میں تھوڑا زیادہ وقت لگ سکتا ہے۔

### ڈیٹا کا انتظام

جب آپ ڈیٹا کے ساتھ کام کرتے ہیں، تو آپ دریافت کر سکتے ہیں کہ کچھ ڈیٹا کو درست ماڈلز بنانے کے لیے [ڈیٹا تیاری](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/2-Working-With-Data/08-data-preparation) کے سبق میں شامل تکنیکوں کا استعمال کرتے ہوئے صاف کرنے کی ضرورت ہے۔ جب نیا ڈیٹا آتا ہے، تو اسے معیار میں مستقل مزاجی برقرار رکھنے کے لیے انہی ایپلیکیشنز کی ضرورت ہوگی۔ کچھ پروجیکٹس میں ڈیٹا کو اس کے آخری مقام پر منتقل کرنے سے پہلے صفائی، مجموعہ، اور کمپریشن کے لیے ایک خودکار ٹول کا استعمال شامل ہوگا۔ Azure Data Factory ان ٹولز میں سے ایک کی مثال ہے۔

### ڈیٹا کو محفوظ بنانا

ڈیٹا کو محفوظ بنانے کے اہم اہداف میں سے ایک یہ یقینی بنانا ہے کہ جو لوگ اس پر کام کر رہے ہیں وہ اس بات پر قابو رکھتے ہیں کہ کیا جمع کیا جا رہا ہے اور کس سیاق و سباق میں اسے استعمال کیا جا رہا ہے۔ ڈیٹا کو محفوظ رکھنا ان لوگوں تک رسائی کو محدود کرنے میں شامل ہے جنہیں اس کی ضرورت ہے، مقامی قوانین اور ضوابط کی پابندی کرنا، اور اخلاقی معیارات کو برقرار رکھنا، جیسا کہ [اخلاقیات کے سبق](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/1-Introduction/02-ethics) میں شامل ہے۔

یہاں کچھ چیزیں ہیں جو ٹیم سیکیورٹی کو مدنظر رکھتے ہوئے کر سکتی ہے:
- اس بات کی تصدیق کریں کہ تمام ڈیٹا انکرپٹڈ ہے
- صارفین کو یہ معلومات فراہم کریں کہ ان کا ڈیٹا کیسے استعمال کیا جا رہا ہے
- پروجیکٹ چھوڑنے والے افراد سے ڈیٹا تک رسائی ختم کریں
- صرف مخصوص پروجیکٹ ممبران کو ڈیٹا میں تبدیلی کرنے کی اجازت دیں

## 🚀 چیلنج

ڈیٹا سائنس لائف سائیکل کے کئی ورژنز ہیں، جہاں ہر مرحلے کے مختلف نام اور مراحل کی تعداد ہو سکتی ہے لیکن اس سبق میں ذکر کردہ عمل شامل ہوں گے۔

[Team Data Science Process lifecycle](https://docs.microsoft.com/en-us/azure/architecture/data-science-process/lifecycle) اور [Cross-industry standard process for data mining](https://www.datascience-pm.com/crisp-dm-2/) کو دریافت کریں۔ ان دونوں کے درمیان 3 مماثلتیں اور فرق بتائیں۔

|Team Data Science Process (TDSP)|Cross-industry standard process for data mining (CRISP-DM)|
|--|--|
|![Team Data Science Lifecycle](../../../../4-Data-Science-Lifecycle/14-Introduction/images/tdsp-lifecycle2.png) | ![Data Science Process Alliance Image](../../../../4-Data-Science-Lifecycle/14-Introduction/images/CRISP-DM.png) |
| تصویر [Microsoft](https://docs.microsoft.comazure/architecture/data-science-process/lifecycle) کی جانب سے | تصویر [Data Science Process Alliance](https://www.datascience-pm.com/crisp-dm-2/) کی جانب سے |

## [لیکچر کے بعد کا کوئز](https://ff-quizzes.netlify.app/en/ds/quiz/27)

## جائزہ اور خود مطالعہ

ڈیٹا سائنس لائف سائیکل کو اپنانا متعدد کرداروں اور کاموں پر مشتمل ہوتا ہے، جہاں کچھ ہر مرحلے کے مخصوص حصوں پر توجہ مرکوز کر سکتے ہیں۔ Team Data Science Process کچھ وسائل فراہم کرتا ہے جو وضاحت کرتے ہیں کہ کسی پروجیکٹ میں کسی کے کردار اور کام کیا ہو سکتے ہیں۔

* [Team Data Science Process کے کردار اور کام](https://docs.microsoft.com/en-us/azure/architecture/data-science-process/roles-tasks)
* [ڈیٹا سائنس کے کام انجام دینا: دریافت، ماڈلنگ، اور تعیناتی](https://docs.microsoft.com/en-us/azure/architecture/data-science-process/execute-data-science-tasks)

## اسائنمنٹ

[ڈیٹا سیٹ کا جائزہ لینا](assignment.md)

---

**ڈسکلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا غیر درستیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔