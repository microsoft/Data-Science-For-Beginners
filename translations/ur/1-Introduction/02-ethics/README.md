<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1341f6da63d434f5ba31b08ea951b02c",
  "translation_date": "2025-09-06T06:49:17+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "ur"
}
-->
# ڈیٹا اخلاقیات کا تعارف

|![ اسکیچ نوٹ [(@sketchthedocs)](https://sketchthedocs.dev) کی طرف سے ](../../sketchnotes/02-Ethics.png)|
|:---:|
| ڈیٹا سائنس اخلاقیات - _اسکیچ نوٹ [@nitya](https://twitter.com/nitya) کی طرف سے_ |

---

ہم سب ایک ڈیٹا سے بھرپور دنیا میں ڈیٹا کے شہری ہیں۔

مارکیٹ کے رجحانات ہمیں بتاتے ہیں کہ 2022 تک، ہر تین میں سے ایک بڑی تنظیم اپنا ڈیٹا آن لائن [مارکیٹ پلیسز اور ایکسچینجز](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/) کے ذریعے خریدے گی اور بیچے گی۔ بطور **ایپ ڈویلپرز**، ہمارے لیے ڈیٹا سے چلنے والی بصیرتوں اور الگورتھم سے چلنے والی خودکاریت کو روزمرہ کے صارف تجربات میں شامل کرنا آسان اور سستا ہوگا۔ لیکن جیسے جیسے AI عام ہوتا جا رہا ہے، ہمیں ان الگورتھمز کے [ہتھیاروں کے طور پر استعمال](https://www.youtube.com/watch?v=TQHs8SA1qpk) کے ممکنہ نقصانات کو بھی سمجھنا ہوگا۔

رجحانات یہ بھی ظاہر کرتے ہیں کہ ہم 2025 تک [180 زیٹا بائٹس](https://www.statista.com/statistics/871513/worldwide-data-created/) سے زیادہ ڈیٹا تخلیق کریں گے اور استعمال کریں گے۔ بطور **ڈیٹا سائنسدان**، یہ ہمیں ذاتی ڈیٹا تک بے مثال رسائی فراہم کرتا ہے۔ اس کا مطلب ہے کہ ہم صارفین کے رویے کے پروفائل بنا سکتے ہیں اور فیصلہ سازی پر اثر ڈال سکتے ہیں، جس سے ایک [آزاد انتخاب کا دھوکہ](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) پیدا ہو سکتا ہے، جبکہ ممکنہ طور پر صارفین کو ان نتائج کی طرف دھکیل سکتے ہیں جو ہمیں پسند ہیں۔ یہ ڈیٹا کی پرائیویسی اور صارفین کے تحفظات پر وسیع سوالات بھی اٹھاتا ہے۔

ڈیٹا اخلاقیات اب ڈیٹا سائنس اور انجینئرنگ کے لیے _ضروری حفاظتی اصول_ ہیں، جو ہمارے ڈیٹا سے چلنے والے اقدامات کے ممکنہ نقصانات اور غیر ارادی نتائج کو کم کرنے میں مدد کرتے ہیں۔ [گارٹنر ہائپ سائیکل برائے AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) ڈیجیٹل اخلاقیات، ذمہ دار AI، اور AI گورننس میں متعلقہ رجحانات کو _AI کی جمہوریت سازی_ اور _صنعت کاری_ کے بڑے رجحانات کے کلیدی محرکات کے طور پر شناخت کرتا ہے۔

![گارٹنر کا ہائپ سائیکل برائے AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

اس سبق میں، ہم ڈیٹا اخلاقیات کے دلچسپ علاقے کو دریافت کریں گے - بنیادی تصورات اور چیلنجز سے لے کر کیس اسٹڈیز اور AI کے عملی تصورات جیسے گورننس - جو ڈیٹا اور AI کے ساتھ کام کرنے والی ٹیموں اور تنظیموں میں اخلاقیات کی ثقافت قائم کرنے میں مدد کرتے ہیں۔

## [لیکچر سے پہلے کا کوئز](https://ff-quizzes.netlify.app/en/ds/quiz/2) 🎯

## بنیادی تعریفیں

آئیے بنیادی اصطلاحات کو سمجھنے سے شروع کرتے ہیں۔

لفظ "اخلاقیات" [یونانی لفظ "ethikos"](https://en.wikipedia.org/wiki/Ethics) (اور اس کی جڑ "ethos") سے آیا ہے، جس کا مطلب ہے _کردار یا اخلاقی فطرت_۔

**اخلاقیات** ان مشترکہ اقدار اور اخلاقی اصولوں کے بارے میں ہیں جو معاشرے میں ہمارے رویے کو کنٹرول کرتے ہیں۔ اخلاقیات قوانین پر مبنی نہیں ہیں بلکہ اس بات کے وسیع پیمانے پر قبول شدہ اصولوں پر مبنی ہیں کہ کیا "صحیح بمقابلہ غلط" ہے۔ تاہم، اخلاقی غور و فکر کارپوریٹ گورننس اقدامات اور حکومتی ضوابط کو متاثر کر سکتے ہیں جو تعمیل کے لیے مزید مراعات پیدا کرتے ہیں۔

**ڈیٹا اخلاقیات** اخلاقیات کی ایک [نئی شاخ](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1) ہے جو "_ڈیٹا، الگورتھمز اور متعلقہ طریقوں_" سے متعلق اخلاقی مسائل کا مطالعہ اور جائزہ لیتی ہے۔ یہاں، **"ڈیٹا"** ان اعمال پر مرکوز ہے جو تخلیق، ریکارڈنگ، کیوریشن، پروسیسنگ، تقسیم، اشتراک، اور استعمال سے متعلق ہیں، **"الگورتھمز"** AI، ایجنٹس، مشین لرننگ، اور روبوٹس پر مرکوز ہیں، اور **"طریقے"** ذمہ دارانہ جدت، پروگرامنگ، ہیکنگ، اور اخلاقیات کے ضابطوں جیسے موضوعات پر مرکوز ہیں۔

**عملی اخلاقیات** اخلاقی غور و فکر کے [عملی اطلاق](https://en.wikipedia.org/wiki/Applied_ethics) کے بارے میں ہیں۔ یہ _حقیقی دنیا کے اعمال، مصنوعات اور عمل_ کے تناظر میں اخلاقی مسائل کی فعال طور پر تحقیق کرنے، اور اصلاحی اقدامات کرنے کا عمل ہے تاکہ یہ یقینی بنایا جا سکے کہ یہ ہماری بیان کردہ اخلاقی اقدار کے مطابق رہیں۔

**اخلاقیات کی ثقافت** [_عملی اخلاقیات کو نافذ کرنے_](https://hbr.org/2019/05/how-to-design-an-ethical-organization) کے بارے میں ہے تاکہ یہ یقینی بنایا جا سکے کہ ہماری اخلاقی اصول اور طریقے پورے تنظیم میں مستقل اور قابل پیمانہ انداز میں اپنائے جائیں۔ کامیاب اخلاقیات کی ثقافتیں تنظیمی سطح پر اخلاقی اصولوں کی وضاحت کرتی ہیں، تعمیل کے لیے بامعنی مراعات فراہم کرتی ہیں، اور ہر سطح پر مطلوبہ رویوں کو فروغ دے کر اور بڑھا کر اخلاقیات کے اصولوں کو تقویت دیتی ہیں۔

## اخلاقیات کے تصورات

اس حصے میں، ہم **مشترکہ اقدار** (اصول) اور **اخلاقی چیلنجز** (مسائل) جیسے تصورات پر بات کریں گے، اور **کیس اسٹڈیز** کا جائزہ لیں گے جو آپ کو حقیقی دنیا کے تناظر میں ان تصورات کو سمجھنے میں مدد فراہم کریں گے۔

### 1. اخلاقیات کے اصول

ہر ڈیٹا اخلاقیات کی حکمت عملی _اخلاقی اصولوں_ کی وضاحت سے شروع ہوتی ہے - وہ "مشترکہ اقدار" جو قابل قبول رویوں کو بیان کرتی ہیں اور ہمارے ڈیٹا اور AI منصوبوں میں تعمیل کے اقدامات کی رہنمائی کرتی ہیں۔ آپ ان اصولوں کو انفرادی یا ٹیم کی سطح پر بیان کر سکتے ہیں۔ تاہم، زیادہ تر بڑی تنظیمیں انہیں ایک _اخلاقی AI_ مشن بیان یا فریم ورک میں بیان کرتی ہیں جو کارپوریٹ سطح پر بیان کی جاتی ہے اور تمام ٹیموں میں مستقل طور پر نافذ کی جاتی ہے۔

**مثال:** مائیکروسافٹ کا [ذمہ دار AI](https://www.microsoft.com/en-us/ai/responsible-ai) مشن بیان کہتا ہے: _"ہم AI کی ترقی کے لیے پرعزم ہیں جو اخلاقی اصولوں کے ذریعے لوگوں کو اولین ترجیح دیتا ہے"_ - اور اس فریم ورک میں 6 اخلاقی اصولوں کی وضاحت کرتا ہے:

![مائیکروسافٹ میں ذمہ دار AI](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

آئیے ان اصولوں کو مختصراً دریافت کریں۔ _شفافیت_ اور _جوابدہی_ بنیادی اقدار ہیں جن پر دیگر اصول تعمیر کیے گئے ہیں - تو آئیے یہاں سے شروع کریں:

* [**جوابدہی**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) پریکٹیشنرز کو ان کے ڈیٹا اور AI آپریشنز کے لیے _ذمہ دار_ بناتی ہے، اور ان اخلاقی اصولوں کی تعمیل کو یقینی بناتی ہے۔
* [**شفافیت**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) اس بات کو یقینی بناتی ہے کہ ڈیٹا اور AI کے اقدامات صارفین کے لیے _سمجھنے کے قابل_ ہوں، فیصلوں کے پیچھے کیا اور کیوں کی وضاحت کرتے ہوئے۔
* [**منصفانہ برتاؤ**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - اس بات پر توجہ مرکوز کرتا ہے کہ AI تمام لوگوں کے ساتھ _منصفانہ_ برتاؤ کرے، ڈیٹا اور نظام میں کسی بھی نظامی یا غیر واضح سماجی-تکنیکی تعصبات کو حل کرے۔
* [**قابل اعتماد اور حفاظت**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - اس بات کو یقینی بناتا ہے کہ AI _مخصوص اقدار_ کے ساتھ مستقل طور پر کام کرے، ممکنہ نقصانات یا غیر ارادی نتائج کو کم کرے۔
* [**پرائیویسی اور سیکیورٹی**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - ڈیٹا کی اصلیت کو سمجھنے اور صارفین کو _ڈیٹا پرائیویسی اور متعلقہ تحفظات_ فراہم کرنے کے بارے میں ہے۔
* [**شمولیت**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - AI حل کو ارادے کے ساتھ ڈیزائن کرنے کے بارے میں ہے، انہیں _وسیع انسانی ضروریات_ اور صلاحیتوں کو پورا کرنے کے لیے ڈھالنا۔

> 🚨 اپنے ڈیٹا اخلاقیات کے مشن بیان کے بارے میں سوچیں۔ دیگر تنظیموں کے اخلاقی AI فریم ورک کو دریافت کریں - یہاں [IBM](https://www.ibm.com/cloud/learn/ai-ethics)، [Google](https://ai.google/principles)، اور [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/) کی مثالیں ہیں۔ ان میں کون سی مشترکہ اقدار ہیں؟ یہ اصول ان کے AI پروڈکٹ یا صنعت سے کیسے متعلق ہیں؟

### 2. اخلاقیات کے چیلنجز

جب ہم اخلاقی اصولوں کی وضاحت کر لیتے ہیں، تو اگلا قدم یہ ہے کہ ہمارے ڈیٹا اور AI اقدامات کا جائزہ لیا جائے کہ آیا وہ ان مشترکہ اقدار کے مطابق ہیں۔ اپنے اقدامات کو دو زمروں میں سوچیں: _ڈیٹا جمع کرنا_ اور _الگورتھم ڈیزائن_۔

ڈیٹا جمع کرنے کے ساتھ، اقدامات ممکنہ طور پر **ذاتی ڈیٹا** یا ذاتی طور پر قابل شناخت معلومات (PII) شامل کریں گے جو زندہ افراد کی شناخت کر سکتی ہیں۔ اس میں [غیر ذاتی ڈیٹا کی مختلف اشیاء](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) شامل ہیں جو _اجتماعی طور پر_ کسی فرد کی شناخت کرتی ہیں۔ اخلاقی چیلنجز _ڈیٹا پرائیویسی_، _ڈیٹا کی ملکیت_، اور متعلقہ موضوعات جیسے _مطلع رضامندی_ اور _صارفین کے دانشورانہ املاک کے حقوق_ سے متعلق ہو سکتے ہیں۔

الگورتھم ڈیزائن کے ساتھ، اقدامات **ڈیٹا سیٹس** کو جمع کرنے اور ان کی کیوریشن میں شامل ہوں گے، پھر انہیں **ڈیٹا ماڈلز** کو تربیت دینے اور تعینات کرنے کے لیے استعمال کریں گے جو حقیقی دنیا کے تناظر میں نتائج کی پیش گوئی کرتے ہیں یا فیصلے خودکار بناتے ہیں۔ اخلاقی چیلنجز _ڈیٹا سیٹ کے تعصب_، _ڈیٹا کے معیار_ کے مسائل، _غیر منصفانہ برتاؤ_، اور الگورتھمز میں _غلط نمائندگی_ سے پیدا ہو سکتے ہیں - جن میں سے کچھ مسائل نظامی نوعیت کے ہیں۔

دونوں صورتوں میں، اخلاقیات کے چیلنجز ان علاقوں کو اجاگر کرتے ہیں جہاں ہمارے اقدامات ہمارے مشترکہ اقدار کے ساتھ تنازعہ پیدا کر سکتے ہیں۔ ان خدشات کا پتہ لگانے، کم کرنے، کم سے کم کرنے، یا ختم کرنے کے لیے - ہمیں اپنے اقدامات سے متعلق اخلاقی "ہاں/نہیں" سوالات پوچھنے کی ضرورت ہے، پھر ضرورت کے مطابق اصلاحی اقدامات کریں۔ آئیے کچھ اخلاقی چیلنجز اور ان کے اٹھائے گئے اخلاقی سوالات پر نظر ڈالیں:

#### 2.1 ڈیٹا کی ملکیت

ڈیٹا جمع کرنا اکثر ذاتی ڈیٹا شامل کرتا ہے جو ڈیٹا کے موضوعات کی شناخت کر سکتا ہے۔ [ڈیٹا کی ملکیت](https://permission.io/blog/data-ownership) _کنٹرول_ اور [_صارف کے حقوق_](https://permission.io/blog/data-ownership) سے متعلق ہے جو ڈیٹا کی تخلیق، پروسیسنگ، اور تقسیم سے متعلق ہیں۔

اخلاقی سوالات جو ہمیں پوچھنے کی ضرورت ہے:
 * ڈیٹا کا مالک کون ہے؟ (صارف یا تنظیم)
 * ڈیٹا کے موضوعات کے کیا حقوق ہیں؟ (مثلاً: رسائی، حذف، پورٹیبلٹی)
 * تنظیموں کے کیا حقوق ہیں؟ (مثلاً: بدنیتی پر مبنی صارف جائزوں کو درست کرنا)

#### 2.2 مطلع رضامندی

[مطلع رضامندی](https://legaldictionary.net/informed-consent/) صارفین کے کسی عمل (جیسے ڈیٹا جمع کرنا) پر _مکمل سمجھ_ کے ساتھ رضامندی دینے کے عمل کی وضاحت کرتی ہے، جس میں مقصد، ممکنہ خطرات، اور متبادل شامل ہیں۔

یہاں دریافت کرنے کے سوالات:
 * کیا صارف (ڈیٹا کا موضوع) نے ڈیٹا کیپچر اور استعمال کی اجازت دی؟
 * کیا صارف نے اس مقصد کو سمجھا جس کے لیے وہ ڈیٹا جمع کیا گیا؟
 * کیا صارف نے اپنی شرکت سے پیدا ہونے والے ممکنہ خطرات کو سمجھا؟

#### 2.3 دانشورانہ املاک

[دانشورانہ املاک](https://en.wikipedia.org/wiki/Intellectual_property) انسانی پہل سے پیدا ہونے والی غیر محسوس تخلیقات کو ظاہر کرتی ہے، جو افراد یا کاروبار کے لیے _معاشی قدر_ رکھ سکتی ہیں۔

یہاں دریافت کرنے کے سوالات:
 * کیا جمع کردہ ڈیٹا صارف یا کاروبار کے لیے معاشی قدر رکھتا ہے؟
 * کیا یہاں **صارف** کے پاس دانشورانہ املاک ہیں؟
 * کیا یہاں **تنظیم** کے پاس دانشورانہ املاک ہیں؟
 * اگر یہ حقوق موجود ہیں، تو ہم انہیں کیسے محفوظ کر رہے ہیں؟

#### 2.4 ڈیٹا پرائیویسی

[ڈیٹا پرائیویسی](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) یا معلومات کی پرائیویسی صارف کی پرائیویسی کو محفوظ رکھنے اور ذاتی طور پر قابل شناخت معلومات کے ساتھ صارف کی شناخت کے تحفظ سے متعلق ہے۔

یہاں دریافت کرنے کے سوالات:
 * کیا صارفین کا (ذاتی) ڈیٹا ہیک اور لیک سے محفوظ ہے؟
 * کیا صارفین کا ڈیٹا صرف مجاز صارفین اور سیاق و سباق تک قابل رسائی ہے؟
 * کیا ڈیٹا کے اشتراک یا تقسیم کے وقت صارفین کی گمنامی محفوظ ہے؟
 * کیا صارف کو گمنام ڈیٹا سیٹس سے دوبارہ شناخت کیا جا سکتا ہے؟

#### 2.5 بھول جانے کا حق

[بھول جانے کا حق](https://en.wikipedia.org/wiki/Right_to_be_forgotten) یا [حذف کرنے کا حق](https://www.gdpreu.org/right-to-be-forgotten/) صارفین کو اضافی ذاتی ڈیٹا تحفظ فراہم کرتا ہے۔ خاص طور پر، یہ صارفین کو انٹرنیٹ تلاشوں اور دیگر مقامات سے ذاتی ڈیٹا کو حذف یا ہٹانے کی درخواست کرنے کا حق دیتا ہے، _مخصوص حالات کے تحت_ - انہیں آن لائن ایک نئی شروعات کرنے کی اجازت دیتا ہے بغیر ماضی کے اعمال کو ان کے خلاف رکھا جائے۔

یہاں دریافت کرنے کے سوالات:
 * کیا نظام ڈیٹا کے موضوعات کو حذف کرنے کی درخواست کرنے کی اجازت دیتا ہے؟
 * کیا صارف کی رضامندی کی واپسی خودکار حذف کو متحرک کرنی چاہیے؟
 * کیا ڈیٹا رضامندی کے بغیر یا غیر قانونی ذرائع سے جمع کیا گیا؟
 * کیا ہم ڈیٹا پرائیویسی کے لیے حکومتی ضوابط کے مطابق ہیں؟

#### 2.6 ڈیٹا سیٹ کا تعصب

ڈیٹا سیٹ یا [جمع کرنے کا تعصب](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) ایک _غیر نمائندہ_ ڈیٹا کے ذیلی سیٹ کو الگورتھم کی ترقی کے لیے منتخب کرنے کے بارے میں ہے، جو مختلف گروہوں کے لیے ممکنہ طور پر غیر منصفانہ نتائج پیدا کرتا ہے۔ تعصب کی اقسام میں انتخاب یا نمونہ تعصب، رضاکارانہ تعصب، اور آلے کا تعصب شامل ہیں۔

یہاں دریافت کرنے کے سوالات:
 * کیا ہم نے ڈیٹا کے موضوعات کا نمائندہ سیٹ بھرتی کیا؟
 * کیا ہم نے مختلف تعصبات کے لیے اپنے جمع کردہ یا کیوریٹڈ ڈیٹا سیٹ کی جانچ کی؟
 * کیا ہم دریافت شدہ تعصبات کو کم یا ختم کر سکتے ہیں؟

#### 2.7 ڈیٹا کا معیار

[ڈیٹا کا معیار](https://lakefs.io/data-quality-testing/) ہمارے الگورتھمز کو تیار کرنے کے لیے استعمال کیے گئے کیوریٹڈ ڈیٹا سیٹ کی درستگی کو دیکھتا ہے، یہ چیک کرتے ہوئے کہ آیا خصوصیات اور ریکارڈز ہمارے AI مقصد کے لیے مطلوبہ سطح کی درستگی اور مستقل مزاجی کی ضروریات کو پورا کرتے ہیں۔

یہاں دریافت کرنے کے سوالات:
 * کیا ہم نے اپنے استعمال کے کیس کے لیے درست _خصوصیات_ کو جمع کیا؟
 * کیا مختلف ڈیٹا ذرائع کے درمیان ڈیٹا _مسلسل_ طور پر جمع کیا گیا؟
 * کیا ڈیٹا سیٹ مختلف حالات یا منظرناموں کے لیے _مکمل_ ہے؟
 * کیا معلومات حقیقت کی عکاسی کرتے ہوئے _درست_ طور پر جمع کی گئی ہیں؟

#### 2.8 الگورتھم کی من
[Algorithm Fairness](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) یہ جانچتا ہے کہ آیا الگورتھم کا ڈیزائن مخصوص گروہوں کے خلاف منظم طور پر امتیاز کرتا ہے، جس کے نتیجے میں _وسائل کی تقسیم_ (جہاں وسائل کو اس گروہ سے انکار یا روکا جاتا ہے) اور _سروس کے معیار_ (جہاں AI کچھ گروہوں کے لیے اتنا درست نہیں جتنا دوسروں کے لیے ہے) میں [ممکنہ نقصانات](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) پیدا ہوتے ہیں۔

یہاں غور کرنے کے سوالات:
 * کیا ہم نے مختلف گروہوں اور حالات کے لیے ماڈل کی درستگی کا جائزہ لیا؟
 * کیا ہم نے ممکنہ نقصانات (جیسے، دقیانوسی تصورات) کے لیے نظام کا بغور جائزہ لیا؟
 * کیا ہم ڈیٹا کو دوبارہ ترتیب دے سکتے ہیں یا ماڈلز کو دوبارہ تربیت دے سکتے ہیں تاکہ شناخت شدہ نقصانات کو کم کیا جا سکے؟

مزید جاننے کے لیے [AI Fairness checklists](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) جیسے وسائل کو دیکھیں۔

#### 2.9 غلط بیانی

[Data Misrepresentation](https://www.sciencedirect.com/topics/computer-science/misrepresentation) یہ سوال اٹھاتا ہے کہ آیا ہم دیانتداری سے رپورٹ کیے گئے ڈیٹا سے حاصل کردہ بصیرت کو دھوکہ دہی کے انداز میں پیش کر رہے ہیں تاکہ مطلوبہ بیانیہ کی حمایت کی جا سکے۔

یہاں غور کرنے کے سوالات:
 * کیا ہم نامکمل یا غلط ڈیٹا رپورٹ کر رہے ہیں؟
 * کیا ہم ڈیٹا کو اس طرح سے پیش کر رہے ہیں جو گمراہ کن نتائج کو جنم دیتا ہے؟
 * کیا ہم نتائج کو جوڑنے کے لیے منتخب شماریاتی تکنیک استعمال کر رہے ہیں؟
 * کیا متبادل وضاحتیں موجود ہیں جو مختلف نتیجہ پیش کر سکتی ہیں؟

#### 2.10 آزاد انتخاب
[Illusion of Free Choice](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) اس وقت پیدا ہوتی ہے جب نظام کے "چوائس آرکیٹیکچرز" فیصلہ سازی کے الگورتھمز کا استعمال کرتے ہوئے لوگوں کو ایک ترجیحی نتیجہ کی طرف دھکیلتے ہیں، جبکہ انہیں اختیارات اور کنٹرول دینے کا تاثر دیتے ہیں۔ یہ [dark patterns](https://www.darkpatterns.org/) صارفین کو سماجی اور اقتصادی نقصان پہنچا سکتے ہیں۔ چونکہ صارف کے فیصلے رویے کے پروفائلز پر اثر انداز ہوتے ہیں، یہ اقدامات ممکنہ طور پر مستقبل کے انتخاب کو بڑھا سکتے ہیں یا ان نقصانات کے اثرات کو بڑھا سکتے ہیں۔

یہاں غور کرنے کے سوالات:
 * کیا صارف نے اس انتخاب کے اثرات کو سمجھا؟
 * کیا صارف کو (متبادل) انتخاب اور ہر ایک کے فوائد و نقصانات کا علم تھا؟
 * کیا صارف بعد میں خودکار یا متاثرہ انتخاب کو تبدیل کر سکتا ہے؟

### 3. کیس اسٹڈیز

ان اخلاقی چیلنجز کو حقیقی دنیا کے سیاق و سباق میں رکھنے کے لیے، ایسے کیس اسٹڈیز کو دیکھنا مددگار ثابت ہوتا ہے جو ان اخلاقی خلاف ورزیوں کو نظر انداز کرنے پر افراد اور معاشرے پر ممکنہ نقصانات اور نتائج کو اجاگر کرتے ہیں۔

یہاں کچھ مثالیں ہیں:

| اخلاقی چیلنج | کیس اسٹڈی  | 
|--- |--- |
| **مطلع رضامندی** | 1972 - [Tuskegee Syphilis Study](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - افریقی امریکی مردوں کو جو اس مطالعے میں شامل تھے، مفت طبی دیکھ بھال کا وعدہ کیا گیا تھا _لیکن دھوکہ دیا گیا_، کیونکہ محققین نے شرکاء کو ان کی تشخیص یا علاج کی دستیابی کے بارے میں مطلع کرنے میں ناکام رہے۔ کئی شرکاء فوت ہو گئے اور ان کے شریک حیات یا بچے متاثر ہوئے؛ مطالعہ 40 سال تک جاری رہا۔ | 
| **ڈیٹا پرائیویسی** |  2007 - [Netflix data prize](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) نے محققین کو _50K صارفین کے 10M گمنام فلمی درجہ بندی_ فراہم کی تاکہ سفارش الگورتھمز کو بہتر بنایا جا سکے۔ تاہم، محققین گمنام ڈیٹا کو _بیرونی ڈیٹاسیٹس_ (جیسے، IMDb تبصرے) میں ذاتی طور پر شناختی ڈیٹا کے ساتھ جوڑنے میں کامیاب رہے - مؤثر طریقے سے کچھ Netflix صارفین کو "ڈی-گمنام" کر دیا۔|
| **کلیکشن تعصب**  | 2013 - بوسٹن شہر نے [Street Bump](https://www.boston.gov/transportation/street-bump) تیار کیا، ایک ایپ جو شہریوں کو گڑھے رپورٹ کرنے دیتی ہے، جس سے شہر کو بہتر سڑک کے ڈیٹا حاصل کرنے اور مسائل کو حل کرنے میں مدد ملی۔ تاہم، [کم آمدنی والے گروہوں کے لوگوں کو کاروں اور فونز تک کم رسائی حاصل تھی](https://hbr.org/2013/04/the-hidden-biases-in-big-data)، جس سے ان کے سڑک کے مسائل اس ایپ میں پوشیدہ ہو گئے۔ ڈویلپرز نے منصفانہ رسائی اور ڈیجیٹل تقسیم کے مسائل کے لیے ماہرین کے ساتھ کام کیا۔ |
| **الگورتھمک انصاف**  | 2018 - MIT [Gender Shades Study](http://gendershades.org/overview.html) نے صنفی درجہ بندی AI مصنوعات کی درستگی کا جائزہ لیا، خواتین اور رنگین افراد کے لیے درستگی میں فرق کو ظاہر کیا۔ ایک [2019 Apple Card](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) نے مردوں کے مقابلے میں خواتین کو کم کریڈٹ پیش کیا۔ دونوں نے الگورتھمک تعصب میں مسائل کو اجاگر کیا، جس کے نتیجے میں سماجی و اقتصادی نقصانات ہوئے۔|
| **ڈیٹا غلط بیانی** | 2020 - [Georgia Department of Public Health نے COVID-19 چارٹس جاری کیے](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) جو شہریوں کو تصدیق شدہ کیسز کے رجحانات کے بارے میں گمراہ کن معلومات فراہم کرتے نظر آئے، x-axis پر غیر زمانی ترتیب کے ساتھ۔ یہ بصری چالوں کے ذریعے غلط بیانی کو ظاہر کرتا ہے۔ |
| **آزاد انتخاب کا دھوکہ** | 2020 - لرننگ ایپ [ABCmouse نے FTC شکایت کو حل کرنے کے لیے $10M ادا کیے](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/) جہاں والدین کو ایسی سبسکرپشنز کے لیے ادائیگی کرنے پر مجبور کیا گیا جنہیں وہ منسوخ نہیں کر سکتے تھے۔ یہ چوائس آرکیٹیکچرز میں تاریک نمونوں کو ظاہر کرتا ہے، جہاں صارفین کو ممکنہ طور پر نقصان دہ انتخاب کی طرف دھکیل دیا گیا۔ |
| **ڈیٹا پرائیویسی اور صارف کے حقوق** | 2021 - Facebook [Data Breach](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) نے 530M صارفین کا ڈیٹا افشا کیا، جس کے نتیجے میں FTC کو $5B کا تصفیہ ہوا۔ تاہم، اس نے صارفین کو خلاف ورزی کے بارے میں مطلع کرنے سے انکار کر دیا، صارف کے ڈیٹا شفافیت اور رسائی کے حقوق کی خلاف ورزی کی۔ |

مزید کیس اسٹڈیز دریافت کرنا چاہتے ہیں؟ ان وسائل کو دیکھیں:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - مختلف صنعتوں میں اخلاقی مخمصے۔
* [Data Science Ethics course](https://www.coursera.org/learn/data-science-ethics#syllabus) - اہم کیس اسٹڈیز کا جائزہ۔
* [Where things have gone wrong](https://deon.drivendata.org/examples/) - ڈیون چیک لسٹ کے ساتھ مثالیں۔

> 🚨 ان کیس اسٹڈیز کے بارے میں سوچیں جو آپ نے دیکھے ہیں - کیا آپ نے اپنی زندگی میں اسی طرح کے اخلاقی چیلنج کا سامنا کیا ہے یا اس سے متاثر ہوئے ہیں؟ کیا آپ کم از کم ایک اور کیس اسٹڈی کے بارے میں سوچ سکتے ہیں جو اس سیکشن میں زیر بحث اخلاقی چیلنجز میں سے ایک کو ظاہر کرتا ہو؟

## عملی اخلاقیات

ہم نے اخلاقیات کے تصورات، چیلنجز، اور حقیقی دنیا کے سیاق و سباق میں کیس اسٹڈیز پر بات کی۔ لیکن ہم اپنے منصوبوں میں اخلاقی اصولوں اور طریقوں کو _لاگو_ کرنے کا آغاز کیسے کریں؟ اور ہم بہتر حکمرانی کے لیے ان طریقوں کو _عملی شکل_ کیسے دے سکتے ہیں؟ آئیے کچھ حقیقی دنیا کے حل تلاش کریں:

### 1. پیشہ ورانہ ضابطے

پیشہ ورانہ ضابطے تنظیموں کو اپنے اخلاقی اصولوں اور مشن بیان کی حمایت کرنے کے لیے ممبران کو "ترغیب دینے" کا ایک آپشن پیش کرتے ہیں۔ ضابطے پیشہ ورانہ رویے کے لیے _اخلاقی رہنما خطوط_ ہیں، جو ملازمین یا ممبران کو ایسے فیصلے کرنے میں مدد دیتے ہیں جو ان کی تنظیم کے اصولوں کے مطابق ہوں۔ یہ صرف ممبران کی رضاکارانہ تعمیل کے طور پر اچھے ہیں؛ تاہم، بہت سی تنظیمیں ممبران کی تعمیل کو متحرک کرنے کے لیے اضافی انعامات اور سزائیں پیش کرتی ہیں۔

مثالیں شامل ہیں:

 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Code of Ethics
 * [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Code of Conduct (2013 میں تخلیق کیا گیا)
 * [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (1993 سے)

> 🚨 کیا آپ کسی پیشہ ور انجینئرنگ یا ڈیٹا سائنس تنظیم کے ممبر ہیں؟ ان کی سائٹ کو دیکھیں کہ آیا وہ پیشہ ورانہ اخلاقیات کا ضابطہ بیان کرتے ہیں۔ یہ ان کے اخلاقی اصولوں کے بارے میں کیا کہتا ہے؟ وہ ممبران کو ضابطے پر عمل کرنے کے لیے کیسے "ترغیب دے رہے ہیں"؟

### 2. اخلاقیات چیک لسٹس

جبکہ پیشہ ورانہ ضابطے پریکٹیشنرز سے مطلوبہ _اخلاقی رویے_ کی وضاحت کرتے ہیں، وہ [نفاذ میں معلوم حدود](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) رکھتے ہیں، خاص طور پر بڑے پیمانے پر منصوبوں میں۔ اس کے بجائے، بہت سے ڈیٹا سائنس ماہرین [چیک لسٹس کی وکالت کرتے ہیں](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md)، جو **اصولوں کو طریقوں سے جوڑ سکتے ہیں** زیادہ تعیناتی اور قابل عمل طریقے سے۔

چیک لسٹس سوالات کو "ہاں/نہیں" کاموں میں تبدیل کرتی ہیں جنہیں عملی شکل دی جا سکتی ہے، انہیں معیاری پروڈکٹ ریلیز ورک فلو کے حصے کے طور پر ٹریک کرنے کی اجازت دیتی ہیں۔

مثالیں شامل ہیں:
 * [Deon](https://deon.drivendata.org/) - صنعت کی سفارشات سے تخلیق کردہ ایک عمومی مقصد ڈیٹا اخلاقیات چیک لسٹ [کمانڈ لائن ٹول](https://deon.drivendata.org/#checklist-citations) کے ساتھ آسان انضمام کے لیے۔
 * [Privacy Audit Checklist](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - قانونی اور سماجی نمائش کے نقطہ نظر سے معلوماتی ہینڈلنگ کے طریقوں کے لیے عمومی رہنمائی فراہم کرتا ہے۔
 * [AI Fairness Checklist](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - AI پریکٹیشنرز کے ذریعہ تخلیق کردہ، AI ترقیاتی سائیکلوں میں انصاف کے چیکوں کو اپنانے اور انضمام کی حمایت کرنے کے لیے۔
 * [22 questions for ethics in data and AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - زیادہ کھلا فریم ورک، ڈیزائن، نفاذ، اور تنظیمی سیاق و سباق میں اخلاقی مسائل کی ابتدائی تلاش کے لیے تشکیل دیا گیا۔

### 3. اخلاقیات کے ضوابط

اخلاقیات مشترکہ اقدار کی وضاحت کرنے اور _رضاکارانہ طور پر_ صحیح کام کرنے کے بارے میں ہے۔ **تعمیل** اس بارے میں ہے کہ _قانون کی پیروی کرنا_ اگر اور جہاں بیان کیا گیا ہو۔ **حکمرانی** وسیع پیمانے پر ان تمام طریقوں کا احاطہ کرتا ہے جن کے ذریعے تنظیمیں اخلاقی اصولوں کو نافذ کرنے اور قائم کردہ قوانین کی تعمیل کرنے کے لیے کام کرتی ہیں۔

آج، تنظیموں کے اندر حکمرانی دو شکلیں اختیار کرتی ہے۔ پہلے، یہ **اخلاقی AI** اصولوں کی وضاحت کرنے اور تنظیم میں تمام AI سے متعلق منصوبوں میں اپنانے کو عملی شکل دینے کے طریقوں کو قائم کرنے کے بارے میں ہے۔ دوسرا، یہ ان تمام حکومت کے ذریعہ لازمی **ڈیٹا تحفظ کے ضوابط** کی تعمیل کرنے کے بارے میں ہے جن علاقوں میں یہ کام کرتی ہے۔

ڈیٹا تحفظ اور پرائیویسی ضوابط کی مثالیں:

 * `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - _وفاقی حکومت_ کے ذاتی معلومات کے جمع کرنے، استعمال، اور انکشاف کو منظم کرتا ہے۔
 * `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - ذاتی صحت کے ڈیٹا کی حفاظت کرتا ہے۔
 * `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - 13 سال سے کم عمر بچوں کے ڈیٹا پرائیویسی کی حفاظت کرتا ہے۔
 * `2018`, [General Data Protection Regulation (GDPR)](https://gdpr-info.eu/) - صارف کے حقوق، ڈیٹا تحفظ، اور پرائیویسی فراہم کرتا ہے۔
 * `2018`, [California Consumer Privacy Act (CCPA)](https://www.oag.ca.gov/privacy/ccpa) صارفین کو ان کے (ذاتی) ڈیٹا پر زیادہ _حقوق_ دیتا ہے۔
 * `2021`, چین کا [Personal Information Protection Law](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) ابھی پاس ہوا، دنیا بھر میں آن لائن ڈیٹا پرائیویسی کے سب سے مضبوط ضوابط میں سے ایک تخلیق کرتا ہے۔

> 🚨 یورپی یونین کی طرف سے بیان کردہ GDPR (General Data Protection Regulation) آج ڈیٹا پرائیویسی کے سب سے زیادہ اثر انگیز ضوابط میں سے ایک ہے۔ کیا آپ جانتے ہیں کہ یہ [8 صارف کے حقوق](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) بھی بیان کرتا ہے تاکہ شہریوں کی ڈیجیٹل پرائیویسی اور ذاتی ڈیٹا کی حفاظت کی جا سکے؟ ان کے بارے میں جانیں کہ یہ کیا ہیں اور کیوں اہم ہیں۔

### 4. اخلاقیات کی ثقافت

نوٹ کریں کہ _تعمیل_ (قانون کے "حرف" کو پورا کرنے کے لیے کافی کرنا) اور [نظامی مسائل](https://www.coursera.org/learn/data-science-ethics/home/week/4) (جیسے، جمود، معلوماتی عدم توازن، اور تقسیماتی غیر منصفانہ) کو حل کرنے کے درمیان ایک غیر محسوس فرق موجود ہے جو AI کے ہتھیاروں کو تیز کر سکتا ہے۔

بعد والے کو [اخلاقیات کی ثقافتوں کی وضاحت کے لیے تعاون پر مبنی طریقوں](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f) کی ضرورت ہوتی ہے جو صنعت میں _تنظیموں_ کے درمیان جذباتی تعلقات اور مستقل مشترکہ اقدار کو تشکیل دیتے ہیں۔ اس کے لیے تنظیموں میں زیادہ [باضابطہ ڈیٹا اخلاقیات کی ثقافتیں](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) بنانے کی ضرورت ہوتی ہے - جس سے _کوئی بھی_ [Andon cord کھینچ سکتا ہے](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (عمل کے ابتدائی مرحلے میں اخلاقیات کے خدشات کو اٹھانے کے لیے) اور _اخلاقی تشخیصات_ (جیسے، بھرتی میں) کو AI منصوبوں میں ٹیم کی تشکیل کے لیے ایک بنیادی معیار بناتا ہے۔

---
## [لیکچر کے بعد کا کوئز](https://ff-quizzes.netlify.app/en/ds/quiz/3) 🎯
## جائزہ اور خود مطالعہ 

کورسز اور کتابیں اخلاقیات کے بنیادی تصورات اور چیلنجز کو سمجھنے میں مدد کرتی ہیں، جبکہ کیس اسٹڈیز اور ٹولز حقیقی دنیا کے سیاق و سباق میں عملی اخلاقیات کے طریقوں میں مدد کرتے ہیں۔ یہاں شروع کرنے کے لیے کچھ وسائل ہیں۔

* [Machine Learning For Beginners](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - Microsoft کی طرف سے انصاف پر سبق۔
* [ذمہ دار AI کے اصول](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - مائیکروسافٹ لرن سے مفت سیکھنے کا راستہ۔
* [اخلاقیات اور ڈیٹا سائنس](https://resources.oreilly.com/examples/0636920203964) - او'ریلی ای بک (ایم لوکائیڈز، ایچ میسن وغیرہ)
* [ڈیٹا سائنس اخلاقیات](https://www.coursera.org/learn/data-science-ethics#syllabus) - مشی گن یونیورسٹی کا آن لائن کورس۔
* [اخلاقیات انریپڈ](https://ethicsunwrapped.utexas.edu/case-studies) - ٹیکساس یونیورسٹی کے کیس اسٹڈیز۔

# اسائنمنٹ

[ڈیٹا اخلاقیات کا کیس اسٹڈی لکھیں](assignment.md)

---

**ڈسکلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا غیر درستیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔