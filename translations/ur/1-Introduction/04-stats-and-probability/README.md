<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1cf49f029ba1f25a54f0d5bc2fa575fc",
  "translation_date": "2025-09-06T06:46:52+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "ur"
}
-->
# شماریات اور احتمال کا مختصر تعارف

|![ اسکیچ نوٹ [(@sketchthedocs)](https://sketchthedocs.dev) کی طرف سے ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| شماریات اور احتمال - _اسکیچ نوٹ [@nitya](https://twitter.com/nitya) کی طرف سے_ |

شماریات اور احتمال کا نظریہ ریاضی کے دو ایسے شعبے ہیں جو ڈیٹا سائنس کے لیے بہت اہم ہیں۔ ڈیٹا کے ساتھ کام کرنا ممکن ہے بغیر ریاضی کی گہری معلومات کے، لیکن پھر بھی کچھ بنیادی تصورات جاننا بہتر ہے۔ یہاں ہم ایک مختصر تعارف پیش کریں گے جو آپ کو شروع کرنے میں مدد دے گا۔

[![تعارفی ویڈیو](../../../../1-Introduction/04-stats-and-probability/images/video-prob-and-stats.png)](https://youtu.be/Z5Zy85g4Yjw)

## [لیکچر سے پہلے کا کوئز](https://ff-quizzes.netlify.app/en/ds/quiz/6)

## احتمال اور بے ترتیب متغیرات

**احتمال** ایک عدد ہے جو 0 اور 1 کے درمیان ہوتا ہے اور کسی **واقعہ** کے ہونے کے امکان کو ظاہر کرتا ہے۔ یہ مثبت نتائج کی تعداد (جو واقعہ کی طرف لے جاتے ہیں) کو کل نتائج کی تعداد سے تقسیم کر کے بیان کیا جاتا ہے، بشرطیکہ تمام نتائج برابر احتمال رکھتے ہوں۔ مثال کے طور پر، جب ہم ایک ڈائس پھینکتے ہیں، تو ایک جفت عدد حاصل کرنے کا احتمال 3/6 = 0.5 ہے۔

جب ہم واقعات کی بات کرتے ہیں، تو ہم **بے ترتیب متغیرات** استعمال کرتے ہیں۔ مثال کے طور پر، وہ بے ترتیب متغیر جو ڈائس پھینکنے پر حاصل ہونے والے عدد کو ظاہر کرتا ہے، وہ 1 سے 6 تک کے اعداد لے سکتا ہے۔ 1 سے 6 تک کے اعداد کا مجموعہ **نمونہ کی جگہ** کہلاتا ہے۔ ہم بے ترتیب متغیر کے کسی خاص قدر لینے کے احتمال کے بارے میں بات کر سکتے ہیں، جیسے P(X=3)=1/6۔

پچھلی مثال میں بے ترتیب متغیر کو **غیر مسلسل** کہا جاتا ہے، کیونکہ اس کی نمونہ کی جگہ قابل شمار ہے، یعنی الگ الگ اقدار ہیں جنہیں گنا جا سکتا ہے۔ کچھ صورتوں میں نمونہ کی جگہ حقیقی اعداد کی حد یا پورے حقیقی اعداد کا مجموعہ ہو سکتی ہے۔ ایسے متغیرات کو **مسلسل** کہا جاتا ہے۔ ایک اچھی مثال بس کے پہنچنے کا وقت ہے۔

## احتمال کی تقسیم

غیر مسلسل بے ترتیب متغیرات کے معاملے میں، ہر واقعہ کے احتمال کو ایک فنکشن P(X) کے ذریعے بیان کرنا آسان ہے۔ نمونہ کی جگہ *S* سے ہر قدر *s* کے لیے یہ 0 سے 1 تک کا عدد دے گا، اس طرح کہ تمام واقعات کے لیے P(X=s) کی تمام اقدار کا مجموعہ 1 ہوگا۔

سب سے مشہور غیر مسلسل تقسیم **یکساں تقسیم** ہے، جس میں N عناصر کی نمونہ کی جگہ ہوتی ہے، اور ہر ایک کے لیے برابر احتمال 1/N ہوتا ہے۔

مسلسل متغیر کی احتمال کی تقسیم کو بیان کرنا زیادہ مشکل ہے، جس کی اقدار کسی حد [a,b] یا پورے حقیقی اعداد ℝ سے لی جاتی ہیں۔ بس کے پہنچنے کے وقت کے معاملے پر غور کریں۔ حقیقت میں، کسی خاص وقت *t* پر بس کے بالکل اسی وقت پہنچنے کا احتمال 0 ہے!

> اب آپ جانتے ہیں کہ 0 احتمال والے واقعات ہوتے ہیں، اور بہت بار ہوتے ہیں! کم از کم ہر بار جب بس پہنچتی ہے!

ہم صرف متغیر کے کسی دیے گئے حد میں اقدار کے گرنے کے احتمال کے بارے میں بات کر سکتے ہیں، جیسے P(t<sub>1</sub>≤X<t<sub>2</sub>)۔ اس صورت میں، احتمال کی تقسیم کو **احتمال کی کثافت کا فنکشن** p(x) کے ذریعے بیان کیا جاتا ہے، اس طرح کہ

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../1-Introduction/04-stats-and-probability/images/probability-density.png)

یکساں تقسیم کا مسلسل متبادل **مسلسل یکساں** کہلاتا ہے، جو ایک محدود حد پر بیان کیا جاتا ہے۔ احتمال کہ قدر X کسی حد کی لمبائی l میں گرتی ہے، l کے تناسب سے ہوتا ہے، اور 1 تک بڑھتا ہے۔

ایک اور اہم تقسیم **معمولی تقسیم** ہے، جس کے بارے میں ہم نیچے مزید تفصیل سے بات کریں گے۔

## اوسط، تغیر اور معیاری انحراف

فرض کریں ہم بے ترتیب متغیر X کے n نمونوں کی ترتیب کھینچتے ہیں: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>۔ ہم ترتیب کی **اوسط** (یا **حسابی اوسط**) قدر کو روایتی طریقے سے (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n کے طور پر بیان کر سکتے ہیں۔ جیسے جیسے ہم نمونے کا سائز بڑھاتے ہیں (یعنی n→∞ کی حد لیتے ہیں)، ہم تقسیم کی اوسط (جسے **توقع** بھی کہا جاتا ہے) حاصل کریں گے۔ ہم توقع کو **E**(x) سے ظاہر کریں گے۔

> یہ دکھایا جا سکتا ہے کہ کسی بھی غیر مسلسل تقسیم کے لیے جس میں اقدار {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} اور متعلقہ احتمالات p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub> ہوں، توقع E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub> کے برابر ہوگی۔

یہ معلوم کرنے کے لیے کہ اقدار کتنی دور تک پھیلی ہوئی ہیں، ہم تغیر σ<sup>2</sup> = ∑(x<sub>i</sub> - μ)<sup>2</sup>/n کا حساب لگا سکتے ہیں، جہاں μ ترتیب کی اوسط ہے۔ قدر σ کو **معیاری انحراف** کہا جاتا ہے، اور σ<sup>2</sup> کو **تغیر** کہا جاتا ہے۔

## موڈ، میڈین اور کوارٹائلز

کبھی کبھی، اوسط ڈیٹا کے "عام" قدر کو مناسب طریقے سے ظاہر نہیں کرتی۔ مثال کے طور پر، جب کچھ انتہائی اقدار ہوتی ہیں جو مکمل طور پر حد سے باہر ہوتی ہیں، وہ اوسط کو متاثر کر سکتی ہیں۔ ایک اور اچھا اشارہ **میڈین** ہے، ایک قدر جس کے نیچے آدھے ڈیٹا پوائنٹس ہوتے ہیں، اور آدھے - اوپر۔

ڈیٹا کی تقسیم کو سمجھنے میں مدد کے لیے، **کوارٹائلز** کے بارے میں بات کرنا مفید ہے:

* پہلا کوارٹائل، یا Q1، ایک قدر ہے، جس کے نیچے 25% ڈیٹا آتا ہے
* تیسرا کوارٹائل، یا Q3، ایک قدر ہے جس کے نیچے 75% ڈیٹا آتا ہے

گرافک طور پر ہم میڈین اور کوارٹائلز کے تعلق کو ایک ڈایاگرام میں ظاہر کر سکتے ہیں جسے **باکس پلاٹ** کہا جاتا ہے:

<img src="images/boxplot_explanation.png" width="50%"/>

یہاں ہم **انٹر-کوارٹائل رینج** IQR=Q3-Q1، اور نام نہاد **آؤٹلیئرز** - اقدار، جو حدود [Q1-1.5*IQR,Q3+1.5*IQR] سے باہر ہوتی ہیں، کا حساب بھی لگاتے ہیں۔

کسی محدود تقسیم کے لیے جو ممکنہ اقدار کی ایک چھوٹی تعداد پر مشتمل ہو، ایک اچھا "عام" قدر وہ ہے جو سب سے زیادہ بار ظاہر ہوتی ہے، جسے **موڈ** کہا جاتا ہے۔ یہ اکثر زمرہ جاتی ڈیٹا پر لاگو ہوتا ہے، جیسے رنگ۔ فرض کریں کہ ہمارے پاس لوگوں کے دو گروپ ہیں - کچھ جو سرخ کو ترجیح دیتے ہیں، اور دوسرے جو نیلے کو ترجیح دیتے ہیں۔ اگر ہم رنگوں کو نمبروں سے کوڈ کریں، تو پسندیدہ رنگ کے لیے اوسط قدر کہیں نارنجی-سبز سپیکٹرم میں ہوگی، جو کسی بھی گروپ کی اصل ترجیح کو ظاہر نہیں کرتی۔ تاہم، موڈ یا تو ایک رنگ ہوگا، یا دونوں رنگ، اگر ان کے لیے ووٹ دینے والے لوگوں کی تعداد برابر ہو (اس صورت میں ہم نمونے کو **ملٹی موڈل** کہتے ہیں)۔

## حقیقی دنیا کا ڈیٹا

جب ہم حقیقی زندگی کے ڈیٹا کا تجزیہ کرتے ہیں، تو وہ اکثر بے ترتیب متغیرات کی طرح نہیں ہوتے، اس معنی میں کہ ہم نامعلوم نتیجے کے ساتھ تجربات نہیں کرتے۔ مثال کے طور پر، بیس بال کھلاڑیوں کی ایک ٹیم پر غور کریں، اور ان کے جسمانی ڈیٹا، جیسے قد، وزن اور عمر۔ یہ اعداد بالکل بے ترتیب نہیں ہیں، لیکن ہم پھر بھی وہی ریاضیاتی تصورات لاگو کر سکتے ہیں۔ مثال کے طور پر، لوگوں کے وزن کی ترتیب کو کچھ بے ترتیب متغیر سے لی گئی اقدار کی ترتیب سمجھا جا سکتا ہے۔ نیچے [میجر لیگ بیس بال](http://mlb.mlb.com/index.jsp) کے حقیقی بیس بال کھلاڑیوں کے وزن کی ترتیب ہے، جو [اس ڈیٹا سیٹ](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) سے لی گئی ہے (آپ کی سہولت کے لیے، صرف پہلے 20 اقدار دکھائی گئی ہیں):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **نوٹ**: اس ڈیٹا سیٹ کے ساتھ کام کرنے کی مثال دیکھنے کے لیے، [ساتھ والے نوٹ بک](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) پر نظر ڈالیں۔ اس سبق کے دوران کئی چیلنجز بھی ہیں، اور آپ انہیں اس نوٹ بک میں کچھ کوڈ شامل کر کے مکمل کر سکتے ہیں۔ اگر آپ کو ڈیٹا پر کام کرنے کا طریقہ معلوم نہیں ہے، تو فکر نہ کریں - ہم بعد میں پائتھن کا استعمال کرتے ہوئے ڈیٹا پر کام کرنے پر واپس آئیں گے۔ اگر آپ کو جیوپیٹر نوٹ بک میں کوڈ چلانے کا طریقہ معلوم نہیں ہے، تو [اس مضمون](https://soshnikov.com/education/how-to-execute-notebooks-from-github/) پر نظر ڈالیں۔

یہاں ہمارے ڈیٹا کے لیے اوسط، میڈین اور کوارٹائلز کو ظاہر کرنے والا باکس پلاٹ ہے:

![وزن کا باکس پلاٹ](../../../../1-Introduction/04-stats-and-probability/images/weight-boxplot.png)

چونکہ ہمارے ڈیٹا میں مختلف کھلاڑیوں کے **کردار** کے بارے میں معلومات شامل ہیں، ہم کردار کے لحاظ سے بھی باکس پلاٹ بنا سکتے ہیں - یہ ہمیں یہ سمجھنے کی اجازت دے گا کہ پیرامیٹرز کی اقدار کرداروں کے درمیان کیسے مختلف ہوتی ہیں۔ اس بار ہم قد پر غور کریں گے:

![کردار کے لحاظ سے باکس پلاٹ](../../../../1-Introduction/04-stats-and-probability/images/boxplot_byrole.png)

یہ ڈایاگرام تجویز کرتا ہے کہ، اوسطاً، پہلے بیس مین کا قد دوسرے بیس مین کے قد سے زیادہ ہے۔ اس سبق کے بعد ہم سیکھیں گے کہ ہم اس مفروضے کو مزید رسمی طور پر کیسے جانچ سکتے ہیں، اور یہ کیسے ظاہر کر سکتے ہیں کہ ہمارا ڈیٹا شماریاتی طور پر اہم ہے۔

> جب ہم حقیقی دنیا کے ڈیٹا پر کام کرتے ہیں، تو ہم فرض کرتے ہیں کہ تمام ڈیٹا پوائنٹس کسی احتمال کی تقسیم سے لیے گئے نمونے ہیں۔ یہ مفروضہ ہمیں مشین لرننگ تکنیکوں کو لاگو کرنے اور کام کرنے والے پیش گوئی کے ماڈلز بنانے کی اجازت دیتا ہے۔

اپنے ڈیٹا کی تقسیم کو دیکھنے کے لیے، ہم ایک گراف بنا سکتے ہیں جسے **ہسٹوگرام** کہا جاتا ہے۔ X-محور مختلف وزن کے وقفوں (نام نہاد **بِنز**) کی تعداد پر مشتمل ہوگا، اور عمودی محور یہ ظاہر کرے گا کہ ہمارا بے ترتیب متغیر نمونہ دیے گئے وقفے میں کتنی بار آیا۔

![حقیقی دنیا کے ڈیٹا کا ہسٹوگرام](../../../../1-Introduction/04-stats-and-probability/images/weight-histogram.png)

اس ہسٹوگرام سے آپ دیکھ سکتے ہیں کہ تمام اقدار ایک خاص اوسط وزن کے ارد گرد مرکوز ہیں، اور جیسے جیسے ہم اس وزن سے دور جاتے ہیں - ان اقدار کے وزن کم ہوتے جاتے ہیں۔ یعنی، یہ بہت غیر ممکن ہے کہ کسی بیس بال کھلاڑی کا وزن اوسط وزن سے بہت مختلف ہو۔ وزن کا تغیر ظاہر کرتا ہے کہ وزن اوسط سے کتنا مختلف ہونے کا امکان ہے۔

> اگر ہم دوسرے لوگوں کے وزن لیں، جو بیس بال لیگ سے نہیں ہیں، تو تقسیم مختلف ہونے کا امکان ہے۔ تاہم، تقسیم کی شکل وہی ہوگی، لیکن اوسط اور تغیر بدل جائیں گے۔ لہذا، اگر ہم اپنے ماڈل کو بیس بال کھلاڑیوں پر تربیت دیں، تو یہ ممکن ہے کہ یونیورسٹی کے طلباء پر لاگو ہونے پر غلط نتائج دے، کیونکہ بنیادی تقسیم مختلف ہے۔

## معمولی تقسیم

وزن کی تقسیم جو ہم نے اوپر دیکھی ہے وہ بہت عام ہے، اور حقیقی دنیا سے کئی پیمائشیں اسی قسم کی تقسیم کی پیروی کرتی ہیں، لیکن مختلف اوسط اور تغیر کے ساتھ۔ اس تقسیم کو **معمولی تقسیم** کہا جاتا ہے، اور یہ شماریات میں بہت اہم کردار ادا کرتی ہے۔

معمولی تقسیم کا استعمال ممکنہ بیس بال کھلاڑیوں کے بے ترتیب وزن پیدا کرنے کا صحیح طریقہ ہے۔ ایک بار جب ہم اوسط وزن `mean` اور معیاری انحراف `std` جان لیں، تو ہم 1000 وزن کے نمونے درج ذیل طریقے سے پیدا کر سکتے ہیں:
```python
samples = np.random.normal(mean,std,1000)
```

اگر ہم پیدا کردہ نمونوں کا ہسٹوگرام بنائیں تو ہمیں اوپر دکھائی گئی تصویر سے بہت ملتی جلتی تصویر نظر آئے گی۔ اور اگر ہم نمونوں کی تعداد اور بِنز کی تعداد بڑھائیں، تو ہم معمولی تقسیم کی ایک تصویر پیدا کر سکتے ہیں جو مثالی کے قریب ہو:

![معمولی تقسیم mean=0 اور std.dev=1 کے ساتھ](../../../../1-Introduction/04-stats-and-probability/images/normal-histogram.png)

*معمولی تقسیم mean=0 اور std.dev=1 کے ساتھ*

## اعتماد کے وقفے

جب ہم بیس بال کھلاڑیوں کے وزن کی بات کرتے ہیں، تو ہم فرض کرتے ہیں کہ ایک **بے ترتیب متغیر W** ہے جو تمام بیس بال کھلاڑیوں کے وزن کی مثالی احتمال کی تقسیم سے مطابقت رکھتا ہے (نام نہاد **آبادی**)। ہمارے وزن کی ترتیب تمام بیس بال کھلاڑیوں کے ایک ذیلی مجموعہ سے مطابقت رکھتی ہے جسے ہم **نمونہ** کہتے ہیں۔ ایک دلچسپ سوال یہ ہے کہ کیا ہم W کی تقسیم کے پیرامیٹرز، یعنی آبادی کے اوسط اور تغیر کو جان سکتے ہیں؟

سب سے آسان جواب یہ ہوگا کہ ہمارے نمونے کے اوسط اور تغیر کا حساب لگائیں۔ تاہم، یہ ممکن ہے کہ ہمارا بے ترتیب نمونہ مکمل آبادی کی درست نمائندگی نہ کرے۔ لہذا اعتماد کے وقفے کے بارے میں بات کرنا معنی خیز ہے۔

> **اعتماد کا وقفہ** ہمارے نمونے کو دیکھتے ہوئے آبادی کے حقیقی اوسط کا تخمینہ ہے، جو ایک خاص احتمال (یا **اعتماد کی سطح**) پر درست ہے۔

فرض کریں کہ ہمارے پاس ایک نمونہ X
<سب>
1</sub>, ..., X<sub>n</sub> ہماری تقسیم سے۔ ہر بار جب ہم اپنی تقسیم سے نمونہ لیتے ہیں، تو ہمیں مختلف اوسط قدر μ ملے گی۔ اس طرح μ کو ایک تصادفی متغیر سمجھا جا سکتا ہے۔ ایک **اعتماد وقفہ** اعتماد p کے ساتھ دو اقدار (L<sub>p</sub>,R<sub>p</sub>) کا جوڑا ہے، اس طرح کہ **P**(L<sub>p</sub>≤μ≤R<sub>p</sub>) = p، یعنی ماپے گئے اوسط قدر کے وقفہ میں آنے کا امکان p کے برابر ہے۔

یہ ہمارے مختصر تعارف سے آگے بڑھتا ہے کہ ان اعتماد وقفوں کو تفصیل سے کیسے حساب کیا جاتا ہے۔ مزید تفصیلات [ویکیپیڈیا](https://en.wikipedia.org/wiki/Confidence_interval) پر مل سکتی ہیں۔ مختصراً، ہم حقیقی آبادی کے اوسط کے مقابلے میں حساب کردہ نمونہ اوسط کی تقسیم کو بیان کرتے ہیں، جسے **طالب علم کی تقسیم** کہا جاتا ہے۔

> **دلچسپ حقیقت**: طالب علم کی تقسیم کا نام ریاضی دان ولیم سیلی گوسٹ کے نام پر رکھا گیا ہے، جنہوں نے اپنا مقالہ "طالب علم" کے قلمی نام سے شائع کیا۔ وہ گینیس بریوری میں کام کرتے تھے، اور ایک روایت کے مطابق، ان کے آجر نہیں چاہتے تھے کہ عام عوام کو معلوم ہو کہ وہ خام مال کے معیار کا تعین کرنے کے لیے شماریاتی ٹیسٹ استعمال کر رہے ہیں۔

اگر ہم اپنی آبادی کے اوسط μ کو اعتماد p کے ساتھ اندازہ لگانا چاہتے ہیں، تو ہمیں طالب علم کی تقسیم A کا *(1-p)/2-واں پرسنٹائل* لینا ہوگا، جو یا تو جدولوں سے لیا جا سکتا ہے، یا شماریاتی سافٹ ویئر (جیسے Python، R، وغیرہ) کے کچھ بلٹ ان فنکشنز کا استعمال کرتے ہوئے کمپیوٹر پر حساب کیا جا سکتا ہے۔ پھر μ کے لیے وقفہ X±A*D/√n ہوگا، جہاں X نمونہ کا حاصل کردہ اوسط ہے، D معیاری انحراف ہے۔

> **نوٹ**: ہم طالب علم کی تقسیم کے تعلق سے ایک اہم تصور [آزادی کے درجات](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)) پر بحث کو بھی چھوڑ دیتے ہیں۔ آپ اس تصور کو گہرائی سے سمجھنے کے لیے شماریات پر مکمل کتابوں کا حوالہ دے سکتے ہیں۔

وزن اور قد کے لیے اعتماد وقفہ کا حساب کرنے کی ایک مثال [ساتھ والے نوٹ بک](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) میں دی گئی ہے۔

| p | وزن کا اوسط |
|-----|-----------|
| 0.85 | 201.73±0.94 |
| 0.90 | 201.73±1.08 |
| 0.95 | 201.73±1.28 |

نوٹ کریں کہ جتنا زیادہ اعتماد کا امکان ہوگا، اتنا ہی وسیع اعتماد وقفہ ہوگا۔

## مفروضہ ٹیسٹنگ

ہمارے بیس بال کھلاڑیوں کے ڈیٹا سیٹ میں مختلف کھلاڑیوں کے کردار ہیں، جنہیں نیچے خلاصہ کیا جا سکتا ہے (دیکھیں [ساتھ والا نوٹ بک](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) کہ یہ جدول کیسے حساب کیا جا سکتا ہے):

| کردار | قد | وزن | تعداد |
|------|--------|--------|-------|
| کیچر | 72.723684 | 204.328947 | 76 |
| نامزد ہٹر | 74.222222 | 220.888889 | 18 |
| فرسٹ بیس مین | 74.000000 | 213.109091 | 55 |
| آؤٹ فیلڈر | 73.010309 | 199.113402 | 194 |
| ریلیف پچر | 74.374603 | 203.517460 | 315 |
| سیکنڈ بیس مین | 71.362069 | 184.344828 | 58 |
| شارٹ اسٹاپ | 71.903846 | 182.923077 | 52 |
| اسٹارٹنگ پچر | 74.719457 | 205.163636 | 221 |
| تھرڈ بیس مین | 73.044444 | 200.955556 | 45 |

ہم دیکھ سکتے ہیں کہ فرسٹ بیس مین کے اوسط قد سیکنڈ بیس مین کے قد سے زیادہ ہیں۔ اس طرح، ہم یہ نتیجہ اخذ کرنے کی طرف مائل ہو سکتے ہیں کہ **فرسٹ بیس مین سیکنڈ بیس مین سے زیادہ لمبے ہیں**۔

> اس بیان کو **ایک مفروضہ** کہا جاتا ہے، کیونکہ ہمیں معلوم نہیں کہ یہ حقیقت میں درست ہے یا نہیں۔

تاہم، یہ ہمیشہ واضح نہیں ہوتا کہ آیا ہم یہ نتیجہ اخذ کر سکتے ہیں۔ اوپر کی بحث سے ہم جانتے ہیں کہ ہر اوسط کے ساتھ ایک اعتماد وقفہ منسلک ہوتا ہے، اور اس طرح یہ فرق محض ایک شماریاتی غلطی ہو سکتا ہے۔ ہمیں اپنے مفروضے کو جانچنے کے لیے کچھ زیادہ رسمی طریقہ کی ضرورت ہے۔

آئیے فرسٹ اور سیکنڈ بیس مین کے قد کے لیے اعتماد وقفے الگ الگ حساب کرتے ہیں:

| اعتماد | فرسٹ بیس مین | سیکنڈ بیس مین |
|------------|---------------|----------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

ہم دیکھ سکتے ہیں کہ کسی بھی اعتماد کے تحت وقفے ایک دوسرے سے اوورلیپ نہیں کرتے۔ یہ ہمارے مفروضے کو ثابت کرتا ہے کہ فرسٹ بیس مین سیکنڈ بیس مین سے زیادہ لمبے ہیں۔

زیادہ رسمی طور پر، مسئلہ جو ہم حل کر رہے ہیں وہ یہ دیکھنا ہے کہ **دو احتمال تقسیم ایک جیسی ہیں**، یا کم از کم ان کے پیرامیٹرز ایک جیسے ہیں۔ تقسیم کے لحاظ سے، ہمیں اس کے لیے مختلف ٹیسٹ استعمال کرنے کی ضرورت ہے۔ اگر ہمیں معلوم ہو کہ ہماری تقسیم نارمل ہیں، تو ہم **[طالب علم ٹی-ٹیسٹ](https://en.wikipedia.org/wiki/Student%27s_t-test)** لاگو کر سکتے ہیں۔

طالب علم ٹی-ٹیسٹ میں، ہم نام نہاد **t-value** کا حساب کرتے ہیں، جو اوسط کے فرق کو ظاہر کرتا ہے، تغیر کو مدنظر رکھتے ہوئے۔ یہ ظاہر کیا گیا ہے کہ t-value **طالب علم کی تقسیم** کی پیروی کرتا ہے، جو ہمیں دیے گئے اعتماد سطح **p** کے لیے حد قدر حاصل کرنے کی اجازت دیتا ہے (یہ حساب کیا جا سکتا ہے، یا عددی جدولوں میں دیکھا جا سکتا ہے)۔ پھر ہم t-value کو اس حد سے موازنہ کرتے ہیں تاکہ مفروضے کو منظور یا مسترد کریں۔

Python میں، ہم **SciPy** پیکیج استعمال کر سکتے ہیں، جس میں `ttest_ind` فنکشن شامل ہے (بہت سے دیگر مفید شماریاتی فنکشنز کے علاوہ!)۔ یہ ہمارے لیے t-value کا حساب کرتا ہے، اور اعتماد p-value کا ریورس لوک اپ بھی کرتا ہے، تاکہ ہم صرف اعتماد کو دیکھ کر نتیجہ اخذ کر سکیں۔

مثال کے طور پر، فرسٹ اور سیکنڈ بیس مین کے قد کے موازنہ سے ہمیں درج ذیل نتائج ملتے ہیں:
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
ہمارے معاملے میں، p-value بہت کم ہے، جس کا مطلب ہے کہ فرسٹ بیس مین کے زیادہ لمبے ہونے کے حق میں مضبوط ثبوت موجود ہیں۔

مفروضے کی جانچ کے دیگر مختلف اقسام بھی ہیں، مثال کے طور پر:
* یہ ثابت کرنا کہ دیا گیا نمونہ کسی تقسیم کی پیروی کرتا ہے۔ ہمارے معاملے میں ہم نے فرض کیا ہے کہ قد نارمل تقسیم ہیں، لیکن اس کی رسمی شماریاتی تصدیق کی ضرورت ہے۔
* یہ ثابت کرنا کہ نمونہ کی اوسط قدر کسی پہلے سے طے شدہ قدر کے مطابق ہے۔
* کئی نمونوں کے اوسط کا موازنہ کرنا (مثلاً مختلف عمر گروپوں میں خوشی کی سطح میں فرق کیا ہے)

## بڑے نمبروں کا قانون اور مرکزی حد نظریہ

نارمل تقسیم اتنی اہم ہونے کی ایک وجہ **مرکزی حد نظریہ** ہے۔ فرض کریں کہ ہمارے پاس آزاد N اقدار X<sub>1</sub>, ..., X<sub>N</sub> کا بڑا نمونہ ہے، جو کسی بھی تقسیم سے اوسط μ اور تغیر σ<sup>2</sup> کے ساتھ نمونہ لیا گیا ہے۔ پھر، کافی بڑے N کے لیے (دوسرے الفاظ میں، جب N→∞)، اوسط Σ<sub>i</sub>X<sub>i</sub> نارمل تقسیم ہوگا، اوسط μ اور تغیر σ<sup>2</sup>/N کے ساتھ۔

> مرکزی حد نظریہ کی ایک اور تشریح یہ ہے کہ قطع نظر تقسیم کے، جب آپ کسی تصادفی متغیر اقدار کے مجموعے کا اوسط حساب کرتے ہیں تو آپ نارمل تقسیم کے ساتھ ختم ہوتے ہیں۔

مرکزی حد نظریہ سے یہ بھی معلوم ہوتا ہے کہ، جب N→∞، نمونہ اوسط کے μ کے برابر ہونے کا امکان 1 بن جاتا ہے۔ یہ **بڑے نمبروں کا قانون** کے نام سے جانا جاتا ہے۔

## کوورینس اور تعلق

ڈیٹا سائنس جو کام کرتی ہے ان میں سے ایک ڈیٹا کے درمیان تعلقات تلاش کرنا ہے۔ ہم کہتے ہیں کہ دو سلسلے **تعلق رکھتے ہیں** جب وہ ایک ہی وقت میں ایک جیسا رویہ ظاہر کرتے ہیں، یعنی وہ یا تو ایک ساتھ بڑھتے/گرتے ہیں، یا ایک سلسلہ بڑھتا ہے جب دوسرا گرتا ہے اور اس کے برعکس۔ دوسرے الفاظ میں، دو سلسلوں کے درمیان کچھ تعلق معلوم ہوتا ہے۔

> تعلق ضروری نہیں کہ دو سلسلوں کے درمیان سببی تعلق کی نشاندہی کرے؛ کبھی کبھی دونوں متغیرات کسی بیرونی وجہ پر منحصر ہو سکتے ہیں، یا یہ محض اتفاقیہ ہو سکتا ہے کہ دونوں سلسلے تعلق رکھتے ہیں۔ تاہم، مضبوط ریاضیاتی تعلق اس بات کی اچھی نشاندہی ہے کہ دو متغیرات کسی نہ کسی طرح جڑے ہوئے ہیں۔

ریاضیاتی طور پر، دو تصادفی متغیرات کے درمیان تعلق ظاہر کرنے والا بنیادی تصور **کوورینس** ہے، جسے اس طرح حساب کیا جاتا ہے: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]۔ ہم دونوں متغیرات کے اوسط اقدار سے انحراف کا حساب کرتے ہیں، اور پھر ان انحرافات کی پیداوار۔ اگر دونوں متغیرات ایک ساتھ انحراف کرتے ہیں، تو پیداوار ہمیشہ ایک مثبت قدر ہوگی، جو مثبت کوورینس میں شامل ہوگی۔ اگر دونوں متغیرات غیر مطابقت سے انحراف کرتے ہیں (یعنی ایک اوسط سے نیچے گرتا ہے جب دوسرا اوسط سے اوپر بڑھتا ہے)، تو ہمیں ہمیشہ منفی نمبر ملیں گے، جو منفی کوورینس میں شامل ہوں گے۔ اگر انحرافات غیر منحصر ہیں، تو وہ تقریباً صفر میں شامل ہوں گے۔

کوورینس کی مطلق قدر ہمیں یہ نہیں بتاتی کہ تعلق کتنا بڑا ہے، کیونکہ یہ اصل اقدار کی شدت پر منحصر ہے۔ اسے معمول پر لانے کے لیے، ہم کوورینس کو دونوں متغیرات کے معیاری انحراف سے تقسیم کر سکتے ہیں، تاکہ **تعلق** حاصل ہو۔ اچھی بات یہ ہے کہ تعلق ہمیشہ [-1,1] کی حد میں ہوتا ہے، جہاں 1 اقدار کے درمیان مضبوط مثبت تعلق کی نشاندہی کرتا ہے، -1 - مضبوط منفی تعلق، اور 0 - بالکل کوئی تعلق نہیں (متغیرات آزاد ہیں)۔

**مثال**: ہم بیس بال کھلاڑیوں کے وزن اور قد کے درمیان تعلق کا حساب کر سکتے ہیں، جیسا کہ اوپر ذکر کردہ ڈیٹا سیٹ سے:
```python
print(np.corrcoef(weights,heights))
```
نتیجے کے طور پر، ہمیں **تعلق میٹرکس** ملتا ہے جیسے یہ:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> تعلق میٹرکس C کسی بھی تعداد کے ان پٹ سلسلوں S<sub>1</sub>, ..., S<sub>n</sub> کے لیے حساب کیا جا سکتا ہے۔ C<sub>ij</sub> کی قدر S<sub>i</sub> اور S<sub>j</sub> کے درمیان تعلق ہے، اور قطر عناصر ہمیشہ 1 ہوتے ہیں (جو S<sub>i</sub> کی خود تعلق بھی ہے)۔

ہمارے معاملے میں، قدر 0.53 اس بات کی نشاندہی کرتی ہے کہ کسی شخص کے وزن اور قد کے درمیان کچھ تعلق ہے۔ ہم ایک قدر کے خلاف دوسرے کی اسکیٹر پلاٹ بھی بنا سکتے ہیں تاکہ تعلق کو بصری طور پر دیکھ سکیں:

![وزن اور قد کے درمیان تعلق](../../../../1-Introduction/04-stats-and-probability/images/weight-height-relationship.png)

> تعلق اور کوورینس کی مزید مثالیں [ساتھ والے نوٹ بک](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) میں مل سکتی ہیں۔

## نتیجہ

اس سیکشن میں، ہم نے سیکھا:

* ڈیٹا کی بنیادی شماریاتی خصوصیات، جیسے اوسط، تغیر، موڈ اور کوارٹائلز
* تصادفی متغیرات کی مختلف تقسیم، بشمول نارمل تقسیم
* مختلف خصوصیات کے درمیان تعلق کیسے تلاش کریں
* کچھ مفروضوں کو ثابت کرنے کے لیے ریاضی اور شماریات کے مضبوط آلات کا استعمال کیسے کریں،
* دیے گئے ڈیٹا نمونے کے لیے تصادفی متغیر کے اعتماد وقفے کیسے حساب کریں

جبکہ یہ احتمال اور شماریات کے اندر موجود موضوعات کی مکمل فہرست نہیں ہے، یہ اس کورس میں آپ کو اچھی شروعات دینے کے لیے کافی ہونا چاہیے۔

## 🚀 چیلنج

نوٹ بک میں دیے گئے نمونہ کوڈ کا استعمال کریں تاکہ دیگر مفروضوں کو جانچیں:
1. فرسٹ بیس مین سیکنڈ بیس مین سے زیادہ عمر کے ہیں
2. فرسٹ بیس مین تھرڈ بیس مین سے زیادہ لمبے ہیں
3. شارٹ اسٹاپ سیکنڈ بیس مین سے زیادہ لمبے ہیں

## [لیکچر کے بعد کوئز](https://ff-quizzes.netlify.app/en/ds/quiz/7)

## جائزہ اور خود مطالعہ

احتمال اور شماریات ایک اتنا وسیع موضوع ہے کہ یہ اپنے کورس کا مستحق ہے۔ اگر آپ نظریہ میں مزید گہرائی میں جانا چاہتے ہیں، تو آپ درج ذیل کتابوں کو پڑھنا جاری رکھ سکتے ہیں:

1. [کارلوس فرنانڈیز-گرینڈا](https://cims.nyu.edu/~cfgranda/) نیویارک یونیورسٹی سے، کے عظیم لیکچر نوٹس [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (آن لائن دستیاب)
1. [پیٹر اور اینڈریو بروس۔ عملی شماریات برائے ڈیٹا سائنسدان۔](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[نمونہ کوڈ R میں](https://github.com/andrewgbruce/statistics-for-data-scientists)]۔
1. [جیمز ڈی. ملر۔ ڈیٹا سائنس کے لیے شماریات](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[نمونہ کوڈ R میں](https://github.com/PacktPublishing/Statistics-for-Data-Science)]

## اسائنمنٹ

[چھوٹا ذیابیطس مطالعہ](assignment.md)

## کریڈٹس

یہ سبق ♥️ کے ساتھ [دمیتری سوشنیکوف](http://soshnikov.com) کے ذریعے لکھا گیا ہے۔

---

**ڈسکلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا عدم درستگی ہو سکتی ہیں۔ اصل دستاویز، جو اس کی اصل زبان میں ہے، کو مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے لیے ہم ذمہ دار نہیں ہیں۔