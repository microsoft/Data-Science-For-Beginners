<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1cf49f029ba1f25a54f0d5bc2fa575fc",
  "translation_date": "2025-09-06T07:17:10+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "bn"
}
-->
# পরিসংখ্যান এবং সম্ভাবনার সংক্ষিপ্ত পরিচিতি

|![ স্কেচনোট [(@sketchthedocs)](https://sketchthedocs.dev) দ্বারা ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| পরিসংখ্যান এবং সম্ভাবনা - _[@nitya](https://twitter.com/nitya) দ্বারা স্কেচনোট_ |

পরিসংখ্যান এবং সম্ভাবনা তত্ত্ব গণিতের দুটি অত্যন্ত সম্পর্কিত ক্ষেত্র যা ডেটা সায়েন্সের জন্য অত্যন্ত গুরুত্বপূর্ণ। গভীর গণিতের জ্ঞান ছাড়াই ডেটা নিয়ে কাজ করা সম্ভব, তবে অন্তত কিছু মৌলিক ধারণা জানা ভালো। এখানে আমরা একটি সংক্ষিপ্ত পরিচিতি উপস্থাপন করব যা আপনাকে শুরু করতে সাহায্য করবে।

[![ভূমিকা ভিডিও](../../../../1-Introduction/04-stats-and-probability/images/video-prob-and-stats.png)](https://youtu.be/Z5Zy85g4Yjw)

## [পূর্ব-লেকচার কুইজ](https://ff-quizzes.netlify.app/en/ds/quiz/6)

## সম্ভাবনা এবং র্যান্ডম ভেরিয়েবল

**সম্ভাবনা** হল 0 এবং 1 এর মধ্যে একটি সংখ্যা যা একটি **ঘটনা** কতটা সম্ভাব্য তা প্রকাশ করে। এটি ইতিবাচক ফলাফলের সংখ্যা (যা ঘটনাটি ঘটায়) দ্বারা সংজ্ঞায়িত হয়, মোট ফলাফলের সংখ্যা দ্বারা ভাগ করে, যদি সমস্ত ফলাফল সমানভাবে সম্ভাব্য হয়। উদাহরণস্বরূপ, যখন আমরা একটি পাশা গড়াই, একটি জোড় সংখ্যার সম্ভাবনা পাওয়ার সম্ভাবনা 3/6 = 0.5।

যখন আমরা ঘটনাগুলি নিয়ে আলোচনা করি, আমরা **র্যান্ডম ভেরিয়েবল** ব্যবহার করি। উদাহরণস্বরূপ, একটি পাশা গড়ানোর সময় প্রাপ্ত সংখ্যাকে উপস্থাপনকারী র্যান্ডম ভেরিয়েবলটি 1 থেকে 6 পর্যন্ত মান নেবে। 1 থেকে 6 পর্যন্ত সংখ্যার সেটটিকে **নমুনা স্থান** বলা হয়। আমরা একটি নির্দিষ্ট মান নেওয়ার র্যান্ডম ভেরিয়েবলের সম্ভাবনা সম্পর্কে কথা বলতে পারি, উদাহরণস্বরূপ P(X=3)=1/6।

পূর্ববর্তী উদাহরণে র্যান্ডম ভেরিয়েবলটিকে **বিচ্ছিন্ন** বলা হয়, কারণ এর একটি গণনাযোগ্য নমুনা স্থান রয়েছে, অর্থাৎ পৃথক মান রয়েছে যা গণনা করা যেতে পারে। এমন কিছু ক্ষেত্রে রয়েছে যেখানে নমুনা স্থানটি বাস্তব সংখ্যার একটি পরিসর বা সম্পূর্ণ সেট। এই ধরনের ভেরিয়েবলগুলিকে **ধারাবাহিক** বলা হয়। একটি ভাল উদাহরণ হল বাস আসার সময়।

## সম্ভাবনা বিতরণ

বিচ্ছিন্ন র্যান্ডম ভেরিয়েবলের ক্ষেত্রে, প্রতিটি ঘটনার সম্ভাবনাকে একটি ফাংশন P(X) দ্বারা বর্ণনা করা সহজ। নমুনা স্থান *S* থেকে প্রতিটি মান *s* এর জন্য এটি 0 থেকে 1 পর্যন্ত একটি সংখ্যা দেবে, যাতে সমস্ত ঘটনার জন্য P(X=s) এর সমস্ত মানের যোগফল 1 হয়।

সবচেয়ে পরিচিত বিচ্ছিন্ন বিতরণ হল **সমUniform Distribution**, যেখানে N উপাদানের একটি নমুনা স্থান রয়েছে, প্রতিটির জন্য সমান সম্ভাবনা 1/N।

ধারাবাহিক ভেরিয়েবলের সম্ভাবনা বিতরণ বর্ণনা করা আরও কঠিন, যার মান কিছু [a,b] অন্তরাল থেকে বা বাস্তব সংখ্যার সম্পূর্ণ সেট ℝ থেকে নেওয়া হয়। বাস আসার সময়ের ক্ষেত্রে বিবেচনা করুন। প্রকৃতপক্ষে, প্রতিটি সুনির্দিষ্ট আসার সময় *t* এর জন্য, বাসটি ঠিক সেই সময়ে আসার সম্ভাবনা 0!

> এখন আপনি জানেন যে 0 সম্ভাবনার ঘটনা ঘটে, এবং খুব ঘন ঘন! অন্তত প্রতিবার যখন বাস আসে!

আমরা শুধুমাত্র একটি ভেরিয়েবলের একটি প্রদত্ত মানের অন্তরালের মধ্যে পড়ার সম্ভাবনা সম্পর্কে কথা বলতে পারি, যেমন P(t<sub>1</sub>≤X<t<sub>2</sub>)। এই ক্ষেত্রে, সম্ভাবনা বিতরণটি একটি **সম্ভাবনা ঘনত্ব ফাংশন** p(x) দ্বারা বর্ণনা করা হয়, যাতে

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../1-Introduction/04-stats-and-probability/images/probability-density.png)

সমUniform Distribution-এর ধারাবাহিক রূপটি **ধারাবাহিক সমUniform** নামে পরিচিত, যা একটি সসীম অন্তরালে সংজ্ঞায়িত। একটি মান X একটি দৈর্ঘ্য l এর অন্তরালে পড়ার সম্ভাবনা l এর সাথে সমানুপাতিক এবং 1 পর্যন্ত বৃদ্ধি পায়।

আরেকটি গুরুত্বপূর্ণ বিতরণ হল **Normal Distribution**, যা আমরা নীচে আরও বিস্তারিতভাবে আলোচনা করব।

## গড়, বৈচিত্র্য এবং স্ট্যান্ডার্ড ডেভিয়েশন

ধরা যাক আমরা একটি র্যান্ডম ভেরিয়েবল X এর n নমুনার একটি ক্রম আঁকি: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>। আমরা **গড়** (বা **গাণিতিক গড়**) মানকে ঐতিহ্যগতভাবে সংজ্ঞায়িত করতে পারি (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n হিসাবে। যখন আমরা নমুনার আকার বাড়াই (অর্থাৎ n→∞ এর সীমা গ্রহণ করি), আমরা বিতরণের গড় (যাকে **প্রত্যাশা**ও বলা হয়) পাই। আমরা প্রত্যাশাকে **E**(x) দ্বারা চিহ্নিত করব।

> এটি প্রদর্শিত হতে পারে যে {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} মান এবং p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub> সম্ভাবনা সহ যেকোনো বিচ্ছিন্ন বিতরণের জন্য, প্রত্যাশা হবে E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>।

মানগুলি কতটা ছড়িয়ে আছে তা চিহ্নিত করতে, আমরা বৈচিত্র্য σ<sup>2</sup> = ∑(x<sub>i</sub> - μ)<sup>2</sup>/n গণনা করতে পারি, যেখানে μ হল ক্রমের গড়। σ কে **স্ট্যান্ডার্ড ডেভিয়েশন** বলা হয় এবং σ<sup>2</sup> কে **বৈচিত্র্য** বলা হয়।

## মোড, মিডিয়ান এবং কোয়ার্টাইল

কখনও কখনও, গড় ডেটার "সাধারণ" মানকে যথাযথভাবে উপস্থাপন করে না। উদাহরণস্বরূপ, যখন কয়েকটি চরম মান থাকে যা সম্পূর্ণরূপে পরিসরের বাইরে থাকে, তারা গড়কে প্রভাবিত করতে পারে। আরেকটি ভাল সূচক হল **মিডিয়ান**, একটি মান যাতে ডেটা পয়েন্টের অর্ধেক তার চেয়ে কম এবং অন্য অর্ধেক - বেশি।

ডেটার বিতরণ বুঝতে সাহায্য করার জন্য, **কোয়ার্টাইল** সম্পর্কে কথা বলা সহায়ক:

* প্রথম কোয়ার্টাইল, বা Q1, একটি মান, যাতে 25% ডেটা তার চেয়ে কম পড়ে
* তৃতীয় কোয়ার্টাইল, বা Q3, একটি মান যাতে 75% ডেটা তার চেয়ে কম পড়ে

গ্রাফিকভাবে আমরা মিডিয়ান এবং কোয়ার্টাইলের মধ্যে সম্পর্ককে **বক্স প্লট** নামে একটি ডায়াগ্রামে উপস্থাপন করতে পারি:

<img src="images/boxplot_explanation.png" width="50%"/>

এখানে আমরা **ইন্টার-কোয়ার্টাইল রেঞ্জ** IQR=Q3-Q1 এবং তথাকথিত **আউটলায়ার** - মানগুলি গণনা করি, যা [Q1-1.5*IQR,Q3+1.5*IQR] সীমানার বাইরে থাকে।

যে সীমিত বিতরণে সম্ভাব্য মানের সংখ্যা কম থাকে, একটি ভাল "সাধারণ" মান হল সেই মান যা সবচেয়ে বেশি ঘন ঘন উপস্থিত হয়, যাকে **মোড** বলা হয়। এটি প্রায়শই শ্রেণীবদ্ধ ডেটার ক্ষেত্রে প্রয়োগ করা হয়, যেমন রং। একটি পরিস্থিতি বিবেচনা করুন যেখানে আমাদের দুটি গোষ্ঠী রয়েছে - কিছু যারা লালকে দৃঢ়ভাবে পছন্দ করে এবং অন্যরা যারা নীলকে পছন্দ করে। যদি আমরা সংখ্যার দ্বারা রং কোড করি, প্রিয় রঙের গড় মানটি কমলা-সবুজ বর্ণালীতে কোথাও হবে, যা প্রকৃত পছন্দকে নির্দেশ করে না। তবে, মোডটি হয় একটি রঙ হবে, অথবা উভয় রঙ হবে, যদি তাদের জন্য ভোট দেওয়া লোকের সংখ্যা সমান হয় (এই ক্ষেত্রে আমরা নমুনাকে **মাল্টিমোডাল** বলি)।

## বাস্তব-জগতের ডেটা

যখন আমরা বাস্তব জীবনের ডেটা বিশ্লেষণ করি, তারা প্রায়শই র্যান্ডম ভেরিয়েবল নয়, অর্থাৎ আমরা অজানা ফলাফলের সাথে পরীক্ষা করি না। উদাহরণস্বরূপ, একটি বেসবল খেলোয়াড়দের দল এবং তাদের শরীরের ডেটা, যেমন উচ্চতা, ওজন এবং বয়স বিবেচনা করুন। এই সংখ্যাগুলি ঠিক র্যান্ডম নয়, তবে আমরা এখনও একই গণিতীয় ধারণাগুলি প্রয়োগ করতে পারি। উদাহরণস্বরূপ, মানুষের ওজনের একটি ক্রমকে কিছু র্যান্ডম ভেরিয়েবল থেকে নেওয়া মানগুলির একটি ক্রম হিসাবে বিবেচনা করা যেতে পারে। নীচে [মেজর লীগ বেসবল](http://mlb.mlb.com/index.jsp) থেকে আসা প্রকৃত বেসবল খেলোয়াড়দের ওজনের ক্রম রয়েছে, [এই ডেটাসেট](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) থেকে নেওয়া হয়েছে (আপনার সুবিধার জন্য, শুধুমাত্র প্রথম 20 মান দেখানো হয়েছে):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Note**: এই ডেটাসেট নিয়ে কাজ করার উদাহরণ দেখতে, [সংযুক্ত নোটবুক](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) দেখুন। এই পাঠে বেশ কিছু চ্যালেঞ্জ রয়েছে, এবং আপনি সেই নোটবুকে কিছু কোড যোগ করে সেগুলি সম্পূর্ণ করতে পারেন। যদি আপনি ডেটা নিয়ে কাজ করতে না জানেন, চিন্তা করবেন না - আমরা পরে পাইথন ব্যবহার করে ডেটা নিয়ে কাজ করার জন্য ফিরে আসব। যদি আপনি জুপিটার নোটবুকে কোড চালানোর পদ্ধতি না জানেন, [এই নিবন্ধটি](https://soshnikov.com/education/how-to-execute-notebooks-from-github/) দেখুন।

এখানে আমাদের ডেটার জন্য গড়, মিডিয়ান এবং কোয়ার্টাইল দেখানো একটি বক্স প্লট রয়েছে:

![Weight Box Plot](../../../../1-Introduction/04-stats-and-probability/images/weight-boxplot.png)

আমাদের ডেটা বিভিন্ন খেলোয়াড়ের **ভূমিকা** সম্পর্কে তথ্য ধারণ করে, আমরা ভূমিকা অনুসারে বক্স প্লটও করতে পারি - এটি আমাদের পরামিতি মানগুলি ভূমিকা জুড়ে কীভাবে আলাদা হয় তা সম্পর্কে ধারণা পেতে সাহায্য করবে। এবার আমরা উচ্চতা বিবেচনা করব:

![Box plot by role](../../../../1-Introduction/04-stats-and-probability/images/boxplot_byrole.png)

এই ডায়াগ্রামটি পরামর্শ দেয় যে, গড়ে, প্রথম বেসম্যানদের উচ্চতা দ্বিতীয় বেসম্যানদের উচ্চতার চেয়ে বেশি। এই পাঠে পরে আমরা আরও আনুষ্ঠানিকভাবে এই অনুমানটি পরীক্ষা করার এবং আমাদের ডেটা পরিসংখ্যানগতভাবে গুরুত্বপূর্ণ তা দেখানোর পদ্ধতি শিখব।

> বাস্তব-জগতের ডেটা নিয়ে কাজ করার সময়, আমরা ধরে নিই যে সমস্ত ডেটা পয়েন্টগুলি কিছু সম্ভাবনা বিতরণ থেকে নেওয়া নমুনা। এই অনুমানটি আমাদের মেশিন লার্নিং কৌশল প্রয়োগ করতে এবং কার্যকর ভবিষ্যদ্বাণীমূলক মডেল তৈরি করতে দেয়।

আমাদের ডেটার বিতরণটি দেখতে, আমরা **হিস্টোগ্রাম** নামে একটি গ্রাফ আঁকতে পারি। X-অক্ষটি বিভিন্ন ওজনের অন্তরালের সংখ্যা (তথাকথিত **বিন**) ধারণ করবে এবং উল্লম্ব অক্ষটি দেখাবে যে আমাদের র্যান্ডম ভেরিয়েবল নমুনাটি একটি প্রদত্ত অন্তরালের মধ্যে কতবার ছিল।

![Histogram of real world data](../../../../1-Introduction/04-stats-and-probability/images/weight-histogram.png)

এই হিস্টোগ্রাম থেকে আপনি দেখতে পারেন যে সমস্ত মান একটি নির্দিষ্ট গড় ওজনের চারপাশে কেন্দ্রীভূত, এবং আমরা সেই ওজন থেকে যত দূরে যাই - সেই মানের ওজনের সংখ্যা তত কম। অর্থাৎ, একটি বেসবল খেলোয়াড়ের ওজন গড় ওজন থেকে খুব আলাদা হওয়া খুবই অসম্ভব। ওজনের বৈচিত্র্য দেখায় যে ওজনগুলি গড় থেকে কতটা আলাদা হতে পারে।

> যদি আমরা অন্য লোকেদের ওজন নিই, যারা বেসবল লিগের অন্তর্ভুক্ত নয়, বিতরণটি সম্ভবত ভিন্ন হবে। তবে, বিতরণের আকৃতি একই থাকবে, তবে গড় এবং বৈচিত্র্য পরিবর্তিত হবে। সুতরাং, যদি আমরা আমাদের মডেলটি বেসবল খেলোয়াড়দের উপর প্রশিক্ষণ দিই, এটি বিশ্ববিদ্যালয়ের ছাত্রদের উপর প্রয়োগ করার সময় ভুল ফলাফল দিতে পারে, কারণ অন্তর্নিহিত বিতরণটি ভিন্ন।

## Normal Distribution

উপরের ওজনের বিতরণটি খুবই সাধারণ, এবং বাস্তব জগতের অনেক পরিমাপ একই ধরনের বিতরণ অনুসরণ করে, তবে বিভিন্ন গড় এবং বৈচিত্র্য সহ। এই বিতরণটিকে **Normal Distribution** বলা হয়, এবং এটি পরিসংখ্যানের ক্ষেত্রে একটি অত্যন্ত গুরুত্বপূর্ণ ভূমিকা পালন করে।

Normal Distribution ব্যবহার করে সম্ভাব্য বেসবল খেলোয়াড়দের র্যান্ডম ওজন তৈরি করা একটি সঠিক পদ্ধতি। একবার আমরা গড় ওজন `mean` এবং স্ট্যান্ডার্ড ডেভিয়েশন `std` জানলে, আমরা নিম্নলিখিতভাবে 1000 ওজনের নমুনা তৈরি করতে পারি:
```python
samples = np.random.normal(mean,std,1000)
``` 

যদি আমরা তৈরি করা নমুনার হিস্টোগ্রাম আঁকি, আমরা উপরের ছবির সাথে খুব মিল দেখতে পাব। এবং যদি আমরা নমুনার সংখ্যা এবং বিনের সংখ্যা বাড়াই, আমরা একটি Normal Distribution-এর একটি ছবি তৈরি করতে পারি যা আদর্শের কাছাকাছি:

![Normal Distribution with mean=0 and std.dev=1](../../../../1-Introduction/04-stats-and-probability/images/normal-histogram.png)

*গড়=0 এবং স্ট্যান্ডার্ড ডেভিয়েশন=1 সহ Normal Distribution*

## Confidence Intervals

যখন আমরা বেসবল খেলোয়াড়দের ওজন নিয়ে কথা বলি, আমরা ধরে নিই যে একটি **র্যান্ডম ভেরিয়েবল W** রয়েছে যা সমস্ত বেসবল খেলোয়াড়দের ওজনের আদর্শ সম্ভাবনা বিতরণকে নির্দেশ করে (তথাকথিত **জনসংখ্যা**)। আমাদের ওজনের ক্রমটি সমস্ত বেসবল খেলোয়াড়দের একটি উপসেটের সাথে মিলে যায়, যাকে আমরা **নমুনা** বলি। একটি আকর্ষণীয় প্রশ্ন হল, আমরা কি W-এর বিতরণের পরামিতিগুলি জানতে পারি, অর্থাৎ জনসংখ্যার গড় এবং বৈচিত্র্য?

সবচেয়ে সহজ উত্তর হবে আমাদের নমুনার গড় এবং বৈচিত্র্য গণনা করা। তবে, এটি ঘটতে পারে যে আমাদের র্যান্ডম নমুনা সম্পূর্ণ জনসংখ্যাকে সঠিকভাবে উপস্থাপন করে না। সুতরাং **Confidence Interval** সম্পর্কে কথা বলা অর্থপূর্ণ।

> **Confidence Interval** হল আমাদের নমুনা দেওয়া জনসংখ্যার প্রকৃত গড়ের অনুমান, যা একটি নির্দিষ্ট সম্ভাবনার (বা **Confidence Level**) সাথে সঠিক।
<sub>
1</sub>, ..., X<sub>n</sub> আমাদের ডিস্ট্রিবিউশন থেকে। প্রতিবার আমরা আমাদের ডিস্ট্রিবিউশন থেকে একটি নমুনা সংগ্রহ করি, আমরা ভিন্ন গড় মান μ পাব। তাই μ কে একটি র‍্যান্ডম ভেরিয়েবল হিসেবে বিবেচনা করা যেতে পারে। একটি **confidence interval** যার confidence p হল একটি মানের জোড়া (L<sub>p</sub>,R<sub>p</sub>), যাতে **P**(L<sub>p</sub>≤μ≤R<sub>p</sub>) = p, অর্থাৎ পরিমাপিত গড় মানের এই ইন্টারভালের মধ্যে পড়ার সম্ভাবনা p এর সমান।

এই confidence interval কীভাবে গণনা করা হয় তা বিস্তারিতভাবে আলোচনা করা আমাদের সংক্ষিপ্ত পরিচয়ের বাইরে। আরও কিছু তথ্য [উইকিপিডিয়ায়](https://en.wikipedia.org/wiki/Confidence_interval) পাওয়া যেতে পারে। সংক্ষেপে, আমরা প্রকৃত জনসংখ্যার গড়ের তুলনায় গণিতকৃত নমুনার গড়ের ডিস্ট্রিবিউশন সংজ্ঞায়িত করি, যা **student distribution** নামে পরিচিত।

> **মজার তথ্য**: Student distribution এর নামকরণ করা হয়েছে গণিতবিদ উইলিয়াম সিলি গোসেট এর নামে, যিনি "Student" ছদ্মনামে তার গবেষণা প্রকাশ করেছিলেন। তিনি গিনেস ব্রুয়ারিতে কাজ করতেন, এবং একটি মতানুযায়ী, তার নিয়োগকর্তা সাধারণ জনগণকে জানাতে চাননি যে তারা কাঁচামালের গুণমান নির্ধারণে পরিসংখ্যানগত পরীক্ষা ব্যবহার করছিলেন।

যদি আমরা আমাদের জনসংখ্যার গড় μ কে confidence p দিয়ে অনুমান করতে চাই, তাহলে আমাদের Student distribution A এর *(1-p)/2-th percentile* নিতে হবে, যা টেবিল থেকে নেওয়া যেতে পারে বা পরিসংখ্যান সফটওয়্যারের (যেমন Python, R, ইত্যাদি) কিছু বিল্ট-ইন ফাংশন ব্যবহার করে গণনা করা যেতে পারে। এরপর μ এর ইন্টারভাল হবে X±A*D/√n, যেখানে X হল নমুনার প্রাপ্ত গড়, D হল standard deviation।

> **Note**: আমরা [degrees of freedom](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)) এর একটি গুরুত্বপূর্ণ ধারণার আলোচনা এড়িয়ে যাচ্ছি, যা Student distribution এর সাথে সম্পর্কিত। এই ধারণা আরও গভীরভাবে বুঝতে পরিসংখ্যানের সম্পূর্ণ বইগুলোতে রেফার করা যেতে পারে।

ওজন এবং উচ্চতার জন্য confidence interval গণনার একটি উদাহরণ [সংযুক্ত নোটবুকে](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) দেওয়া হয়েছে।

| p | Weight mean |
|-----|-----------|
| 0.85 | 201.73±0.94 |
| 0.90 | 201.73±1.08 |
| 0.95 | 201.73±1.28 |

লক্ষ্য করুন যে confidence probability যত বেশি হয়, confidence interval তত বেশি প্রশস্ত হয়।

## Hypothesis Testing 

আমাদের বেসবল খেলোয়াড়দের dataset-এ বিভিন্ন খেলোয়াড়ের ভূমিকা রয়েছে, যা নিচে সংক্ষেপে দেওয়া হলো (এই টেবিল কীভাবে গণনা করা যায় তা দেখতে [সংযুক্ত নোটবুক](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) দেখুন):

| Role | Height | Weight | Count |
|------|--------|--------|-------|
| Catcher | 72.723684 | 204.328947 | 76 |
| Designated_Hitter | 74.222222 | 220.888889 | 18 |
| First_Baseman | 74.000000 | 213.109091 | 55 |
| Outfielder | 73.010309 | 199.113402 | 194 |
| Relief_Pitcher | 74.374603 | 203.517460 | 315 |
| Second_Baseman | 71.362069 | 184.344828 | 58 |
| Shortstop | 71.903846 | 182.923077 | 52 |
| Starting_Pitcher | 74.719457 | 205.163636 | 221 |
| Third_Baseman | 73.044444 | 200.955556 | 45 |

আমরা লক্ষ্য করতে পারি যে first basemen এর গড় উচ্চতা second basemen এর তুলনায় বেশি। তাই আমরা এই সিদ্ধান্তে পৌঁছাতে পারি যে **first basemen এর উচ্চতা second basemen এর তুলনায় বেশি**।

> এই বিবৃতিকে **hypothesis** বলা হয়, কারণ আমরা জানি না এই তথ্যটি আসলে সত্য কিনা।

তবে, এই সিদ্ধান্ত নেওয়া সবসময় স্পষ্ট নয়। উপরের আলোচনায় আমরা জানি যে প্রতিটি গড়ের সাথে একটি confidence interval যুক্ত থাকে, এবং এই পার্থক্যটি শুধুমাত্র একটি পরিসংখ্যানগত ত্রুটি হতে পারে। আমাদের hypothesis পরীক্ষা করার জন্য আরও আনুষ্ঠানিক পদ্ধতি প্রয়োজন।

চলুন first এবং second basemen এর উচ্চতার জন্য আলাদাভাবে confidence interval গণনা করি:

| Confidence | First Basemen | Second Basemen |
|------------|---------------|----------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

আমরা দেখতে পাই যে কোনো confidence এর অধীনে এই ইন্টারভালগুলো overlap করে না। এটি প্রমাণ করে যে first basemen এর উচ্চতা second basemen এর তুলনায় বেশি।

আরও আনুষ্ঠানিকভাবে, আমরা যে সমস্যাটি সমাধান করছি তা হল **দুটি probability distribution একই কিনা**, অথবা অন্তত তাদের একই parameter আছে কিনা। distribution এর উপর নির্ভর করে, আমাদের জন্য বিভিন্ন পরীক্ষা প্রযোজ্য। যদি আমরা জানি যে আমাদের distribution গুলো normal, তাহলে আমরা **[Student t-test](https://en.wikipedia.org/wiki/Student%27s_t-test)** প্রয়োগ করতে পারি।

Student t-test এ, আমরা তথাকথিত **t-value** গণনা করি, যা variance বিবেচনা করে গড়ের পার্থক্য নির্দেশ করে। এটি প্রমাণিত হয়েছে যে t-value **student distribution** অনুসরণ করে, যা আমাদের একটি নির্দিষ্ট confidence level **p** এর জন্য threshold value পেতে সাহায্য করে (এটি গণনা করা যেতে পারে, অথবা সংখ্যাসূচক টেবিল থেকে দেখা যেতে পারে)। আমরা এই t-value কে threshold এর সাথে তুলনা করি hypothesis অনুমোদন বা প্রত্যাখ্যান করার জন্য।

Python-এ, আমরা **SciPy** প্যাকেজ ব্যবহার করতে পারি, যা `ttest_ind` ফাংশন অন্তর্ভুক্ত করে (অন্যান্য অনেক দরকারী পরিসংখ্যানগত ফাংশন সহ!)। এটি আমাদের জন্য t-value গণনা করে এবং confidence p-value এর reverse lookup করে, যাতে আমরা শুধুমাত্র confidence দেখে সিদ্ধান্ত নিতে পারি।

উদাহরণস্বরূপ, first এবং second basemen এর উচ্চতার তুলনা আমাদের নিম্নলিখিত ফলাফল দেয়: 
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
আমাদের ক্ষেত্রে, p-value খুবই কম, যা প্রমাণ করে যে first basemen এর উচ্চতা বেশি।

এছাড়াও বিভিন্ন ধরনের hypothesis রয়েছে যা আমরা পরীক্ষা করতে চাইতে পারি, যেমন:
* প্রমাণ করা যে একটি নির্দিষ্ট নমুনা কোনো distribution অনুসরণ করে। আমাদের ক্ষেত্রে আমরা ধরে নিয়েছি যে উচ্চতা normal distribution অনুসরণ করে, কিন্তু এটি আনুষ্ঠানিক পরিসংখ্যানগত যাচাই প্রয়োজন।
* প্রমাণ করা যে একটি নমুনার গড় মান কোনো পূর্বনির্ধারিত মানের সাথে মিলে যায়
* একাধিক নমুনার গড়ের তুলনা করা (যেমন: বিভিন্ন বয়সের গ্রুপের মধ্যে সুখের স্তরের পার্থক্য)

## Law of Large Numbers and Central Limit Theorem

Normal distribution এত গুরুত্বপূর্ণ হওয়ার একটি কারণ হল **central limit theorem**। ধরুন আমাদের কাছে N সংখ্যক স্বাধীন মান X<sub>1</sub>, ..., X<sub>N</sub> এর একটি বড় নমুনা রয়েছে, যা কোনো distribution থেকে গড় μ এবং variance σ<sup>2</sup> সহ সংগ্রহ করা হয়েছে। তাহলে, যথেষ্ট বড় N এর জন্য (অন্য কথায়, যখন N→∞), গড় Σ<sub>i</sub>X<sub>i</sub> normal distribution অনুসরণ করবে, যার গড় μ এবং variance σ<sup>2</sup>/N।

> Central limit theorem এর আরেকটি ব্যাখ্যা হল যে, যেকোনো random variable এর মানের যোগফলের গড় গণনা করলে আপনি normal distribution পাবেন।

Central limit theorem থেকে আরও বোঝা যায় যে, যখন N→∞, নমুনার গড় μ এর সমান হওয়ার সম্ভাবনা 1 হয়ে যায়। এটি **law of large numbers** নামে পরিচিত।

## Covariance and Correlation

Data Science এর একটি কাজ হল ডেটার মধ্যে সম্পর্ক খুঁজে বের করা। আমরা বলি যে দুটি sequence **correlate** করে যখন তারা একই সময়ে একই আচরণ প্রদর্শন করে, অর্থাৎ তারা একসাথে বৃদ্ধি/হ্রাস পায়, অথবা একটি sequence বৃদ্ধি পায় যখন অন্যটি হ্রাস পায় এবং এর বিপরীত। অন্য কথায়, দুটি sequence এর মধ্যে কিছু সম্পর্ক রয়েছে বলে মনে হয়।

> Correlation সবসময় দুটি sequence এর মধ্যে কারণগত সম্পর্ক নির্দেশ করে না; কখনও কখনও উভয় ভেরিয়েবল কোনো বাহ্যিক কারণের উপর নির্ভর করতে পারে, অথবা এটি সম্পূর্ণভাবে কাকতালীয় হতে পারে যে দুটি sequence correlate করে। তবে, শক্তিশালী গাণিতিক correlation একটি ভালো ইঙ্গিত দেয় যে দুটি ভেরিয়েবল কোনোভাবে সংযুক্ত।

গাণিতিকভাবে, দুটি random variable এর মধ্যে সম্পর্ক দেখানোর প্রধান ধারণা হল **covariance**, যা এইভাবে গণনা করা হয়: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]। আমরা উভয় ভেরিয়েবল এর গড় মান থেকে deviation গণনা করি, এবং তারপর সেই deviation এর গুণফল। যদি উভয় ভেরিয়েবল একসাথে deviate করে, গুণফল সবসময় একটি ধনাত্মক মান হবে, যা ধনাত্মক covariance যোগ করবে। যদি উভয় ভেরিয়েবল out-of-sync deviate করে (অর্থাৎ একটি গড়ের নিচে পড়ে যখন অন্যটি গড়ের উপরে উঠে), আমরা সবসময় ঋণাত্মক সংখ্যা পাব, যা ঋণাত্মক covariance যোগ করবে। যদি deviation গুলো নির্ভরশীল না হয়, তারা আনুমানিক শূন্য যোগ করবে।

Covariance এর absolute মান আমাদের correlation এর মাত্রা সম্পর্কে খুব বেশি কিছু বলে না, কারণ এটি প্রকৃত মানের মাত্রার উপর নির্ভর করে। এটি normal করতে, আমরা covariance কে উভয় ভেরিয়েবল এর standard deviation দিয়ে ভাগ করতে পারি, যাতে **correlation** পাওয়া যায়। ভালো দিক হল correlation সবসময় [-1,1] এর মধ্যে থাকে, যেখানে 1 মানে মানগুলোর মধ্যে শক্তিশালী ধনাত্মক সম্পর্ক, -1 মানে শক্তিশালী ঋণাত্মক সম্পর্ক, এবং 0 মানে কোনো সম্পর্ক নেই (ভেরিয়েবল গুলো স্বাধীন)।

**উদাহরণ**: আমরা বেসবল খেলোয়াড়দের dataset থেকে ওজন এবং উচ্চতার মধ্যে correlation গণনা করতে পারি:
```python
print(np.corrcoef(weights,heights))
```
ফলস্বরূপ, আমরা একটি **correlation matrix** পাই যা এইরকম:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> Correlation matrix C যেকোনো সংখ্যক input sequence S<sub>1</sub>, ..., S<sub>n</sub> এর জন্য গণনা করা যেতে পারে। C<sub>ij</sub> এর মান হল S<sub>i</sub> এবং S<sub>j</sub> এর মধ্যে correlation, এবং diagonal elements সবসময় 1 হয় (যা S<sub>i</sub> এর self-correlation)।

আমাদের ক্ষেত্রে, মান 0.53 নির্দেশ করে যে একজন ব্যক্তির ওজন এবং উচ্চতার মধ্যে কিছু সম্পর্ক রয়েছে। আমরা একটি scatter plot তৈরি করতে পারি যেখানে একটি মান অন্যটির বিরুদ্ধে চিত্রিত করা হয়, যাতে সম্পর্কটি দৃশ্যমান হয়:

![ওজন এবং উচ্চতার মধ্যে সম্পর্ক](../../../../1-Introduction/04-stats-and-probability/images/weight-height-relationship.png)

> Correlation এবং covariance এর আরও উদাহরণ [সংযুক্ত নোটবুকে](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) পাওয়া যেতে পারে।

## Conclusion

এই অংশে আমরা শিখেছি:

* ডেটার মৌলিক পরিসংখ্যানগত বৈশিষ্ট্য, যেমন গড়, variance, mode এবং quartiles
* random variable এর বিভিন্ন distribution, যার মধ্যে normal distribution অন্তর্ভুক্ত
* বিভিন্ন বৈশিষ্ট্যের মধ্যে সম্পর্ক খুঁজে বের করার পদ্ধতি
* কিছু hypothesis প্রমাণ করার জন্য গণিত এবং পরিসংখ্যানের সঠিক apparatus ব্যবহার করার পদ্ধতি
* ডেটা নমুনা থেকে random variable এর জন্য confidence interval গণনা করার পদ্ধতি

যদিও এটি probability এবং statistics এর মধ্যে বিদ্যমান বিষয়গুলোর একটি সম্পূর্ণ তালিকা নয়, এটি এই কোর্সে একটি ভালো সূচনা দেওয়ার জন্য যথেষ্ট।

## 🚀 Challenge

নোটবুকে দেওয়া নমুনা কোড ব্যবহার করে নিম্নলিখিত hypothesis পরীক্ষা করুন: 
1. First basemen এর বয়স second basemen এর তুলনায় বেশি
2. First basemen এর উচ্চতা third basemen এর তুলনায় বেশি
3. Shortstops এর উচ্চতা second basemen এর তুলনায় বেশি

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ds/quiz/7)

## Review & Self Study

Probability এবং statistics এত বিস্তৃত একটি বিষয় যে এটি একটি আলাদা কোর্সের যোগ্য। আপনি যদি তত্ত্বে আরও গভীরভাবে যেতে আগ্রহী হন, তাহলে আপনি নিম্নলিখিত বইগুলো পড়তে চাইতে পারেন:

1. [Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/) নিউ ইয়র্ক ইউনিভার্সিটি থেকে [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (অনলাইনে উপলব্ধ) এর চমৎকার লেকচার নোট।
1. [Peter এবং Andrew Bruce. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[R এ নমুনা কোড](https://github.com/andrewgbruce/statistics-for-data-scientists)]। 
1. [James D. Miller. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[R এ নমুনা কোড](https://github.com/PacktPublishing/Statistics-for-Data-Science)]।

## Assignment

[Small Diabetes Study](assignment.md)

## Credits

এই পাঠটি ♥️ দিয়ে [Dmitry Soshnikov](http://soshnikov.com) দ্বারা রচিত।

---

**অস্বীকৃতি**:  
এই নথিটি AI অনুবাদ পরিষেবা [Co-op Translator](https://github.com/Azure/co-op-translator) ব্যবহার করে অনুবাদ করা হয়েছে। আমরা যথাসম্ভব সঠিক অনুবাদ প্রদানের চেষ্টা করি, তবে অনুগ্রহ করে মনে রাখবেন যে স্বয়ংক্রিয় অনুবাদে ত্রুটি বা অসঙ্গতি থাকতে পারে। মূল ভাষায় থাকা নথিটিকে প্রামাণিক উৎস হিসেবে বিবেচনা করা উচিত। গুরুত্বপূর্ণ তথ্যের জন্য, পেশাদার মানব অনুবাদ সুপারিশ করা হয়। এই অনুবাদ ব্যবহারের ফলে কোনো ভুল বোঝাবুঝি বা ভুল ব্যাখ্যা হলে আমরা তার জন্য দায়ী থাকব না।