{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# সম্ভাবনা এবং পরিসংখ্যানের পরিচিতি\n",
    "এই নোটবুকে, আমরা পূর্বে আলোচনা করা কিছু ধারণার সাথে খেলাবো। সম্ভাবনা এবং পরিসংখ্যানের অনেক ধারণা পাইথনের ডেটা প্রসেসিংয়ের প্রধান লাইব্রেরিগুলিতে ভালভাবে উপস্থাপিত রয়েছে, যেমন `numpy` এবং `pandas`।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## র‍্যান্ডম ভেরিয়েবল এবং বণ্টনসমূহ\n",
    "চলুন 0 থেকে 9 পর্যন্ত একটি সমজাতীয় বণ্টন থেকে ৩০টি মানের একটি নমুনা আঁকি। আমরা গড় এবং বৈচিত্র্যও হিসাব করব।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [ random.randint(0,10) for _ in range(30) ]\n",
    "print(f\"Sample: {sample}\")\n",
    "print(f\"Mean = {np.mean(sample)}\")\n",
    "print(f\"Variance = {np.var(sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "নমুনায় কতগুলি ভিন্ন মান রয়েছে তা بصریভাবে অনুমান করতে, আমরা **হিস্টোগ্রাম** অঙ্কন করতে পারি:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## বাস্তব ডেটা বিশ্লেষণ\n",
    "\n",
    "গড় এবং বৈচিত্র্য বাস্তব-জগতের ডেটা বিশ্লেষণে খুবই গুরুত্বপূর্ণ। চলুন [SOCR MLB Height/Weight Data](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) থেকে বেসবল খেলোয়াড়দের ডেটা লোড করি।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/SOCR_MLB.tsv\",sep='\\t', header=None, names=['Name','Team','Role','Weight','Height','Age'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> আমরা এখানে ডেটা বিশ্লেষণের জন্য [**Pandas**](https://pandas.pydata.org/) নামক একটি প্যাকেজ ব্যবহার করছি। আমরা এই কোর্সের পরবর্তী অংশে Pandas এবং পাইথনে ডেটার সাথে কাজ করার বিষয়ে আরও আলোচনা করব।\n",
    "\n",
    "চলুন বয়স, উচ্চতা এবং ওজনের গড় মান গণনা করি:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Age','Height','Weight']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "এখন চলুন উচ্চতার ওপর মনোযোগ দেওয়া যাক, এবং স্ট্যান্ডার্ড ডিভিয়েশন ও বৈচিত্র্য (ভ্যারিয়েন্স) গণনা করা যাক:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df['Height'])[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df['Height'].mean()\n",
    "var = df['Height'].var()\n",
    "std = df['Height'].std()\n",
    "print(f\"Mean = {mean}\\nVariance = {var}\\nStandard Deviation = {std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "গড়ের পাশাপাশি, মধ্যমমান এবং চতুর্থাংশগুলো দেখা বোধগম্য। সেগুলোকে **বক্স প্লট** ব্যবহার করে দৃশ্যমান করা যায়:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2))\n",
    "plt.boxplot(df['Height'].ffill(), vert=False, showmeans=True)\n",
    "plt.grid(color='gray', linestyle='dotted')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "আমরা আমাদের ডেটাসেটের উপসেটগুলির বক্স প্লটও করতে পারি, উদাহরণস্বরূপ, প্লেয়ারের ভূমিকা অনুযায়ী গোষ্ঠীবদ্ধ করে।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='Height', by='Role', figsize=(10,8))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **নোট**: এই চিত্রটি নির্দেশ করে, যে গড়ে প্রথম বেসম্যানদের উচ্চতা দ্বিতীয় বেসম্যানদের উচ্চতার চেয়ে বেশি। পরে আমরা শিখব কীভাবে এই অনুমানটিকে আরও আনুষ্ঠানিকভাবে পরীক্ষা করা যায়, এবং কীভাবে প্রদর্শন করা যায় যে আমাদের ডেটা পরিসংখ্যানগতভাবে তা প্রদর্শনের জন্য গুরুত্বপূর্ণ।  \n",
    "\n",
    "বয়স, উচ্চতা এবং ওজন সবই ধারাবাহিক র্যান্ডম ভেরিয়েবল। আপনি কী মনে করেন তাদের বন্টন কী হতে পারে? একটি ভাল উপায় হল মানগুলির হিস্টোগ্রাম আঁকা: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weight'].hist(bins=15, figsize=(10,6))\n",
    "plt.suptitle('Weight distribution of MLB Players')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Distribution\n",
    "\n",
    "চলুন একটি কৃত্রিম ওজন নমুনা তৈরি করি যা আমাদের বাস্তব ডেটার সমান গড় এবং বৈচিত্র্যের সাথে একটি স্বাভাবিক বণ্টন অনুসরণ করে:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = np.random.normal(mean, std, 1000)\n",
    "generated[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(generated, bins=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(np.random.normal(0,1,50000), bins=300)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "কারণ বাস্তবে অধিকাংশ মান সাধারণত স্বাভাবিক বণ্টিত থাকে, আমরা নমুনা ডেটা তৈরির জন্য ইউনিফর্ম র্যান্ডম নম্বর জেনারেটর ব্যবহার করা উচিত নয়। এখানে কী হয় যখন আমরা ইউনিফর্ম ডিস্ট্রিবিউশন দিয়ে ওজন তৈরি করার চেষ্টা করি (যা `np.random.rand` দ্বারা তৈরি):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_sample = np.random.rand(1000)*2*std+mean-std\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(wrong_sample)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## বিশ্বাসযোগ্যতা অন্তর\n",
    "\n",
    "এবার চলুন বেসবল খেলোয়াড়দের ওজন এবং উচ্চতার জন্য বিশ্বাসযোগ্যতা অন্তর গণনা করি। আমরা [এই স্ট্যাকওভারফ্লো আলোচনার](https://stackoverflow.com/questions/15033511/compute-a-confidence-interval-from-sample-data) কোড ব্যবহার করব:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, h\n",
    "\n",
    "for p in [0.85, 0.9, 0.95]:\n",
    "    m, h = mean_confidence_interval(df['Weight'].fillna(method='pad'),p)\n",
    "    print(f\"p={p:.2f}, mean = {m:.2f} ± {h:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## অনুমান পরীক্ষা\n",
    "\n",
    "চলুন আমাদের বেসবল খেলোয়াড়দের ডেটাসেটে বিভিন্ন ভূমিকা অন্বেষণ করি:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Role').agg({ 'Weight' : 'mean', 'Height' : 'mean', 'Age' : 'count'}).rename(columns={ 'Age' : 'Count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "চলুন এই অনুমানটি পরীক্ষা করি যে প্রথম বেসম্যানরা দ্বিতীয় বেসম্যানদের চেয়ে লম্বা। এটি পরীক্ষা করার সবচেয়ে সহজ উপায় হলো আত্মবিশ্বাসের ইন্টারভাল পরীক্ষা করা:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [0.85,0.9,0.95]:\n",
    "    m1, h1 = mean_confidence_interval(df.loc[df['Role']=='First_Baseman',['Height']],p)\n",
    "    m2, h2 = mean_confidence_interval(df.loc[df['Role']=='Second_Baseman',['Height']],p)\n",
    "    print(f'Conf={p:.2f}, 1st basemen height: {m1-h1[0]:.2f}..{m1+h1[0]:.2f}, 2nd basemen height: {m2-h2[0]:.2f}..{m2+h2[0]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "আমরা দেখতে পাচ্ছি যে অন্তরগুলি ওভারল্যাপ করছে না।\n",
    "\n",
    "পরিসংখ্যানগতভাবে আরও সঠিক উপায় হ'ল হাইপোথিসিস প্রমাণ করার জন্য **স্টুডেন্ট টি-টেস্ট** ব্যবহার করা:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Second_Baseman',['Height']],equal_var=False)\n",
    "print(f\"T-value = {tval[0]:.2f}\\nP-value: {pval[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ttest_ind` ফাংশন দ্বারা ফেরত আসা দুটি মান হল:\n",
    "* p-মানকে দুইটি বন্টনের একই গড় থাকার সম্ভাবনা হিসেবে বিবেচনা করা যেতে পারে। আমাদের ক্ষেত্রে, এটি খুবই কম, যার অর্থ প্রথম বেসম্যানরা লম্বা হওয়ার পক্ষে শক্তিশালী প্রমাণ পাওয়া গেছে।\n",
    "* t-মান হলো স্বাভাবিককৃত গড় পার্থক্যের মধ্যবর্তী মান যা t-পরীক্ষায় ব্যবহৃত হয়, এবং এটি নির্দিষ্ট আস্থা মানের জন্য একটি সীমা মানের সাথে তুলনা করা হয়।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## মধ্যবিন্দু সীমা থিওরেম ব্যবহার করে একটি স্বাভাবিক বণ্টনের অনুকরণ\n",
    "\n",
    "পাইথনে ছদ্ম-যাদৃচ্ছিক জেনারেটরটি আমাদের একটি সমজাতীয় বণ্টন দিতে ডিজাইন করা হয়েছে। যদি আমরা একটি স্বাভাবিক বণ্টনের জন্য একটি জেনারেটর তৈরি করতে চাই, তাহলে আমরা মধ্যবিন্দু সীমা থিওরেম ব্যবহার করতে পারি। একটি স্বাভাবিক বণ্টিত মান পেতে আমরা কেবল সমজাতীয়ভাবে তৈরি একটি নমুনার গড় গণনা করব।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_random(sample_size=100):\n",
    "    sample = [random.uniform(0,1) for _ in range(sample_size) ]\n",
    "    return sum(sample)/sample_size\n",
    "\n",
    "sample = [normal_random() for _ in range(100)]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(sample)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## সম্পর্ক এবং ইভিল বেসবল কর্পোরেশন\n",
    "\n",
    "সম্পর্ক আমাদের ডেটা সিকুয়েন্সগুলোর মধ্যে সম্পর্ক খুঁজে পেতে সাহায্য করে। আমাদের খেলনা উদাহরণে, ধরা যাক একটি ইভিল বেসবল কর্পোরেশন রয়েছে যা তার খেলোয়াড়দের তাদের উচ্চতার ওপর ভিত্তি করে বেতন দেয় - খেলোয়াড় যত লম্বা, তিনি তত বেশি টাকা পান। ধরা যাক একটি ভিত্তিক বেতন $১০০০, এবং উচ্চতার ওপর ভিত্তি করে $০ থেকে $১০০ পর্যন্ত অতিরিক্ত বোনাস রয়েছে। আমরা MLB-এর আসল খেলোয়াড়দের নিয়ে তাদের কাল্পনিক বেতন হিসাব করব:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = df['Height'].fillna(method='pad')\n",
    "salaries = 1000+(heights-heights.min())/(heights.max()-heights.mean())*100\n",
    "print(list(zip(heights, salaries))[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "এখন চলুন ঐ সিকোয়েন্সগুলোর কোভেরিয়েন্স এবং সম্পর্ক হিসাব করি। `np.cov` আমাদের একটি sogenannten **কোভেরিয়েন্স ম্যাট্রিক্স** দেবে, যা একাধিক ভেরিয়েবল এর জন্য কোভেরিয়েন্সের একটি সম্প্রসারণ। কোভেরিয়েন্স ম্যাট্রিক্স $M$ এর উপাদান $M_{ij}$ হলো ইনপুট ভেরিয়েবলের $X_i$ এবং $X_j$ এর মধ্যে সম্পর্ক, এবং ডায়াগোনাল মান $M_{ii}$ হলো $X_i$ এর বৈচিত্র্য। একইভাবে, `np.corrcoef` আমাদের **সম্পর্ক ম্যাট্রিক্স** দেবে।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Covariance matrix:\\n{np.cov(heights, salaries)}\")\n",
    "print(f\"Covariance = {np.cov(heights, salaries)[0,1]}\")\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "একটি সহসর্মতা সমান ১ অর্থ হলো দুইটি ভেরিয়েবলের মধ্যে একটি শক্তিশালী **রৈখিক সম্পর্ক** রয়েছে। আমরা একটি মানকে অন্য মানের বিপরীত দিকে প্লট করে রৈখিক সম্পর্ক দৃশ্যমানভাবে দেখতে পারি:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(heights,salaries)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "চলুন দেখি কি হয় যদি সম্পর্কটা সরলরেখীয় না হয়। ধরুন আমাদের কর্পোরেশন উচ্চতা এবং বেতরের মধ্যে স্পষ্ট সরলরেখীয় নির্ভরতাকে লুকানোর সিদ্ধান্ত নিয়েছে, এবং সূত্রে কিছু অ-সরলরেখীয়তা যেমন `sin` যোগ করেছে:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = 1000+np.sin((heights-heights.min())/(heights.max()-heights.mean()))*100\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "এই ক্ষেত্রে, সম্পর্কটি একটু কম হলেও তা এখনও যথেষ্ট উচ্চ। এবার, সম্পর্কটি আরও কম স্পষ্ট করতে, আমরা বেতন প্রথমে একটি র্যাণ্ডম পরিবর্তক যোগ করে কিছু অতিরিক্ত র‍্যানডমনেস যোগ করতে চাইতে পারি। চলুন দেখি কী হয়:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = 1000+np.sin((heights-heights.min())/(heights.max()-heights.mean()))*100+np.random.random(size=len(heights))*20-10\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(heights, salaries)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> আপনি কি অনুমান করতে পারেন কেন ডটগুলো এইভাবে খাড়া লাইনে সারিবদ্ধ হয়?\n",
    "\n",
    "আমরা একটি কৃত্রিমভাবে নির্মিত ধারণা যেমন বেতন এবং পর্যবেক্ষিত পরিবর্তনশীল *উচ্চতা* এর মধ্যকার সম্পর্ক লক্ষ্য করেছি। এবার আমরা দেখতে চাই দুইটি পর্যবেক্ষিত পরিবর্তনশীল, যেমন উচ্চতা এবং ওজন, তাদের মধ্যেও কি সম্পর্ক আছে কিনা:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df['Height'].ffill(),df['Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "দুর্ভাগ্যবশত, আমরা কোনো ফলাফল পাইনি - শুধুমাত্র কিছু অদ্ভুত `nan` মান। এর কারণ হলো আমাদের সিরিজের কিছু মান অনির্ধারিত, যা `nan` হিসেবে উপস্থাপিত হয়েছে, যা অপারেশনের ফলাফলকেও অনির্ধারিত করে তোলে। ম্যাট্রিক্সটির দিকে নজর দিলে দেখা যায় যে `Weight` হল সমস্যা সৃষ্টিকারী কলাম, কারণ `Height` মানগুলির মধ্যে স্ব-কোরিলেশন গণনা করা হয়েছে।\n",
    "\n",
    "> এই উদাহরণটি **ডেটা প্রস্তুতি** এবং **পরিষ্কারের** গুরুত্ব দেখায়। সঠিক ডেটা ছাড়া আমরা কিছুই গণনা করতে পারব না।\n",
    "\n",
    "চলুন হারিয়ে যাওয়া মানগুলি পূরণের জন্য `fillna` পদ্ধতি ব্যবহার করি এবং কোরিলেশন গণনা করি:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df['Height'].fillna(method='pad'), df['Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "অবশ্যই একটি সংযোগ বিদ্যমান, তবে আমাদের কৃত্রিম উদাহরণের মত এতটা শক্তিশালী নয়। আসলে, যদি আমরা একটি মানকে অন্যটির বিরুদ্ধে স্থানচিত্রিত করি, সম্পর্ক অনেক কম স্পষ্ট হবে:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(df['Weight'],df['Height'])\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Height')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## উপসংহার\n",
    "\n",
    "এই নোটবুকে আমরা শিখেছি কীভাবে ডেটার ওপর মৌলিক অপারেশনগুলো সম্পাদন করে পরিসংখ্যানগত ফাংশনগুলি গণনা করা যায়। এখন আমরা জানি কীভাবে গণিত এবং পরিসংখ্যানের একটি শক্তিশালী যন্ত্রপাতি ব্যবহার করে কিছু অনুমান প্রমাণ করতে হয়, এবং কীভাবে একটি ডেটা নমুনা থেকে ইচ্ছা মতো ভেরিয়েবলের জন্য আত্মবিশ্বাসের অন্তরালা গণনা করতে হয়।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**অস্বীকারোক্তি**:  \nএই নথিটি AI অনুবাদক সেবা [Co-op Translator](https://github.com/Azure/co-op-translator) ব্যবহার করে অনূদিত হয়েছে। যদিও আমরা যথাসম্ভব যথার্থতার চেষ্টা করি, তবুও দয়া করে মাথায় রাখবেন যে স্বয়ংক্রিয় অনুবাদে ত্রুটি বা অসুস্পষ্টতা থাকতে পারে। মূল নথিটি তার নিজ ভাষায় কর্তৃত্বপূর্ণ উৎস হিসাবে বিবেচিত হওয়া উচিত। জরুরি তথ্যের জন্য পেশাদার মানব অনুবাদ পরামর্শ দেওয়া হয়। এই অনুবাদের ব্যবহার থেকে উদ্ভূত কোনো ভ্রান্তিমূলক অর্থ বা ভুল ব্যাখ্যার জন্য আমরা দায়ী নই।\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86193a1ab0ba47eac1c69c1756090baa3b420b3eea7d4aafab8b85f8b312f0c5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "coopTranslator": {
   "original_hash": "0f899e3c5019f948e7c787b22f3b2304",
   "translation_date": "2026-01-16T11:51:47+00:00",
   "source_file": "1-Introduction/04-stats-and-probability/notebook.ipynb",
   "language_code": "bn"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}