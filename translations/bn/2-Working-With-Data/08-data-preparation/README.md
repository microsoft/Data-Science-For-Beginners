<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1b560955ff39a2bcf2a049fce474a951",
  "translation_date": "2025-09-06T07:10:37+00:00",
  "source_file": "2-Working-With-Data/08-data-preparation/README.md",
  "language_code": "bn"
}
-->
# ডেটার সাথে কাজ করা: ডেটা প্রস্তুতি

|![ স্কেচনোট [(@sketchthedocs)](https://sketchthedocs.dev) দ্বারা ](../../sketchnotes/08-DataPreparation.png)|
|:---:|
|ডেটা প্রস্তুতি - _[@nitya](https://twitter.com/nitya) দ্বারা স্কেচনোট_ |

## [পূর্ব-লেকচার কুইজ](https://ff-quizzes.netlify.app/en/ds/quiz/14)

ডেটার উৎসের উপর নির্ভর করে, কাঁচা ডেটাতে কিছু অসঙ্গতি থাকতে পারে যা বিশ্লেষণ এবং মডেলিংয়ে চ্যালেঞ্জ সৃষ্টি করবে। অন্যভাবে বললে, এই ডেটা "নোংরা" হিসাবে শ্রেণীবদ্ধ করা যেতে পারে এবং এটি পরিষ্কার করতে হবে। এই পাঠে অনুপস্থিত, ভুল বা অসম্পূর্ণ ডেটার চ্যালেঞ্জ মোকাবেলার জন্য ডেটা পরিষ্কার এবং রূপান্তর করার কৌশলগুলির উপর ফোকাস করা হয়েছে। এই পাঠে আলোচনা করা বিষয়গুলি Python এবং Pandas লাইব্রেরি ব্যবহার করবে এবং এই ডিরেক্টরির [নোটবুকে](../../../../2-Working-With-Data/08-data-preparation/notebook.ipynb) প্রদর্শিত হবে।

## ডেটা পরিষ্কার করার গুরুত্ব

- **ব্যবহার এবং পুনরায় ব্যবহারের সহজতা**: যখন ডেটা সঠিকভাবে সংগঠিত এবং স্বাভাবিকীকৃত হয়, তখন এটি অনুসন্ধান, ব্যবহার এবং অন্যদের সাথে শেয়ার করা সহজ হয়।

- **সঙ্গতি**: ডেটা সায়েন্স প্রায়ই একাধিক ডেটাসেট নিয়ে কাজ করার প্রয়োজন হয়, যেখানে বিভিন্ন উৎস থেকে ডেটাসেট একত্রিত করতে হয়। নিশ্চিত করা যে প্রতিটি পৃথক ডেটাসেটের সাধারণ মানকরণ রয়েছে, এটি একত্রিত হলে ডেটা এখনও কার্যকর থাকবে।

- **মডেলের সঠিকতা**: পরিষ্কার করা ডেটা মডেলের সঠিকতা উন্নত করে যা এর উপর নির্ভর করে।

## সাধারণ পরিষ্কারের লক্ষ্য এবং কৌশল

- **ডেটাসেট অন্বেষণ**: ডেটা অন্বেষণ, যা [পরবর্তী পাঠে](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/4-Data-Science-Lifecycle/15-analyzing) আলোচনা করা হয়েছে, আপনাকে এমন ডেটা আবিষ্কার করতে সাহায্য করতে পারে যা পরিষ্কার করার প্রয়োজন। ডেটাসেটের মধ্যে মানগুলি চাক্ষুষভাবে পর্যবেক্ষণ করা বাকিটা কেমন দেখাবে তার প্রত্যাশা তৈরি করতে পারে বা সমাধানযোগ্য সমস্যাগুলির ধারণা দিতে পারে। অন্বেষণ মৌলিক প্রশ্ন, ভিজ্যুয়ালাইজেশন এবং নমুনা অন্তর্ভুক্ত করতে পারে।

- **ফরম্যাটিং**: উৎসের উপর নির্ভর করে, ডেটাতে উপস্থাপনের ক্ষেত্রে অসঙ্গতি থাকতে পারে। এটি মান অনুসন্ধান এবং উপস্থাপনে সমস্যা সৃষ্টি করতে পারে, যেখানে এটি ডেটাসেটে দেখা যায় কিন্তু ভিজ্যুয়ালাইজেশন বা প্রশ্নের ফলাফলে সঠিকভাবে উপস্থাপিত হয় না। সাধারণ ফরম্যাটিং সমস্যাগুলির মধ্যে রয়েছে হোয়াইটস্পেস, তারিখ এবং ডেটা টাইপ সমাধান করা। ফরম্যাটিং সমস্যাগুলি সাধারণত ডেটা ব্যবহারকারীদের উপর নির্ভর করে সমাধান করা হয়। উদাহরণস্বরূপ, তারিখ এবং সংখ্যাগুলি কীভাবে উপস্থাপিত হয় তার মান দেশভেদে আলাদা হতে পারে।

- **ডুপ্লিকেশন**: ডেটাতে একাধিক ঘটনা থাকলে এটি ভুল ফলাফল তৈরি করতে পারে এবং সাধারণত এটি সরিয়ে ফেলা উচিত। এটি দুটি বা তার বেশি ডেটাসেট একত্রিত করার সময় একটি সাধারণ ঘটনা হতে পারে। তবে, এমন কিছু ক্ষেত্রে ডুপ্লিকেশন থাকা অংশগুলি অতিরিক্ত তথ্য সরবরাহ করতে পারে এবং সংরক্ষণ করা প্রয়োজন হতে পারে।

- **অনুপস্থিত ডেটা**: অনুপস্থিত ডেটা ভুল এবং পক্ষপাতদুষ্ট ফলাফল সৃষ্টি করতে পারে। কখনও কখনও এগুলি ডেটার "পুনরায় লোড" করে, Python-এর মতো কোড এবং গণনার মাধ্যমে অনুপস্থিত মানগুলি পূরণ করে বা কেবল মান এবং সংশ্লিষ্ট ডেটা সরিয়ে দিয়ে সমাধান করা যেতে পারে। ডেটা কেন এবং কীভাবে অনুপস্থিত হয়েছে তার উপর নির্ভর করে এই মানগুলি সমাধানের জন্য নেওয়া পদক্ষেপগুলি পরিবর্তিত হতে পারে।

## DataFrame তথ্য অন্বেষণ
> **শিক্ষার লক্ষ্য:** এই উপ-অধ্যায়ের শেষে, আপনি pandas DataFrame-এ সংরক্ষিত ডেটার সাধারণ তথ্য খুঁজে পেতে স্বাচ্ছন্দ্য বোধ করবেন।

আপনার ডেটা pandas-এ লোড করার পরে, এটি সম্ভবত একটি DataFrame-এ থাকবে (পূর্ববর্তী [পাঠ](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/2-Working-With-Data/07-python#dataframe) থেকে বিস্তারিত ওভারভিউ দেখুন)। তবে, যদি আপনার DataFrame-এ 60,000 সারি এবং 400 কলাম থাকে, তাহলে আপনি কীভাবে কাজ শুরু করবেন তা বুঝবেন কীভাবে? সৌভাগ্যক্রমে, [pandas](https://pandas.pydata.org/) DataFrame-এর সামগ্রিক তথ্য দ্রুত দেখার জন্য কিছু সুবিধাজনক টুল সরবরাহ করে, পাশাপাশি প্রথম এবং শেষ কয়েকটি সারি।

এই কার্যকারিতা অন্বেষণ করতে, আমরা Python scikit-learn লাইব্রেরি আমদানি করব এবং একটি আইকনিক ডেটাসেট ব্যবহার করব: **Iris ডেটাসেট**।

```python
import pandas as pd
from sklearn.datasets import load_iris

iris = load_iris()
iris_df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])
```
|                                        |sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|
|----------------------------------------|-----------------|----------------|-----------------|----------------|
|0                                       |5.1              |3.5             |1.4              |0.2             |
|1                                       |4.9              |3.0             |1.4              |0.2             |
|2                                       |4.7              |3.2             |1.3              |0.2             |
|3                                       |4.6              |3.1             |1.5              |0.2             |
|4                                       |5.0              |3.6             |1.4              |0.2             |

- **DataFrame.info**: শুরু করার জন্য, `info()` পদ্ধতি ব্যবহার করে একটি DataFrame-এ উপস্থিত বিষয়বস্তুর সারাংশ প্রিন্ট করা হয়। আসুন এই ডেটাসেটটি দেখি:
```python
iris_df.info()
```
```
RangeIndex: 150 entries, 0 to 149
Data columns (total 4 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   sepal length (cm)  150 non-null    float64
 1   sepal width (cm)   150 non-null    float64
 2   petal length (cm)  150 non-null    float64
 3   petal width (cm)   150 non-null    float64
dtypes: float64(4)
memory usage: 4.8 KB
```
এখান থেকে আমরা জানি যে *Iris* ডেটাসেটে চারটি কলামে 150টি এন্ট্রি রয়েছে এবং কোনও null এন্ট্রি নেই। সমস্ত ডেটা 64-বিট ফ্লোটিং-পয়েন্ট সংখ্যার হিসাবে সংরক্ষিত।

- **DataFrame.head()**: পরবর্তী, DataFrame-এর প্রকৃত বিষয়বস্তু পরীক্ষা করতে, আমরা `head()` পদ্ধতি ব্যবহার করি। আসুন দেখি আমাদের `iris_df`-এর প্রথম কয়েকটি সারি কেমন দেখাচ্ছে:
```python
iris_df.head()
```
```
   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
0                5.1               3.5                1.4               0.2
1                4.9               3.0                1.4               0.2
2                4.7               3.2                1.3               0.2
3                4.6               3.1                1.5               0.2
4                5.0               3.6                1.4               0.2
```
- **DataFrame.tail()**: বিপরীতভাবে, DataFrame-এর শেষ কয়েকটি সারি পরীক্ষা করতে, আমরা `tail()` পদ্ধতি ব্যবহার করি:
```python
iris_df.tail()
```
```
     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
145                6.7               3.0                5.2               2.3
146                6.3               2.5                5.0               1.9
147                6.5               3.0                5.2               2.0
148                6.2               3.4                5.4               2.3
149                5.9               3.0                5.1               1.8
```
> **মূল কথা:** DataFrame-এর তথ্য সম্পর্কে মেটাডেটা বা এর প্রথম এবং শেষ কয়েকটি মান দেখেই, আপনি যে ডেটা নিয়ে কাজ করছেন তার আকার, আকৃতি এবং বিষয়বস্তু সম্পর্কে তাৎক্ষণিক ধারণা পেতে পারেন।

## অনুপস্থিত ডেটা মোকাবেলা করা
> **শিক্ষার লক্ষ্য:** এই উপ-অধ্যায়ের শেষে, আপনি DataFrame থেকে null মান প্রতিস্থাপন বা সরানোর পদ্ধতি জানতে পারবেন।

প্রায়শই আপনি যে ডেটাসেটগুলি ব্যবহার করতে চান (বা ব্যবহার করতে বাধ্য হন) তাতে অনুপস্থিত মান থাকে। অনুপস্থিত ডেটা কীভাবে পরিচালনা করা হয় তার সাথে সূক্ষ্ম আপস থাকে যা আপনার চূড়ান্ত বিশ্লেষণ এবং বাস্তব-বিশ্বের ফলাফলে প্রভাব ফেলতে পারে।

Pandas দুটি উপায়ে অনুপস্থিত মান পরিচালনা করে। প্রথমটি আপনি আগের বিভাগে দেখেছেন: `NaN`, বা Not a Number। এটি আসলে IEEE ফ্লোটিং-পয়েন্ট স্পেসিফিকেশনের একটি বিশেষ মান এবং এটি শুধুমাত্র অনুপস্থিত ফ্লোটিং-পয়েন্ট মান নির্দেশ করতে ব্যবহৃত হয়।

ফ্লোট ছাড়া অন্য অনুপস্থিত মানগুলির জন্য, pandas Python `None` অবজেক্ট ব্যবহার করে। যদিও এটি বিভ্রান্তিকর মনে হতে পারে যে আপনি দুটি ভিন্ন ধরনের মানের সম্মুখীন হবেন যা মূলত একই জিনিস বলে, এই নকশা পছন্দের জন্য সাউন্ড প্রোগ্রাম্যাটিক কারণ রয়েছে এবং, বাস্তবে, এই পথে যাওয়া pandas-কে বেশিরভাগ ক্ষেত্রে একটি ভাল আপস প্রদান করতে সক্ষম করে। তবুও, `None` এবং `NaN` উভয়ই সীমাবদ্ধতা বহন করে যা আপনি কীভাবে সেগুলি ব্যবহার করতে পারেন তার সাথে সম্পর্কিত।

`NaN` এবং `None` সম্পর্কে আরও জানুন [নোটবুক](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/4-Data-Science-Lifecycle/15-analyzing/notebook.ipynb) থেকে!

- **Null মান সনাক্ত করা**: pandas-এ, `isnull()` এবং `notnull()` পদ্ধতিগুলি null ডেটা সনাক্ত করার জন্য আপনার প্রাথমিক পদ্ধতি। উভয়ই আপনার ডেটার উপর Boolean মাস্ক প্রদান করে। আমরা `NaN` মানগুলির জন্য `numpy` ব্যবহার করব:
```python
import numpy as np

example1 = pd.Series([0, np.nan, '', None])
example1.isnull()
```
```
0    False
1     True
2    False
3     True
dtype: bool
```
আউটপুটটি ঘনিষ্ঠভাবে দেখুন। এর কোনটি আপনাকে অবাক করে? যদিও `0` একটি গাণিতিক null, এটি তবুও একটি সম্পূর্ণ ভাল পূর্ণসংখ্যা এবং pandas এটিকে সেইভাবে বিবেচনা করে। `''` একটু বেশি সূক্ষ্ম। যদিও আমরা এটি বিভাগ 1-এ একটি খালি স্ট্রিং মান উপস্থাপন করতে ব্যবহার করেছি, এটি তবুও একটি স্ট্রিং অবজেক্ট এবং pandas-এর দৃষ্টিতে null-এর প্রতিনিধিত্ব নয়।

এখন, আসুন এটি ঘুরিয়ে দিই এবং এই পদ্ধতিগুলি এমনভাবে ব্যবহার করি যেভাবে আপনি বাস্তবে সেগুলি ব্যবহার করবেন। আপনি Boolean মাস্কগুলি সরাসরি একটি ``Series`` বা ``DataFrame`` সূচক হিসাবে ব্যবহার করতে পারেন, যা অনুপস্থিত (বা উপস্থিত) মানগুলির সাথে কাজ করার সময় সহায়ক হতে পারে।

> **মূল কথা:** `isnull()` এবং `notnull()` পদ্ধতিগুলি `DataFrame`-এ ব্যবহার করার সময় অনুরূপ ফলাফল তৈরি করে: তারা ফলাফল এবং সেই ফলাফলের সূচক দেখায়, যা আপনার ডেটার সাথে লড়াই করার সময় আপনাকে ব্যাপকভাবে সাহায্য করবে।

- **Null মান বাদ দেওয়া**: অনুপস্থিত মান সনাক্ত করার বাইরে, pandas `Series` এবং `DataFrame` থেকে null মান সরানোর একটি সুবিধাজনক উপায় প্রদান করে। (বিশেষত বড় ডেটাসেটে, এটি প্রায়শই আপনার বিশ্লেষণ থেকে অনুপস্থিত [NA] মানগুলি সরিয়ে ফেলা আরও পরামর্শযোগ্য হয় অন্য উপায়ে সেগুলি মোকাবেলা করার চেয়ে।) এটি ক্রিয়ায় দেখতে, আসুন `example1`-এ ফিরে যাই:
```python
example1 = example1.dropna()
example1
```
```
0    0
2     
dtype: object
```
লক্ষ্য করুন যে এটি আপনার `example3[example3.notnull()]` থেকে আউটপুটের মতো দেখাচ্ছে। এখানে পার্থক্য হল, মাস্কড মানগুলিতে সূচক করার পরিবর্তে, `dropna` সেই অনুপস্থিত মানগুলি `Series` `example1` থেকে সরিয়ে দিয়েছে।

কারণ `DataFrame`-এর দুটি মাত্রা রয়েছে, তারা ডেটা বাদ দেওয়ার জন্য আরও বিকল্প প্রদান করে।

```python
example2 = pd.DataFrame([[1,      np.nan, 7], 
                         [2,      5,      8], 
                         [np.nan, 6,      9]])
example2
```
|      | 0 | 1 | 2 |
|------|---|---|---|
|0     |1.0|NaN|7  |
|1     |2.0|5.0|8  |
|2     |NaN|6.0|9  |

(pandas দুটি কলামকে ফ্লোটে আপকাস্ট করেছে `NaN`-গুলিকে সামঞ্জস্য করার জন্য কি আপনি লক্ষ্য করেছেন?)

আপনি একটি `DataFrame` থেকে একটি একক মান বাদ দিতে পারবেন না, তাই আপনাকে সম্পূর্ণ সারি বা কলাম বাদ দিতে হবে। আপনি যা করছেন তার উপর নির্ভর করে, আপনি এক বা অন্যটি করতে চাইতে পারেন, এবং তাই pandas আপনাকে উভয়ের জন্য বিকল্প দেয়। কারণ ডেটা সায়েন্সে, কলামগুলি সাধারণত ভেরিয়েবল এবং সারিগুলি পর্যবেক্ষণ উপস্থাপন করে, আপনি ডেটার সারি বাদ দেওয়ার সম্ভাবনা বেশি; `dropna()`-এর ডিফল্ট সেটিং হল যেকোন null মান ধারণকারী সমস্ত সারি বাদ দেওয়া:

```python
example2.dropna()
```
```
	0	1	2
1	2.0	5.0	8
```
প্রয়োজনে, আপনি কলাম থেকে NA মান বাদ দিতে পারেন। এটি করতে `axis=1` ব্যবহার করুন:
```python
example2.dropna(axis='columns')
```
```
	2
0	7
1	8
2	9
```
লক্ষ্য করুন যে এটি অনেক ডেটা বাদ দিতে পারে যা আপনি রাখতে চাইতে পারেন, বিশেষত ছোট ডেটাসেটে। যদি আপনি শুধুমাত্র এমন সারি বা কলাম বাদ দিতে চান যা বেশ কয়েকটি বা এমনকি সমস্ত null মান ধারণ করে? আপনি `dropna`-এ `how` এবং `thresh` প্যারামিটার দিয়ে সেই সেটিংগুলি নির্দিষ্ট করেন।

ডিফল্টভাবে, `how='any'` (যদি আপনি নিজের জন্য পরীক্ষা করতে চান বা পদ্ধতিটির অন্য কোন প্যারামিটার রয়েছে তা দেখতে চান, একটি কোড সেলে `example4.dropna?` চালান)। আপনি বিকল্পভাবে `how='all'` নির্দিষ্ট করতে পারেন যাতে শুধুমাত্র সারি বা কলাম বাদ দেওয়া হয় যা সমস্ত null মান ধারণ করে। আসুন আমাদের উদাহরণ `DataFrame` প্রসারিত করি এটি ক্রিয়ায় দেখতে।

```python
example2[3] = np.nan
example2
```
|      |0  |1  |2  |3  |
|------|---|---|---|---|
|0     |1.0|NaN|7  |NaN|
|1     |2.0|5.0|8  |NaN|
|2     |NaN|6.0|9  |NaN|

`thresh` প্যারামিটার আপনাকে আরও সূক্ষ্ম নিয়ন্ত্রণ দেয়: আপনি একটি সারি বা কলামে *non-null* মানের সংখ্যা সেট করেন যা রাখা প্রয়োজন:
```python
example2.dropna(axis='rows', thresh=3)
```
```
	0	1	2	3
1	2.0	5.0	8	NaN
```
এখানে, প্রথম এবং শেষ সারি বাদ দেওয়া হয়েছে, কারণ তারা শুধুমাত্র দুটি non-null মান ধারণ করে।

- **Null মান পূরণ করা**: আপনার ডেটাসেটের উপর নির্ভর করে, কখনও কখনও null মানগুলি বৈধ মান দিয়ে পূরণ করা আরও অর্থবহ হতে পারে। আপনি এটি ইন-প্লেস করতে `isnull` ব্যবহার করতে পারেন, তবে এটি শ্রমসাধ্য হতে পারে, বিশেষত যদি আপনার পূরণ করার জন্য অনেক মান থাকে। যেহেতু এটি ডেটা সায়েন্সে একটি সাধারণ কাজ, pandas `fillna` প্রদান করে, যা আপনার পছন্দের একটি মান দিয়ে অনুপস্থিত মানগুলি প্রতিস্থাপন করে একটি `Series` বা `DataFrame`-এর একটি কপি প্রদান করে। এটি বাস্তবে কীভাবে কাজ করে তা দেখতে একটি উদাহরণ `Series` তৈরি করি।
```python
example3 = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))
example3
```
```
a    1.0
b    NaN
c    2.0
d    NaN
e    3.0
dtype: float64
```
আপনি সমস্ত null এন্ট্রি একটি একক মান দিয়ে পূরণ করতে পারেন, যেমন `0`:
```python
example3.fillna(0)
```
```
a    1.0
b    0.0
c    2.0
d    0.0
e    3.0
dtype: float64
```
আপনি null মানগুলি **forward-fill** করতে পারেন, যা null পূরণ করতে শেষ বৈধ মান ব্যবহার করে:
```python
example3.fillna(method='ffill')
```
```
a    1.0
b    1.0
c    2.0
d    2.0
e    3.0
dtype: float64
```
আপনি null পূরণ করতে **back-fill** করতে পারেন, যা null পূরণ করতে পরবর্তী বৈধ মানটি পিছনে প্রচার করে:
```python
example3.fillna(method='bfill')
```
```
a    1.0
b    2.0
c    2.0
d    3.0
e    3.0
dtype: float64
```
আপনি অনুমান করতে পারেন, এটি `DataFrame`-এর সাথে একইভাবে কাজ করে, তবে আপনি null মানগুলি পূরণ করতে একটি `axis` নির্দিষ্ট করতে পারেন। পূর্বে ব্যবহৃত `example2` আবার ব্যবহার করে:
```python
example2.fillna(method='ffill', axis=1)
```
```
	0	1	2	3
0	1.0	1.0	7.0	7.0
1	2.0	5.0	8.0	8.0
2	NaN	6.0	9.0	9.0
```
লক্ষ্য করুন যে যখন forward-filling-এর জন্য পূর্ববর্তী মান উপলব্ধ থাকে না, তখন null মানটি রয়ে যায়।
> **মূল কথা:** আপনার ডেটাসেটে অনুপস্থিত মানগুলোর সাথে মোকাবিলা করার বিভিন্ন উপায় রয়েছে। আপনি যে নির্দিষ্ট কৌশলটি ব্যবহার করবেন (সেগুলো সরিয়ে ফেলা, প্রতিস্থাপন করা, বা কীভাবে প্রতিস্থাপন করবেন) তা সেই ডেটার নির্দিষ্ট বৈশিষ্ট্যের উপর নির্ভর করবে। আপনি যত বেশি ডেটাসেট পরিচালনা করবেন এবং এর সাথে কাজ করবেন, অনুপস্থিত মানগুলোর সাথে মোকাবিলা করার ক্ষেত্রে তত ভালো ধারণা তৈরি হবে।
## ডুপ্লিকেট ডেটা সরানো

> **শিক্ষার লক্ষ্য:** এই উপ-অধ্যায়ের শেষে, আপনি ডেটাফ্রেম থেকে ডুপ্লিকেট মান সনাক্ত এবং সরাতে স্বাচ্ছন্দ্যবোধ করবেন।

অনুপস্থিত ডেটার পাশাপাশি, বাস্তব জীবনের ডেটাসেটে প্রায়ই ডুপ্লিকেট ডেটার সম্মুখীন হতে হয়। সৌভাগ্যক্রমে, `pandas` ডুপ্লিকেট এন্ট্রি সনাক্ত এবং সরানোর একটি সহজ উপায় প্রদান করে।

- **ডুপ্লিকেট সনাক্ত করা: `duplicated`**: আপনি সহজেই `pandas`-এর `duplicated` মেথড ব্যবহার করে ডুপ্লিকেট মান সনাক্ত করতে পারেন, যা একটি বুলিয়ান মাস্ক প্রদান করে যা নির্দেশ করে যে একটি `DataFrame`-এর এন্ট্রি পূর্বের একটি এন্ট্রির ডুপ্লিকেট কিনা। চলুন একটি উদাহরণ `DataFrame` তৈরি করে এটি দেখার চেষ্টা করি।
```python
example4 = pd.DataFrame({'letters': ['A','B'] * 2 + ['B'],
                         'numbers': [1, 2, 1, 3, 3]})
example4
```
|      |letters|numbers|
|------|-------|-------|
|0     |A      |1      |
|1     |B      |2      |
|2     |A      |1      |
|3     |B      |3      |
|4     |B      |3      |

```python
example4.duplicated()
```
```
0    False
1    False
2     True
3    False
4     True
dtype: bool
```
- **ডুপ্লিকেট সরানো: `drop_duplicates`:** এটি শুধুমাত্র সেই ডেটার একটি কপি প্রদান করে যেখানে সমস্ত `duplicated` মান `False`:
```python
example4.drop_duplicates()
```
```
	letters	numbers
0	A	1
1	B	2
3	B	3
```
`duplicated` এবং `drop_duplicates` ডিফল্টভাবে সমস্ত কলাম বিবেচনা করে, তবে আপনি নির্দিষ্ট করতে পারেন যে তারা আপনার `DataFrame`-এর শুধুমাত্র একটি সাবসেট কলাম পরীক্ষা করবে:
```python
example4.drop_duplicates(['letters'])
```
```
letters	numbers
0	A	1
1	B	2
```

> **মূল কথা:** ডুপ্লিকেট ডেটা সরানো প্রায় প্রতিটি ডেটা-সায়েন্স প্রকল্পের একটি গুরুত্বপূর্ণ অংশ। ডুপ্লিকেট ডেটা আপনার বিশ্লেষণের ফলাফল পরিবর্তন করতে পারে এবং আপনাকে ভুল ফলাফল দিতে পারে!


## 🚀 চ্যালেঞ্জ

এই আলোচিত উপকরণগুলো [Jupyter Notebook](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/2-Working-With-Data/08-data-preparation/notebook.ipynb)-এ প্রদান করা হয়েছে। এছাড়াও, প্রতিটি সেকশনের পরে অনুশীলন রয়েছে, সেগুলো চেষ্টা করে দেখুন!

## [পোস্ট-লেকচার কুইজ](https://ff-quizzes.netlify.app/en/ds/quiz/15)



## পর্যালোচনা ও স্ব-অধ্যয়ন

আপনার ডেটা বিশ্লেষণ এবং মডেলিংয়ের জন্য প্রস্তুত করার বিভিন্ন উপায় আবিষ্কার এবং এগুলোর কাছে পৌঁছানোর অনেক পদ্ধতি রয়েছে। ডেটা পরিষ্কার করা একটি গুরুত্বপূর্ণ ধাপ যা "হ্যান্ডস অন" অভিজ্ঞতা। Kaggle থেকে এই চ্যালেঞ্জগুলো চেষ্টা করুন যা এই পাঠে আলোচনা করা হয়নি এমন কৌশলগুলো অন্বেষণ করতে সাহায্য করবে।

- [ডেটা ক্লিনিং চ্যালেঞ্জ: তারিখ পার্সিং](https://www.kaggle.com/rtatman/data-cleaning-challenge-parsing-dates/)

- [ডেটা ক্লিনিং চ্যালেঞ্জ: ডেটা স্কেল এবং নরমালাইজ করা](https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data)


## অ্যাসাইনমেন্ট

[ফর্ম থেকে ডেটা মূল্যায়ন](assignment.md)

---

**অস্বীকৃতি**:  
এই নথিটি AI অনুবাদ পরিষেবা [Co-op Translator](https://github.com/Azure/co-op-translator) ব্যবহার করে অনুবাদ করা হয়েছে। আমরা যথাসাধ্য সঠিকতার জন্য চেষ্টা করি, তবে অনুগ্রহ করে মনে রাখবেন যে স্বয়ংক্রিয় অনুবাদে ত্রুটি বা অসঙ্গতি থাকতে পারে। মূল ভাষায় থাকা নথিটিকে প্রামাণিক উৎস হিসেবে বিবেচনা করা উচিত। গুরুত্বপূর্ণ তথ্যের জন্য, পেশাদার মানব অনুবাদ সুপারিশ করা হয়। এই অনুবাদ ব্যবহারের ফলে কোনো ভুল বোঝাবুঝি বা ভুল ব্যাখ্যা হলে আমরা তার জন্য দায়ী থাকব না।