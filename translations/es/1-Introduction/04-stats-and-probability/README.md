<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b706a07cfa87ba091cbb91e0aa775600",
  "translation_date": "2025-08-24T00:04:39+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "es"
}
-->
# Una Breve Introducci√≥n a Estad√≠stica y Probabilidad

|![ Sketchnote por [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| Estad√≠stica y Probabilidad - _Sketchnote por [@nitya](https://twitter.com/nitya)_ |

La Teor√≠a de Estad√≠stica y Probabilidad son dos √°reas de las Matem√°ticas estrechamente relacionadas que tienen gran relevancia en la Ciencia de Datos. Es posible trabajar con datos sin un conocimiento profundo de matem√°ticas, pero siempre es mejor conocer al menos algunos conceptos b√°sicos. Aqu√≠ presentaremos una breve introducci√≥n que te ayudar√° a comenzar.

[![Video Introductorio](../../../../1-Introduction/04-stats-and-probability/images/video-prob-and-stats.png)](https://youtu.be/Z5Zy85g4Yjw)

## [Cuestionario previo a la clase](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/6)

## Probabilidad y Variables Aleatorias

**Probabilidad** es un n√∫mero entre 0 y 1 que expresa cu√°n probable es un **evento**. Se define como el n√∫mero de resultados positivos (que conducen al evento), dividido por el n√∫mero total de resultados, dado que todos los resultados son igualmente probables. Por ejemplo, cuando lanzamos un dado, la probabilidad de obtener un n√∫mero par es 3/6 = 0.5.

Cuando hablamos de eventos, usamos **variables aleatorias**. Por ejemplo, la variable aleatoria que representa el n√∫mero obtenido al lanzar un dado tomar√≠a valores del 1 al 6. El conjunto de n√∫meros del 1 al 6 se llama **espacio muestral**. Podemos hablar de la probabilidad de que una variable aleatoria tome un cierto valor, por ejemplo P(X=3)=1/6.

La variable aleatoria en el ejemplo anterior se llama **discreta**, porque tiene un espacio muestral contable, es decir, hay valores separados que pueden enumerarse. Hay casos en los que el espacio muestral es un rango de n√∫meros reales, o el conjunto completo de n√∫meros reales. Estas variables se llaman **continuas**. Un buen ejemplo es el tiempo de llegada de un autob√∫s.

## Distribuci√≥n de Probabilidad

En el caso de variables aleatorias discretas, es f√°cil describir la probabilidad de cada evento mediante una funci√≥n P(X). Para cada valor *s* del espacio muestral *S*, dar√° un n√∫mero entre 0 y 1, de modo que la suma de todos los valores de P(X=s) para todos los eventos sea 1.

La distribuci√≥n discreta m√°s conocida es la **distribuci√≥n uniforme**, en la que hay un espacio muestral de N elementos, con una probabilidad igual de 1/N para cada uno de ellos.

Es m√°s dif√≠cil describir la distribuci√≥n de probabilidad de una variable continua, con valores extra√≠dos de alg√∫n intervalo [a,b], o del conjunto completo de n√∫meros reales ‚Ñù. Consideremos el caso del tiempo de llegada de un autob√∫s. De hecho, para cada tiempo exacto de llegada *t*, ¬°la probabilidad de que un autob√∫s llegue exactamente en ese momento es 0!

> Ahora sabes que los eventos con probabilidad 0 ocurren, ¬°y muy a menudo! ¬°Al menos cada vez que llega el autob√∫s!

Solo podemos hablar de la probabilidad de que una variable caiga en un intervalo dado de valores, por ejemplo P(t<sub>1</sub>‚â§X<t<sub>2</sub>). En este caso, la distribuci√≥n de probabilidad se describe mediante una **funci√≥n de densidad de probabilidad** p(x), tal que

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../1-Introduction/04-stats-and-probability/images/probability-density.png)

Un an√°logo continuo de la distribuci√≥n uniforme se llama **uniforme continua**, que se define en un intervalo finito. La probabilidad de que el valor X caiga en un intervalo de longitud l es proporcional a l, y aumenta hasta 1.

Otra distribuci√≥n importante es la **distribuci√≥n normal**, de la que hablaremos m√°s en detalle a continuaci√≥n.

## Media, Varianza y Desviaci√≥n Est√°ndar

Supongamos que extraemos una secuencia de n muestras de una variable aleatoria X: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. Podemos definir el valor **medio** (o **promedio aritm√©tico**) de la secuencia de la manera tradicional como (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n. A medida que aumentamos el tama√±o de la muestra (es decir, tomamos el l√≠mite con n‚Üí‚àû), obtendremos la media (tambi√©n llamada **esperanza**) de la distribuci√≥n. Denotaremos la esperanza como **E**(x).

> Se puede demostrar que para cualquier distribuci√≥n discreta con valores {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} y probabilidades correspondientes p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, la esperanza ser√≠a igual a E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>.

Para identificar qu√© tan dispersos est√°n los valores, podemos calcular la varianza œÉ<sup>2</sup> = ‚àë(x<sub>i</sub> - Œº)<sup>2</sup>/n, donde Œº es la media de la secuencia. El valor œÉ se llama **desviaci√≥n est√°ndar**, y œÉ<sup>2</sup> se llama **varianza**.

## Moda, Mediana y Cuartiles

A veces, la media no representa adecuadamente el valor "t√≠pico" de los datos. Por ejemplo, cuando hay algunos valores extremos que est√°n completamente fuera de rango, pueden afectar la media. Otra buena indicaci√≥n es la **mediana**, un valor tal que la mitad de los puntos de datos son menores que √©l, y la otra mitad - mayores.

Para ayudarnos a entender la distribuci√≥n de los datos, es √∫til hablar de **cuartiles**:

* El primer cuartil, o Q1, es un valor tal que el 25% de los datos est√°n por debajo de √©l.
* El tercer cuartil, o Q3, es un valor tal que el 75% de los datos est√°n por debajo de √©l.

Gr√°ficamente podemos representar la relaci√≥n entre la mediana y los cuartiles en un diagrama llamado **gr√°fico de caja**:

<img src="images/boxplot_explanation.png" width="50%"/>

Aqu√≠ tambi√©n calculamos el **rango intercuartil** IQR=Q3-Q1, y los llamados **valores at√≠picos** - valores que est√°n fuera de los l√≠mites [Q1-1.5*IQR,Q3+1.5*IQR].

Para una distribuci√≥n finita que contiene un peque√±o n√∫mero de valores posibles, un buen valor "t√≠pico" es el que aparece con mayor frecuencia, llamado **moda**. A menudo se aplica a datos categ√≥ricos, como colores. Consideremos una situaci√≥n en la que tenemos dos grupos de personas: algunos que prefieren fuertemente el rojo, y otros que prefieren el azul. Si codificamos los colores con n√∫meros, el valor promedio para un color favorito estar√≠a en alg√∫n lugar del espectro naranja-verde, lo que no indica la preferencia real de ninguno de los grupos. Sin embargo, la moda ser√≠a uno de los colores, o ambos colores, si el n√∫mero de personas que votan por ellos es igual (en este caso llamamos a la muestra **multimodal**).

## Datos del Mundo Real

Cuando analizamos datos de la vida real, a menudo no son variables aleatorias como tal, en el sentido de que no realizamos experimentos con resultados desconocidos. Por ejemplo, consideremos un equipo de jugadores de b√©isbol y sus datos corporales, como altura, peso y edad. Esos n√∫meros no son exactamente aleatorios, pero a√∫n podemos aplicar los mismos conceptos matem√°ticos. Por ejemplo, una secuencia de pesos de personas puede considerarse como una secuencia de valores extra√≠dos de alguna variable aleatoria. A continuaci√≥n se muestra la secuencia de pesos de jugadores de b√©isbol reales de [Major League Baseball](http://mlb.mlb.com/index.jsp), tomada de [este conjunto de datos](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) (para tu conveniencia, solo se muestran los primeros 20 valores):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Nota**: Para ver el ejemplo de trabajo con este conjunto de datos, echa un vistazo al [notebook asociado](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb). Tambi√©n hay varios desaf√≠os a lo largo de esta lecci√≥n, y puedes completarlos agregando algo de c√≥digo a ese notebook. Si no est√°s seguro de c√≥mo operar con datos, no te preocupes: volveremos a trabajar con datos usando Python m√°s adelante. Si no sabes c√≥mo ejecutar c√≥digo en Jupyter Notebook, consulta [este art√≠culo](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

Aqu√≠ est√° el gr√°fico de caja que muestra la media, mediana y cuartiles de nuestros datos:

![Gr√°fico de Caja de Peso](../../../../1-Introduction/04-stats-and-probability/images/weight-boxplot.png)

Dado que nuestros datos contienen informaci√≥n sobre diferentes **roles** de jugadores, tambi√©n podemos hacer el gr√°fico de caja por rol, lo que nos permitir√° tener una idea de c√≥mo los valores de los par√°metros difieren seg√∫n los roles. Esta vez consideraremos la altura:

![Gr√°fico de Caja por Rol](../../../../1-Introduction/04-stats-and-probability/images/boxplot_byrole.png)

Este diagrama sugiere que, en promedio, la altura de los jugadores de primera base es mayor que la altura de los jugadores de segunda base. M√°s adelante en esta lecci√≥n aprenderemos c√≥mo podemos probar esta hip√≥tesis de manera m√°s formal y c√≥mo demostrar que nuestros datos son estad√≠sticamente significativos para mostrar esto.

> Al trabajar con datos del mundo real, asumimos que todos los puntos de datos son muestras extra√≠das de alguna distribuci√≥n de probabilidad. Esta suposici√≥n nos permite aplicar t√©cnicas de aprendizaje autom√°tico y construir modelos predictivos funcionales.

Para ver cu√°l es la distribuci√≥n de nuestros datos, podemos graficar un **histograma**. El eje X contendr√° un n√∫mero de diferentes intervalos de peso (los llamados **bins**), y el eje vertical mostrar√° el n√∫mero de veces que nuestra muestra de variable aleatoria estuvo dentro de un intervalo dado.

![Histograma de datos del mundo real](../../../../1-Introduction/04-stats-and-probability/images/weight-histogram.png)

En este histograma puedes ver que todos los valores est√°n centrados alrededor de cierto peso promedio, y cuanto m√°s nos alejamos de ese peso, menos frecuentemente se encuentran pesos de ese valor. Es decir, es muy improbable que el peso de un jugador de b√©isbol sea muy diferente del peso promedio. La varianza de los pesos muestra la medida en que los pesos tienden a diferir del promedio.

> Si tomamos los pesos de otras personas, no de la liga de b√©isbol, es probable que la distribuci√≥n sea diferente. Sin embargo, la forma de la distribuci√≥n ser√° la misma, pero el promedio y la varianza cambiar√°n. Por lo tanto, si entrenamos nuestro modelo con jugadores de b√©isbol, es probable que d√© resultados incorrectos cuando se aplique a estudiantes de una universidad, porque la distribuci√≥n subyacente es diferente.

## Distribuci√≥n Normal

La distribuci√≥n de pesos que hemos visto anteriormente es muy t√≠pica, y muchas mediciones del mundo real siguen el mismo tipo de distribuci√≥n, pero con diferentes promedios y varianzas. Esta distribuci√≥n se llama **distribuci√≥n normal**, y juega un papel muy importante en estad√≠stica.

Usar la distribuci√≥n normal es una forma correcta de generar pesos aleatorios de posibles jugadores de b√©isbol. Una vez que conocemos el peso promedio `mean` y la desviaci√≥n est√°ndar `std`, podemos generar 1000 muestras de peso de la siguiente manera:
```python
samples = np.random.normal(mean,std,1000)
``` 

Si graficamos el histograma de las muestras generadas, veremos una imagen muy similar a la mostrada anteriormente. Y si aumentamos el n√∫mero de muestras y el n√∫mero de bins, podemos generar una imagen de una distribuci√≥n normal m√°s cercana al ideal:

![Distribuci√≥n Normal con media=0 y desviaci√≥n est√°ndar=1](../../../../1-Introduction/04-stats-and-probability/images/normal-histogram.png)

*Distribuci√≥n Normal con media=0 y desviaci√≥n est√°ndar=1*

## Intervalos de Confianza

Cuando hablamos de los pesos de los jugadores de b√©isbol, asumimos que existe cierta **variable aleatoria W** que corresponde a la distribuci√≥n de probabilidad ideal de los pesos de todos los jugadores de b√©isbol (la llamada **poblaci√≥n**). Nuestra secuencia de pesos corresponde a un subconjunto de todos los jugadores de b√©isbol que llamamos **muestra**. Una pregunta interesante es, ¬øpodemos conocer los par√°metros de la distribuci√≥n de W, es decir, la media y la varianza de la poblaci√≥n?

La respuesta m√°s sencilla ser√≠a calcular la media y la varianza de nuestra muestra. Sin embargo, podr√≠a suceder que nuestra muestra aleatoria no represente con precisi√≥n a la poblaci√≥n completa. Por lo tanto, tiene sentido hablar de **intervalos de confianza**.
> **El intervalo de confianza** es la estimaci√≥n del valor medio verdadero de la poblaci√≥n dado nuestro muestra, que es precisa con una cierta probabilidad (o **nivel de confianza**).
Supongamos que tenemos una muestra X<sub>1</sub>, ..., X<sub>n</sub> de nuestra distribuci√≥n. Cada vez que tomamos una muestra de nuestra distribuci√≥n, obtendremos un valor medio diferente Œº. Por lo tanto, Œº puede considerarse una variable aleatoria. Un **intervalo de confianza** con confianza p es un par de valores (L<sub>p</sub>,R<sub>p</sub>), tal que **P**(L<sub>p</sub>‚â§Œº‚â§R<sub>p</sub>) = p, es decir, la probabilidad de que el valor medio medido caiga dentro del intervalo es igual a p.

Va m√°s all√° de nuestra breve introducci√≥n discutir en detalle c√≥mo se calculan esos intervalos de confianza. Se pueden encontrar m√°s detalles [en Wikipedia](https://en.wikipedia.org/wiki/Confidence_interval). En resumen, definimos la distribuci√≥n de la media de la muestra calculada en relaci√≥n con la media verdadera de la poblaci√≥n, lo que se llama **distribuci√≥n t de Student**.

> **Dato interesante**: La distribuci√≥n t de Student lleva ese nombre en honor al matem√°tico William Sealy Gosset, quien public√≥ su art√≠culo bajo el seud√≥nimo "Student". Trabajaba en la cervecer√≠a Guinness y, seg√∫n una de las versiones, su empleador no quer√≠a que el p√∫blico supiera que utilizaban pruebas estad√≠sticas para determinar la calidad de las materias primas.

Si queremos estimar la media Œº de nuestra poblaci√≥n con confianza p, necesitamos tomar el *percentil (1-p)/2* de una distribuci√≥n t de Student A, que puede obtenerse de tablas o calcularse usando algunas funciones integradas de software estad√≠stico (por ejemplo, Python, R, etc.). Entonces, el intervalo para Œº ser√≠a dado por X¬±A*D/‚àön, donde X es la media obtenida de la muestra y D es la desviaci√≥n est√°ndar.

> **Nota**: Tambi√©n omitimos la discusi√≥n de un concepto importante de [grados de libertad](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)), que es relevante en relaci√≥n con la distribuci√≥n t de Student. Puedes consultar libros m√°s completos sobre estad√≠stica para entender este concepto en profundidad.

Un ejemplo de c√°lculo de intervalos de confianza para pesos y alturas se encuentra en los [notebooks adjuntos](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb).

| p    | Media del peso |
|------|----------------|
| 0.85 | 201.73¬±0.94    |
| 0.90 | 201.73¬±1.08    |
| 0.95 | 201.73¬±1.28    |

Observa que cuanto mayor es la probabilidad de confianza, m√°s amplio es el intervalo de confianza.

## Pruebas de hip√≥tesis

En nuestro conjunto de datos de jugadores de b√©isbol, hay diferentes roles de jugadores, que se pueden resumir a continuaci√≥n (consulta el [notebook adjunto](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) para ver c√≥mo se puede calcular esta tabla):

| Rol                | Altura     | Peso       | Cantidad |
|--------------------|------------|------------|----------|
| Catcher            | 72.723684  | 204.328947 | 76       |
| Designated_Hitter  | 74.222222  | 220.888889 | 18       |
| First_Baseman      | 74.000000  | 213.109091 | 55       |
| Outfielder         | 73.010309  | 199.113402 | 194      |
| Relief_Pitcher     | 74.374603  | 203.517460 | 315      |
| Second_Baseman     | 71.362069  | 184.344828 | 58       |
| Shortstop          | 71.903846  | 182.923077 | 52       |
| Starting_Pitcher   | 74.719457  | 205.163636 | 221      |
| Third_Baseman      | 73.044444  | 200.955556 | 45       |

Podemos notar que la altura media de los primera base es mayor que la de los segunda base. Por lo tanto, podr√≠amos estar tentados a concluir que **los primera base son m√°s altos que los segunda base**.

> Esta afirmaci√≥n se llama **una hip√≥tesis**, porque no sabemos si el hecho es realmente cierto o no.

Sin embargo, no siempre es obvio si podemos llegar a esta conclusi√≥n. Por la discusi√≥n anterior, sabemos que cada media tiene un intervalo de confianza asociado, y por lo tanto esta diferencia podr√≠a ser solo un error estad√≠stico. Necesitamos una forma m√°s formal de probar nuestra hip√≥tesis.

Calculemos los intervalos de confianza por separado para las alturas de los primera y segunda base:

| Confianza | Primera base   | Segunda base   |
|-----------|----------------|----------------|
| 0.85      | 73.62..74.38   | 71.04..71.69   |
| 0.90      | 73.56..74.44   | 70.99..71.73   |
| 0.95      | 73.47..74.53   | 70.92..71.81   |

Podemos ver que en ning√∫n nivel de confianza los intervalos se superponen. Esto prueba nuestra hip√≥tesis de que los primera base son m√°s altos que los segunda base.

M√°s formalmente, el problema que estamos resolviendo es ver si **dos distribuciones de probabilidad son iguales**, o al menos tienen los mismos par√°metros. Dependiendo de la distribuci√≥n, necesitamos usar diferentes pruebas para ello. Si sabemos que nuestras distribuciones son normales, podemos aplicar el **[t-test de Student](https://en.wikipedia.org/wiki/Student%27s_t-test)**.

En el t-test de Student, calculamos el llamado **valor t**, que indica la diferencia entre las medias, teniendo en cuenta la varianza. Se ha demostrado que el valor t sigue la **distribuci√≥n t de Student**, lo que nos permite obtener el valor umbral para un nivel de confianza **p** dado (esto puede calcularse o consultarse en tablas num√©ricas). Luego comparamos el valor t con este umbral para aprobar o rechazar la hip√≥tesis.

En Python, podemos usar el paquete **SciPy**, que incluye la funci√≥n `ttest_ind` (adem√°s de muchas otras funciones estad√≠sticas √∫tiles). Esta funci√≥n calcula el valor t por nosotros y tambi√©n realiza la b√∫squeda inversa del valor p de confianza, de modo que solo necesitamos observar la confianza para sacar una conclusi√≥n.

Por ejemplo, nuestra comparaci√≥n entre las alturas de los primera y segunda base nos da los siguientes resultados: 
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
En nuestro caso, el valor p es muy bajo, lo que significa que hay una fuerte evidencia que respalda que los primera base son m√°s altos.

Tambi√©n hay otros tipos de hip√≥tesis que podr√≠amos querer probar, por ejemplo:
* Probar que una muestra dada sigue alguna distribuci√≥n. En nuestro caso, hemos asumido que las alturas est√°n distribuidas normalmente, pero eso necesita una verificaci√≥n estad√≠stica formal.
* Probar que el valor medio de una muestra corresponde a un valor predefinido.
* Comparar las medias de varias muestras (por ejemplo, cu√°l es la diferencia en los niveles de felicidad entre diferentes grupos de edad).

## Ley de los grandes n√∫meros y teorema central del l√≠mite

Una de las razones por las que la distribuci√≥n normal es tan importante es el llamado **teorema central del l√≠mite**. Supongamos que tenemos una gran muestra de N valores independientes X<sub>1</sub>, ..., X<sub>N</sub>, muestreados de cualquier distribuci√≥n con media Œº y varianza œÉ<sup>2</sup>. Entonces, para un N suficientemente grande (en otras palabras, cuando N‚Üí‚àû), la media Œ£<sub>i</sub>X<sub>i</sub> estar√° distribuida normalmente, con media Œº y varianza œÉ<sup>2</sup>/N.

> Otra forma de interpretar el teorema central del l√≠mite es decir que, independientemente de la distribuci√≥n, cuando calculas la media de una suma de valores de cualquier variable aleatoria, terminas con una distribuci√≥n normal.

Del teorema central del l√≠mite tambi√©n se deduce que, cuando N‚Üí‚àû, la probabilidad de que la media de la muestra sea igual a Œº se convierte en 1. Esto se conoce como **la ley de los grandes n√∫meros**.

## Covarianza y correlaci√≥n

Una de las cosas que hace la ciencia de datos es encontrar relaciones entre datos. Decimos que dos secuencias **correlacionan** cuando exhiben un comportamiento similar al mismo tiempo, es decir, ambas suben/bajan simult√°neamente, o una sube cuando la otra baja y viceversa. En otras palabras, parece haber alguna relaci√≥n entre las dos secuencias.

> La correlaci√≥n no necesariamente indica una relaci√≥n causal entre dos secuencias; a veces ambas variables pueden depender de una causa externa, o puede ser pura casualidad que las dos secuencias correlacionen. Sin embargo, una fuerte correlaci√≥n matem√°tica es una buena indicaci√≥n de que dos variables est√°n de alguna manera conectadas.

Matem√°ticamente, el concepto principal que muestra la relaci√≥n entre dos variables aleatorias es la **covarianza**, que se calcula as√≠: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. Calculamos la desviaci√≥n de ambas variables respecto a sus valores medios, y luego el producto de esas desviaciones. Si ambas variables se desv√≠an juntas, el producto ser√° siempre un valor positivo, lo que sumar√° una covarianza positiva. Si ambas variables se desv√≠an de forma desincronizada (es decir, una cae por debajo del promedio cuando la otra sube por encima del promedio), siempre obtendremos n√∫meros negativos, que sumar√°n una covarianza negativa. Si las desviaciones no son dependientes, sumar√°n aproximadamente cero.

El valor absoluto de la covarianza no nos dice mucho sobre cu√°n grande es la correlaci√≥n, porque depende de la magnitud de los valores reales. Para normalizarlo, podemos dividir la covarianza por la desviaci√≥n est√°ndar de ambas variables, para obtener la **correlaci√≥n**. Lo bueno es que la correlaci√≥n siempre est√° en el rango de [-1,1], donde 1 indica una fuerte correlaci√≥n positiva entre los valores, -1 una fuerte correlaci√≥n negativa, y 0 ninguna correlaci√≥n en absoluto (las variables son independientes).

**Ejemplo**: Podemos calcular la correlaci√≥n entre los pesos y las alturas de los jugadores de b√©isbol del conjunto de datos mencionado anteriormente:
```python
print(np.corrcoef(weights,heights))
```
Como resultado, obtenemos una **matriz de correlaci√≥n** como esta:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> La matriz de correlaci√≥n C puede calcularse para cualquier n√∫mero de secuencias de entrada S<sub>1</sub>, ..., S<sub>n</sub>. El valor de C<sub>ij</sub> es la correlaci√≥n entre S<sub>i</sub> y S<sub>j</sub>, y los elementos diagonales siempre son 1 (que tambi√©n es la autocorrelaci√≥n de S<sub>i</sub>).

En nuestro caso, el valor 0.53 indica que hay cierta correlaci√≥n entre el peso y la altura de una persona. Tambi√©n podemos hacer un diagrama de dispersi√≥n de un valor contra el otro para ver la relaci√≥n visualmente:

![Relaci√≥n entre peso y altura](../../../../1-Introduction/04-stats-and-probability/images/weight-height-relationship.png)

> M√°s ejemplos de correlaci√≥n y covarianza se pueden encontrar en el [notebook adjunto](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb).

## Conclusi√≥n

En esta secci√≥n, hemos aprendido:

* Propiedades estad√≠sticas b√°sicas de los datos, como media, varianza, moda y cuartiles.
* Diferentes distribuciones de variables aleatorias, incluida la distribuci√≥n normal.
* C√≥mo encontrar la correlaci√≥n entre diferentes propiedades.
* C√≥mo usar un aparato matem√°tico y estad√≠stico s√≥lido para probar algunas hip√≥tesis.
* C√≥mo calcular intervalos de confianza para una variable aleatoria dada una muestra de datos.

Aunque esta no es una lista exhaustiva de temas que existen dentro de la probabilidad y la estad√≠stica, deber√≠a ser suficiente para darte un buen comienzo en este curso.

## üöÄ Desaf√≠o

Usa el c√≥digo de ejemplo en el notebook para probar otras hip√≥tesis como: 
1. Los primera base son mayores que los segunda base.
2. Los primera base son m√°s altos que los tercera base.
3. Los shortstops son m√°s altos que los segunda base.

## [Cuestionario posterior a la lecci√≥n](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/7)

## Revisi√≥n y autoestudio

La probabilidad y la estad√≠stica son temas tan amplios que merecen su propio curso. Si est√°s interesado en profundizar en la teor√≠a, puedes continuar leyendo algunos de los siguientes libros:

1. [Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/) de la Universidad de Nueva York tiene excelentes notas de clase [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (disponibles en l√≠nea).
1. [Peter y Andrew Bruce. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[c√≥digo de ejemplo en R](https://github.com/andrewgbruce/statistics-for-data-scientists)].
1. [James D. Miller. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[c√≥digo de ejemplo en R](https://github.com/PacktPublishing/Statistics-for-Data-Science)].

## Tarea

[Peque√±o estudio sobre diabetes](assignment.md)

## Cr√©ditos

Esta lecci√≥n ha sido creada con ‚ô•Ô∏è por [Dmitry Soshnikov](http://soshnikov.com)

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.