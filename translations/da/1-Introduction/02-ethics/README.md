<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1341f6da63d434f5ba31b08ea951b02c",
  "translation_date": "2025-09-05T22:09:26+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "da"
}
-->
# Introduktion til Dataetik

|![ Sketchnote af [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Data Science Ethics - _Sketchnote af [@nitya](https://twitter.com/nitya)_ |

---

Vi er alle databorger i en verden pr칝get af data.

Markedsanalyser viser, at inden 2022 vil 1 ud af 3 store organisationer k칮be og s칝lge deres data via online [markedspladser og b칮rser](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Som **appudviklere** vil vi finde det nemmere og billigere at integrere datadrevne indsigter og algoritmebaseret automatisering i daglige brugeroplevelser. Men efterh친nden som AI bliver mere udbredt, skal vi ogs친 forst친 de potentielle skader, der kan opst친 ved [v친benisering](https://www.youtube.com/watch?v=TQHs8SA1qpk) af s친danne algoritmer i stor skala.

Tendenser viser ogs친, at vi vil skabe og forbruge over [180 zettabytes](https://www.statista.com/statistics/871513/worldwide-data-created/) data inden 2025. Som **dataforskere** giver dette os en hidtil uset adgang til personlige data. Det betyder, at vi kan opbygge adf칝rdsprofiler af brugere og p친virke beslutningstagning p친 m친der, der skaber en [illusion af frit valg](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice), mens vi potentielt skubber brugere mod resultater, vi foretr칝kker. Det rejser ogs친 bredere sp칮rgsm친l om databeskyttelse og brugerrettigheder.

Dataetik er nu _n칮dvendige retningslinjer_ for data science og ingeni칮rarbejde, der hj칝lper os med at minimere potentielle skader og utilsigtede konsekvenser af vores datadrevne handlinger. [Gartner Hype Cycle for AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) identificerer relevante tendenser inden for digital etik, ansvarlig AI og AI-styring som n칮glefaktorer for st칮rre megatrends omkring _demokratisering_ og _industrialisering_ af AI.

![Gartner's Hype Cycle for AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

I denne lektion vil vi udforske det fascinerende omr친de dataetik - fra kernekoncepter og udfordringer til casestudier og anvendte AI-koncepter som styring - der hj칝lper med at etablere en etik-kultur i teams og organisationer, der arbejder med data og AI.

## [Quiz f칮r lektionen](https://ff-quizzes.netlify.app/en/ds/quiz/2) 游꿢

## Grundl칝ggende Definitioner

Lad os starte med at forst친 den grundl칝ggende terminologi.

Ordet "etik" stammer fra det [gr칝ske ord "ethikos"](https://en.wikipedia.org/wiki/Ethics) (og dets rod "ethos"), som betyder _karakter eller moralsk natur_. 

**Etik** handler om de f칝lles v칝rdier og moralske principper, der styrer vores adf칝rd i samfundet. Etik er ikke baseret p친 love, men p친 bredt accepterede normer for, hvad der er "rigtigt vs. forkert". Dog kan etiske overvejelser p친virke initiativer inden for virksomhedsledelse og regeringsregulering, der skaber flere incitamenter til overholdelse.

**Dataetik** er en [ny gren af etik](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1), der "unders칮ger og evaluerer moralske problemer relateret til _data, algoritmer og tilsvarende praksis_". Her fokuserer **"data"** p친 handlinger relateret til generering, registrering, kuratering, behandling, spredning, deling og brug, **"algoritmer"** fokuserer p친 AI, agenter, maskinl칝ring og robotter, og **"praksis"** fokuserer p친 emner som ansvarlig innovation, programmering, hacking og etiske koder.

**Anvendt etik** er den [praktiske anvendelse af moralske overvejelser](https://en.wikipedia.org/wiki/Applied_ethics). Det er processen med aktivt at unders칮ge etiske sp칮rgsm친l i konteksten af _virkelige handlinger, produkter og processer_ og tage korrigerende foranstaltninger for at sikre, at disse forbliver i overensstemmelse med vores definerede etiske v칝rdier.

**Etik-kultur** handler om [_operationelt at anvende_ etik](https://hbr.org/2019/05/how-to-design-an-ethical-organization) for at sikre, at vores etiske principper og praksis bliver vedtaget p친 en konsekvent og skalerbar m친de i hele organisationen. Succesfulde etik-kulturer definerer organisationens etiske principper, giver meningsfulde incitamenter til overholdelse og forst칝rker etiske normer ved at opmuntre og fremh칝ve 칮nsket adf칝rd p친 alle niveauer i organisationen.

## Etiske Koncepter

I denne sektion vil vi diskutere koncepter som **f칝lles v칝rdier** (principper) og **etiske udfordringer** (problemer) inden for dataetik - og udforske **casestudier**, der hj칝lper dig med at forst친 disse koncepter i virkelige kontekster.

### 1. Etiske Principper

Enhver dataetik-strategi begynder med at definere _etiske principper_ - de "f칝lles v칝rdier", der beskriver acceptable adf칝rdsm칮nstre og guider overholdelse i vores data- og AI-projekter. Du kan definere disse p친 individuelt eller teamniveau. Dog beskriver de fleste store organisationer disse i en _etisk AI_-missionserkl칝ring eller rammev칝rk, der er defineret p친 virksomhedsniveau og konsekvent h친ndh칝vet p친 tv칝rs af alle teams.

**Eksempel:** Microsofts [Ansvarlig AI](https://www.microsoft.com/en-us/ai/responsible-ai)-missionserkl칝ring lyder: _"Vi er forpligtet til at fremme AI drevet af etiske principper, der s칝tter mennesker f칮rst"_ - og identificerer 6 etiske principper i rammev칝rket nedenfor:

![Ansvarlig AI hos Microsoft](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

Lad os kort udforske disse principper. _Transparens_ og _ansvarlighed_ er grundl칝ggende v칝rdier, som de andre principper bygger p친 - s친 lad os starte der:

* [**Ansvarlighed**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) g칮r praktikere _ansvarlige_ for deres data- og AI-operationer og overholdelse af disse etiske principper.
* [**Transparens**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) sikrer, at data- og AI-handlinger er _forst친elige_ (fortolkelige) for brugere, og forklarer hvad og hvorfor bag beslutninger.
* [**Retf칝rdighed**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) fokuserer p친 at sikre, at AI behandler _alle mennesker_ retf칝rdigt og adresserer eventuelle systemiske eller implicitte socio-tekniske bias i data og systemer.
* [**P친lidelighed & Sikkerhed**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) sikrer, at AI opf칮rer sig _konsekvent_ med definerede v칝rdier og minimerer potentielle skader eller utilsigtede konsekvenser.
* [**Privatliv & Sikkerhed**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) handler om at forst친 dataens oprindelse og give _databeskyttelse og relaterede rettigheder_ til brugere.
* [**Inklusion**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) handler om at designe AI-l칮sninger med intention og tilpasse dem til at im칮dekomme et _bredt spektrum af menneskelige behov_ og evner.

> 游뚿 Overvej, hvad din dataetik-missionserkl칝ring kunne v칝re. Udforsk etiske AI-rammer fra andre organisationer - her er eksempler fra [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles) og [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Hvilke f칝lles v칝rdier har de? Hvordan relaterer disse principper sig til AI-produkterne eller -industrien, de opererer i?

### 2. Etiske Udfordringer

N친r vi har defineret etiske principper, er n칝ste skridt at evaluere vores data- og AI-handlinger for at se, om de stemmer overens med disse f칝lles v칝rdier. T칝nk p친 dine handlinger i to kategorier: _datainnsamling_ og _algoritmedesign_. 

Ved datainnsamling vil handlinger sandsynligvis involvere **personlige data** eller personligt identificerbare oplysninger (PII) for identificerbare levende individer. Dette inkluderer [forskellige typer af ikke-personlige data](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en), der _samlet set_ identificerer en person. Etiske udfordringer kan relateres til _databeskyttelse_, _dataejerskab_ og relaterede emner som _informeret samtykke_ og _intellektuelle ejendomsrettigheder_ for brugere.

Ved algoritmedesign vil handlinger involvere indsamling og kuratering af **datas칝t**, som derefter bruges til at tr칝ne og implementere **datamodeller**, der forudsiger resultater eller automatiserer beslutninger i virkelige kontekster. Etiske udfordringer kan opst친 fra _datas칝tbias_, _datakvalitetsproblemer_, _uretf칝rdighed_ og _fejlrepr칝sentation_ i algoritmer - inklusive nogle problemer, der er systemiske af natur.

I begge tilf칝lde fremh칝ver etiske udfordringer omr친der, hvor vores handlinger kan komme i konflikt med vores f칝lles v칝rdier. For at opdage, afb칮de, minimere eller eliminere disse bekymringer skal vi stille moralske "ja/nej"-sp칮rgsm친l relateret til vores handlinger og derefter tage korrigerende handlinger efter behov. Lad os se p친 nogle etiske udfordringer og de moralske sp칮rgsm친l, de rejser:

#### 2.1 Dataejerskab

Datainnsamling involverer ofte personlige data, der kan identificere datasubjekterne. [Dataejerskab](https://permission.io/blog/data-ownership) handler om _kontrol_ og [_brugerrettigheder_](https://permission.io/blog/data-ownership) relateret til oprettelse, behandling og spredning af data. 

De moralske sp칮rgsm친l, vi skal stille, er: 
 * Hvem ejer dataene? (bruger eller organisation)
 * Hvilke rettigheder har datasubjekterne? (fx adgang, sletning, portabilitet)
 * Hvilke rettigheder har organisationer? (fx rette skadelige brugeranmeldelser)

#### 2.2 Informeret Samtykke

[Informeret samtykke](https://legaldictionary.net/informed-consent/) definerer handlingen, hvor brugere accepterer en handling (som datainnsamling) med en _fuld forst친else_ af relevante fakta, herunder form친l, potentielle risici og alternativer. 

Sp칮rgsm친l at udforske her er:
 * Gav brugeren (datasubjektet) tilladelse til datainnsamling og brug?
 * Forstod brugeren form친let med, hvorfor dataene blev indsamlet?
 * Forstod brugeren de potentielle risici ved deres deltagelse?

#### 2.3 Intellektuel Ejendom

[Intellektuel ejendom](https://en.wikipedia.org/wiki/Intellectual_property) refererer til immaterielle skabelser, der er resultatet af menneskelig initiativ, og som kan _have 칮konomisk v칝rdi_ for individer eller virksomheder. 

Sp칮rgsm친l at udforske her er:
 * Havde de indsamlede data 칮konomisk v칝rdi for en bruger eller virksomhed?
 * Har **brugeren** intellektuel ejendom her?
 * Har **organisationen** intellektuel ejendom her?
 * Hvis disse rettigheder eksisterer, hvordan beskytter vi dem?

#### 2.4 Databeskyttelse

[Databeskyttelse](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) eller informationsbeskyttelse refererer til bevarelse af brugerens privatliv og beskyttelse af brugerens identitet med hensyn til personligt identificerbare oplysninger. 

Sp칮rgsm친l at udforske her er:
 * Er brugernes (personlige) data sikret mod hacks og l칝kager?
 * Er brugernes data kun tilg칝ngelige for autoriserede brugere og kontekster?
 * Er brugernes anonymitet bevaret, n친r data deles eller spredes?
 * Kan en bruger blive de-identificeret fra anonymiserede datas칝t?

#### 2.5 Retten til at Blive Glemt

[Retten til at blive glemt](https://en.wikipedia.org/wiki/Right_to_be_forgotten) eller [Retten til Sletning](https://www.gdpreu.org/right-to-be-forgotten/) giver yderligere beskyttelse af personlige data til brugere. Specifikt giver det brugere ret til at anmode om sletning eller fjernelse af personlige data fra internets칮gninger og andre steder, _under specifikke omst칝ndigheder_ - hvilket giver dem en ny start online uden tidligere handlinger, der holdes imod dem.

Sp칮rgsm친l at udforske her er:
 * Tillader systemet datasubjekter at anmode om sletning?
 * Skal tilbagetr칝kning af brugerens samtykke udl칮se automatisk sletning?
 * Blev data indsamlet uden samtykke eller p친 ulovlig vis?
 * Overholder vi regeringsregler for databeskyttelse?

#### 2.6 Datas칝tbias

Datas칝t eller [indsamlingsbias](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) handler om at v칝lge et _ikke-repr칝sentativt_ datas칝t til algoritmeudvikling, hvilket skaber potentiel uretf칝rdighed i resultatet for forskellige grupper. Typer af bias inkluderer udv칝lgelses- eller pr칮vebias, frivillig bias og instrumentbias. 

Sp칮rgsm친l at udforske her er:
 * Rekrutterede vi et repr칝sentativt datas칝t af datasubjekter?
 * Testede vi vores indsamlede eller kuraterede datas칝t for forskellige bias?
 * Kan vi afb칮de eller fjerne opdagede bias?

#### 2.7 Datakvalitet

[Datakvalitet](https://lakefs.io/data-quality-testing/) ser p친 gyldigheden af det kuraterede datas칝t, der bruges til at udvikle vores algoritmer, og kontrollerer, om funktioner og poster opfylder kravene til det niveau af n칮jagtighed og konsistens, der er n칮dvendigt for vores AI-form친l.

Sp칮rgsm친l at udforske her er:
 * Indfangede vi gyldige _funktioner_ til vores brugssag?
 * Blev data indsamlet _konsekvent_ p친 tv칝rs af forskellige datakilder?
 * Er datas칝ttet _komplet_ for forskellige forhold eller scenarier?
 * Er informationen indsamlet _n칮jagtigt_ i forhold til virkeligheden?

#### 2.8 Algoritme Retf칝rdighed
[Algorithm Fairness](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) unders칮ger, om algoritmedesign systematisk diskriminerer specifikke undergrupper af datasubjekter, hvilket kan f칮re til [potentielle skader](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) inden for _fordeling_ (hvor ressourcer n칝gtes eller tilbageholdes fra den gruppe) og _kvaliteten af service_ (hvor AI ikke er lige s친 pr칝cis for nogle undergrupper som for andre).

Sp칮rgsm친l, der kan udforskes her, er:
 * Evaluerede vi modelpr칝cision for forskellige undergrupper og forhold?
 * Unders칮gte vi systemet for potentielle skader (f.eks. stereotyper)?
 * Kan vi revidere data eller genoptr칝ne modeller for at afhj칝lpe identificerede skader?

Udforsk ressourcer som [AI Fairness checklister](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) for at l칝re mere.

#### 2.9 Fejlrepr칝sentation

[Data Fejlrepr칝sentation](https://www.sciencedirect.com/topics/computer-science/misrepresentation) handler om at sp칮rge, om vi kommunikerer indsigter fra 칝rligt rapporterede data p친 en vildledende m친de for at underst칮tte en 칮nsket fort칝lling.

Sp칮rgsm친l, der kan udforskes her, er:
 * Rapporterer vi ufuldst칝ndige eller un칮jagtige data?
 * Visualiserer vi data p친 en m친de, der f칮rer til vildledende konklusioner?
 * Bruger vi selektive statistiske teknikker til at manipulere resultater?
 * Er der alternative forklaringer, der kan give en anden konklusion?

#### 2.10 Fri Valg
[Illusionen af Fri Valg](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) opst친r, n친r systemets "valgarkitekturer" bruger beslutningsalgoritmer til at skubbe folk mod at tage et foretrukket resultat, mens det ser ud som om, de har muligheder og kontrol. Disse [m칮rke m칮nstre](https://www.darkpatterns.org/) kan for친rsage sociale og 칮konomiske skader for brugere. Fordi brugerbeslutninger p친virker adf칝rdsprofiler, kan disse handlinger potentielt drive fremtidige valg, der kan forst칝rke eller udvide virkningen af disse skader.

Sp칮rgsm친l, der kan udforskes her, er:
 * Forstod brugeren konsekvenserne af at tr칝ffe det valg?
 * Var brugeren opm칝rksom p친 (alternative) valg og fordele & ulemper ved hver?
 * Kan brugeren senere fortryde et automatiseret eller p친virket valg?

### 3. Case Studier

For at s칝tte disse etiske udfordringer i virkelige kontekster hj칝lper det at se p친 case studier, der fremh칝ver de potentielle skader og konsekvenser for individer og samfund, n친r s친danne etiske overtr칝delser overses.

Her er nogle eksempler:

| Etisk Udfordring | Case Studie  | 
|--- |--- |
| **Informeret Samtykke** | 1972 - [Tuskegee Syphilis Study](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - Afroamerikanske m칝nd, der deltog i unders칮gelsen, blev lovet gratis medicinsk behandling _men blev bedraget_ af forskere, der undlod at informere dem om deres diagnose eller om tilg칝ngelig behandling. Mange d칮de, og partnere eller b칮rn blev p친virket; unders칮gelsen varede i 40 친r. | 
| **Data Privatliv** |  2007 - [Netflix data prize](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) gav forskere _10M anonymiserede filmvurderinger fra 50K kunder_ for at hj칝lpe med at forbedre anbefalingsalgoritmer. Forskere var dog i stand til at korrelere anonymiserede data med personligt identificerbare data i _eksterne datas칝t_ (f.eks. IMDb-kommentarer) - effektivt "de-anonymiserende" nogle Netflix-abonnenter.|
| **Indsamlingsbias**  | 2013 - Boston City [udviklede Street Bump](https://www.boston.gov/transportation/street-bump), en app, der lod borgere rapportere huller i vejen, hvilket gav byen bedre data til at finde og l칮se problemer. Dog havde [folk i lavindkomstgrupper mindre adgang til biler og telefoner](https://hbr.org/2013/04/the-hidden-biases-in-big-data), hvilket gjorde deres vejproblemer usynlige i denne app. Udviklere arbejdede med akademikere for at l칮se _lighed i adgang og digitale skel_ for retf칝rdighed. |
| **Algoritmisk Retf칝rdighed**  | 2018 - MIT [Gender Shades Study](http://gendershades.org/overview.html) evaluerede pr칝cisionen af AI-produkter til k칮nsidentifikation og afsl칮rede mangler i pr칝cision for kvinder og farvede personer. Et [2019 Apple Card](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) syntes at tilbyde mindre kredit til kvinder end m칝nd. Begge eksempler illustrerer problemer med algoritmisk bias, der f칮rer til socio칮konomiske skader.|
| **Data Fejlrepr칝sentation** | 2020 - [Georgia Department of Public Health udgav COVID-19 diagrammer](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening), der syntes at vildlede borgere om tendenser i bekr칝ftede tilf칝lde med ikke-kronologisk orden p친 x-aksen. Dette illustrerer fejlrepr칝sentation gennem visualiseringstricks. |
| **Illusionen af fri valg** | 2020 - L칝ringsappen [ABCmouse betalte $10M for at l칮se en FTC-klage](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/), hvor for칝ldre blev fanget i at betale for abonnementer, de ikke kunne annullere. Dette illustrerer m칮rke m칮nstre i valgarkitekturer, hvor brugere blev skubbet mod potentielt skadelige valg. |
| **Data Privatliv & Brugerrettigheder** | 2021 - Facebook [Data Brud](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) afsl칮rede data fra 530M brugere, hvilket resulterede i en $5B forlig med FTC. Det n칝gtede dog at informere brugere om bruddet, hvilket overtr친dte brugerrettigheder omkring datatransparens og adgang. |

Vil du udforske flere case studier? Tjek disse ressourcer:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - etiske dilemmaer p친 tv칝rs af forskellige industrier. 
* [Data Science Ethics course](https://www.coursera.org/learn/data-science-ethics#syllabus) - landmark case studier udforsket.
* [Where things have gone wrong](https://deon.drivendata.org/examples/) - deon checklist med eksempler.


> 游뚿 T칝nk over de case studier, du har set - har du oplevet eller v칝ret p친virket af en lignende etisk udfordring i dit liv? Kan du t칝nke p친 mindst 칠n anden case studie, der illustrerer en af de etiske udfordringer, vi har diskuteret i dette afsnit?

## Anvendt Etik

Vi har talt om etiske begreber, udfordringer og case studier i virkelige kontekster. Men hvordan kommer vi i gang med at _anvende_ etiske principper og praksisser i vores projekter? Og hvordan _operationaliserer_ vi disse praksisser for bedre styring? Lad os udforske nogle virkelige l칮sninger: 

### 1. Professionelle Koder

Professionelle koder tilbyder en mulighed for organisationer til at "incitamentere" medlemmer til at st칮tte deres etiske principper og mission. Koder er _moralske retningslinjer_ for professionel adf칝rd, der hj칝lper medarbejdere eller medlemmer med at tr칝ffe beslutninger, der stemmer overens med organisationens principper. De er kun s친 gode som den frivillige overholdelse fra medlemmer; dog tilbyder mange organisationer yderligere bel칮nninger og sanktioner for at motivere overholdelse.

Eksempler inkluderer:

 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Code of Ethics
 * [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Code of Conduct (oprettet 2013)
 * [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (siden 1993)

> 游뚿 Tilh칮rer du en professionel ingeni칮r- eller data science-organisation? Udforsk deres hjemmeside for at se, om de definerer en professionel kodeks for etik. Hvad siger dette om deres etiske principper? Hvordan "incitamenterer" de medlemmer til at f칮lge koden?

### 2. Etiske Checklister

Mens professionelle koder definerer kr칝vet _etisk adf칝rd_ fra praktikere, har de [kendte begr칝nsninger](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) i h친ndh칝velse, is칝r i store projekter. I stedet anbefaler mange data science-eksperter [checklister](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), der kan **forbinde principper med praksis** p친 mere deterministiske og handlingsorienterede m친der.

Checklister konverterer sp칮rgsm친l til "ja/nej"-opgaver, der kan operationaliseres, hvilket g칮r det muligt at spore dem som en del af standard produktudgivelsesarbejdsgange.

Eksempler inkluderer:
 * [Deon](https://deon.drivendata.org/) - en generel dataetik-checkliste oprettet fra [industriens anbefalinger](https://deon.drivendata.org/#checklist-citations) med et kommandolinjev칝rkt칮j for nem integration.
 * [Privacy Audit Checklist](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - giver generel vejledning til informationsh친ndteringspraksis fra juridiske og sociale eksponeringsperspektiver.
 * [AI Fairness Checklist](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - oprettet af AI-praktikere for at st칮tte adoption og integration af fairness-checks i AI-udviklingscyklusser.
 * [22 sp칮rgsm친l om etik i data og AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - en mere 친ben ramme, struktureret til indledende udforskning af etiske sp칮rgsm친l i design, implementering og organisatoriske kontekster.

### 3. Etiske Reguleringer

Etik handler om at definere f칝lles v칝rdier og g칮re det rigtige _frivilligt_. **Overholdelse** handler om _at f칮lge loven_, hvis og hvor den er defineret. **Styring** d칝kker bredt alle de m친der, hvorp친 organisationer opererer for at h친ndh칝ve etiske principper og overholde etablerede love.

I dag tager styring to former inden for organisationer. For det f칮rste handler det om at definere **etiske AI**-principper og etablere praksisser for at operationalisere adoption p친 tv칝rs af alle AI-relaterede projekter i organisationen. For det andet handler det om at overholde alle regeringsmandaterede **databeskyttelsesreguleringer** for de regioner, den opererer i.

Eksempler p친 databeskyttelse og privatlivsreguleringer:

 * `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - regulerer _f칮deral regeringens_ indsamling, brug og offentligg칮relse af personlige oplysninger.
 * `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - beskytter personlige sundhedsdata.
 * `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - beskytter dataprivacy for b칮rn under 13.
 * `2018`, [General Data Protection Regulation (GDPR)](https://gdpr-info.eu/) - giver brugerrettigheder, databeskyttelse og privatliv.
 * `2018`, [California Consumer Privacy Act (CCPA)](https://www.oag.ca.gov/privacy/ccpa) giver forbrugere flere _rettigheder_ over deres (personlige) data.
 * `2021`, Kinas [Personal Information Protection Law](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) blev netop vedtaget og skaber en af de st칝rkeste online dataprivacy-reguleringer i verden.

> 游뚿 Den Europ칝iske Union definerede GDPR (General Data Protection Regulation) forbliver en af de mest indflydelsesrige dataprivacy-reguleringer i dag. Vidste du, at den ogs친 definerer [8 brugerrettigheder](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) for at beskytte borgeres digitale privatliv og personlige data? L칝r om, hvad disse er, og hvorfor de betyder noget.


### 4. Etisk Kultur

Bem칝rk, at der stadig er en uh친ndgribelig kl칮ft mellem _overholdelse_ (at g칮re nok til at opfylde "lovens bogstav") og adressering af [systemiske problemer](https://www.coursera.org/learn/data-science-ethics/home/week/4) (som stivhed, informationsasymmetri og fordelingsm칝ssig uretf칝rdighed), der kan fremskynde v친beniseringen af AI.

Sidstn칝vnte kr칝ver [samarbejdsmetoder til at definere etiske kulturer](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f), der bygger f칮lelsesm칝ssige forbindelser og konsistente f칝lles v칝rdier _p친 tv칝rs af organisationer_ i branchen. Dette kr칝ver mere [formaliserede dataetiske kulturer](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) i organisationer - hvilket giver _alle_ mulighed for at [tr칝kke Andon-snoren](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (for at rejse etiske bekymringer tidligt i processen) og g칮re _etiske vurderinger_ (f.eks. ved ans칝ttelse) til et kernekriterium for teamdannelse i AI-projekter.

---
## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ds/quiz/3) 游꿢
## Gennemgang & Selvstudie 

Kurser og b칮ger hj칝lper med at forst친 kerneetikbegreber og udfordringer, mens case studier og v칝rkt칮jer hj칝lper med anvendte etiske praksisser i virkelige kontekster. Her er nogle ressourcer at starte med.

* [Machine Learning For Beginners](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - lektion om retf칝rdighed, fra Microsoft.
* [Principper for ansvarlig AI](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - gratis l칝ringsforl칮b fra Microsoft Learn.
* [Etik og Data Science](https://resources.oreilly.com/examples/0636920203964) - O'Reilly EBook (M. Loukides, H. Mason m.fl.)
* [Data Science Etik](https://www.coursera.org/learn/data-science-ethics#syllabus) - online kursus fra University of Michigan.
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - casestudier fra University of Texas.

# Opgave 

[Skriv en case study om dataetik](assignment.md)

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj칝lp af AI-overs칝ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr칝ber os p친 at sikre n칮jagtighed, skal det bem칝rkes, at automatiserede overs칝ttelser kan indeholde fejl eller un칮jagtigheder. Det originale dokument p친 dets oprindelige sprog b칮r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs칝ttelse. Vi p친tager os ikke ansvar for eventuelle misforst친elser eller fejltolkninger, der m친tte opst친 som f칮lge af brugen af denne overs칝ttelse.