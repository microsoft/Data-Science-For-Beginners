<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1cf49f029ba1f25a54f0d5bc2fa575fc",
  "translation_date": "2025-09-05T22:07:11+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "da"
}
-->
# En kort introduktion til statistik og sandsynlighed

|![ Sketchnote af [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| Statistik og sandsynlighed - _Sketchnote af [@nitya](https://twitter.com/nitya)_ |

Statistik og sandsynlighedsteori er to n√¶rt besl√¶gtede omr√•der inden for matematik, som er yderst relevante for datavidenskab. Det er muligt at arbejde med data uden en dyb forst√•else af matematik, men det er stadig en fordel at kende til nogle grundl√¶ggende begreber. Her pr√¶senterer vi en kort introduktion, der kan hj√¶lpe dig i gang.

[![Introduktionsvideo](../../../../1-Introduction/04-stats-and-probability/images/video-prob-and-stats.png)](https://youtu.be/Z5Zy85g4Yjw)

## [Quiz f√∏r forel√¶sning](https://ff-quizzes.netlify.app/en/ds/quiz/6)

## Sandsynlighed og stokastiske variable

**Sandsynlighed** er et tal mellem 0 og 1, der udtrykker, hvor sandsynligt en **h√¶ndelse** er. Det defineres som antallet af positive udfald (der f√∏rer til h√¶ndelsen) divideret med det samlede antal udfald, forudsat at alle udfald er lige sandsynlige. For eksempel, n√•r vi kaster en terning, er sandsynligheden for at f√• et lige tal 3/6 = 0,5.

N√•r vi taler om h√¶ndelser, bruger vi **stokastiske variable**. For eksempel vil den stokastiske variabel, der repr√¶senterer et tal opn√•et ved at kaste en terning, tage v√¶rdier fra 1 til 6. M√¶ngden af tal fra 1 til 6 kaldes **udfaldsrummet**. Vi kan tale om sandsynligheden for, at en stokastisk variabel tager en bestemt v√¶rdi, for eksempel P(X=3)=1/6.

Den stokastiske variabel i det foreg√•ende eksempel kaldes **diskret**, fordi den har et t√¶lleligt udfaldsrum, dvs. der er adskilte v√¶rdier, der kan opregnes. Der findes ogs√• tilf√¶lde, hvor udfaldsrummet er et interval af reelle tal eller hele m√¶ngden af reelle tal. S√•danne variable kaldes **kontinuerte**. Et godt eksempel er tidspunktet, hvor bussen ankommer.

## Sandsynlighedsfordeling

For diskrete stokastiske variable er det nemt at beskrive sandsynligheden for hver h√¶ndelse ved en funktion P(X). For hver v√¶rdi *s* fra udfaldsrummet *S* vil den give et tal mellem 0 og 1, s√•dan at summen af alle v√¶rdier af P(X=s) for alle h√¶ndelser er 1.

Den mest kendte diskrete fordeling er **den uniforme fordeling**, hvor der er et udfaldsrum med N elementer, og hver af dem har lige sandsynlighed p√• 1/N.

Det er mere kompliceret at beskrive sandsynlighedsfordelingen for en kontinuert variabel med v√¶rdier trukket fra et interval [a,b] eller hele m√¶ngden af reelle tal ‚Ñù. Overvej tilf√¶ldet med bustidspunkt. Faktisk er sandsynligheden for, at bussen ankommer pr√¶cis p√• et bestemt tidspunkt *t*, 0!

> Nu ved du, at h√¶ndelser med sandsynlighed 0 sker, og det sker ofte! I hvert fald hver gang bussen ankommer!

Vi kan kun tale om sandsynligheden for, at en variabel falder inden for et givet interval af v√¶rdier, fx P(t<sub>1</sub>‚â§X<t<sub>2</sub>). I dette tilf√¶lde beskrives sandsynlighedsfordelingen af en **sandsynlighedst√¶thedsfunktion** p(x), s√•dan at

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../1-Introduction/04-stats-and-probability/images/probability-density.png)

En kontinuert analog til den uniforme fordeling kaldes **kontinuerlig uniform**, som er defineret p√• et endeligt interval. Sandsynligheden for, at v√¶rdien X falder inden for et interval af l√¶ngde l, er proportional med l og stiger op til 1.

En anden vigtig fordeling er **den normale fordeling**, som vi vil tale mere om nedenfor.

## Middelv√¶rdi, varians og standardafvigelse

Antag, at vi tr√¶kker en sekvens af n pr√∏ver af en stokastisk variabel X: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. Vi kan definere **middelv√¶rdien** (eller **aritmetisk gennemsnit**) af sekvensen p√• traditionel vis som (x<sub>1</sub>+x<sub>2</sub>+...+x<sub>n</sub>)/n. N√•r vi √∏ger st√∏rrelsen af pr√∏ven (dvs. tager gr√¶nsen med n‚Üí‚àû), opn√•r vi middelv√¶rdien (ogs√• kaldet **forventningen**) af fordelingen. Vi betegner forventningen med **E**(x).

> Det kan vises, at for enhver diskret fordeling med v√¶rdier {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} og tilsvarende sandsynligheder p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, vil forventningen v√¶re E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>.

For at identificere, hvor meget v√¶rdierne spreder sig, kan vi beregne variansen œÉ<sup>2</sup> = ‚àë(x<sub>i</sub> - Œº)<sup>2</sup>/n, hvor Œº er middelv√¶rdien af sekvensen. V√¶rdien œÉ kaldes **standardafvigelse**, og œÉ<sup>2</sup> kaldes **varians**.

## Typetal, median og kvartiler

Nogle gange repr√¶senterer middelv√¶rdien ikke tilstr√¶kkeligt den "typiske" v√¶rdi for data. For eksempel, n√•r der er nogle f√• ekstreme v√¶rdier, der ligger helt uden for r√¶kkevidde, kan de p√•virke middelv√¶rdien. En anden god indikator er **medianen**, en v√¶rdi, s√•dan at halvdelen af datapunkterne er lavere end den, og den anden halvdel er h√∏jere.

For at forst√• datafordelingen bedre er det nyttigt at tale om **kvartiler**:

* F√∏rste kvartil, eller Q1, er en v√¶rdi, s√•dan at 25% af dataene ligger under den
* Tredje kvartil, eller Q3, er en v√¶rdi, s√•dan at 75% af dataene ligger under den

Grafisk kan vi repr√¶sentere forholdet mellem median og kvartiler i et diagram kaldet **boksplot**:

<img src="images/boxplot_explanation.png" width="50%"/>

Her beregner vi ogs√• **interkvartilomr√•det** IQR=Q3-Q1 og s√•kaldte **outliers** - v√¶rdier, der ligger uden for gr√¶nserne [Q1-1.5*IQR, Q3+1.5*IQR].

For en endelig fordeling, der indeholder et lille antal mulige v√¶rdier, er en god "typisk" v√¶rdi den, der forekommer hyppigst, og den kaldes **typetallet**. Det anvendes ofte p√• kategoriske data, s√•som farver. Overvej en situation, hvor vi har to grupper af mennesker - nogle, der st√¶rkt foretr√¶kker r√∏d, og andre, der foretr√¶kker bl√•. Hvis vi koder farver med tal, vil middelv√¶rdien for en favoritfarve ligge et sted i det orange-gr√∏nne spektrum, hvilket ikke afspejler den faktiske pr√¶ference for nogen af grupperne. Typetallet vil dog v√¶re enten en af farverne eller begge farver, hvis antallet af personer, der stemmer p√• dem, er lige (i dette tilf√¶lde kalder vi pr√∏ven **multimodal**).

## Data fra den virkelige verden

N√•r vi analyserer data fra den virkelige verden, er de ofte ikke stokastiske variable i den forstand, at vi ikke udf√∏rer eksperimenter med ukendte resultater. For eksempel, overvej et hold af baseballspillere og deres kropsdata, s√•som h√∏jde, v√¶gt og alder. Disse tal er ikke pr√¶cis tilf√¶ldige, men vi kan stadig anvende de samme matematiske begreber. For eksempel kan en sekvens af folks v√¶gte betragtes som en sekvens af v√¶rdier trukket fra en stokastisk variabel. Nedenfor er sekvensen af v√¶gte for faktiske baseballspillere fra [Major League Baseball](http://mlb.mlb.com/index.jsp), taget fra [dette datas√¶t](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) (for nemheds skyld vises kun de f√∏rste 20 v√¶rdier):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Bem√¶rk**: For at se et eksempel p√•, hvordan man arbejder med dette datas√¶t, kan du kigge p√• [den tilh√∏rende notebook](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb). Der er ogs√• en r√¶kke udfordringer gennem denne lektion, som du kan l√∏se ved at tilf√∏je noget kode til den notebook. Hvis du ikke er sikker p√•, hvordan du arbejder med data, skal du ikke bekymre dig - vi vender tilbage til at arbejde med data ved hj√¶lp af Python senere. Hvis du ikke ved, hvordan du k√∏rer kode i Jupyter Notebook, kan du l√¶se [denne artikel](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

Her er boksplottet, der viser middelv√¶rdi, median og kvartiler for vores data:

![V√¶gt boksplot](../../../../1-Introduction/04-stats-and-probability/images/weight-boxplot.png)

Da vores data indeholder information om forskellige spilleres **roller**, kan vi ogs√• lave et boksplot efter rolle - det giver os en id√© om, hvordan parameterv√¶rdierne varierer p√• tv√¶rs af roller. Denne gang vil vi overveje h√∏jden:

![Boksplot efter rolle](../../../../1-Introduction/04-stats-and-probability/images/boxplot_byrole.png)

Dette diagram antyder, at h√∏jden af f√∏rste basemen i gennemsnit er h√∏jere end h√∏jden af anden basemen. Senere i denne lektion vil vi l√¶re, hvordan vi kan teste denne hypotese mere formelt, og hvordan vi kan vise, at vores data er statistisk signifikante.

> N√•r vi arbejder med data fra den virkelige verden, antager vi, at alle datapunkter er pr√∏ver trukket fra en sandsynlighedsfordeling. Denne antagelse giver os mulighed for at anvende maskinl√¶ringsteknikker og bygge fungerende pr√¶diktive modeller.

For at se, hvordan fordelingen af vores data ser ud, kan vi tegne en graf kaldet et **histogram**. X-aksen vil indeholde et antal forskellige v√¶gtintervaller (s√•kaldte **bins**), og Y-aksen vil vise antallet af gange, vores stokastiske variabelpr√∏ve l√• inden for et givet interval.

![Histogram af data fra den virkelige verden](../../../../1-Introduction/04-stats-and-probability/images/weight-histogram.png)

Fra dette histogram kan du se, at alle v√¶rdier er centreret omkring en vis gennemsnitsv√¶gt, og jo l√¶ngere vi bev√¶ger os v√¶k fra denne v√¶gt, desto f√¶rre v√¶gte af den v√¶rdi forekommer. Dvs. det er meget usandsynligt, at v√¶gten af en baseballspiller vil v√¶re meget forskellig fra gennemsnitsv√¶gten. Variansen af v√¶gtene viser, i hvilket omfang v√¶gtene sandsynligvis afviger fra gennemsnittet.

> Hvis vi tager v√¶gtene af andre mennesker, der ikke er fra baseballligaen, vil fordelingen sandsynligvis v√¶re anderledes. Formen af fordelingen vil dog v√¶re den samme, men gennemsnittet og variansen vil √¶ndre sig. S√• hvis vi tr√¶ner vores model p√• baseballspillere, vil den sandsynligvis give forkerte resultater, n√•r den anvendes p√• universitetsstuderende, fordi den underliggende fordeling er anderledes.

## Normalfordeling

Den v√¶gtfordeling, vi har set ovenfor, er meget typisk, og mange m√•linger fra den virkelige verden f√∏lger samme type fordeling, men med forskellige gennemsnit og varians. Denne fordeling kaldes **normalfordeling**, og den spiller en meget vigtig rolle i statistik.

At bruge normalfordeling er en korrekt m√•de at generere tilf√¶ldige v√¶gte af potentielle baseballspillere. N√•r vi kender gennemsnitsv√¶gten `mean` og standardafvigelsen `std`, kan vi generere 1000 v√¶gtpr√∏ver p√• f√∏lgende m√•de:
```python
samples = np.random.normal(mean,std,1000)
```

Hvis vi tegner histogrammet for de genererede pr√∏ver, vil vi se et billede, der ligner det, der er vist ovenfor. Og hvis vi √∏ger antallet af pr√∏ver og antallet af bins, kan vi generere et billede af en normalfordeling, der er t√¶ttere p√• det ideelle:

![Normalfordeling med gennemsnit=0 og std.afvigelse=1](../../../../1-Introduction/04-stats-and-probability/images/normal-histogram.png)

*Normalfordeling med gennemsnit=0 og std.afvigelse=1*

## Konfidensintervaller

N√•r vi taler om v√¶gtene af baseballspillere, antager vi, at der er en vis **stokastisk variabel W**, der svarer til den ideelle sandsynlighedsfordeling af v√¶gtene for alle baseballspillere (den s√•kaldte **population**). Vores sekvens af v√¶gte svarer til et udsnit af alle baseballspillere, som vi kalder **pr√∏ven**. Et interessant sp√∏rgsm√•l er, om vi kan kende parametrene for fordelingen af W, dvs. gennemsnittet og variansen af populationen.

Det nemmeste svar ville v√¶re at beregne gennemsnittet og variansen af vores pr√∏ve. Det kan dog ske, at vores tilf√¶ldige pr√∏ve ikke n√∏jagtigt repr√¶senterer hele populationen. Derfor giver det mening at tale om **konfidensintervaller**.

> **Konfidensinterval** er en estimering af den sande middelv√¶rdi for populationen givet vores pr√∏ve, som er pr√¶cis med en vis sandsynlighed (eller **konfidensniveau**).

Antag, at vi har en pr√∏ve X...

1</sub>, ..., X<sub>n</sub> fra vores distribution. Hver gang vi tr√¶kker en pr√∏ve fra vores distribution, vil vi ende med en forskellig middelv√¶rdi Œº. Derfor kan Œº betragtes som en stokastisk variabel. Et **konfidensinterval** med konfidens p er et par af v√¶rdier (L<sub>p</sub>,R<sub>p</sub>), s√•dan at **P**(L<sub>p</sub>‚â§Œº‚â§R<sub>p</sub>) = p, dvs. sandsynligheden for, at den m√•lte middelv√¶rdi falder inden for intervallet, er lig med p.

Det g√•r ud over vores korte introduktion at diskutere i detaljer, hvordan disse konfidensintervaller beregnes. Flere detaljer kan findes [p√• Wikipedia](https://en.wikipedia.org/wiki/Confidence_interval). Kort sagt definerer vi fordelingen af den beregnede pr√∏ve-middelv√¶rdi i forhold til den sande middelv√¶rdi af populationen, hvilket kaldes **student distribution**.

> **Interessant fakta**: Student distribution er opkaldt efter matematikeren William Sealy Gosset, som udgav sin artikel under pseudonymet "Student". Han arbejdede p√• Guinness-bryggeriet, og if√∏lge en af versionerne √∏nskede hans arbejdsgiver ikke, at offentligheden skulle vide, at de brugte statistiske tests til at bestemme kvaliteten af r√•materialer.

Hvis vi √∏nsker at estimere middelv√¶rdien Œº af vores population med konfidens p, skal vi tage *(1-p)/2-percentilen* af en Student distribution A, som enten kan tages fra tabeller eller beregnes ved hj√¶lp af indbyggede funktioner i statistisk software (f.eks. Python, R osv.). Derefter vil intervallet for Œº v√¶re givet ved X¬±A*D/‚àön, hvor X er den opn√•ede middelv√¶rdi af pr√∏ven, og D er standardafvigelsen.

> **Note**: Vi udelader ogs√• diskussionen om et vigtigt begreb kaldet [frihedsgrader](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)), som er vigtigt i relation til Student distribution. Du kan henvise til mere komplette b√∏ger om statistik for at forst√• dette begreb dybere.

Et eksempel p√• beregning af konfidensinterval for v√¶gt og h√∏jde er givet i de [tilh√∏rende notebooks](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb).

| p | V√¶gt middelv√¶rdi |
|-----|----------------|
| 0.85 | 201.73¬±0.94 |
| 0.90 | 201.73¬±1.08 |
| 0.95 | 201.73¬±1.28 |

Bem√¶rk, at jo h√∏jere konfidens sandsynligheden er, jo bredere er konfidensintervallet.

## Hypotesetestning 

I vores dataset med baseballspillere er der forskellige spillerroller, som kan opsummeres nedenfor (se den [tilh√∏rende notebook](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) for at se, hvordan denne tabel kan beregnes):

| Rolle | H√∏jde | V√¶gt | Antal |
|-------|-------|------|-------|
| Catcher | 72.723684 | 204.328947 | 76 |
| Designated_Hitter | 74.222222 | 220.888889 | 18 |
| First_Baseman | 74.000000 | 213.109091 | 55 |
| Outfielder | 73.010309 | 199.113402 | 194 |
| Relief_Pitcher | 74.374603 | 203.517460 | 315 |
| Second_Baseman | 71.362069 | 184.344828 | 58 |
| Shortstop | 71.903846 | 182.923077 | 52 |
| Starting_Pitcher | 74.719457 | 205.163636 | 221 |
| Third_Baseman | 73.044444 | 200.955556 | 45 |

Vi kan bem√¶rke, at middelh√∏jden for first basemen er h√∏jere end for second basemen. Derfor kan vi v√¶re fristet til at konkludere, at **first basemen er h√∏jere end second basemen**.

> Denne erkl√¶ring kaldes **en hypotese**, fordi vi ikke ved, om det faktisk er sandt eller ej.

Det er dog ikke altid indlysende, om vi kan drage denne konklusion. Fra diskussionen ovenfor ved vi, at hver middelv√¶rdi har et tilh√∏rende konfidensinterval, og derfor kan denne forskel blot v√¶re en statistisk fejl. Vi har brug for en mere formel m√•de at teste vores hypotese p√•.

Lad os beregne konfidensintervaller separat for h√∏jderne af first og second basemen:

| Konfidens | First Basemen | Second Basemen |
|-----------|---------------|----------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

Vi kan se, at under ingen konfidens overlapper intervallerne. Det beviser vores hypotese om, at first basemen er h√∏jere end second basemen.

Mere formelt er problemet, vi l√∏ser, at se, om **to sandsynlighedsfordelinger er de samme**, eller i det mindste har de samme parametre. Afh√¶ngigt af fordelingen skal vi bruge forskellige tests til det. Hvis vi ved, at vores fordelinger er normale, kan vi anvende **[Student t-test](https://en.wikipedia.org/wiki/Student%27s_t-test)**.

I Student t-test beregner vi den s√•kaldte **t-v√¶rdi**, som angiver forskellen mellem middelv√¶rdierne, idet der tages h√∏jde for variansen. Det er demonstreret, at t-v√¶rdien f√∏lger **student distribution**, hvilket giver os mulighed for at f√• t√¶rskelv√¶rdien for et givet konfidensniveau **p** (dette kan beregnes eller findes i numeriske tabeller). Vi sammenligner derefter t-v√¶rdien med denne t√¶rskel for at godkende eller afvise hypotesen.

I Python kan vi bruge **SciPy**-pakken, som inkluderer funktionen `ttest_ind` (ud over mange andre nyttige statistiske funktioner!). Den beregner t-v√¶rdien for os og udf√∏rer ogs√• den omvendte opslagning af konfidens p-v√¶rdien, s√• vi blot kan se p√• konfidensen for at drage konklusionen.

For eksempel giver vores sammenligning mellem h√∏jderne af first og second basemen os f√∏lgende resultater: 
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
I vores tilf√¶lde er p-v√¶rdien meget lav, hvilket betyder, at der er st√¶rke beviser for, at first basemen er h√∏jere.

Der er ogs√• forskellige andre typer hypoteser, som vi m√•ske √∏nsker at teste, for eksempel:
* At bevise, at en given pr√∏ve f√∏lger en bestemt fordeling. I vores tilf√¶lde har vi antaget, at h√∏jder er normalt fordelt, men det kr√¶ver formel statistisk verifikation. 
* At bevise, at middelv√¶rdien af en pr√∏ve svarer til en foruddefineret v√¶rdi
* At sammenligne middelv√¶rdierne af flere pr√∏ver (f.eks. hvad er forskellen i lykkeniveauer blandt forskellige aldersgrupper)

## Lov om store tal og central gr√¶nsev√¶rdi-s√¶tning

En af grundene til, at normalfordeling er s√• vigtig, er den s√•kaldte **central gr√¶nsev√¶rdi-s√¶tning**. Antag, at vi har en stor pr√∏ve af uafh√¶ngige N v√¶rdier X<sub>1</sub>, ..., X<sub>N</sub>, udtaget fra en hvilken som helst fordeling med middelv√¶rdi Œº og varians œÉ<sup>2</sup>. S√•, for tilstr√¶kkeligt store N (med andre ord, n√•r N‚Üí‚àû), vil middelv√¶rdien Œ£<sub>i</sub>X<sub>i</sub> v√¶re normalt fordelt med middelv√¶rdi Œº og varians œÉ<sup>2</sup>/N.

> En anden m√•de at fortolke den centrale gr√¶nsev√¶rdi-s√¶tning p√• er at sige, at uanset fordeling, n√•r du beregner middelv√¶rdien af en sum af vilk√•rlige stokastiske variabelv√¶rdier, ender du med en normalfordeling.

Fra den centrale gr√¶nsev√¶rdi-s√¶tning f√∏lger det ogs√•, at n√•r N‚Üí‚àû, bliver sandsynligheden for, at pr√∏ve-middelv√¶rdien er lig med Œº, 1. Dette er kendt som **loven om store tal**.

## Kovarians og korrelation

En af de ting, Data Science g√∏r, er at finde relationer mellem data. Vi siger, at to sekvenser **korrelerer**, n√•r de udviser lignende adf√¶rd p√• samme tid, dvs. de enten stiger/falder samtidig, eller √©n sekvens stiger, n√•r en anden falder og omvendt. Med andre ord ser der ud til at v√¶re en relation mellem to sekvenser.

> Korrelation indikerer ikke n√∏dvendigvis en √•rsagssammenh√¶ng mellem to sekvenser; nogle gange kan begge variabler afh√¶nge af en ekstern √•rsag, eller det kan v√¶re rent tilf√¶ldigt, at de to sekvenser korrelerer. Dog er st√¶rk matematisk korrelation en god indikation p√•, at to variabler p√• en eller anden m√•de er forbundet.

Matematisk er det vigtigste begreb, der viser relationen mellem to stokastiske variabler, **kovarians**, som beregnes s√•dan: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. Vi beregner afvigelsen af begge variabler fra deres middelv√¶rdier og derefter produktet af disse afvigelser. Hvis begge variabler afviger sammen, vil produktet altid v√¶re en positiv v√¶rdi, der vil summere til positiv kovarians. Hvis begge variabler afviger ude af sync (dvs. √©n falder under gennemsnittet, n√•r en anden stiger over gennemsnittet), vil vi altid f√• negative tal, der vil summere til negativ kovarians. Hvis afvigelserne ikke er afh√¶ngige, vil de summere til cirka nul.

Den absolutte v√¶rdi af kovarians fort√¶ller os ikke meget om, hvor stor korrelationen er, fordi den afh√¶nger af st√∏rrelsen af de faktiske v√¶rdier. For at normalisere den kan vi dividere kovarians med standardafvigelsen af begge variabler for at f√• **korrelation**. Det gode ved korrelation er, at den altid ligger i intervallet [-1,1], hvor 1 angiver st√¶rk positiv korrelation mellem v√¶rdier, -1 - st√¶rk negativ korrelation, og 0 - ingen korrelation overhovedet (variablerne er uafh√¶ngige).

**Eksempel**: Vi kan beregne korrelationen mellem v√¶gt og h√∏jde for baseballspillere fra det n√¶vnte dataset:
```python
print(np.corrcoef(weights,heights))
```
Som resultat f√•r vi **korrelationsmatrix** som denne:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> Korrelationsmatrix C kan beregnes for et vilk√•rligt antal inputsekvenser S<sub>1</sub>, ..., S<sub>n</sub>. V√¶rdien af C<sub>ij</sub> er korrelationen mellem S<sub>i</sub> og S<sub>j</sub>, og diagonalelementerne er altid 1 (hvilket ogs√• er selvkorrelationen af S<sub>i</sub>).

I vores tilf√¶lde indikerer v√¶rdien 0.53, at der er en vis korrelation mellem en persons v√¶gt og h√∏jde. Vi kan ogs√• lave et scatterplot af √©n v√¶rdi mod den anden for at se relationen visuelt:

![Relation mellem v√¶gt og h√∏jde](../../../../1-Introduction/04-stats-and-probability/images/weight-height-relationship.png)

> Flere eksempler p√• korrelation og kovarians kan findes i [den tilh√∏rende notebook](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb).

## Konklusion

I denne sektion har vi l√¶rt:

* grundl√¶ggende statistiske egenskaber ved data, s√•som middelv√¶rdi, varians, typetal og kvartiler
* forskellige fordelinger af stokastiske variabler, herunder normalfordeling
* hvordan man finder korrelation mellem forskellige egenskaber
* hvordan man bruger matematiske og statistiske metoder til at bevise nogle hypoteser
* hvordan man beregner konfidensintervaller for stokastiske variabler givet en datapr√∏ve

Selvom dette bestemt ikke er en udt√∏mmende liste over emner inden for sandsynlighed og statistik, b√∏r det v√¶re nok til at give dig en god start p√• dette kursus.

## üöÄ Udfordring

Brug eksempelkoden i notebooken til at teste andre hypoteser:
1. First basemen er √¶ldre end second basemen
2. First basemen er h√∏jere end third basemen
3. Shortstops er h√∏jere end second basemen

## [Quiz efter forel√¶sning](https://ff-quizzes.netlify.app/en/ds/quiz/7)

## Gennemgang & Selvstudie

Sandsynlighed og statistik er et s√• bredt emne, at det fortjener sit eget kursus. Hvis du er interesseret i at g√• dybere ind i teorien, kan du overveje at l√¶se nogle af f√∏lgende b√∏ger:

1. [Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/) fra New York University har fantastiske forel√¶sningsnoter [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (tilg√¶ngelig online)
1. [Peter og Andrew Bruce. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[eksempelkode i R](https://github.com/andrewgbruce/statistics-for-data-scientists)]. 
1. [James D. Miller. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[eksempelkode i R](https://github.com/PacktPublishing/Statistics-for-Data-Science)]

## Opgave

[Small Diabetes Study](assignment.md)

## Credits

Denne lektion er skrevet med ‚ô•Ô∏è af [Dmitry Soshnikov](http://soshnikov.com)

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, skal du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det originale dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller fejltolkninger, der m√•tte opst√• som f√∏lge af brugen af denne overs√¶ttelse.