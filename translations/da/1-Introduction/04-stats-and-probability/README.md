<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ce95884566a74db72572cd51f0cb25ad",
  "translation_date": "2025-09-06T13:39:06+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "da"
}
-->
# En Kort Introduktion til Statistik og Sandsynlighed

|![ Sketchnote af [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| Statistik og Sandsynlighed - _Sketchnote af [@nitya](https://twitter.com/nitya)_ |

Statistik og Sandsynlighedsteori er to n√¶rt besl√¶gtede omr√•der inden for matematik, som er meget relevante for datavidenskab. Det er muligt at arbejde med data uden dyb matematisk viden, men det er stadig bedre at kende i det mindste nogle grundl√¶ggende begreber. Her pr√¶senterer vi en kort introduktion, der kan hj√¶lpe dig med at komme i gang.

[![Introduktionsvideo](../../../../translated_images/video-prob-and-stats.e4282e5efa2f2543400843ed98b1057065c9600cebfc8a728e8931b5702b2ae4.da.png)](https://youtu.be/Z5Zy85g4Yjw)

## [Quiz f√∏r forel√¶sning](https://ff-quizzes.netlify.app/en/ds/quiz/6)

## Sandsynlighed og Tilf√¶ldige Variable

**Sandsynlighed** er et tal mellem 0 og 1, der udtrykker, hvor sandsynligt en **begivenhed** er. Det defineres som antallet af positive udfald (der f√∏rer til begivenheden) divideret med det samlede antal udfald, givet at alle udfald er lige sandsynlige. For eksempel, n√•r vi kaster en terning, er sandsynligheden for at f√• et lige tal 3/6 = 0,5.

N√•r vi taler om begivenheder, bruger vi **tilf√¶ldige variable**. For eksempel vil den tilf√¶ldige variabel, der repr√¶senterer et tal opn√•et ved at kaste en terning, tage v√¶rdier fra 1 til 6. S√¶ttet af tal fra 1 til 6 kaldes **udfaldsrummet**. Vi kan tale om sandsynligheden for, at en tilf√¶ldig variabel tager en bestemt v√¶rdi, for eksempel P(X=3)=1/6.

Den tilf√¶ldige variabel i det tidligere eksempel kaldes **diskret**, fordi den har et t√¶lleligt udfaldsrum, dvs. der er separate v√¶rdier, der kan opregnes. Der er tilf√¶lde, hvor udfaldsrummet er et interval af reelle tal eller hele m√¶ngden af reelle tal. S√•danne variable kaldes **kontinuerlige**. Et godt eksempel er tidspunktet, hvor bussen ankommer.

## Sandsynlighedsfordeling

I tilf√¶lde af diskrete tilf√¶ldige variable er det nemt at beskrive sandsynligheden for hver begivenhed med en funktion P(X). For hver v√¶rdi *s* fra udfaldsrummet *S* vil den give et tal fra 0 til 1, s√•dan at summen af alle v√¶rdier af P(X=s) for alle begivenheder vil v√¶re 1.

Den mest kendte diskrete fordeling er **uniform fordeling**, hvor der er et udfaldsrum med N elementer, med lige sandsynlighed p√• 1/N for hver af dem.

Det er mere vanskeligt at beskrive sandsynlighedsfordelingen for en kontinuerlig variabel med v√¶rdier trukket fra et interval [a,b] eller hele m√¶ngden af reelle tal ‚Ñù. Overvej tilf√¶ldet med busankomsttidspunktet. Faktisk er sandsynligheden for, at en bus ankommer pr√¶cis p√• et bestemt tidspunkt *t*, 0!

> Nu ved du, at begivenheder med sandsynlighed 0 sker, og meget ofte! I det mindste hver gang bussen ankommer!

Vi kan kun tale om sandsynligheden for, at en variabel falder inden for et givet interval af v√¶rdier, fx P(t<sub>1</sub>‚â§X<t<sub>2</sub>). I dette tilf√¶lde beskrives sandsynlighedsfordelingen af en **sandsynlighedst√¶thedsfunktion** p(x), s√•dan at

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../translated_images/probability-density.a8aad29f17a14afb519b407c7b6edeb9f3f9aa5f69c9e6d9445f604e5f8a2bf7.da.png)

En kontinuerlig analog til uniform fordeling kaldes **kontinuerlig uniform**, som er defineret p√• et endeligt interval. Sandsynligheden for, at v√¶rdien X falder inden for et interval af l√¶ngde l, er proportional med l og stiger op til 1.

En anden vigtig fordeling er **normal fordeling**, som vi vil tale mere om nedenfor.

## Middelv√¶rdi, Varians og Standardafvigelse

Antag, at vi tr√¶kker en sekvens af n pr√∏ver af en tilf√¶ldig variabel X: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. Vi kan definere **middelv√¶rdi** (eller **aritmetisk gennemsnit**) af sekvensen p√• traditionel vis som (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n. N√•r vi √∏ger st√∏rrelsen af pr√∏ven (dvs. tager gr√¶nsen med n‚Üí‚àû), vil vi opn√• middelv√¶rdien (ogs√• kaldet **forventning**) af fordelingen. Vi vil betegne forventningen med **E**(x).

> Det kan demonstreres, at for enhver diskret fordeling med v√¶rdier {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} og tilsvarende sandsynligheder p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, vil forventningen v√¶re E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>.

For at identificere, hvor langt v√¶rdierne er spredt, kan vi beregne variansen œÉ<sup>2</sup> = ‚àë(x<sub>i</sub> - Œº)<sup>2</sup>/n, hvor Œº er middelv√¶rdien af sekvensen. V√¶rdien œÉ kaldes **standardafvigelse**, og œÉ<sup>2</sup> kaldes **varians**.

## Typetal, Median og Kvartiler

Nogle gange repr√¶senterer middelv√¶rdien ikke tilstr√¶kkeligt den "typiske" v√¶rdi for data. For eksempel, n√•r der er nogle f√• ekstreme v√¶rdier, der er helt uden for r√¶kkevidde, kan de p√•virke middelv√¶rdien. En anden god indikator er **medianen**, en v√¶rdi s√•dan at halvdelen af datapunkterne er lavere end den, og den anden halvdel - h√∏jere.

For at hj√¶lpe os med at forst√• fordelingen af data er det nyttigt at tale om **kvartiler**:

* F√∏rste kvartil, eller Q1, er en v√¶rdi, s√•dan at 25% af dataene ligger under den
* Tredje kvartil, eller Q3, er en v√¶rdi, s√•dan at 75% af dataene ligger under den

Grafisk kan vi repr√¶sentere forholdet mellem median og kvartiler i et diagram kaldet **boksplot**:

<img src="images/boxplot_explanation.png" alt="Forklaring af boksplot" width="50%">

Her beregner vi ogs√• **interkvartilafstand** IQR=Q3-Q1 og s√•kaldte **outliers** - v√¶rdier, der ligger uden for gr√¶nserne [Q1-1.5*IQR,Q3+1.5*IQR].

For en endelig fordeling, der indeholder et lille antal mulige v√¶rdier, er en god "typisk" v√¶rdi den, der optr√¶der hyppigst, hvilket kaldes **typetal**. Det anvendes ofte p√• kategoriske data, s√•som farver. Overvej en situation, hvor vi har to grupper af mennesker - nogle, der st√¶rkt foretr√¶kker r√∏d, og andre, der foretr√¶kker bl√•. Hvis vi koder farver med tal, vil middelv√¶rdien for en favoritfarve v√¶re et sted i det orange-gr√∏nne spektrum, hvilket ikke angiver den faktiske pr√¶ference for nogen af grupperne. Typetallet vil dog v√¶re enten en af farverne eller begge farver, hvis antallet af mennesker, der stemmer for dem, er lige (i dette tilf√¶lde kalder vi pr√∏ven **multimodal**).

## Data fra den virkelige verden

N√•r vi analyserer data fra den virkelige verden, er de ofte ikke tilf√¶ldige variable i den forstand, at vi ikke udf√∏rer eksperimenter med ukendt resultat. For eksempel, overvej et hold af baseballspillere og deres kropsdata, s√•som h√∏jde, v√¶gt og alder. Disse tal er ikke pr√¶cis tilf√¶ldige, men vi kan stadig anvende de samme matematiske begreber. For eksempel kan en sekvens af folks v√¶gte betragtes som en sekvens af v√¶rdier trukket fra en tilf√¶ldig variabel. Nedenfor er sekvensen af v√¶gte for faktiske baseballspillere fra [Major League Baseball](http://mlb.mlb.com/index.jsp), taget fra [dette datas√¶t](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) (for din bekvemmelighed vises kun de f√∏rste 20 v√¶rdier):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Note**: For at se et eksempel p√• arbejde med dette datas√¶t, kig p√• den [tilh√∏rende notebook](notebook.ipynb). Der er ogs√• en r√¶kke udfordringer gennem denne lektion, og du kan fuldf√∏re dem ved at tilf√∏je noget kode til den notebook. Hvis du ikke er sikker p√•, hvordan man arbejder med data, skal du ikke bekymre dig - vi vender tilbage til at arbejde med data ved hj√¶lp af Python senere. Hvis du ikke ved, hvordan man k√∏rer kode i Jupyter Notebook, s√• kig p√• [denne artikel](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

Her er boksplottet, der viser middelv√¶rdi, median og kvartiler for vores data:

![V√¶gt Boksplot](../../../../translated_images/weight-boxplot.1dbab1c03af26f8a008fff4e17680082c8ab147d6df646cbac440bbf8f5b9c42.da.png)

Da vores data indeholder information om forskellige spiller **roller**, kan vi ogs√• lave boksplot efter rolle - det vil give os en id√© om, hvordan parameterv√¶rdierne varierer p√• tv√¶rs af roller. Denne gang vil vi overveje h√∏jde:

![Boksplot efter rolle](../../../../translated_images/boxplot_byrole.036b27a1c3f52d42f66fba2324ec5cde0a1bca6a01a619eeb0ce7cd054b2527b.da.png)

Dette diagram antyder, at gennemsnitligt er h√∏jden af f√∏rste basemen h√∏jere end h√∏jden af anden basemen. Senere i denne lektion vil vi l√¶re, hvordan vi kan teste denne hypotese mere formelt, og hvordan vi kan demonstrere, at vores data er statistisk signifikante for at vise det.

> N√•r vi arbejder med data fra den virkelige verden, antager vi, at alle datapunkter er pr√∏ver trukket fra en sandsynlighedsfordeling. Denne antagelse giver os mulighed for at anvende maskinl√¶ringsteknikker og bygge fungerende forudsigelsesmodeller.

For at se, hvordan fordelingen af vores data er, kan vi plotte en graf kaldet et **histogram**. X-aksen vil indeholde et antal forskellige v√¶gtintervaller (s√•kaldte **bins**), og den lodrette akse vil vise antallet af gange, vores tilf√¶ldige variabelpr√∏ve var inden for et givet interval.

![Histogram af data fra den virkelige verden](../../../../translated_images/weight-histogram.bfd00caf7fc30b145b21e862dba7def41c75635d5280de25d840dd7f0b00545e.da.png)

Fra dette histogram kan du se, at alle v√¶rdier er centreret omkring en bestemt gennemsnitsv√¶gt, og jo l√¶ngere vi bev√¶ger os v√¶k fra den v√¶gt, jo f√¶rre v√¶gte af den v√¶rdi optr√¶der. Dvs., det er meget usandsynligt, at v√¶gten af en baseballspiller vil v√¶re meget forskellig fra gennemsnitsv√¶gten. Variansen af v√¶gtene viser, i hvilket omfang v√¶gtene sandsynligvis vil afvige fra gennemsnittet.

> Hvis vi tager v√¶gtene af andre mennesker, ikke fra baseballligaen, vil fordelingen sandsynligvis v√¶re anderledes. Formen af fordelingen vil dog v√¶re den samme, men gennemsnittet og variansen vil √¶ndre sig. S√• hvis vi tr√¶ner vores model p√• baseballspillere, vil den sandsynligvis give forkerte resultater, n√•r den anvendes p√• studerende p√• et universitet, fordi den underliggende fordeling er anderledes.

## Normalfordeling

Fordelingen af v√¶gte, som vi har set ovenfor, er meget typisk, og mange m√•linger fra den virkelige verden f√∏lger samme type fordeling, men med forskellige gennemsnit og varians. Denne fordeling kaldes **normalfordeling**, og den spiller en meget vigtig rolle i statistik.

At bruge normalfordeling er en korrekt m√•de at generere tilf√¶ldige v√¶gte af potentielle baseballspillere. N√•r vi kender gennemsnitsv√¶gten `mean` og standardafvigelsen `std`, kan vi generere 1000 v√¶gtpr√∏ver p√• f√∏lgende m√•de:
```python
samples = np.random.normal(mean,std,1000)
```

Hvis vi plotter histogrammet for de genererede pr√∏ver, vil vi se et billede, der ligner det, der er vist ovenfor. Og hvis vi √∏ger antallet af pr√∏ver og antallet af bins, kan vi generere et billede af en normalfordeling, der er t√¶ttere p√• det ideelle:

![Normalfordeling med gennemsnit=0 og std.afvigelse=1](../../../../translated_images/normal-histogram.dfae0d67c202137d552d0015fb87581eca263925e512404f3c12d8885315432e.da.png)

*Normalfordeling med gennemsnit=0 og std.afvigelse=1*

## Konfidensintervaller

N√•r vi taler om v√¶gtene af baseballspillere, antager vi, at der er en bestemt **tilf√¶ldig variabel W**, der svarer til den ideelle sandsynlighedsfordeling af v√¶gtene for alle baseballspillere (s√•kaldt **population**). Vores sekvens af v√¶gte svarer til en delm√¶ngde af alle baseballspillere, som vi kalder **pr√∏ve**. Et interessant sp√∏rgsm√•l er, om vi kan kende parametrene for fordelingen af W, dvs. gennemsnit og varians for populationen?

Det nemmeste svar ville v√¶re at beregne gennemsnit og varians for vores pr√∏ve. Det kunne dog ske, at vores tilf√¶ldige pr√∏ve ikke n√∏jagtigt repr√¶senterer den komplette population. Derfor giver det mening at tale om **konfidensinterval**.

> **Konfidensinterval** er en estimering af den sande middelv√¶rdi for populationen givet vores pr√∏ve, som er n√∏jagtig med en vis sandsynlighed (eller **konfidensniveau**).

Antag, vi har en pr√∏ve X

1</sub>, ..., X<sub>n</sub> fra vores distribution. Hver gang vi tr√¶kker en pr√∏ve fra vores distribution, vil vi ende med en forskellig middelv√¶rdi Œº. Derfor kan Œº betragtes som en stokastisk variabel. Et **konfidensinterval** med konfidens p er et par af v√¶rdier (L<sub>p</sub>,R<sub>p</sub>), s√•dan at **P**(L<sub>p</sub>‚â§Œº‚â§R<sub>p</sub>) = p, dvs. sandsynligheden for, at den m√•lte middelv√¶rdi falder inden for intervallet, er lig med p.

Det g√•r ud over vores korte introduktion at diskutere i detaljer, hvordan disse konfidensintervaller beregnes. Flere detaljer kan findes [p√• Wikipedia](https://en.wikipedia.org/wiki/Confidence_interval). Kort sagt definerer vi fordelingen af den beregnede pr√∏ve-middelv√¶rdi i forhold til den sande middelv√¶rdi af populationen, hvilket kaldes **student distribution**.

> **Interessant fakta**: Student distribution er opkaldt efter matematikeren William Sealy Gosset, som udgav sin artikel under pseudonymet "Student". Han arbejdede p√• Guinness-bryggeriet, og if√∏lge en af versionerne √∏nskede hans arbejdsgiver ikke, at offentligheden skulle vide, at de brugte statistiske tests til at bestemme kvaliteten af r√•materialer.

Hvis vi √∏nsker at estimere middelv√¶rdien Œº af vores population med konfidens p, skal vi tage *(1-p)/2-th percentil* af en Student distribution A, som enten kan tages fra tabeller eller beregnes ved hj√¶lp af indbyggede funktioner i statistisk software (f.eks. Python, R osv.). Intervallet for Œº vil da v√¶re givet ved X¬±A*D/‚àön, hvor X er den opn√•ede middelv√¶rdi af pr√∏ven, og D er standardafvigelsen.

> **Bem√¶rk**: Vi udelader ogs√• diskussionen om et vigtigt begreb kaldet [frihedsgrader](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)), som er vigtigt i relation til Student distribution. Du kan henvise til mere komplette b√∏ger om statistik for at forst√• dette begreb dybere.

Et eksempel p√• beregning af konfidensinterval for v√¶gt og h√∏jde er givet i [de medf√∏lgende notebooks](notebook.ipynb).

| p | V√¶gt middelv√¶rdi |
|-----|----------------|
| 0.85 | 201.73¬±0.94 |
| 0.90 | 201.73¬±1.08 |
| 0.95 | 201.73¬±1.28 |

Bem√¶rk, at jo h√∏jere konfidens sandsynligheden er, jo bredere er konfidensintervallet.

## Hypotesetestning 

I vores dataset med baseballspillere er der forskellige spillerroller, som kan opsummeres nedenfor (se [den medf√∏lgende notebook](notebook.ipynb) for at se, hvordan denne tabel kan beregnes):

| Rolle | H√∏jde | V√¶gt | Antal |
|-------|-------|------|-------|
| Catcher | 72.723684 | 204.328947 | 76 |
| Designated_Hitter | 74.222222 | 220.888889 | 18 |
| First_Baseman | 74.000000 | 213.109091 | 55 |
| Outfielder | 73.010309 | 199.113402 | 194 |
| Relief_Pitcher | 74.374603 | 203.517460 | 315 |
| Second_Baseman | 71.362069 | 184.344828 | 58 |
| Shortstop | 71.903846 | 182.923077 | 52 |
| Starting_Pitcher | 74.719457 | 205.163636 | 221 |
| Third_Baseman | 73.044444 | 200.955556 | 45 |

Vi kan bem√¶rke, at middelh√∏jden for first basemen er h√∏jere end for second basemen. Derfor kan vi v√¶re fristet til at konkludere, at **first basemen er h√∏jere end second basemen**.

> Denne erkl√¶ring kaldes **en hypotese**, fordi vi ikke ved, om det faktisk er sandt eller ej.

Det er dog ikke altid indlysende, om vi kan drage denne konklusion. Fra diskussionen ovenfor ved vi, at hver middelv√¶rdi har et tilh√∏rende konfidensinterval, og derfor kan denne forskel blot v√¶re en statistisk fejl. Vi har brug for en mere formel m√•de at teste vores hypotese p√•.

Lad os beregne konfidensintervaller separat for h√∏jderne af first og second basemen:

| Konfidens | First Basemen | Second Basemen |
|-----------|---------------|----------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

Vi kan se, at under ingen konfidens overlapper intervallerne. Det beviser vores hypotese om, at first basemen er h√∏jere end second basemen.

Mere formelt er problemet, vi l√∏ser, at se, om **to sandsynlighedsfordelinger er ens**, eller i det mindste har de samme parametre. Afh√¶ngigt af fordelingen skal vi bruge forskellige tests til det. Hvis vi ved, at vores fordelinger er normale, kan vi anvende **[Student t-test](https://en.wikipedia.org/wiki/Student%27s_t-test)**.

I Student t-test beregner vi den s√•kaldte **t-v√¶rdi**, som angiver forskellen mellem middelv√¶rdierne, idet der tages h√∏jde for variansen. Det er p√•vist, at t-v√¶rdien f√∏lger **student distribution**, hvilket giver os mulighed for at f√• t√¶rskelv√¶rdien for et givet konfidensniveau **p** (dette kan beregnes eller findes i numeriske tabeller). Vi sammenligner derefter t-v√¶rdien med denne t√¶rskel for at godkende eller afvise hypotesen.

I Python kan vi bruge **SciPy**-pakken, som inkluderer funktionen `ttest_ind` (ud over mange andre nyttige statistiske funktioner!). Den beregner t-v√¶rdien for os og udf√∏rer ogs√• den omvendte opslagning af konfidens p-v√¶rdien, s√• vi blot kan se p√• konfidensen for at drage konklusionen.

For eksempel giver vores sammenligning mellem h√∏jderne af first og second basemen os f√∏lgende resultater: 
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
I vores tilf√¶lde er p-v√¶rdien meget lav, hvilket betyder, at der er st√¶rke beviser for, at first basemen er h√∏jere.

Der er ogs√• forskellige andre typer hypoteser, som vi m√•ske √∏nsker at teste, for eksempel:
* At bevise, at en given pr√∏ve f√∏lger en bestemt fordeling. I vores tilf√¶lde har vi antaget, at h√∏jder er normalt fordelt, men det kr√¶ver formel statistisk verifikation. 
* At bevise, at middelv√¶rdien af en pr√∏ve svarer til en foruddefineret v√¶rdi
* At sammenligne middelv√¶rdierne af flere pr√∏ver (f.eks. hvad er forskellen i lykkeniveauer blandt forskellige aldersgrupper)

## Lov om store tal og central gr√¶nsev√¶rdi

En af grundene til, at normalfordeling er s√• vigtig, er den s√•kaldte **central gr√¶nsev√¶rdi**. Antag, at vi har en stor pr√∏ve af uafh√¶ngige N v√¶rdier X<sub>1</sub>, ..., X<sub>N</sub>, udtaget fra en hvilken som helst fordeling med middelv√¶rdi Œº og varians œÉ<sup>2</sup>. S√•, for tilstr√¶kkeligt store N (med andre ord, n√•r N‚Üí‚àû), vil middelv√¶rdien Œ£<sub>i</sub>X<sub>i</sub> v√¶re normalt fordelt med middelv√¶rdi Œº og varians œÉ<sup>2</sup>/N.

> En anden m√•de at fortolke den centrale gr√¶nsev√¶rdi p√• er at sige, at uanset fordeling, n√•r du beregner middelv√¶rdien af en sum af vilk√•rlige stokastiske variabelv√¶rdier, ender du med en normalfordeling. 

Fra den centrale gr√¶nsev√¶rdi f√∏lger det ogs√•, at n√•r N‚Üí‚àû, bliver sandsynligheden for, at pr√∏ve-middelv√¶rdien er lig med Œº, 1. Dette er kendt som **loven om store tal**.

## Kovarians og korrelation

En af de ting, Data Science g√∏r, er at finde relationer mellem data. Vi siger, at to sekvenser **korrelerer**, n√•r de udviser lignende adf√¶rd p√• samme tid, dvs. de enten stiger/falder samtidig, eller √©n sekvens stiger, n√•r en anden falder og omvendt. Med andre ord ser der ud til at v√¶re en relation mellem to sekvenser.

> Korrelation indikerer ikke n√∏dvendigvis en √•rsagssammenh√¶ng mellem to sekvenser; nogle gange kan begge variabler afh√¶nge af en ekstern √•rsag, eller det kan v√¶re rent tilf√¶ldigt, at de to sekvenser korrelerer. Dog er st√¶rk matematisk korrelation en god indikation p√•, at to variabler p√• en eller anden m√•de er forbundet.

Matematisk er det vigtigste begreb, der viser relationen mellem to stokastiske variabler, **kovarians**, som beregnes s√•dan: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. Vi beregner afvigelsen af begge variabler fra deres middelv√¶rdier og derefter produktet af disse afvigelser. Hvis begge variabler afviger sammen, vil produktet altid v√¶re en positiv v√¶rdi, der vil summere til positiv kovarians. Hvis begge variabler afviger ude af sync (dvs. √©n falder under gennemsnittet, n√•r en anden stiger over gennemsnittet), vil vi altid f√• negative tal, der vil summere til negativ kovarians. Hvis afvigelserne ikke er afh√¶ngige, vil de summere til cirka nul.

Den absolutte v√¶rdi af kovarians fort√¶ller os ikke meget om, hvor stor korrelationen er, fordi den afh√¶nger af st√∏rrelsen af de faktiske v√¶rdier. For at normalisere den kan vi dividere kovarians med standardafvigelsen af begge variabler for at f√• **korrelation**. Det gode ved korrelation er, at den altid ligger i intervallet [-1,1], hvor 1 angiver st√¶rk positiv korrelation mellem v√¶rdier, -1 - st√¶rk negativ korrelation, og 0 - ingen korrelation overhovedet (variablerne er uafh√¶ngige).

**Eksempel**: Vi kan beregne korrelationen mellem v√¶gt og h√∏jde for baseballspillere fra det n√¶vnte dataset:
```python
print(np.corrcoef(weights,heights))
```
Som resultat f√•r vi **korrelationsmatrix** som denne:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> Korrelationsmatrix C kan beregnes for et vilk√•rligt antal inputsekvenser S<sub>1</sub>, ..., S<sub>n</sub>. V√¶rdien af C<sub>ij</sub> er korrelationen mellem S<sub>i</sub> og S<sub>j</sub>, og diagonalelementerne er altid 1 (hvilket ogs√• er selvkorrelationen af S<sub>i</sub>).

I vores tilf√¶lde indikerer v√¶rdien 0.53, at der er en vis korrelation mellem en persons v√¶gt og h√∏jde. Vi kan ogs√• lave et scatterplot af √©n v√¶rdi mod den anden for at se relationen visuelt:

![Forhold mellem v√¶gt og h√∏jde](../../../../translated_images/weight-height-relationship.3f06bde4ca2aba9974182c4ef037ed602acd0fbbbbe2ca91cefd838a9e66bcf9.da.png)

> Flere eksempler p√• korrelation og kovarians kan findes i [den medf√∏lgende notebook](notebook.ipynb).

## Konklusion

I denne sektion har vi l√¶rt:

* grundl√¶ggende statistiske egenskaber ved data, s√•som middelv√¶rdi, varians, typetal og kvartiler
* forskellige fordelinger af stokastiske variabler, herunder normalfordeling
* hvordan man finder korrelation mellem forskellige egenskaber
* hvordan man bruger matematiske og statistiske metoder til at bevise hypoteser
* hvordan man beregner konfidensintervaller for stokastiske variabler givet en datapr√∏ve

Selvom dette bestemt ikke er en udt√∏mmende liste over emner inden for sandsynlighed og statistik, b√∏r det v√¶re nok til at give dig en god start p√• dette kursus.

## üöÄ Udfordring

Brug eksemplerne i notebooken til at teste andre hypoteser:
1. First basemen er √¶ldre end second basemen
2. First basemen er h√∏jere end third basemen
3. Shortstops er h√∏jere end second basemen

## [Quiz efter forel√¶sning](https://ff-quizzes.netlify.app/en/ds/quiz/7)

## Gennemgang & Selvstudie

Sandsynlighed og statistik er et s√• bredt emne, at det fortjener sit eget kursus. Hvis du er interesseret i at g√• dybere ind i teorien, kan du overveje at l√¶se nogle af f√∏lgende b√∏ger:

1. [Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/) fra New York University har fantastiske noter [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (tilg√¶ngelig online)
1. [Peter og Andrew Bruce. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[eksempler i R](https://github.com/andrewgbruce/statistics-for-data-scientists)]. 
1. [James D. Miller. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[eksempler i R](https://github.com/PacktPublishing/Statistics-for-Data-Science)]

## Opgave

[Small Diabetes Study](assignment.md)

## Credits

Denne lektion er skrevet med ‚ô•Ô∏è af [Dmitry Soshnikov](http://soshnikov.com)

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, skal du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det originale dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller fejltolkninger, der opst√•r som f√∏lge af brugen af denne overs√¶ttelse.