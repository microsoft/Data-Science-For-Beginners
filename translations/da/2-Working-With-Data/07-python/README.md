<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "577a611517482c3ceaf76d3d8142cba9",
  "translation_date": "2025-09-05T21:57:59+00:00",
  "source_file": "2-Working-With-Data/07-python/README.md",
  "language_code": "da"
}
-->
# Arbejde med Data: Python og Pandas-biblioteket

| ![ Sketchnote af [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/07-WorkWithPython.png) |
| :-------------------------------------------------------------------------------------------------------: |
|                 Arbejde med Python - _Sketchnote af [@nitya](https://twitter.com/nitya)_                 |

[![Introduktionsvideo](../../../../2-Working-With-Data/07-python/images/video-ds-python.png)](https://youtu.be/dZjWOGbsN4Y)

Selvom databaser tilbyder meget effektive m친der at gemme data og foresp칮rge dem ved hj칝lp af foresp칮rgselssprog, er den mest fleksible m친de at bearbejde data p친 at skrive dit eget program til at manipulere data. I mange tilf칝lde vil en databaseforesp칮rgsel v칝re en mere effektiv l칮sning. Men i nogle tilf칝lde, hvor mere kompleks databehandling er n칮dvendig, kan det ikke nemt udf칮res med SQL. 
Databehandling kan programmeres i ethvert programmeringssprog, men der er visse sprog, der er mere velegnede til at arbejde med data. Dataforskere foretr칝kker typisk et af f칮lgende sprog:

* **[Python](https://www.python.org/)**, et generelt programmeringssprog, som ofte anses for at v칝re en af de bedste muligheder for begyndere p친 grund af dets enkelhed. Python har mange ekstra biblioteker, der kan hj칝lpe dig med at l칮se praktiske problemer, s친som at udtr칝kke data fra en ZIP-fil eller konvertere et billede til gr친toner. Ud over data science bruges Python ogs친 ofte til webudvikling. 
* **[R](https://www.r-project.org/)** er et traditionelt v칝rkt칮j udviklet med statistisk databehandling i tankerne. Det indeholder ogs친 et stort bibliotek (CRAN), hvilket g칮r det til et godt valg til databehandling. Dog er R ikke et generelt programmeringssprog og bruges sj칝ldent uden for data science-dom칝net.
* **[Julia](https://julialang.org/)** er et andet sprog udviklet specifikt til data science. Det er designet til at give bedre ydeevne end Python, hvilket g칮r det til et fremragende v칝rkt칮j til videnskabelige eksperimenter.

I denne lektion vil vi fokusere p친 at bruge Python til simpel databehandling. Vi antager grundl칝ggende kendskab til sproget. Hvis du 칮nsker en dybere introduktion til Python, kan du henvise til en af f칮lgende ressourcer:

* [L칝r Python p친 en sjov m친de med Turtle Graphics og Fractals](https://github.com/shwars/pycourse) - GitHub-baseret hurtig introduktionskursus i Python-programmering
* [Tag dine f칮rste skridt med Python](https://docs.microsoft.com/en-us/learn/paths/python-first-steps/?WT.mc_id=academic-77958-bethanycheum) L칝ringssti p친 [Microsoft Learn](http://learn.microsoft.com/?WT.mc_id=academic-77958-bethanycheum)

Data kan komme i mange former. I denne lektion vil vi se p친 tre former for data - **tabul칝re data**, **tekst** og **billeder**.

Vi vil fokusere p친 nogle f친 eksempler p친 databehandling i stedet for at give dig en fuld oversigt over alle relaterede biblioteker. Dette vil give dig en id칠 om, hvad der er muligt, og efterlade dig med en forst친else af, hvor du kan finde l칮sninger p친 dine problemer, n친r du har brug for dem.

> **Det mest nyttige r친d**. N친r du skal udf칮re en bestemt operation p친 data, som du ikke ved, hvordan du g칮r, s친 pr칮v at s칮ge efter det p친 internettet. [Stackoverflow](https://stackoverflow.com/) indeholder ofte mange nyttige kodeeksempler i Python til mange typiske opgaver.



## [Quiz f칮r lektionen](https://ff-quizzes.netlify.app/en/ds/quiz/12)

## Tabul칝re data og Dataframes

Du har allerede stiftet bekendtskab med tabul칝re data, da vi talte om relationelle databaser. N친r du har mange data, og de er indeholdt i mange forskellige sammenk칝dede tabeller, giver det bestemt mening at bruge SQL til at arbejde med dem. Men der er mange tilf칝lde, hvor vi har en tabel med data, og vi skal opn친 en **forst친else** eller **indsigt** om disse data, s친som fordeling, korrelation mellem v칝rdier osv. Inden for data science er der mange tilf칝lde, hvor vi skal udf칮re nogle transformationer af de originale data, efterfulgt af visualisering. Begge disse trin kan nemt udf칮res ved hj칝lp af Python.

Der er to mest nyttige biblioteker i Python, der kan hj칝lpe dig med at arbejde med tabul칝re data:
* **[Pandas](https://pandas.pydata.org/)** giver dig mulighed for at manipulere s친kaldte **Dataframes**, som er analoge med relationelle tabeller. Du kan have navngivne kolonner og udf칮re forskellige operationer p친 r칝kker, kolonner og dataframes generelt. 
* **[Numpy](https://numpy.org/)** er et bibliotek til at arbejde med **tensore**, dvs. multidimensionelle **arrays**. Et array har v칝rdier af samme underliggende type og er enklere end en dataframe, men det tilbyder flere matematiske operationer og skaber mindre overhead.

Der er ogs친 et par andre biblioteker, du b칮r kende til:
* **[Matplotlib](https://matplotlib.org/)** er et bibliotek, der bruges til datavisualisering og graftegning
* **[SciPy](https://www.scipy.org/)** er et bibliotek med nogle ekstra videnskabelige funktioner. Vi er allerede st칮dt p친 dette bibliotek, da vi talte om sandsynlighed og statistik

Her er et stykke kode, som du typisk vil bruge til at importere disse biblioteker i begyndelsen af dit Python-program:
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import ... # you need to specify exact sub-packages that you need
``` 

Pandas er centreret omkring nogle f친 grundl칝ggende begreber.

### Series 

**Series** er en sekvens af v칝rdier, der ligner en liste eller numpy-array. Den st칮rste forskel er, at en series ogs친 har en **indeks**, og n친r vi opererer p친 series (f.eks. l칝gger dem sammen), tages indekset i betragtning. Indekset kan v칝re s친 simpelt som et heltal (det er standardindekset, n친r man opretter en series fra en liste eller et array), eller det kan have en kompleks struktur, s친som et datointerval.

> **Bem칝rk**: Der er noget introducerende Pandas-kode i den medf칮lgende notebook [`notebook.ipynb`](../../../../2-Working-With-Data/07-python/notebook.ipynb). Vi skitserer kun nogle af eksemplerne her, og du er bestemt velkommen til at tjekke hele notebooken.

Lad os tage et eksempel: vi vil analysere salget i vores isbutik. Lad os generere en series af salgsnumre (antal solgte varer hver dag) for en given tidsperiode:

```python
start_date = "Jan 1, 2020"
end_date = "Mar 31, 2020"
idx = pd.date_range(start_date,end_date)
print(f"Length of index is {len(idx)}")
items_sold = pd.Series(np.random.randint(25,50,size=len(idx)),index=idx)
items_sold.plot()
```
![Tidsserieplot](../../../../2-Working-With-Data/07-python/images/timeseries-1.png)

Antag nu, at vi hver uge arrangerer en fest for venner, og vi tager yderligere 10 pakker is til festen. Vi kan oprette en anden series, indekseret efter uge, for at demonstrere det:
```python
additional_items = pd.Series(10,index=pd.date_range(start_date,end_date,freq="W"))
```
N친r vi l칝gger to series sammen, f친r vi det samlede antal:
```python
total_items = items_sold.add(additional_items,fill_value=0)
total_items.plot()
```
![Tidsserieplot](../../../../2-Working-With-Data/07-python/images/timeseries-2.png)

> **Bem칝rk** at vi ikke bruger den simple syntaks `total_items+additional_items`. Hvis vi gjorde det, ville vi f친 mange `NaN` (*Not a Number*) v칝rdier i den resulterende series. Dette skyldes, at der mangler v칝rdier for nogle af indeksene i `additional_items`-serien, og at l칝gge `NaN` til noget resulterer i `NaN`. Derfor skal vi angive parameteren `fill_value` under additionen.

Med tidsserier kan vi ogs친 **resample** serien med forskellige tidsintervaller. For eksempel, hvis vi vil beregne gennemsnitligt salgsvolumen m친nedligt, kan vi bruge f칮lgende kode:
```python
monthly = total_items.resample("1M").mean()
ax = monthly.plot(kind='bar')
```
![M친nedlige tidsserie-gennemsnit](../../../../2-Working-With-Data/07-python/images/timeseries-3.png)

### DataFrame

En DataFrame er i bund og grund en samling af series med samme indeks. Vi kan kombinere flere series til en DataFrame:
```python
a = pd.Series(range(1,10))
b = pd.Series(["I","like","to","play","games","and","will","not","change"],index=range(0,9))
df = pd.DataFrame([a,b])
```
Dette vil skabe en horisontal tabel som denne:
|     | 0   | 1    | 2   | 3   | 4      | 5   | 6      | 7    | 8    |
| --- | --- | ---- | --- | --- | ------ | --- | ------ | ---- | ---- |
| 0   | 1   | 2    | 3   | 4   | 5      | 6   | 7      | 8    | 9    |
| 1   | I   | like | to  | use | Python | and | Pandas | very | much |

Vi kan ogs친 bruge series som kolonner og angive kolonnenavne ved hj칝lp af en ordbog:
```python
df = pd.DataFrame({ 'A' : a, 'B' : b })
```
Dette vil give os en tabel som denne:

|     | A   | B      |
| --- | --- | ------ |
| 0   | 1   | I      |
| 1   | 2   | like   |
| 2   | 3   | to     |
| 3   | 4   | use    |
| 4   | 5   | Python |
| 5   | 6   | and    |
| 6   | 7   | Pandas |
| 7   | 8   | very   |
| 8   | 9   | much   |

**Bem칝rk** at vi ogs친 kan f친 denne tabelops칝tning ved at transponere den tidligere tabel, f.eks. ved at skrive 
```python
df = pd.DataFrame([a,b]).T..rename(columns={ 0 : 'A', 1 : 'B' })
```
Her betyder `.T` operationen at transponere DataFrame, dvs. bytte r칝kker og kolonner, og `rename`-operationen giver os mulighed for at omd칮be kolonnerne, s친 de matcher det tidligere eksempel.

Her er nogle af de vigtigste operationer, vi kan udf칮re p친 DataFrames:

**Kolonnevalg**. Vi kan v칝lge individuelle kolonner ved at skrive `df['A']` - denne operation returnerer en series. Vi kan ogs친 v칝lge et subset af kolonner til en anden DataFrame ved at skrive `df[['B','A']]` - dette returnerer en ny DataFrame.

**Filtrering** af kun visse r칝kker baseret p친 kriterier. For eksempel, for kun at beholde r칝kker, hvor kolonnen `A` er st칮rre end 5, kan vi skrive `df[df['A']>5]`.

> **Bem칝rk**: M친den filtrering fungerer p친 er f칮lgende. Udtrykket `df['A']<5` returnerer en boolsk series, som angiver, om udtrykket er `True` eller `False` for hvert element i den originale series `df['A']`. N친r en boolsk series bruges som indeks, returnerer den et subset af r칝kker i DataFrame. Derfor er det ikke muligt at bruge vilk친rlige Python-boolske udtryk, f.eks. at skrive `df[df['A']>5 and df['A']<7]` ville v칝re forkert. I stedet skal du bruge den specielle `&`-operation p친 boolske series, ved at skrive `df[(df['A']>5) & (df['A']<7)]` (*parenteser er vigtige her*).

**Oprettelse af nye beregnelige kolonner**. Vi kan nemt oprette nye beregnelige kolonner for vores DataFrame ved at bruge intuitive udtryk som dette:
```python
df['DivA'] = df['A']-df['A'].mean() 
``` 
Dette eksempel beregner afvigelsen af A fra dens gennemsnitsv칝rdi. Hvad der faktisk sker her er, at vi beregner en series og derefter tildeler denne series til venstre side, hvilket skaber en ny kolonne. Derfor kan vi ikke bruge operationer, der ikke er kompatible med series, f.eks. er koden nedenfor forkert:
```python
# Wrong code -> df['ADescr'] = "Low" if df['A'] < 5 else "Hi"
df['LenB'] = len(df['B']) # <- Wrong result
``` 
Det sidste eksempel, selvom det er syntaktisk korrekt, giver os et forkert resultat, fordi det tildeler l칝ngden af serien `B` til alle v칝rdier i kolonnen og ikke l칝ngden af de individuelle elementer, som vi havde t칝nkt os.

Hvis vi skal beregne komplekse udtryk som dette, kan vi bruge funktionen `apply`. Det sidste eksempel kan skrives som f칮lger:
```python
df['LenB'] = df['B'].apply(lambda x : len(x))
# or 
df['LenB'] = df['B'].apply(len)
```

Efter ovenst친ende operationer ender vi med f칮lgende DataFrame:

|     | A   | B      | DivA | LenB |
| --- | --- | ------ | ---- | ---- |
| 0   | 1   | I      | -4.0 | 1    |
| 1   | 2   | like   | -3.0 | 4    |
| 2   | 3   | to     | -2.0 | 2    |
| 3   | 4   | use    | -1.0 | 3    |
| 4   | 5   | Python | 0.0  | 6    |
| 5   | 6   | and    | 1.0  | 3    |
| 6   | 7   | Pandas | 2.0  | 6    |
| 7   | 8   | very   | 3.0  | 4    |
| 8   | 9   | much   | 4.0  | 4    |

**Valg af r칝kker baseret p친 numre** kan g칮res ved hj칝lp af `iloc`-konstruktionen. For eksempel, for at v칝lge de f칮rste 5 r칝kker fra DataFrame:
```python
df.iloc[:5]
```

**Gruppering** bruges ofte til at opn친 et resultat, der ligner *pivot-tabeller* i Excel. Antag, at vi vil beregne gennemsnitsv칝rdien af kolonnen `A` for hver given v칝rdi af `LenB`. S친 kan vi gruppere vores DataFrame efter `LenB` og kalde `mean`:
```python
df.groupby(by='LenB').mean()
```
Hvis vi skal beregne gennemsnit og antallet af elementer i gruppen, kan vi bruge den mere komplekse `aggregate`-funktion:
```python
df.groupby(by='LenB') \
 .aggregate({ 'DivA' : len, 'A' : lambda x: x.mean() }) \
 .rename(columns={ 'DivA' : 'Count', 'A' : 'Mean'})
```
Dette giver os f칮lgende tabel:

| LenB | Count | Mean     |
| ---- | ----- | -------- |
| 1    | 1     | 1.000000 |
| 2    | 1     | 3.000000 |
| 3    | 2     | 5.000000 |
| 4    | 3     | 6.333333 |
| 6    | 2     | 6.000000 |

### Hentning af Data
Vi har set, hvor nemt det er at oprette Series og DataFrames fra Python-objekter. Dog kommer data som regel i form af en tekstfil eller en Excel-tabel. Heldigvis tilbyder Pandas en enkel m친de at indl칝se data fra disken. For eksempel er det lige s친 nemt at l칝se en CSV-fil som dette:  
```python
df = pd.read_csv('file.csv')
```  
Vi vil se flere eksempler p친 indl칝sning af data, herunder at hente det fra eksterne websteder, i afsnittet "Udfordring".

### Udskrivning og Visualisering

En Data Scientist skal ofte udforske data, og derfor er det vigtigt at kunne visualisere dem. N친r en DataFrame er stor, vil vi mange gange bare sikre os, at vi g칮r alting korrekt, ved at udskrive de f칮rste par r칝kker. Dette kan g칮res ved at kalde `df.head()`. Hvis du k칮rer det fra Jupyter Notebook, vil det udskrive DataFrame i en p칝n tabelform.

Vi har ogs친 set brugen af funktionen `plot` til at visualisere nogle kolonner. Selvom `plot` er meget nyttig til mange opgaver og underst칮tter mange forskellige graf-typer via parameteren `kind=`, kan du altid bruge det r친 `matplotlib`-bibliotek til at lave noget mere komplekst. Vi vil d칝kke datavisualisering i detaljer i separate kursuslektioner.

Denne oversigt d칝kker de vigtigste koncepter i Pandas, men biblioteket er meget omfattende, og der er ingen gr칝nser for, hvad du kan g칮re med det! Lad os nu anvende denne viden til at l칮se et specifikt problem.

## 游 Udfordring 1: Analyse af COVID-spredning

Det f칮rste problem, vi vil fokusere p친, er modellering af den epidemiske spredning af COVID-19. For at g칮re det vil vi bruge data om antallet af smittede personer i forskellige lande, leveret af [Center for Systems Science and Engineering](https://systems.jhu.edu/) (CSSE) ved [Johns Hopkins University](https://jhu.edu/). Datas칝ttet er tilg칝ngeligt i [dette GitHub-repository](https://github.com/CSSEGISandData/COVID-19).

Da vi 칮nsker at demonstrere, hvordan man arbejder med data, inviterer vi dig til at 친bne [`notebook-covidspread.ipynb`](../../../../2-Working-With-Data/07-python/notebook-covidspread.ipynb) og l칝se det fra top til bund. Du kan ogs친 k칮re cellerne og l칮se nogle af de udfordringer, vi har efterladt til dig i slutningen.

![COVID Spredning](../../../../2-Working-With-Data/07-python/images/covidspread.png)

> Hvis du ikke ved, hvordan man k칮rer kode i Jupyter Notebook, kan du l칝se [denne artikel](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

## Arbejde med Ustrukturerede Data

Selvom data ofte kommer i tabelform, skal vi i nogle tilf칝lde arbejde med mindre strukturerede data, for eksempel tekst eller billeder. I s친danne tilf칝lde skal vi for at anvende de databehandlingsteknikker, vi har set ovenfor, p친 en eller anden m친de **udtr칝kke** strukturerede data. Her er nogle eksempler:

* Udtr칝kke n칮gleord fra tekst og se, hvor ofte disse n칮gleord forekommer
* Bruge neurale netv칝rk til at udtr칝kke information om objekter p친 et billede
* F친 information om folks f칮lelser fra et videokamerafeed

## 游 Udfordring 2: Analyse af COVID-artikler

I denne udfordring forts칝tter vi med emnet COVID-pandemien og fokuserer p친 behandling af videnskabelige artikler om emnet. Der findes [CORD-19-datas칝ttet](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) med mere end 7000 (p친 tidspunktet for skrivningen) artikler om COVID, tilg칝ngeligt med metadata og abstracts (og for omkring halvdelen af dem er der ogs친 fuld tekst tilg칝ngelig).

Et fuldt eksempel p친 analyse af dette datas칝t ved hj칝lp af [Text Analytics for Health](https://docs.microsoft.com/azure/cognitive-services/text-analytics/how-tos/text-analytics-for-health/?WT.mc_id=academic-77958-bethanycheum) kognitive tjeneste er beskrevet [i dette blogindl칝g](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). Vi vil diskutere en forenklet version af denne analyse.

> **NOTE**: Vi leverer ikke en kopi af datas칝ttet som en del af dette repository. Du skal muligvis f칮rst downloade [`metadata.csv`](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge?select=metadata.csv) fra [dette datas칝t p친 Kaggle](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge). Registrering hos Kaggle kan v칝re p친kr칝vet. Du kan ogs친 downloade datas칝ttet uden registrering [herfra](https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/historical_releases.html), men det vil inkludere alle fulde tekster ud over metadatafilen.

칀bn [`notebook-papers.ipynb`](../../../../2-Working-With-Data/07-python/notebook-papers.ipynb) og l칝s det fra top til bund. Du kan ogs친 k칮re cellerne og l칮se nogle af de udfordringer, vi har efterladt til dig i slutningen.

![COVID Medicinsk Behandling](../../../../2-Working-With-Data/07-python/images/covidtreat.png)

## Behandling af Billeddata

For nylig er der udviklet meget kraftfulde AI-modeller, der g칮r det muligt at forst친 billeder. Der er mange opgaver, der kan l칮ses ved hj칝lp af forudtr칝nede neurale netv칝rk eller cloud-tjenester. Nogle eksempler inkluderer:

* **Billedklassifikation**, som kan hj칝lpe dig med at kategorisere billedet i en af de foruddefinerede klasser. Du kan nemt tr칝ne dine egne billedklassifikatorer ved hj칝lp af tjenester som [Custom Vision](https://azure.microsoft.com/services/cognitive-services/custom-vision-service/?WT.mc_id=academic-77958-bethanycheum)
* **Objektdetektion** til at finde forskellige objekter p친 billedet. Tjenester som [computer vision](https://azure.microsoft.com/services/cognitive-services/computer-vision/?WT.mc_id=academic-77958-bethanycheum) kan finde en r칝kke almindelige objekter, og du kan tr칝ne en [Custom Vision](https://azure.microsoft.com/services/cognitive-services/custom-vision-service/?WT.mc_id=academic-77958-bethanycheum)-model til at finde specifikke objekter af interesse.
* **Ansigtsgenkendelse**, herunder alder, k칮n og f칮lelsesdetektion. Dette kan g칮res via [Face API](https://azure.microsoft.com/services/cognitive-services/face/?WT.mc_id=academic-77958-bethanycheum).

Alle disse cloud-tjenester kan kaldes ved hj칝lp af [Python SDKs](https://docs.microsoft.com/samples/azure-samples/cognitive-services-python-sdk-samples/cognitive-services-python-sdk-samples/?WT.mc_id=academic-77958-bethanycheum), og kan derfor nemt integreres i din dataudforskningsarbejdsgang.

Her er nogle eksempler p친 udforskning af data fra billedkilder:
* I blogindl칝gget [How to Learn Data Science without Coding](https://soshnikov.com/azure/how-to-learn-data-science-without-coding/) udforsker vi Instagram-billeder og fors칮ger at forst친, hvad der f친r folk til at give flere likes til et billede. Vi udtr칝kker f칮rst s친 meget information som muligt fra billederne ved hj칝lp af [computer vision](https://azure.microsoft.com/services/cognitive-services/computer-vision/?WT.mc_id=academic-77958-bethanycheum) og bruger derefter [Azure Machine Learning AutoML](https://docs.microsoft.com/azure/machine-learning/concept-automated-ml/?WT.mc_id=academic-77958-bethanycheum) til at bygge en fortolkelig model.
* I [Facial Studies Workshop](https://github.com/CloudAdvocacy/FaceStudies) bruger vi [Face API](https://azure.microsoft.com/services/cognitive-services/face/?WT.mc_id=academic-77958-bethanycheum) til at udtr칝kke f칮lelser fra mennesker p친 fotografier fra begivenheder for at fors칮ge at forst친, hvad der g칮r folk glade.

## Konklusion

Uanset om du allerede har strukturerede eller ustrukturerede data, kan du med Python udf칮re alle trin relateret til databehandling og forst친else. Det er sandsynligvis den mest fleksible m친de at behandle data p친, og det er grunden til, at st칮rstedelen af dataforskere bruger Python som deres prim칝re v칝rkt칮j. At l칝re Python i dybden er sandsynligvis en god id칠, hvis du er seri칮s omkring din rejse inden for data science!

## [Quiz efter lektionen](https://ff-quizzes.netlify.app/en/ds/quiz/13)

## Gennemgang & Selvstudie

**B칮ger**  
* [Wes McKinney. Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython](https://www.amazon.com/gp/product/1491957662)

**Online Ressourcer**  
* Officiel [10 minutter til Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html) tutorial  
* [Dokumentation om Pandas-visualisering](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html)

**L칝r Python**  
* [L칝r Python p친 en sjov m친de med Turtle Graphics og Fractals](https://github.com/shwars/pycourse)  
* [Tag dine f칮rste skridt med Python](https://docs.microsoft.com/learn/paths/python-first-steps/?WT.mc_id=academic-77958-bethanycheum) l칝ringssti p친 [Microsoft Learn](http://learn.microsoft.com/?WT.mc_id=academic-77958-bethanycheum)

## Opgave

[Udf칮r en mere detaljeret dataunders칮gelse for udfordringerne ovenfor](assignment.md)

## Kreditering

Denne lektion er skrevet med 鮫봺잺 af [Dmitry Soshnikov](http://soshnikov.com)

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj칝lp af AI-overs칝ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr칝ber os p친 at opn친 n칮jagtighed, skal du v칝re opm칝rksom p친, at automatiserede overs칝ttelser kan indeholde fejl eller un칮jagtigheder. Det originale dokument p친 dets oprindelige sprog b칮r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs칝ttelse. Vi er ikke ansvarlige for eventuelle misforst친elser eller fejltolkninger, der m친tte opst친 som f칮lge af brugen af denne overs칝ttelse.