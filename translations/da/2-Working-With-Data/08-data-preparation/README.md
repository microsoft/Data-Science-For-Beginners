<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1b560955ff39a2bcf2a049fce474a951",
  "translation_date": "2025-09-05T21:59:34+00:00",
  "source_file": "2-Working-With-Data/08-data-preparation/README.md",
  "language_code": "da"
}
-->
# Arbejde med data: Dataklarg√∏ring

|![ Sketchnote af [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/08-DataPreparation.png)|
|:---:|
|Dataklarg√∏ring - _Sketchnote af [@nitya](https://twitter.com/nitya)_ |

## [Quiz f√∏r lektion](https://ff-quizzes.netlify.app/en/ds/quiz/14)

Afh√¶ngigt af kilden kan r√•data indeholde nogle uoverensstemmelser, der skaber udfordringer i analyse og modellering. Med andre ord kan disse data kategoriseres som "beskidte" og skal renses. Denne lektion fokuserer p√• teknikker til at rense og transformere data for at h√•ndtere udfordringer med manglende, un√∏jagtige eller ufuldst√¶ndige data. Emnerne i denne lektion vil benytte Python og Pandas-biblioteket og vil blive [demonstreret i notebooken](../../../../2-Working-With-Data/08-data-preparation/notebook.ipynb) i denne mappe.

## Vigtigheden af at rense data

- **Lettere at bruge og genbruge**: N√•r data er korrekt organiseret og normaliseret, bliver det nemmere at s√∏ge, bruge og dele med andre.

- **Konsistens**: Data science kr√¶ver ofte arbejde med flere datas√¶t, hvor datas√¶t fra forskellige kilder skal kombineres. At sikre, at hvert enkelt datas√¶t har f√¶lles standardisering, g√∏r det muligt at bruge dataene, n√•r de samles i √©t datas√¶t.

- **Modeln√∏jagtighed**: Rensede data forbedrer n√∏jagtigheden af de modeller, der er afh√¶ngige af dem.

## Almindelige m√•l og strategier for datarensning

- **Udforskning af et datas√¶t**: Dataudforskning, som d√¶kkes i en [senere lektion](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/4-Data-Science-Lifecycle/15-analyzing), kan hj√¶lpe dig med at identificere data, der skal renses. Visuel observation af v√¶rdier i et datas√¶t kan give en id√© om, hvordan resten ser ud, eller hvilke problemer der kan l√∏ses. Udforskning kan involvere grundl√¶ggende foresp√∏rgsler, visualiseringer og sampling.

- **Formatering**: Afh√¶ngigt af kilden kan data have uoverensstemmelser i, hvordan de pr√¶senteres. Dette kan skabe problemer med at s√∏ge efter og repr√¶sentere v√¶rdier, hvor de ses i datas√¶ttet, men ikke vises korrekt i visualiseringer eller foresp√∏rgselsresultater. Almindelige formateringsproblemer involverer fjernelse af mellemrum, datoer og datatyper. L√∏sning af formateringsproblemer afh√¶nger typisk af dem, der bruger dataene. For eksempel kan standarder for, hvordan datoer og tal pr√¶senteres, variere fra land til land.

- **Duplikationer**: Data med flere forekomster kan give un√∏jagtige resultater og b√∏r normalt fjernes. Dette kan ofte ske, n√•r man kombinerer to eller flere datas√¶t. Dog kan der v√¶re tilf√¶lde, hvor duplikationer indeholder ekstra information, der skal bevares.

- **Manglende data**: Manglende data kan f√∏re til un√∏jagtigheder samt svage eller forudindtagede resultater. Nogle gange kan dette l√∏ses ved at genindl√¶se dataene, udfylde de manglende v√¶rdier med beregninger og kode som Python, eller blot fjerne v√¶rdien og de tilh√∏rende data. Der er mange grunde til, at data kan mangle, og de handlinger, der tages for at l√∏se dette, afh√¶nger af, hvordan og hvorfor de mangler.

## Udforskning af DataFrame-information
> **L√¶ringsm√•l:** Ved slutningen af dette afsnit b√∏r du v√¶re komfortabel med at finde generel information om data, der er gemt i pandas DataFrames.

N√•r du har indl√¶st dine data i pandas, vil de sandsynligvis v√¶re i en DataFrame (se den tidligere [lektion](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/2-Working-With-Data/07-python#dataframe) for en detaljeret oversigt). Men hvis datas√¶ttet i din DataFrame har 60.000 r√¶kker og 400 kolonner, hvordan begynder du s√• at f√• en fornemmelse af, hvad du arbejder med? Heldigvis giver [pandas](https://pandas.pydata.org/) nogle praktiske v√¶rkt√∏jer til hurtigt at f√• et overblik over en DataFrame samt de f√∏rste og sidste r√¶kker.

For at udforske denne funktionalitet vil vi importere Python scikit-learn biblioteket og bruge et ikonisk datas√¶t: **Iris-datas√¶ttet**.

```python
import pandas as pd
from sklearn.datasets import load_iris

iris = load_iris()
iris_df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])
```
|                                        |sepal l√¶ngde (cm)|sepal bredde (cm)|petal l√¶ngde (cm)|petal bredde (cm)|
|----------------------------------------|-----------------|-----------------|-----------------|----------------|
|0                                       |5.1              |3.5             |1.4              |0.2             |
|1                                       |4.9              |3.0             |1.4              |0.2             |
|2                                       |4.7              |3.2             |1.3              |0.2             |
|3                                       |4.6              |3.1             |1.5              |0.2             |
|4                                       |5.0              |3.6             |1.4              |0.2             |

- **DataFrame.info**: For at starte bruges `info()`-metoden til at udskrive en oversigt over indholdet i en `DataFrame`. Lad os se p√• dette datas√¶t for at se, hvad vi har:
```python
iris_df.info()
```
```
RangeIndex: 150 entries, 0 to 149
Data columns (total 4 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   sepal length (cm)  150 non-null    float64
 1   sepal width (cm)   150 non-null    float64
 2   petal length (cm)  150 non-null    float64
 3   petal width (cm)   150 non-null    float64
dtypes: float64(4)
memory usage: 4.8 KB
```
Ud fra dette ved vi, at *Iris*-datas√¶ttet har 150 poster i fire kolonner uden null-v√¶rdier. Alle data er gemt som 64-bit floating-point tal.

- **DataFrame.head()**: For at kontrollere det faktiske indhold af `DataFrame` bruger vi `head()`-metoden. Lad os se, hvordan de f√∏rste par r√¶kker af vores `iris_df` ser ud:
```python
iris_df.head()
```
```
   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
0                5.1               3.5                1.4               0.2
1                4.9               3.0                1.4               0.2
2                4.7               3.2                1.3               0.2
3                4.6               3.1                1.5               0.2
4                5.0               3.6                1.4               0.2
```
- **DataFrame.tail()**: Omvendt, for at kontrollere de sidste par r√¶kker af `DataFrame`, bruger vi `tail()`-metoden:
```python
iris_df.tail()
```
```
     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
145                6.7               3.0                5.2               2.3
146                6.3               2.5                5.0               1.9
147                6.5               3.0                5.2               2.0
148                6.2               3.4                5.4               2.3
149                5.9               3.0                5.1               1.8
```
> **Konklusion:** Bare ved at kigge p√• metadata om informationen i en DataFrame eller de f√∏rste og sidste v√¶rdier, kan du hurtigt f√• en id√© om st√∏rrelsen, formen og indholdet af de data, du arbejder med.

## H√•ndtering af manglende data
> **L√¶ringsm√•l:** Ved slutningen af dette afsnit b√∏r du vide, hvordan du erstatter eller fjerner null-v√¶rdier fra DataFrames.

Ofte har de datas√¶t, du vil bruge (eller skal bruge), manglende v√¶rdier. Hvordan manglende data h√•ndteres indeb√¶rer subtile afvejninger, der kan p√•virke din endelige analyse og virkelige resultater.

Pandas h√•ndterer manglende v√¶rdier p√• to m√•der. Den f√∏rste har du set f√∏r i tidligere afsnit: `NaN`, eller Not a Number. Dette er faktisk en speciel v√¶rdi, der er en del af IEEE floating-point specifikationen og bruges kun til at indikere manglende floating-point v√¶rdier.

For manglende v√¶rdier udover floats bruger pandas Python-objektet `None`. Selvom det kan virke forvirrende at st√∏de p√• to forskellige typer v√¶rdier, der i bund og grund betyder det samme, er der gode programmatiske grunde til dette designvalg. I praksis giver det pandas mulighed for at levere en god kompromisl√∏sning for de fleste tilf√¶lde. Ikke desto mindre har b√•de `None` og `NaN` begr√¶nsninger, som du skal v√¶re opm√¶rksom p√• med hensyn til, hvordan de kan bruges.

L√¶s mere om `NaN` og `None` i [notebooken](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/4-Data-Science-Lifecycle/15-analyzing/notebook.ipynb)!

- **Detektering af null-v√¶rdier**: I `pandas` er `isnull()` og `notnull()` dine prim√¶re metoder til at detektere null-data. Begge returnerer Boolean-masker over dine data. Vi vil bruge `numpy` til `NaN`-v√¶rdier:
```python
import numpy as np

example1 = pd.Series([0, np.nan, '', None])
example1.isnull()
```
```
0    False
1     True
2    False
3     True
dtype: bool
```
Se n√∏je p√• outputtet. Overrasker noget dig? Mens `0` er en aritmetisk null, er det stadig en gyldig integer, og pandas behandler det som s√•dan. `''` er lidt mere subtil. Selvom vi brugte det i afsnit 1 til at repr√¶sentere en tom strengv√¶rdi, er det stadig et strengobjekt og ikke en repr√¶sentation af null if√∏lge pandas.

Nu vender vi dette rundt og bruger disse metoder p√• en m√•de, der ligner, hvordan du vil bruge dem i praksis. Du kan bruge Boolean-masker direkte som en ``Series`` eller ``DataFrame``-indeks, hvilket kan v√¶re nyttigt, n√•r du arbejder med isolerede manglende (eller tilstedev√¶rende) v√¶rdier.

> **Konklusion**: B√•de `isnull()` og `notnull()` giver lignende resultater, n√•r du bruger dem i `DataFrame`s: de viser resultaterne og indekset for disse resultater, hvilket vil hj√¶lpe dig enormt, n√•r du arbejder med dine data.

- **Fjernelse af null-v√¶rdier**: Ud over at identificere manglende v√¶rdier giver pandas en praktisk metode til at fjerne null-v√¶rdier fra `Series` og `DataFrame`s. (Is√¶r med store datas√¶t er det ofte mere tilr√•deligt blot at fjerne manglende [NA] v√¶rdier fra din analyse end at h√•ndtere dem p√• andre m√•der.) For at se dette i praksis vender vi tilbage til `example1`:
```python
example1 = example1.dropna()
example1
```
```
0    0
2     
dtype: object
```
Bem√¶rk, at dette b√∏r ligne dit output fra `example3[example3.notnull()]`. Forskellen her er, at `dropna` har fjernet de manglende v√¶rdier fra `Series` `example1`.

Fordi `DataFrame`s har to dimensioner, giver de flere muligheder for at fjerne data.

```python
example2 = pd.DataFrame([[1,      np.nan, 7], 
                         [2,      5,      8], 
                         [np.nan, 6,      9]])
example2
```
|      | 0 | 1 | 2 |
|------|---|---|---|
|0     |1.0|NaN|7  |
|1     |2.0|5.0|8  |
|2     |NaN|6.0|9  |

(Har du bem√¶rket, at pandas opgraderede to af kolonnerne til floats for at rumme `NaN`?)

Du kan ikke fjerne en enkelt v√¶rdi fra en `DataFrame`, s√• du skal fjerne hele r√¶kker eller kolonner. Afh√¶ngigt af hvad du laver, kan du v√¶lge det ene eller det andet, og pandas giver dig muligheder for begge dele. Fordi kolonner generelt repr√¶senterer variabler og r√¶kker repr√¶senterer observationer i data science, er det mere sandsynligt, at du fjerner r√¶kker af data; standardindstillingen for `dropna()` er at fjerne alle r√¶kker, der indeholder null-v√¶rdier:

```python
example2.dropna()
```
```
	0	1	2
1	2.0	5.0	8
```
Hvis n√∏dvendigt kan du fjerne NA-v√¶rdier fra kolonner. Brug `axis=1` for at g√∏re dette:
```python
example2.dropna(axis='columns')
```
```
	2
0	7
1	8
2	9
```
Bem√¶rk, at dette kan fjerne mange data, som du m√•ske vil beholde, is√¶r i mindre datas√¶t. Hvad hvis du kun vil fjerne r√¶kker eller kolonner, der indeholder flere eller alle null-v√¶rdier? Du kan angive disse indstillinger i `dropna` med parametrene `how` og `thresh`.

Som standard er `how='any'` (hvis du vil kontrollere dette selv eller se, hvilke andre parametre metoden har, kan du k√∏re `example4.dropna?` i en kodecelle). Du kan alternativt angive `how='all'` for kun at fjerne r√¶kker eller kolonner, der indeholder alle null-v√¶rdier. Lad os udvide vores eksempel `DataFrame` for at se dette i praksis.

```python
example2[3] = np.nan
example2
```
|      |0  |1  |2  |3  |
|------|---|---|---|---|
|0     |1.0|NaN|7  |NaN|
|1     |2.0|5.0|8  |NaN|
|2     |NaN|6.0|9  |NaN|

Parameteren `thresh` giver dig mere pr√¶cis kontrol: du angiver antallet af *ikke-null* v√¶rdier, som en r√¶kke eller kolonne skal have for at blive bevaret:
```python
example2.dropna(axis='rows', thresh=3)
```
```
	0	1	2	3
1	2.0	5.0	8	NaN
```
Her er den f√∏rste og sidste r√¶kke blevet fjernet, fordi de kun indeholder to ikke-null v√¶rdier.

- **Udfyldning af null-v√¶rdier**: Afh√¶ngigt af dit datas√¶t kan det nogle gange give mere mening at udfylde null-v√¶rdier med gyldige v√¶rdier i stedet for at fjerne dem. Du kunne bruge `isnull` til at g√∏re dette direkte, men det kan v√¶re besv√¶rligt, is√¶r hvis du har mange v√¶rdier at udfylde. Fordi dette er en s√• almindelig opgave i data science, giver pandas `fillna`, som returnerer en kopi af `Series` eller `DataFrame` med de manglende v√¶rdier erstattet med en af dine valg. Lad os oprette et andet eksempel `Series` for at se, hvordan dette fungerer i praksis.
```python
example3 = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))
example3
```
```
a    1.0
b    NaN
c    2.0
d    NaN
e    3.0
dtype: float64
```
Du kan udfylde alle null-poster med en enkelt v√¶rdi, s√•som `0`:
```python
example3.fillna(0)
```
```
a    1.0
b    0.0
c    2.0
d    0.0
e    3.0
dtype: float64
```
Du kan **forward-fill** null-v√¶rdier, hvilket betyder at bruge den sidste gyldige v√¶rdi til at udfylde en null:
```python
example3.fillna(method='ffill')
```
```
a    1.0
b    1.0
c    2.0
d    2.0
e    3.0
dtype: float64
```
Du kan ogs√• **back-fill** for at propagere den n√¶ste gyldige v√¶rdi bagud for at udfylde en null:
```python
example3.fillna(method='bfill')
```
```
a    1.0
b    2.0
c    2.0
d    3.0
e    3.0
dtype: float64
```
Som du m√•ske g√¶tter, fungerer dette p√• samme m√•de med `DataFrame`s, men du kan ogs√• angive en `axis` langs hvilken null-v√¶rdier skal udfyldes. Brug igen det tidligere anvendte `example2`:
```python
example2.fillna(method='ffill', axis=1)
```
```
	0	1	2	3
0	1.0	1.0	7.0	7.0
1	2.0	5.0	8.0	8.0
2	NaN	6.0	9.0	9.0
```
Bem√¶rk, at n√•r en tidligere v√¶rdi ikke er tilg√¶ngelig til forward-filling, forbliver null-v√¶rdien.
> **Vigtig pointe:** Der er flere m√•der at h√•ndtere manglende v√¶rdier i dine datas√¶t. Den specifikke strategi, du v√¶lger (at fjerne dem, erstatte dem eller endda hvordan du erstatter dem), b√∏r afh√¶nge af de specifikke detaljer i dataene. Du vil f√• en bedre forst√•else af, hvordan man h√•ndterer manglende v√¶rdier, jo mere du arbejder med og interagerer med datas√¶t.
## Fjernelse af duplikerede data

> **L√¶ringsm√•l:** Ved slutningen af dette afsnit b√∏r du v√¶re komfortabel med at identificere og fjerne duplikerede v√¶rdier fra DataFrames.

Ud over manglende data vil du ofte st√∏de p√• duplikerede data i virkelige datas√¶t. Heldigvis tilbyder `pandas` en nem m√•de at opdage og fjerne duplikerede poster.

- **Identificering af duplikater: `duplicated`**: Du kan nemt finde duplikerede v√¶rdier ved hj√¶lp af metoden `duplicated` i pandas, som returnerer en Boolean-maske, der angiver, om en post i en `DataFrame` er en duplikat af en tidligere. Lad os oprette et andet eksempel p√• en `DataFrame` for at se dette i praksis.
```python
example4 = pd.DataFrame({'letters': ['A','B'] * 2 + ['B'],
                         'numbers': [1, 2, 1, 3, 3]})
example4
```
|      |bogstaver|tal   |
|------|---------|------|
|0     |A        |1     |
|1     |B        |2     |
|2     |A        |1     |
|3     |B        |3     |
|4     |B        |3     |

```python
example4.duplicated()
```
```
0    False
1    False
2     True
3    False
4     True
dtype: bool
```
- **Fjernelse af duplikater: `drop_duplicates`:** returnerer simpelthen en kopi af dataene, hvor alle `duplicated` v√¶rdier er `False`:
```python
example4.drop_duplicates()
```
```
	letters	numbers
0	A	1
1	B	2
3	B	3
```
B√•de `duplicated` og `drop_duplicates` tager som standard alle kolonner i betragtning, men du kan specificere, at de kun skal unders√∏ge et delm√¶ngde af kolonner i din `DataFrame`:
```python
example4.drop_duplicates(['letters'])
```
```
letters	numbers
0	A	1
1	B	2
```

> **Vigtig pointe:** Fjernelse af duplikerede data er en essentiel del af n√¶sten alle data science-projekter. Duplikerede data kan √¶ndre resultaterne af dine analyser og give dig un√∏jagtige resultater!


## üöÄ Udfordring

Alt det diskuterede materiale er tilg√¶ngeligt som en [Jupyter Notebook](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/2-Working-With-Data/08-data-preparation/notebook.ipynb). Derudover er der √∏velser efter hver sektion ‚Äì pr√∏v dem!

## [Quiz efter forel√¶sning](https://ff-quizzes.netlify.app/en/ds/quiz/15)



## Gennemgang & Selvstudie

Der er mange m√•der at opdage og n√¶rme sig forberedelsen af dine data til analyse og modellering, og reng√∏ring af data er et vigtigt skridt, der kr√¶ver praktisk erfaring. Pr√∏v disse udfordringer fra Kaggle for at udforske teknikker, som denne lektion ikke d√¶kkede.

- [Data Cleaning Challenge: Parsing Dates](https://www.kaggle.com/rtatman/data-cleaning-challenge-parsing-dates/)

- [Data Cleaning Challenge: Scale and Normalize Data](https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data)


## Opgave

[Evaluering af data fra en formular](assignment.md)

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, skal du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det originale dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller fejltolkninger, der m√•tte opst√• som f√∏lge af brugen af denne overs√¶ttelse.