<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1cf49f029ba1f25a54f0d5bc2fa575fc",
  "translation_date": "2025-09-06T07:35:09+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "mr"
}
-->
# सांख्यिकी आणि संभाव्यता यांचे संक्षिप्त परिचय

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| सांख्यिकी आणि संभाव्यता - _Sketchnote by [@nitya](https://twitter.com/nitya)_ |

सांख्यिकी आणि संभाव्यता सिद्धांत हे गणिताचे दोन परस्पर संबंधित क्षेत्र आहेत जे डेटा सायन्ससाठी अत्यंत महत्त्वाचे आहेत. गणिताचा सखोल अभ्यास न करता डेटा हाताळणे शक्य आहे, परंतु किमान काही मूलभूत संकल्पना जाणून घेणे चांगले आहे. येथे आम्ही एक संक्षिप्त परिचय देऊ जो तुम्हाला सुरुवात करण्यास मदत करेल.

[![Intro Video](../../../../1-Introduction/04-stats-and-probability/images/video-prob-and-stats.png)](https://youtu.be/Z5Zy85g4Yjw)

## [पूर्व-व्याख्यान प्रश्नमंजूषा](https://ff-quizzes.netlify.app/en/ds/quiz/6)

## संभाव्यता आणि रँडम व्हेरिएबल्स

**संभाव्यता** ही 0 ते 1 दरम्यानची संख्या आहे जी एखाद्या **घटने**ची शक्यता व्यक्त करते. ती सकारात्मक परिणामांची संख्या (जे घटनेला कारणीभूत ठरतात) एकूण परिणामांच्या संख्येने विभागून परिभाषित केली जाते, असे गृहीत धरून की सर्व परिणाम समान शक्यतेचे आहेत. उदाहरणार्थ, जर आपण एक फासे टाकला तर सम संख्या येण्याची शक्यता 3/6 = 0.5 आहे.

जेव्हा आपण घटनांबद्दल बोलतो, तेव्हा आपण **रँडम व्हेरिएबल्स** वापरतो. उदाहरणार्थ, फासे टाकल्यावर मिळालेली संख्या दर्शवणारा रँडम व्हेरिएबल 1 ते 6 पर्यंतच्या मूल्ये घेईल. 1 ते 6 पर्यंतच्या संख्यांचा संच **नमुनासंच** (sample space) म्हणून ओळखला जातो. आपण रँडम व्हेरिएबलने विशिष्ट मूल्य घेण्याची शक्यता बोलू शकतो, उदाहरणार्थ P(X=3)=1/6.

मागील उदाहरणातील रँडम व्हेरिएबलला **विभक्त** (discrete) म्हणतात, कारण त्याचा नमुनासंच मोजण्यायोग्य आहे, म्हणजेच वेगवेगळ्या मूल्यांची गणना करता येते. काही वेळा नमुनासंच वास्तविक संख्यांच्या श्रेणीमध्ये किंवा संपूर्ण वास्तविक संख्यांच्या संचामध्ये असतो. अशा व्हेरिएबल्सला **सातत्यपूर्ण** (continuous) म्हणतात. बस येण्याच्या वेळेचे उदाहरण यासाठी चांगले आहे.

## संभाव्यता वितरण

विभक्त रँडम व्हेरिएबल्सच्या बाबतीत, प्रत्येक घटनेची संभाव्यता P(X) फंक्शनद्वारे वर्णन करणे सोपे आहे. नमुनासंच *S* मधील प्रत्येक मूल्य *s* साठी, ते 0 ते 1 दरम्यानची संख्या देईल, ज्यामुळे P(X=s) च्या सर्व घटनांसाठी एकूण मूल्य 1 असेल.

सर्वात प्रसिद्ध विभक्त वितरण म्हणजे **समान वितरण** (uniform distribution), ज्यामध्ये N घटकांचा नमुनासंच असतो, प्रत्येक घटकासाठी समान संभाव्यता 1/N असते.

सातत्यपूर्ण व्हेरिएबल्सच्या संभाव्यता वितरणाचे वर्णन करणे अधिक कठीण आहे, ज्याचे मूल्य [a,b] या श्रेणीमधून किंवा संपूर्ण वास्तविक संख्यांच्या संच ℝ मधून घेतले जाते. बस येण्याच्या वेळेचा विचार करा. प्रत्यक्षात, प्रत्येक विशिष्ट वेळ *t* साठी, बस नेमक्या त्या वेळी येण्याची शक्यता 0 आहे!

> आता तुम्हाला माहित आहे की 0 संभाव्यतेच्या घटना घडतात, आणि खूप वेळा घडतात! किमान प्रत्येक वेळी जेव्हा बस येते!

आपण फक्त एखाद्या व्हेरिएबलने दिलेल्या मूल्यांच्या श्रेणीत पडण्याची शक्यता बोलू शकतो, उदा. P(t<sub>1</sub>≤X<t<sub>2</sub>). या प्रकरणात, संभाव्यता वितरण **संभाव्यता घनता फंक्शन** p(x) द्वारे वर्णन केले जाते, ज्यामुळे

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../1-Introduction/04-stats-and-probability/images/probability-density.png)

सातत्यपूर्ण समान वितरणाचा सातत्यपूर्ण समकक्ष **सातत्यपूर्ण समान वितरण** (continuous uniform) म्हणून ओळखला जातो, जो मर्यादित श्रेणीवर परिभाषित केला जातो. मूल्य X लांबी l च्या श्रेणीत पडण्याची शक्यता l च्या प्रमाणात असते आणि ती 1 पर्यंत वाढते.

आणखी एक महत्त्वाचे वितरण म्हणजे **सामान्य वितरण** (normal distribution), ज्याबद्दल आपण खाली अधिक तपशीलवार चर्चा करू.

## सरासरी, विचलन आणि मानक विचलन

समजा आपण रँडम व्हेरिएबल X चे n नमुने काढतो: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. आपण **सरासरी** (किंवा **गुणाकार सरासरी**) मूल्य पारंपरिक पद्धतीने परिभाषित करू शकतो: (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n. नमुन्याचा आकार वाढवताना (म्हणजे n→∞ च्या मर्यादेपर्यंत), आम्हाला वितरणाची सरासरी (ज्याला **अपेक्षा** म्हणतात) मिळेल. आम्ही अपेक्षेला **E**(x) असे दर्शवू.

> हे सिद्ध करता येते की {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} मूल्यांसह कोणत्याही विभक्त वितरणासाठी आणि p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub> संभाव्यतेसह, अपेक्षा E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub> असेल.

मूल्ये किती प्रमाणात पसरलेली आहेत हे ओळखण्यासाठी, आपण विचलन σ<sup>2</sup> = ∑(x<sub>i</sub> - μ)<sup>2</sup>/n मोजू शकतो, जिथे μ ही अनुक्रमाची सरासरी आहे. σ ला **मानक विचलन** म्हणतात, आणि σ<sup>2</sup> ला **विचलन** म्हणतात.

## मोड, माध्य आणि चतुर्थांश

कधी कधी, सरासरी डेटा साठी "सामान्य" मूल्य योग्य प्रकारे दर्शवत नाही. उदाहरणार्थ, जेव्हा काही अत्यंत मूल्ये असतात जी पूर्णपणे श्रेणीबाहेर असतात, ते सरासरीवर परिणाम करू शकतात. आणखी एक चांगला संकेत म्हणजे **माध्य** (median), एक मूल्य ज्यामुळे अर्धा डेटा पॉइंट्स त्यापेक्षा कमी असतो आणि उर्वरित अर्धा - जास्त असतो.

डेटाचा वितरण समजून घेण्यासाठी **चतुर्थांशां**बद्दल बोलणे उपयुक्त आहे:

* पहिला चतुर्थांश, किंवा Q1, असे मूल्य आहे की 25% डेटा त्यापेक्षा कमी आहे
* तिसरा चतुर्थांश, किंवा Q3, असे मूल्य आहे की 75% डेटा त्यापेक्षा कमी आहे

ग्राफिकदृष्ट्या आपण माध्य आणि चतुर्थांशांमधील संबंध **बॉक्स प्लॉट** मध्ये दर्शवू शकतो:

<img src="images/boxplot_explanation.png" width="50%"/>

येथे आपण **आंतर-चतुर्थांश श्रेणी** IQR=Q3-Q1 आणि तथाकथित **अतिरिक्त मूल्ये** (outliers) - मूल्ये जी [Q1-1.5*IQR,Q3+1.5*IQR] च्या मर्यादेबाहेर असतात, मोजतो.

लहान संभाव्य मूल्ये असलेल्या मर्यादित वितरणासाठी, चांगले "सामान्य" मूल्य म्हणजे ते जे सर्वाधिक वारंवार दिसते, ज्याला **मोड** म्हणतात. हे सहसा श्रेणीबद्ध डेटावर लागू होते, जसे की रंग. उदाहरणार्थ, जर दोन गट असतील - काही लोक ज्यांना लाल रंग आवडतो आणि काही ज्यांना निळा रंग आवडतो. जर आपण रंगांना क्रमांकांनी कोड केले, तर आवडत्या रंगाची सरासरी मूल्य नारिंगी-हिरव्या स्पेक्ट्रममध्ये असेल, जे कोणत्याही गटाच्या वास्तविक पसंतीचे संकेत देत नाही. परंतु मोड लाल किंवा निळा रंग असेल, किंवा दोन्ही रंग असतील, जर त्यांना पसंती देणाऱ्या लोकांची संख्या समान असेल (या प्रकरणात नमुना **मल्टीमोडल** म्हणतो).

## वास्तविक जीवनातील डेटा

जेव्हा आपण वास्तविक जीवनातील डेटा विश्लेषण करतो, तेव्हा ते नेहमी रँडम व्हेरिएबल्स नसतात, कारण आपण अज्ञात परिणामांसह प्रयोग करत नाही. उदाहरणार्थ, बेसबॉल खेळाडूंचा संघ विचार करा, आणि त्यांचे शरीर डेटा, जसे की उंची, वजन आणि वय. ही संख्या नेमकी रँडम नसली तरी आपण त्याच गणितीय संकल्पना लागू करू शकतो. उदाहरणार्थ, लोकांच्या वजनाचा अनुक्रम काही रँडम व्हेरिएबल्समधून काढलेल्या मूल्यांचा अनुक्रम मानला जाऊ शकतो. खाली [मेजर लीग बेसबॉल](http://mlb.mlb.com/index.jsp) मधील वास्तविक बेसबॉल खेळाडूंच्या वजनाचा अनुक्रम आहे, [या डेटासेट](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) मधून घेतलेला (तुमच्या सोयीसाठी, फक्त पहिले 20 मूल्ये दाखवली आहेत):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Note**: या डेटासेटसह काम करण्याचे उदाहरण पाहण्यासाठी [संबंधित नोटबुक](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) पहा. या धड्यादरम्यान अनेक आव्हाने आहेत, आणि तुम्ही त्या नोटबुकमध्ये काही कोड जोडून पूर्ण करू शकता. जर तुम्हाला डेटावर ऑपरेट कसे करायचे हे माहित नसेल, तर काळजी करू नका - आम्ही नंतर पायथन वापरून डेटावर काम करण्याकडे परत येऊ. जर तुम्हाला जुपिटर नोटबुकमध्ये कोड कसे चालवायचे हे माहित नसेल, तर [हा लेख](https://soshnikov.com/education/how-to-execute-notebooks-from-github/) पहा.

येथे आमच्या डेटासाठी सरासरी, माध्य आणि चतुर्थांश दर्शवणारा बॉक्स प्लॉट आहे:

![Weight Box Plot](../../../../1-Introduction/04-stats-and-probability/images/weight-boxplot.png)

आमच्या डेटामध्ये वेगवेगळ्या खेळाडूंच्या **भूमिका** बद्दल माहिती असल्याने, आम्ही भूमिकेनुसार बॉक्स प्लॉट देखील करू शकतो - यामुळे आम्हाला मापदंड मूल्ये भूमिकांमध्ये कशी भिन्न आहेत याची कल्पना मिळेल. यावेळी आपण उंची विचारात घेऊ:

![Box plot by role](../../../../1-Introduction/04-stats-and-probability/images/boxplot_byrole.png)

या आकृतीवरून असे सूचित होते की, सरासरीने पाहता, पहिल्या बेसमनची उंची दुसऱ्या बेसमनच्या उंचीपेक्षा जास्त आहे. या धड्याच्या पुढील भागात आपण अधिक औपचारिकपणे ही गृहीतके कशी तपासू शकतो आणि आमचा डेटा सांख्यिकीयदृष्ट्या महत्त्वाचा आहे हे कसे सिद्ध करू शकतो ते शिकू.

> वास्तविक जीवनातील डेटावर काम करताना, आम्ही गृहीत धरतो की सर्व डेटा पॉइंट्स काही संभाव्यता वितरणातून काढलेले नमुने आहेत. या गृहीतकामुळे आम्हाला मशीन लर्निंग तंत्र लागू करता येते आणि कार्यरत भविष्यवाणी मॉडेल तयार करता येते.

आमच्या डेटाचे वितरण काय आहे हे पाहण्यासाठी, आम्ही **हिस्टोग्राम** नावाचा ग्राफ प्लॉट करू शकतो. X-अक्षावर विविध वजन श्रेणी (ज्याला **बिन्स** म्हणतात) असतील, आणि उभ्या अक्षावर आमचा रँडम व्हेरिएबल नमुना दिलेल्या श्रेणीत किती वेळा होता हे दर्शवले जाईल.

![Histogram of real world data](../../../../1-Introduction/04-stats-and-probability/images/weight-histogram.png)

या हिस्टोग्रामवरून तुम्ही पाहू शकता की सर्व मूल्ये विशिष्ट सरासरी वजनाभोवती केंद्रित आहेत, आणि त्या वजनापासून जितके दूर जातो - त्या मूल्याचे वजन कमी वेळा आढळते. म्हणजेच, बेसबॉल खेळाडूचे वजन सरासरी वजनापासून खूप वेगळे असण्याची शक्यता कमी आहे. वजनांचे विचलन सरासरीपासून वजन किती वेगळे असण्याची शक्यता दर्शवते.

> जर आपण बेसबॉल लीगमधील लोकांऐवजी इतर लोकांचे वजन घेतले, तर वितरण वेगळे असण्याची शक्यता आहे. तथापि, वितरणाचा आकार समान असेल, परंतु सरासरी आणि विचलन बदलतील. त्यामुळे, जर आपण बेसबॉल खेळाडूंवर आमचे मॉडेल प्रशिक्षित केले, तर ते विद्यापीठातील विद्यार्थ्यांवर लागू केल्यास चुकीचे परिणाम देण्याची शक्यता आहे, कारण अंतर्निहित वितरण वेगळे आहे.

## सामान्य वितरण

आपण वर पाहिलेले वजनांचे वितरण अत्यंत सामान्य आहे, आणि वास्तविक जीवनातील अनेक मोजमापे समान प्रकारच्या वितरणाचे अनुसरण करतात, परंतु वेगवेगळ्या सरासरी आणि विचलनासह. या वितरणाला **सामान्य वितरण** म्हणतात, आणि ते सांख्यिकीमध्ये खूप महत्त्वाची भूमिका बजावते.

सामान्य वितरणाचा वापर संभाव्य बेसबॉल खेळाडूंच्या वजनाची रँडम पद्धतीने निर्मिती करण्याचा योग्य मार्ग आहे. एकदा आम्हाला `mean` आणि `std` माहीत झाल्यावर, आम्ही खालीलप्रमाणे 1000 वजन नमुने तयार करू शकतो:
```python
samples = np.random.normal(mean,std,1000)
```

जर आम्ही तयार केलेल्या नमुन्यांचा हिस्टोग्राम प्लॉट केला तर आम्हाला वर दाखवलेल्या चित्रासारखे चित्र दिसेल. आणि जर आम्ही नमुन्यांची संख्या आणि बिन्सची संख्या वाढवली, तर आम्ही आदर्श सामान्य वितरणाच्या अधिक जवळचे चित्र तयार करू शकतो:

![Normal Distribution with mean=0 and std.dev=1](../../../../1-Introduction/04-stats-and-probability/images/normal-histogram.png)

*सरासरी=0 आणि मानक विचलन=1 असलेले सामान्य वितरण*

## विश्वास अंतर

जेव्हा आपण बेसबॉल खेळाडूंच्या वजनाबद्दल बोलतो, तेव्हा आम्ही गृहीत धरतो की **रँडम व्हेरिएबल W** आहे जे सर्व बेसबॉल खेळाडूंच्या वजनाचे आदर्श संभाव्यता वितरण दर्शवते (ज्याला **लोकसंख्या** म्हणतात). आमचा वजन अनुक्रम सर्व बेसबॉल खेळाडूंच्या उपसंचाशी संबंधित आहे ज्याला **नमुना** म्हणतात. एक मनोरंजक प्रश्न असा आहे की, W च्या वितरणाचे पॅरामीटर्स, म्हणजेच लोकसंख्येची सरासरी आणि विचलन, आपण जाणून घेऊ शकतो का?

सर्वात सोपा उत्तर म्हणजे आमच्या नमुन्याची सरासरी आणि विचलन मोजणे. तथापि, असे होऊ शकते की आमचा रँडम नमुना संपूर्ण लोकसंख्येचे अचूक प्रतिनिधित्व करत नाही. त्यामुळे **विश्वास अंतर** बद्दल बोलणे योग्य आहे.

> **विश्वास अंतर** म्हणजे आमच्या नमुन्याच्या आधारे लोकसंख्येच्या खऱ्या सरासरीचा अंदाज, जो विशिष्ट संभाव्यतेने (किंवा **विश्वास स्तर**) अचूक आहे.

समजा आमच्याकडे नमुना X आहे

1</sub>, ..., X<sub>n</sub> आमच्या वितरणातून घेतले जातात. प्रत्येक वेळी आम्ही आमच्या वितरणातून नमुना घेतो, आम्हाला वेगवेगळ्या सरासरी मूल्य μ मिळते. त्यामुळे μ हे एक यादृच्छिक चल मानले जाऊ शकते. **विश्वास अंतर** विश्वास p सह दोन मूल्यांचा जोडी (L<sub>p</sub>,R<sub>p</sub>) आहे, ज्यामुळे **P**(L<sub>p</sub>≤μ≤R<sub>p</sub>) = p, म्हणजे मोजलेल्या सरासरी मूल्याच्या अंतरात येण्याची शक्यता p आहे.

विश्वास अंतर कसे गणना करायचे याबद्दल सविस्तर चर्चा करणे या छोट्या परिचयाच्या पलीकडे जाते. अधिक तपशील [विकिपीडियावर](https://en.wikipedia.org/wiki/Confidence_interval) सापडू शकतात. थोडक्यात, आम्ही लोकसंख्येच्या खऱ्या सरासरीच्या तुलनेत गणना केलेल्या नमुना सरासरीचे वितरण परिभाषित करतो, ज्याला **स्टुडंट वितरण** म्हणतात.

> **आवडता तथ्य**: स्टुडंट वितरणाचे नाव गणितज्ञ विल्यम सीली गॉसेट यांच्या नावावर आहे, ज्यांनी "स्टुडंट" या टोपणनावाखाली आपले पेपर प्रकाशित केले. ते गिनीज ब्रुअरीमध्ये काम करत होते आणि एका आवृत्तीनुसार, त्यांच्या नियोक्त्याला सामान्य लोकांना हे माहित होऊ नये की ते कच्च्या मालाच्या गुणवत्तेचा निर्धारण करण्यासाठी सांख्यिकीय चाचण्या वापरत होते.

जर आपल्याला विश्वास p सह आमच्या लोकसंख्येची सरासरी μ अंदाज करायची असेल, तर आपल्याला स्टुडंट वितरण A चा *(1-p)/2-वा टक्केवारी* घ्यावा लागेल, जो टेबल्समधून घेतला जाऊ शकतो किंवा सांख्यिकीय सॉफ्टवेअरच्या काही अंगभूत फंक्शन्स वापरून संगणकाद्वारे मिळवला जाऊ शकतो (उदा. Python, R, इ.). मग μ साठी अंतर X±A*D/√n असेल, जिथे X हा नमुन्याची मिळालेली सरासरी आहे, D हा मानक विचलन आहे.

> **टीप**: आम्ही [स्वातंत्र्याच्या अंश](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)) या महत्त्वाच्या संकल्पनेची चर्चा देखील वगळतो, जी स्टुडंट वितरणाशी संबंधित आहे. या संकल्पनेला अधिक सखोलपणे समजून घेण्यासाठी तुम्ही सांख्यिकीवरील अधिक संपूर्ण पुस्तके पाहू शकता.

वजन आणि उंचींसाठी विश्वास अंतर कसे गणना करायचे याचे उदाहरण [संबंधित नोटबुक्समध्ये](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) दिले आहे.

| p | वजनाची सरासरी |
|-----|-----------|
| 0.85 | 201.73±0.94 |
| 0.90 | 201.73±1.08 |
| 0.95 | 201.73±1.28 |

लक्षात घ्या की विश्वासाची शक्यता जास्त असेल, तर विश्वास अंतर अधिक विस्तृत असेल.

## गृहीतक चाचणी

आमच्या बेसबॉल खेळाडूंच्या डेटासेटमध्ये वेगवेगळ्या खेळाडूंच्या भूमिका आहेत, ज्याचा सारांश खाली दिला आहे (हे टेबल कसे गणना करायचे ते पाहण्यासाठी [संबंधित नोटबुक](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) पहा):

| भूमिका | उंची | वजन | संख्या |
|------|--------|--------|-------|
| कॅचर | 72.723684 | 204.328947 | 76 |
| डिझिग्नेटेड हिटर | 74.222222 | 220.888889 | 18 |
| फर्स्ट बेसमन | 74.000000 | 213.109091 | 55 |
| आउटफिल्डर | 73.010309 | 199.113402 | 194 |
| रिलीफ पिचर | 74.374603 | 203.517460 | 315 |
| सेकंड बेसमन | 71.362069 | 184.344828 | 58 |
| शॉर्टस्टॉप | 71.903846 | 182.923077 | 52 |
| स्टार्टिंग पिचर | 74.719457 | 205.163636 | 221 |
| थर्ड बेसमन | 73.044444 | 200.955556 | 45 |

आपण पाहू शकतो की फर्स्ट बेसमनची सरासरी उंची सेकंड बेसमनपेक्षा जास्त आहे. त्यामुळे, आपण **फर्स्ट बेसमन सेकंड बेसमनपेक्षा उंच आहेत** असे निष्कर्ष काढण्याचा मोह होऊ शकतो.

> हे विधान **गृहीतक** म्हणून ओळखले जाते, कारण आम्हाला माहित नाही की हा तथ्य प्रत्यक्षात खरा आहे की नाही.

तथापि, आपण हा निष्कर्ष काढू शकतो की नाही हे नेहमी स्पष्ट नसते. वरील चर्चेतून आपल्याला माहित आहे की प्रत्येक सरासरीसह संबंधित विश्वास अंतर आहे, आणि त्यामुळे हा फरक फक्त सांख्यिकीय त्रुटी असू शकतो. आपल्याला आमच्या गृहीतकाची चाचणी घेण्यासाठी अधिक औपचारिक पद्धतीची आवश्यकता आहे.

चला फर्स्ट आणि सेकंड बेसमनच्या उंचींसाठी विश्वास अंतर स्वतंत्रपणे गणना करूया:

| विश्वास | फर्स्ट बेसमन | सेकंड बेसमन |
|------------|---------------|----------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

आपण पाहू शकतो की कोणत्याही विश्वासाखाली अंतर एकमेकांशी ओव्हरलॅप होत नाहीत. हे सिद्ध करते की फर्स्ट बेसमन सेकंड बेसमनपेक्षा उंच आहेत.

आणखी औपचारिकपणे, आपण सोडवत असलेली समस्या म्हणजे **दोन संभाव्यता वितरण समान आहेत का**, किंवा किमान समान पॅरामीटर्स आहेत का हे पाहणे. वितरणावर अवलंबून, आपल्याला त्यासाठी वेगवेगळ्या चाचण्या वापरण्याची आवश्यकता आहे. जर आपल्याला माहित असेल की आमचे वितरण सामान्य आहे, तर आपण **[स्टुडंट t-चाचणी](https://en.wikipedia.org/wiki/Student%27s_t-test)** लागू करू शकतो.

स्टुडंट t-चाचणीत, आम्ही तथाकथित **t-मूल्य** गणना करतो, जे सरासरींमधील फरक दर्शवते, विचलन लक्षात घेऊन. हे सिद्ध झाले आहे की t-मूल्य **स्टुडंट वितरण**चे अनुसरण करते, जे आम्हाला दिलेल्या विश्वास स्तरासाठी **p** थ्रेशोल्ड मूल्य मिळवण्यास अनुमती देते (हे गणना केले जाऊ शकते किंवा संख्यात्मक टेबल्समध्ये पाहिले जाऊ शकते). नंतर आम्ही t-मूल्य या थ्रेशोल्डशी तुलना करतो आणि गृहीतक मंजूर किंवा नाकारतो.

Python मध्ये, आपण **SciPy** पॅकेज वापरू शकतो, ज्यामध्ये `ttest_ind` फंक्शन समाविष्ट आहे (इतर अनेक उपयुक्त सांख्यिकीय फंक्शन्ससह!). हे आमच्यासाठी t-मूल्य गणना करते आणि विश्वास p-मूल्याचा रिव्हर्स लुकअप देखील करते, जेणेकरून आम्ही फक्त विश्वास पाहून निष्कर्ष काढू शकतो.

उदाहरणार्थ, फर्स्ट आणि सेकंड बेसमनच्या उंचींच्या तुलनेत आम्हाला खालील परिणाम मिळतात:
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
आमच्या बाबतीत, p-मूल्य खूप कमी आहे, ज्याचा अर्थ असा आहे की फर्स्ट बेसमन उंच असल्याचे समर्थन करणारे मजबूत पुरावे आहेत.

आम्ही चाचणी करू इच्छित असलेल्या गृहीतकांचे इतर प्रकार देखील आहेत, उदाहरणार्थ:
* एखाद्या नमुन्याचे काही वितरण अनुसरण करते हे सिद्ध करणे. आमच्या बाबतीत आम्ही गृहीत धरले आहे की उंची सामान्य वितरण आहे, परंतु त्याला औपचारिक सांख्यिकीय सत्यापनाची आवश्यकता आहे.
* नमुन्याचे सरासरी मूल्य काही पूर्वनिर्धारित मूल्याशी जुळते हे सिद्ध करणे
* अनेक नमुन्यांच्या सरासरींची तुलना करणे (उदा. वेगवेगळ्या वयोगटांमधील आनंदाच्या पातळीतील फरक काय आहे)

## मोठ्या संख्यांचा नियम आणि केंद्रीय मर्यादा प्रमेय

सामान्य वितरण का महत्त्वाचे आहे याचे एक कारण म्हणजे **केंद्रीय मर्यादा प्रमेय**. समजा आपल्याकडे स्वतंत्र N मूल्यांचा मोठा नमुना आहे X<sub>1</sub>, ..., X<sub>N</sub>, जे कोणत्याही वितरणातून सरासरी μ आणि विचलन σ<sup>2</sup> सह नमुना घेतले जातात. मग, पुरेसे मोठे N साठी (दुसऱ्या शब्दांत, जेव्हा N→∞), सरासरी Σ<sub>i</sub>X<sub>i</sub> सामान्य वितरण असेल, सरासरी μ आणि विचलन σ<sup>2</sup>/N सह.

> केंद्रीय मर्यादा प्रमेयाचे दुसरे स्पष्टीकरण असे आहे की कोणत्याही यादृच्छिक चल मूल्यांच्या बेरीजची सरासरी गणना करताना तुम्ही शेवटी सामान्य वितरण मिळवता.

केंद्रीय मर्यादा प्रमेयातून असेही दिसून येते की, जेव्हा N→∞, नमुना सरासरी μ समान होण्याची शक्यता 1 होते. याला **मोठ्या संख्यांचा नियम** म्हणतात.

## सहसंबंध आणि परस्पर संबंध

डेटा सायन्स जे करते त्यातील एक गोष्ट म्हणजे डेटामधील संबंध शोधणे. आम्ही म्हणतो की दोन अनुक्रम **सहसंबंधित** आहेत जेव्हा ते एकाच वेळी समान वर्तन प्रदर्शित करतात, म्हणजे ते एकत्र वाढतात/घसरतात, किंवा एक अनुक्रम वाढतो तेव्हा दुसरा घसरतो आणि उलट. दुसऱ्या शब्दांत, दोन अनुक्रमांमध्ये काही संबंध असल्याचे दिसते.

> सहसंबंध दोन अनुक्रमांमधील कारणात्मक संबंध सूचित करत नाही; कधीकधी दोन्ही चल काही बाह्य कारणावर अवलंबून असू शकतात, किंवा दोन अनुक्रम सहसंबंधित असणे हे पूर्णपणे योगायोगाने असू शकते. तथापि, मजबूत गणितीय सहसंबंध हे सूचक आहे की दोन चल काही प्रकारे जोडलेले आहेत.

गणितीयदृष्ट्या, दोन यादृच्छिक चलांमधील संबंध दर्शवणारी मुख्य संकल्पना म्हणजे **परस्पर संबंध**, जी अशा प्रकारे गणना केली जाते: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. आम्ही दोन्ही चलांचे त्यांच्या सरासरी मूल्यांपासून विचलन गणना करतो आणि नंतर त्या विचलनांचे गुणाकार करतो. जर दोन्ही चल एकत्र विचलित झाले, तर गुणाकार नेहमी सकारात्मक मूल्य असेल, जे सकारात्मक परस्पर संबंधात जोडले जाईल. जर दोन्ही चल असमकालिक विचलित झाले (म्हणजे एक सरासरीपेक्षा खाली घसरते जेव्हा दुसरे सरासरीपेक्षा वर वाढते), तर आम्हाला नेहमी नकारात्मक संख्या मिळेल, जी नकारात्मक परस्पर संबंधात जोडली जाईल. जर विचलन अवलंबून नसेल, तर ते अंदाजे शून्य जोडले जातील.

परस्पर संबंधाचे परिमाण आपल्याला सहसंबंध किती मोठा आहे याबद्दल फारसे सांगत नाही, कारण ते वास्तविक मूल्यांच्या परिमाणावर अवलंबून असते. ते सामान्यीकृत करण्यासाठी, आम्ही दोन्ही चलांच्या मानक विचलनाने परस्पर संबंध विभागू शकतो, **सहसंबंध** मिळवण्यासाठी. चांगली गोष्ट म्हणजे सहसंबंध नेहमी [-1,1] श्रेणीत असतो, जिथे 1 मूल्यांमधील मजबूत सकारात्मक सहसंबंध सूचित करतो, -1 - मजबूत नकारात्मक सहसंबंध, आणि 0 - कोणताही सहसंबंध नाही (चल स्वतंत्र आहेत).

**उदाहरण**: आम्ही वरील उल्लेख केलेल्या डेटासेटमधील बेसबॉल खेळाडूंच्या वजन आणि उंचीमध्ये सहसंबंध गणना करू शकतो:
```python
print(np.corrcoef(weights,heights))
```
परिणामस्वरूप, आम्हाला **सहसंबंध मॅट्रिक्स** मिळते:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> सहसंबंध मॅट्रिक्स C कोणत्याही इनपुट अनुक्रमांसाठी S<sub>1</sub>, ..., S<sub>n</sub> गणना केली जाऊ शकते. C<sub>ij</sub> चे मूल्य S<sub>i</sub> आणि S<sub>j</sub> यांच्यातील सहसंबंध आहे, आणि कर्णरेषेवरील घटक नेहमी 1 असतात (जे S<sub>i</sub> चे स्वतःचे सहसंबंध देखील आहे).

आमच्या बाबतीत, मूल्य 0.53 सूचित करते की व्यक्तीच्या वजन आणि उंचीमध्ये काही सहसंबंध आहे. आम्ही एक मूल्य दुसऱ्याविरुद्ध प्लॉट करून संबंध दृश्यरित्या पाहू शकतो:

![वजन आणि उंचीमधील संबंध](../../../../1-Introduction/04-stats-and-probability/images/weight-height-relationship.png)

> सहसंबंध आणि परस्पर संबंधाचे अधिक उदाहरणे [संबंधित नोटबुक](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) मध्ये सापडू शकतात.

## निष्कर्ष

या विभागात, आपण शिकले:

* डेटाचे मूलभूत सांख्यिकीय गुणधर्म, जसे की सरासरी, विचलन, मोड आणि क्वार्टाइल्स
* यादृच्छिक चलांचे वेगवेगळे वितरण, सामान्य वितरणासह
* वेगवेगळ्या गुणधर्मांमधील सहसंबंध कसा शोधायचा
* काही गृहीतके सिद्ध करण्यासाठी गणित आणि सांख्यिकीचा योग्य वापर कसा करायचा
* दिलेल्या डेटासेटसाठी यादृच्छिक चलासाठी विश्वास अंतर कसे गणना करायचे

जरी हे संभाव्यता आणि सांख्यिकीमध्ये अस्तित्वात असलेल्या विषयांची संपूर्ण यादी नक्कीच नाही, तरीही या कोर्समध्ये चांगली सुरुवात करण्यासाठी पुरेसे असावे.

## 🚀 आव्हान

नोटबुकमधील नमुना कोड वापरून खालील गृहीतकांची चाचणी घ्या:
1. फर्स्ट बेसमन सेकंड बेसमनपेक्षा वयाने मोठे आहेत
2. फर्स्ट बेसमन थर्ड बेसमनपेक्षा उंच आहेत
3. शॉर्टस्टॉप सेकंड बेसमनपेक्षा उंच आहेत

## [पाठानंतरचा क्विझ](https://ff-quizzes.netlify.app/en/ds/quiz/7)

## पुनरावलोकन आणि स्व-अभ्यास

संभाव्यता आणि सांख्यिकी हा इतका विस्तृत विषय आहे की त्याला स्वतःचा कोर्स लागतो. जर तुम्हाला सिद्धांतात अधिक खोलवर जाण्याची इच्छा असेल, तर तुम्ही खालील पुस्तके वाचणे सुरू ठेवू शकता:

1. [न्यूयॉर्क विद्यापीठातील कार्लोस फर्नांडेज-ग्रांडा](https://cims.nyu.edu/~cfgranda/) यांचे उत्कृष्ट व्याख्यान नोट्स [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (ऑनलाइन उपलब्ध)
1. [पीटर आणि अँड्र्यू ब्रूस. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[R मध्ये नमुना कोड](https://github.com/andrewgbruce/statistics-for-data-scientists)].
1. [जेम्स डी. मिलर. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[R मध्ये नमुना कोड](https://github.com/PacktPublishing/Statistics-for-Data-Science)]

## असाइनमेंट

[लहान मधुमेह अभ्यास](assignment.md)

## क्रेडिट्स

हा धडा [दिमित्री सोश्निकोव्ह](http://soshnikov.com) यांनी ♥️ सह तयार केला आहे.

---

**अस्वीकरण**:  
हा दस्तऐवज AI भाषांतर सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) वापरून भाषांतरित करण्यात आला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी कृपया लक्षात ठेवा की स्वयंचलित भाषांतरे त्रुटी किंवा अचूकतेच्या अभावाने युक्त असू शकतात. मूळ भाषेतील दस्तऐवज हा अधिकृत स्रोत मानला जावा. महत्त्वाच्या माहितीसाठी, व्यावसायिक मानवी भाषांतराची शिफारस केली जाते. या भाषांतराचा वापर करून उद्भवलेल्या कोणत्याही गैरसमज किंवा चुकीच्या अर्थासाठी आम्ही जबाबदार राहणार नाही.