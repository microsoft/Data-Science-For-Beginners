{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# संभाव्यता आणि सांख्यिकीची ओळख\n",
    "या नोटबुकमध्ये, आपण पूर्वी चर्चा केलेल्या काही संकल्पनांसह खेळणार आहोत. संभाव्यता आणि सांख्यिकीतील अनेक संकल्पना Python मधील `numpy` आणि `pandas` सारख्या प्रमुख डेटा प्रक्रियेसाठीच्या लायब्ररींमध्ये चांगल्या प्रकारे सादर केलेल्या असतात.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## रँडम व्हेरिएबल्स आणि वितरण\n",
    "चला 0 ते 9 या युनिफॉर्म वितरणातून 30 किंमतींचा नमुना काढण्यापासून सुरुवात करूया. आपण सरासरी आणि वैचित्र्य देखील गणना करू.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [ random.randint(0,10) for _ in range(30) ]\n",
    "print(f\"Sample: {sample}\")\n",
    "print(f\"Mean = {np.mean(sample)}\")\n",
    "print(f\"Variance = {np.var(sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "नमुन्यात किती वेगवेगळ्या मूल्ये आहेत हे दृष्टीकोनातून अंदाजवण्यासाठी, आपण **हिस्टोग्राम** चित्रित करू शकतो:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## प्रत्यक्ष डेटाचे विश्लेषण\n",
    "\n",
    "प्रत्यक्ष जगातील डेटाचे विश्लेषण करताना सरासरी आणि विचलन खूप महत्त्वाचे असतात. चला [SOCR MLB Height/Weight Data](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) येथून बेसबॉल खेळाडूंची माहिती लोड करूयात.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/SOCR_MLB.tsv\",sep='\\t', header=None, names=['Name','Team','Role','Weight','Height','Age'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> आम्ही येथे डेटा विश्लेषणासाठी [**Pandas**](https://pandas.pydata.org/) नावाच्या पॅकेजचा वापर करीत आहोत. या कोर्समध्ये आम्ही नंतर Pandas आणि Python मधील डेटासह काम करण्याबद्दल अधिक बोलणार आहोत.\n",
    "\n",
    "चला वय, उंची आणि वजनासाठी सरासरी मूल्ये काढू या:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Age','Height','Weight']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आता आपण उंचीवर लक्ष केंद्रित करूया, आणि प्रमाणात्मक विचलन आणि विचलन मोजूया:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df['Height'])[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df['Height'].mean()\n",
    "var = df['Height'].var()\n",
    "std = df['Height'].std()\n",
    "print(f\"Mean = {mean}\\nVariance = {var}\\nStandard Deviation = {std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "सरासरी व्यतिरिक्त, माध्य आणि चौथ्या भागांचे मूल्य पाहणे समंजस ठरते. त्यांची दृष्यात्मक सादरीकरण **बॉक्स प्लॉट** द्वारे करता येते:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2))\n",
    "plt.boxplot(df['Height'].ffill(), vert=False, showmeans=True)\n",
    "plt.grid(color='gray', linestyle='dotted')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आपण आमच्या डेटासेटच्या उपसमुहांचे बॉक्स प्लॉट्स देखील तयार करू शकतो, उदाहरणार्थ, खेळाडूच्या भूमिकेनुसार गटबद्ध केलेले.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='Height', by='Role', figsize=(10,8))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **टीप**: हा आकृती सूचित करतो की, सरासरी दृष्टीने, पहिल्या बेसमनची उंची दुसऱ्या बेसमनच्या उंचीपेक्षा जास्त असते. नंतर आपण शिकलो की आपण या निष्कर्षाची अधिक औपचारिकदृष्ट्या तपासणी कशी करू शकतो आणि आपले डेटा सांख्यिकदृष्ट्या महत्त्वाचे असल्यास ते कसे दाखवता येते.  \n",
    "\n",
    "वय, उंची आणि वजन हे सर्व सलग (continuous) यादृच्छिक चल (random variables) आहेत. आपल्याला काय वाटते त्यांचे वितरण कसे असेल? माहितीसाठी एक चांगला मार्ग म्हणजे मूल्यांचा हिस्टोग्राम काढणे: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weight'].hist(bins=15, figsize=(10,6))\n",
    "plt.suptitle('Weight distribution of MLB Players')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## सामान्य वितरण\n",
    "\n",
    "चला आपला खरा डेटा सारखा समान सरासरी आणि विचलन असलेले सामान्य वितरण पाळणारे वजनाचे एक कृत्रिम नमुना तयार करूया:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = np.random.normal(mean, std, 1000)\n",
    "generated[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(generated, bins=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(np.random.normal(0,1,50000), bins=300)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "जास्तीत जास्त खरे जीवनातील मूल्ये सामान्य वितरणानुसार असतात, म्हणून नमुना डेटा तयार करण्यासाठी आम्ही एकसमान यादृच्छिक संख्या जनक वापरू नये. जर आम्ही एकसमान वितरणाने वजन तयार करण्याचा प्रयत्न केला (जे `np.random.rand` ने तयार केले जाते), तर काय होते ते येथे आहे:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_sample = np.random.rand(1000)*2*std+mean-std\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(wrong_sample)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## आत्मविश्वास अंतराल\n",
    "\n",
    "आता आपण बेसबॉल खेळाडूंच्या वजन आणि उंचीसाठी आत्मविश्वास अंतरालांची गणना करूया. आपण हा कोड [या stackoverflow चर्चेतून](https://stackoverflow.com/questions/15033511/compute-a-confidence-interval-from-sample-data) वापरणार आहोत:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, h\n",
    "\n",
    "for p in [0.85, 0.9, 0.95]:\n",
    "    m, h = mean_confidence_interval(df['Weight'].fillna(method='pad'),p)\n",
    "    print(f\"p={p:.2f}, mean = {m:.2f} ± {h:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## परीक्षण अनुमान\n",
    "\n",
    "चला आपल्या बेसबॉल खेळाडू डेटासेटमधील विविध भूमिका तपासू या:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Role').agg({ 'Weight' : 'mean', 'Height' : 'mean', 'Age' : 'count'}).rename(columns={ 'Age' : 'Count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "चला असा अनुमान तपासूया की फर्स्ट बेसमन दुसऱ्या बेसमनच्या तुलनेत उंच असतात. हे तपासण्याचा सर्वात सोपा मार्ग म्हणजे आत्मविश्वास अंतरांचे परीक्षण करणे:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [0.85,0.9,0.95]:\n",
    "    m1, h1 = mean_confidence_interval(df.loc[df['Role']=='First_Baseman',['Height']],p)\n",
    "    m2, h2 = mean_confidence_interval(df.loc[df['Role']=='Second_Baseman',['Height']],p)\n",
    "    print(f'Conf={p:.2f}, 1st basemen height: {m1-h1[0]:.2f}..{m1+h1[0]:.2f}, 2nd basemen height: {m2-h2[0]:.2f}..{m2+h2[0]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आपण पाहू शकतो की अवधी एकमेकांवर आच्छादित नाहीत.\n",
    "\n",
    "गृहितक सिद्ध करण्याचा सांख्यिकदृष्ट्या अधिक योग्य मार्ग म्हणजे **स्टुडंट t-टेस्ट** वापरणे:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Second_Baseman',['Height']],equal_var=False)\n",
    "print(f\"T-value = {tval[0]:.2f}\\nP-value: {pval[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ttest_ind` फंक्शनने परत केलेली दोन मूल्ये आहेत:\n",
    "* p-मूल्य दोन वितरणांच्या समान सरासरी असण्याची शक्यता म्हणून विचारले जाऊ शकते. आपल्या प्रकरणात, हे खूप कमी आहे, ज्याचा अर्थ असा की प्रथम बेसमन उंच असल्याचे मजबूत पुरावे आहेत.\n",
    "* t-मूल्य म्हणजे सामान्यीकृत सरासरी फरकाचे मध्यम मूल्य जे t-टेस्टमध्ये वापरले जाते, आणि ते दिलेल्या आत्मविश्वास मूल्यासाठी एका थ्रेशोल्ड मूल्याशी तुलना केली जाते.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## सेंट्रल लिमिट थिअरमसह सामान्य वितरणाचे अनुकरण करणे\n",
    "\n",
    "Python मधील छद्म-यादी जनरेटर आपल्याला समान वितरण देण्यासाठी डिझाइन केलेले आहे. जर आपल्याला सामान्य वितरणासाठी एक जनरेटर तयार करायचा असेल, तर आपण सेंट्रल लिमिट थिअरम वापरू शकतो. सामान्य वितरण मूल्य मिळवण्यासाठी आपण फक्त समान-जनरेट केलेल्या नमुन्याचा सरासरी काढू.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_random(sample_size=100):\n",
    "    sample = [random.uniform(0,1) for _ in range(sample_size) ]\n",
    "    return sum(sample)/sample_size\n",
    "\n",
    "sample = [normal_random() for _ in range(100)]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(sample)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## सहसंबंध आणि एविल बेसबॉल कॉर्पोरेशन\n",
    "\n",
    "सहसंबंध आपल्याला डेटा अनुक्रमांमधील संबंध शोधण्यास अनुमती देतो. आपल्या खेळण्याच्या उदाहरणात, समजा एक एविल बेसबॉल कॉर्पोरेशन आहे जे आपल्या खेळाडूंना त्यांच्या उंचीप्रमाणे पैसे देते - खेळाडू जितका उंच आहे, त्याला तितका अधिक पैसा मिळतो. गृहित धरा की बेस वेतन $1000 आहे, आणि उंचीवर अवलंबून $0 ते $100 पर्यंत अतिरिक्त बोनस आहे. आपण MLB मधील वास्तविक खेळाडू घेणार आहोत, आणि त्यांची काल्पनिक पगार गणना करू:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = df['Height'].fillna(method='pad')\n",
    "salaries = 1000+(heights-heights.min())/(heights.max()-heights.mean())*100\n",
    "print(list(zip(heights, salaries))[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आता आपण त्या अनुक्रमांच्या सहचर आणि सहसंबंधाची गणना करूया. `np.cov` आपल्याला असं म्हणतात ते **सहचर मॅट्रिक्स** देईल, जे सहचराचे एकाधिक चलांसाठीचे विस्तार आहे. सहचर मॅट्रिक्स $M$ चा घटक $M_{ij}$ हा इनपुट चल $X_i$ आणि $X_j$ मधील सहसंबंध आहे, आणि तिरक्या मूल्यांना $M_{ii}$ हा $X_{i}$ चा विचलन आहे. त्याचप्रमाणे, `np.corrcoef` आपल्याला **सहसंबंध मॅट्रिक्स** देईल.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Covariance matrix:\\n{np.cov(heights, salaries)}\")\n",
    "print(f\"Covariance = {np.cov(heights, salaries)[0,1]}\")\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "समाजशास्त्रीय सहसंबंध 1 इतका असल्यास, दोन चलांमधील एक मजबूत **रेखीय संबंध** आहे असे सांगते. आम्ही एक चल दुसऱ्या विरुद्ध plotting करून रेखीय संबंध दृष्यरित्या पाहू शकतो:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(heights,salaries)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "चलो पाहूया काय होते जर संबंध रेषीय नसेल. गृहित धरा की आमच्या कंपनीने उंची आणि पगारांमधील स्पष्ट रेषीय अवलंबित्व लपवण्याचा निर्णय घेतला, आणि सूत्रात काही गैर-रेषीयता, जसे की `sin`, आणली:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = 1000+np.sin((heights-heights.min())/(heights.max()-heights.mean()))*100\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "या प्रकरणात, सहसंबंध थोडा कमी आहे, परंतु तो अजूनही खूप जास्त आहे. आता, संबंध आणखी कमी स्पष्ट करण्यासाठी, आपल्याला पगारात काही अतिरिक्त अकार्यक्षमता जोडायची असू शकते. चला पाहूया काय होते:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = 1000+np.sin((heights-heights.min())/(heights.max()-heights.mean()))*100+np.random.random(size=len(heights))*20-10\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(heights, salaries)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> तुम्हाला अंदाज देता येईल का का ही हट्ट्या अशा रेषांमध्ये सरळ उभ्या ओळींत लावल्या आहेत?\n",
    "\n",
    "आपण वेतनासारख्या कृत्रिमरित्या बनवलेल्या संकल्पने आणि निरीक्षित चल *उंची* यामध्ये असलेला संबंध पाहिला आहे. चला आता दोन निरीक्षित चल, उंची आणि वजन यामध्येही असेच काही संबंध आहेत का ते पाहूयात:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df['Height'].ffill(),df['Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "दुर्दैवाने, आम्हाला कोणतेही निकाल मिळाले नाहीत - फक्त काही विचित्र `nan` मूल्ये. हे या कारणास्तव आहे की आपल्या मालिका मधील काही मूल्ये अनिर्धारित आहेत, ज्यांना `nan` म्हणून प्रदर्शित केले गेले आहे, ज्यामुळे ऑपरेशनचे परिणाम देखील अनिर्धारित होतात. मॅट्रिक्सकडे पाहिल्यावर आपण पाहू शकतो की `Weight` हा समस्या निर्माण करणारा स्तंभ आहे, कारण `Height` मूल्यांमधील स्व-संबंध गणना केले गेले आहे.\n",
    "\n",
    "> हे उदाहरण **डेटा तयारी** आणि **स्वच्छतेचे** महत्त्व दाखवते. योग्य डेटा नसेल तर आपण काहीही गणना करू शकत नाही.\n",
    "\n",
    "चला आपण गायब मूल्ये भरिण्यासाठी `fillna` पद्धत वापरू आणि संबंध गणना करू:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df['Height'].fillna(method='pad'), df['Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "खरंच एक संबंध आहे, पण आमच्या कृत्रिम उदाहरणाप्रमाणे इतका मजबूत नाही. खरंच, जर आपण एका मूल्याच्या विरुद्ध दुसऱ्या मूल्याचा स्कॅटर प्लॉट पाहिला तर संबंध फारशी स्पष्ट दिसणार नाही:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(df['Weight'],df['Height'])\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Height')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## निष्कर्ष\n",
    "\n",
    "या नोटबुकमध्ये आपण डेटावर मूलभूत ऑपरेशन्स कसे करायचे ते शिकले आहे जेणेकरून सांख्यिकी फंक्शन्सची गणना करता येईल. आता आपल्याला गणित आणि सांख्यिकीचे एक ठोस साधन कसे वापरायचे हे माहिती आहे ज्यावरून काही अनुमान सिद्ध करता येतील, आणि दिलेल्या डेटा नमुन्यासाठी मनमानी चलांबाबत आत्मविश्वास अंतर कसे मोजायचे ते कळाले आहे.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**तोडकं**:\nहा दस्तऐवज AI भाषांतर सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) वापरून भाषांतरित केला आहे. आम्ही अचूकतेसाठी प्रयत्न करत असलो तरी, कृपया लक्षात ठेवा की स्वयंचलित भाषांतरात चुका किंवा अचूकतेच्या त्रुटी असू शकतात. मूळ दस्तऐवज त्याच्या मूळ भाषेतच अधिकारिक स्रोत मानावा. महत्त्वाच्या माहितीकरिता व्यावसायिक मानवी भाषांतर शिफारस केली जाते. या भाषांतराच्या वापरामुळे होणाऱ्या कोणत्याही गैरसमजुती किंवा चुकीच्या अर्थलागी आम्ही जबाबदार नाही.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86193a1ab0ba47eac1c69c1756090baa3b420b3eea7d4aafab8b85f8b312f0c5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "coopTranslator": {
   "original_hash": "0f899e3c5019f948e7c787b22f3b2304",
   "translation_date": "2026-01-16T11:52:55+00:00",
   "source_file": "1-Introduction/04-stats-and-probability/notebook.ipynb",
   "language_code": "mr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}