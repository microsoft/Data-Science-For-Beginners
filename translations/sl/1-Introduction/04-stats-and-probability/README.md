<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1cf49f029ba1f25a54f0d5bc2fa575fc",
  "translation_date": "2025-09-05T19:43:12+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "sl"
}
-->
# Kratek uvod v statistiko in verjetnost

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| Statistika in verjetnost - _Sketchnote by [@nitya](https://twitter.com/nitya)_ |

Teorija statistike in verjetnosti sta dve tesno povezani podroÄji matematike, ki sta zelo pomembni za podatkovno znanost. ÄŒeprav je mogoÄe delati s podatki brez poglobljenega matematiÄnega znanja, je vseeno koristno poznati vsaj osnovne koncepte. Tukaj bomo predstavili kratek uvod, ki vam bo pomagal zaÄeti.

[![Uvodni video](../../../../1-Introduction/04-stats-and-probability/images/video-prob-and-stats.png)](https://youtu.be/Z5Zy85g4Yjw)

## [Pred-predavanjski kviz](https://ff-quizzes.netlify.app/en/ds/quiz/6)

## Verjetnost in nakljuÄne spremenljivke

**Verjetnost** je Å¡tevilo med 0 in 1, ki izraÅ¾a, kako verjeten je doloÄen **dogodek**. DoloÄena je kot Å¡tevilo pozitivnih izidov (ki vodijo do dogodka), deljeno s skupnim Å¡tevilom izidov, ob predpostavki, da so vsi izidi enako verjetni. Na primer, ko vrÅ¾emo kocko, je verjetnost, da dobimo sodo Å¡tevilo, 3/6 = 0,5.

Ko govorimo o dogodkih, uporabljamo **nakljuÄne spremenljivke**. Na primer, nakljuÄna spremenljivka, ki predstavlja Å¡tevilo, pridobljeno pri metanju kocke, bi imela vrednosti od 1 do 6. MnoÅ¾ica Å¡tevil od 1 do 6 se imenuje **vzorec**. Lahko govorimo o verjetnosti, da nakljuÄna spremenljivka prevzame doloÄeno vrednost, na primer P(X=3)=1/6.

NakljuÄna spremenljivka v prejÅ¡njem primeru se imenuje **diskretna**, ker ima Å¡tevno vzorÄno mnoÅ¾ico, tj. obstajajo loÄene vrednosti, ki jih je mogoÄe preÅ¡teti. Obstajajo primeri, ko je vzorÄna mnoÅ¾ica razpon realnih Å¡tevil ali celoten sklop realnih Å¡tevil. TakÅ¡ne spremenljivke se imenujejo **zvezne**. Dober primer je Äas prihoda avtobusa.

## Porazdelitev verjetnosti

V primeru diskretnih nakljuÄnih spremenljivk je enostavno opisati verjetnost vsakega dogodka s funkcijo P(X). Za vsako vrednost *s* iz vzorÄne mnoÅ¾ice *S* bo podala Å¡tevilo med 0 in 1, tako da bo vsota vseh vrednosti P(X=s) za vse dogodke enaka 1.

Najbolj znana diskretna porazdelitev je **enakomerna porazdelitev**, pri kateri je vzorÄna mnoÅ¾ica sestavljena iz N elementov, z enako verjetnostjo 1/N za vsakega od njih.

TeÅ¾je je opisati porazdelitev verjetnosti zvezne spremenljivke, katere vrednosti so izbrane iz intervala [a,b] ali celotnega sklopa realnih Å¡tevil â„. Razmislite o primeru Äasa prihoda avtobusa. Pravzaprav je za vsak toÄen Äas prihoda *t* verjetnost, da avtobus pride toÄno ob tem Äasu, enaka 0!

> Zdaj veste, da se dogodki z verjetnostjo 0 zgodijo, in to zelo pogosto! Vsaj vsakiÄ, ko avtobus prispe!

Lahko govorimo le o verjetnosti, da spremenljivka pade v doloÄen interval vrednosti, npr. P(t<sub>1</sub>â‰¤X<t<sub>2</sub>). V tem primeru je porazdelitev verjetnosti opisana z **funkcijo gostote verjetnosti** p(x), tako da

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../1-Introduction/04-stats-and-probability/images/probability-density.png)

Zvezni analog enakomerne porazdelitve se imenuje **zvezna enakomerna porazdelitev**, ki je definirana na konÄnem intervalu. Verjetnost, da vrednost X pade v interval dolÅ¾ine l, je sorazmerna z l in se poveÄa do 1.

Druga pomembna porazdelitev je **normalna porazdelitev**, o kateri bomo podrobneje govorili spodaj.

## PovpreÄje, varianca in standardni odklon

Recimo, da vzamemo zaporedje n vzorcev nakljuÄne spremenljivke X: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. **PovpreÄno** (ali **aritmetiÄno sredino**) vrednost zaporedja lahko definiramo na tradicionalen naÄin kot (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n. Ko poveÄujemo velikost vzorca (tj. vzamemo limit z nâ†’âˆ), dobimo povpreÄje (imenovano tudi **priÄakovana vrednost**) porazdelitve. PriÄakovano vrednost bomo oznaÄili z **E**(x).

> Dokazano je, da za katero koli diskretno porazdelitev z vrednostmi {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} in ustreznimi verjetnostmi p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, priÄakovana vrednost ustreza E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>.

Da ugotovimo, kako razprÅ¡ene so vrednosti, lahko izraÄunamo varianco Ïƒ<sup>2</sup> = âˆ‘(x<sub>i</sub> - Î¼)<sup>2</sup>/n, kjer je Î¼ povpreÄje zaporedja. Vrednost Ïƒ se imenuje **standardni odklon**, medtem ko je Ïƒ<sup>2</sup> **varianca**.

## Moda, mediana in kvartili

VÄasih povpreÄje ne predstavlja ustrezno "tipiÄne" vrednosti podatkov. Na primer, ko obstaja nekaj ekstremnih vrednosti, ki so popolnoma izven dosega, lahko vplivajo na povpreÄje. Druga dobra mera je **mediana**, vrednost, pri kateri je polovica podatkov niÅ¾ja od nje, druga polovica pa viÅ¡ja.

Za boljÅ¡e razumevanje porazdelitve podatkov je koristno govoriti o **kvartilih**:

* Prvi kvartil ali Q1 je vrednost, pri kateri 25 % podatkov pade pod njo
* Tretji kvartil ali Q3 je vrednost, pri kateri 75 % podatkov pade pod njo

GrafiÄno lahko razmerje med mediano in kvartili predstavimo v diagramu, imenovanem **Å¡katlasti diagram**:

<img src="images/boxplot_explanation.png" width="50%"/>

Tukaj izraÄunamo tudi **interkvartilni razpon** IQR=Q3-Q1 in tako imenovane **odstopajoÄe vrednosti** - vrednosti, ki leÅ¾ijo zunaj meja [Q1-1.5*IQR,Q3+1.5*IQR].

Za konÄno porazdelitev, ki vsebuje majhno Å¡tevilo moÅ¾nih vrednosti, je dobra "tipiÄna" vrednost tista, ki se pojavi najpogosteje, in se imenuje **moda**. Pogosto se uporablja za kategorijske podatke, kot so barve. Razmislite o situaciji, ko imamo dve skupini ljudi - ene, ki moÄno preferirajo rdeÄo, in druge, ki preferirajo modro. ÄŒe kodiramo barve s Å¡tevilkami, bi povpreÄna vrednost za najljubÅ¡o barvo bila nekje v oranÅ¾no-zelenem spektru, kar ne odraÅ¾a dejanske preference nobene skupine. Vendar bi moda bila ena od barv ali obe barvi, Äe je Å¡tevilo ljudi, ki glasujejo za njih, enako (v tem primeru vzorec imenujemo **multimodalni**).

## Podatki iz resniÄnega sveta

Ko analiziramo podatke iz resniÄnega sveta, ti pogosto niso nakljuÄne spremenljivke v pravem pomenu, saj ne izvajamo eksperimentov z neznanim rezultatom. Na primer, razmislite o ekipi baseball igralcev in njihovih telesnih podatkih, kot so viÅ¡ina, teÅ¾a in starost. Te Å¡tevilke niso povsem nakljuÄne, vendar lahko Å¡e vedno uporabimo iste matematiÄne koncepte. Na primer, zaporedje teÅ¾ baseball igralcev lahko obravnavamo kot zaporedje vrednosti, izbranih iz neke nakljuÄne spremenljivke. Spodaj je zaporedje teÅ¾ dejanskih baseball igralcev iz [Major League Baseball](http://mlb.mlb.com/index.jsp), vzeto iz [tega nabora podatkov](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) (za vaÅ¡o udobje je prikazanih le prvih 20 vrednosti):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Opomba**: ÄŒe Å¾elite videti primer dela s tem naborom podatkov, si oglejte [priloÅ¾eni zvezek](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb). V tej lekciji je tudi veÄ izzivov, ki jih lahko dokonÄate z dodajanjem kode v ta zvezek. ÄŒe niste prepriÄani, kako delati s podatki, ne skrbite - k delu s podatki v Pythonu se bomo vrnili kasneje. ÄŒe ne veste, kako zagnati kodo v Jupyter Notebooku, si oglejte [ta Älanek](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

Tukaj je Å¡katlasti diagram, ki prikazuje povpreÄje, mediano in kvartile za naÅ¡e podatke:

![Å katlasti diagram teÅ¾e](../../../../1-Introduction/04-stats-and-probability/images/weight-boxplot.png)

Ker naÅ¡i podatki vsebujejo informacije o razliÄnih **vlogah** igralcev, lahko naredimo tudi Å¡katlasti diagram po vlogah - to nam omogoÄa, da dobimo idejo o tem, kako se vrednosti parametrov razlikujejo med vlogami. Tokrat bomo upoÅ¡tevali viÅ¡ino:

![Å katlasti diagram po vlogah](../../../../1-Introduction/04-stats-and-probability/images/boxplot_byrole.png)

Ta diagram nakazuje, da je povpreÄna viÅ¡ina igralcev na prvi bazi viÅ¡ja od viÅ¡ine igralcev na drugi bazi. Kasneje v tej lekciji se bomo nauÄili, kako lahko to hipotezo bolj formalno preverimo in kako pokaÅ¾emo, da so naÅ¡i podatki statistiÄno pomembni za dokazovanje tega.

> Pri delu s podatki iz resniÄnega sveta predpostavljamo, da so vse toÄke podatkov vzorci, izbrani iz neke porazdelitve verjetnosti. Ta predpostavka nam omogoÄa uporabo tehnik strojnega uÄenja in gradnjo delujoÄih napovednih modelov.

Da vidimo, kakÅ¡na je porazdelitev naÅ¡ih podatkov, lahko nariÅ¡emo graf, imenovan **histogram**. Os X bo vsebovala Å¡tevilo razliÄnih intervalov teÅ¾e (tako imenovanih **razredov**), os Y pa bo prikazala Å¡tevilo primerov, ko je bil vzorec naÅ¡e nakljuÄne spremenljivke znotraj danega intervala.

![Histogram podatkov iz resniÄnega sveta](../../../../1-Introduction/04-stats-and-probability/images/weight-histogram.png)

Iz tega histograma lahko vidite, da so vse vrednosti osredotoÄene okoli doloÄenega povpreÄja teÅ¾e, in bolj ko se oddaljujemo od tega povpreÄja, manj pogosto se pojavljajo teÅ¾e te vrednosti. To pomeni, da je zelo malo verjetno, da bi bila teÅ¾a baseball igralca zelo razliÄna od povpreÄne teÅ¾e. Varianca teÅ¾ prikazuje, v kolikÅ¡ni meri se teÅ¾e verjetno razlikujejo od povpreÄja.

> ÄŒe vzamemo teÅ¾e drugih ljudi, ki niso iz baseball lige, bo porazdelitev verjetno drugaÄna. Vendar bo oblika porazdelitve enaka, le povpreÄje in varianca se bosta spremenila. ÄŒe torej treniramo naÅ¡ model na baseball igralcih, bo verjetno dal napaÄne rezultate, ko ga uporabimo na Å¡tudentih univerze, ker je osnovna porazdelitev drugaÄna.

## Normalna porazdelitev

Porazdelitev teÅ¾, ki smo jo videli zgoraj, je zelo tipiÄna, in veliko meritev iz resniÄnega sveta sledi istemu tipu porazdelitve, vendar z razliÄnim povpreÄjem in varianco. Ta porazdelitev se imenuje **normalna porazdelitev**, in igra zelo pomembno vlogo v statistiki.

Uporaba normalne porazdelitve je pravilen naÄin za generiranje nakljuÄnih teÅ¾ potencialnih baseball igralcev. Ko poznamo povpreÄno teÅ¾o `mean` in standardni odklon `std`, lahko generiramo 1000 vzorcev teÅ¾e na naslednji naÄin:
```python
samples = np.random.normal(mean,std,1000)
```

ÄŒe nariÅ¡emo histogram generiranih vzorcev, bomo videli sliko, zelo podobno zgoraj prikazani. ÄŒe poveÄamo Å¡tevilo vzorcev in Å¡tevilo razredov, lahko generiramo sliko normalne porazdelitve, ki je bliÅ¾je idealni:

![Normalna porazdelitev s povpreÄjem=0 in std.odklonom=1](../../../../1-Introduction/04-stats-and-probability/images/normal-histogram.png)

*Normalna porazdelitev s povpreÄjem=0 in std.odklonom=1*

## Intervali zaupanja

Ko govorimo o teÅ¾ah baseball igralcev, predpostavljamo, da obstaja doloÄena **nakljuÄna spremenljivka W**, ki ustreza idealni porazdelitvi verjetnosti teÅ¾ vseh baseball igralcev (tako imenovana **populacija**). NaÅ¡e zaporedje teÅ¾ ustreza podmnoÅ¾ici vseh baseball igralcev, ki jo imenujemo **vzorec**. Zanimivo vpraÅ¡anje je, ali lahko poznamo parametre porazdelitve W, tj. povpreÄje in varianco populacije?

NajlaÅ¾ji odgovor bi bil izraÄunati povpreÄje in varianco naÅ¡ega vzorca. Vendar se lahko zgodi, da naÅ¡ nakljuÄni vzorec ne predstavlja natanÄno celotne populacije. Zato je smiselno govoriti o **intervalu zaupanja**.

> **Interval zaupanja** je ocena pravega povpreÄja populacije glede na naÅ¡ vzorec, ki je natanÄna z doloÄeno verjetnostjo (ali **stopnjo zaupanja**).

Recimo, da imamo vzorec X

1</sub>, ..., X<sub>n</sub> iz naÅ¡e porazdelitve. VsakiÄ, ko vzamemo vzorec iz naÅ¡e porazdelitve, dobimo drugaÄno povpreÄno vrednost Î¼. Tako lahko Î¼ obravnavamo kot nakljuÄno spremenljivko. **Interval zaupanja** z zaupanjem p je par vrednosti (L<sub>p</sub>,R<sub>p</sub>), tako da **P**(L<sub>p</sub>â‰¤Î¼â‰¤R<sub>p</sub>) = p, torej verjetnost, da izmerjena povpreÄna vrednost pade v interval, je enaka p.

Podrobna razlaga, kako se ti intervali zaupanja izraÄunajo, presega naÅ¡ kratek uvod. VeÄ podrobnosti najdete [na Wikipediji](https://en.wikipedia.org/wiki/Confidence_interval). Na kratko, definiramo porazdelitev izraÄunanega vzorÄnega povpreÄja glede na pravo povpreÄje populacije, kar imenujemo **Studentova porazdelitev**.

> **Zanimivo dejstvo**: Studentova porazdelitev je poimenovana po matematiku Williamu Sealyju Gossetu, ki je svoje delo objavil pod psevdonimom "Student". Delal je v pivovarni Guinness, in po eni od razliÄic njegov delodajalec ni Å¾elel, da bi Å¡irÅ¡a javnost vedela, da uporabljajo statistiÄne teste za doloÄanje kakovosti surovin.

ÄŒe Å¾elimo oceniti povpreÄje Î¼ naÅ¡e populacije z zaupanjem p, moramo vzeti *(1-p)/2-ti percentil* Studentove porazdelitve A, ki ga lahko pridobimo iz tabel ali izraÄunamo z vgrajenimi funkcijami statistiÄne programske opreme (npr. Python, R itd.). Nato je interval za Î¼ podan z XÂ±A*D/âˆšn, kjer je X pridobljeno povpreÄje vzorca, D pa standardni odklon.

> **Opomba**: Prav tako izpuÅ¡Äamo razpravo o pomembnem konceptu [stopnje svobode](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)), ki je pomemben v povezavi s Studentovo porazdelitvijo. Za globlje razumevanje tega koncepta se lahko obrnete na bolj celovite knjige o statistiki.

Primer izraÄuna intervala zaupanja za teÅ¾o in viÅ¡ino je podan v [priloÅ¾enih zvezkih](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb).

| p | PovpreÄje teÅ¾e |
|-----|-----------|
| 0.85 | 201.73Â±0.94 |
| 0.90 | 201.73Â±1.08 |
| 0.95 | 201.73Â±1.28 |

Opazimo, da je viÅ¡ja verjetnost zaupanja, Å¡irÅ¡i je interval zaupanja.

## Testiranje hipotez

V naÅ¡em naboru podatkov o igralcih baseballa obstajajo razliÄne vloge igralcev, ki jih lahko povzamemo spodaj (glejte [priloÅ¾en zvezek](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb), da vidite, kako se ta tabela izraÄuna):

| Vloga | ViÅ¡ina | TeÅ¾a | Å tevilo |
|------|--------|--------|-------|
| Lovec | 72.723684 | 204.328947 | 76 |
| DoloÄeni udarec | 74.222222 | 220.888889 | 18 |
| Prvi bazni igralec | 74.000000 | 213.109091 | 55 |
| Zunanji igralec | 73.010309 | 199.113402 | 194 |
| Rezervni metalec | 74.374603 | 203.517460 | 315 |
| Drugi bazni igralec | 71.362069 | 184.344828 | 58 |
| Kratki igralec | 71.903846 | 182.923077 | 52 |
| ZaÄetni metalec | 74.719457 | 205.163636 | 221 |
| Tretji bazni igralec | 73.044444 | 200.955556 | 45 |

Opazimo, da je povpreÄna viÅ¡ina prvih baznih igralcev viÅ¡ja od povpreÄne viÅ¡ine drugih baznih igralcev. Tako bi lahko sklepali, da so **prvi bazni igralci viÅ¡ji od drugih baznih igralcev**.

> Ta izjava se imenuje **hipoteza**, ker ne vemo, ali je dejstvo resniÄno ali ne.

Vendar ni vedno oÄitno, ali lahko to sklepamo. Iz zgornje razprave vemo, da ima vsako povpreÄje pripadajoÄi interval zaupanja, zato je lahko ta razlika zgolj statistiÄna napaka. Potrebujemo bolj formalni naÄin za testiranje naÅ¡e hipoteze.

IzraÄunajmo intervale zaupanja loÄeno za viÅ¡ine prvih in drugih baznih igralcev:

| Zaupanje | Prvi bazni igralci | Drugi bazni igralci |
|------------|---------------|----------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

Vidimo, da se pri nobenem zaupanju intervali ne prekrivajo. To dokazuje naÅ¡o hipotezo, da so prvi bazni igralci viÅ¡ji od drugih baznih igralcev.

Bolj formalno, problem, ki ga reÅ¡ujemo, je ugotoviti, ali sta **dve porazdelitvi verjetnosti enaki**, ali imata vsaj enake parametre. Glede na porazdelitev moramo za to uporabiti razliÄne teste. ÄŒe vemo, da sta naÅ¡i porazdelitvi normalni, lahko uporabimo **[Studentov t-test](https://en.wikipedia.org/wiki/Student%27s_t-test)**.

Pri Studentovem t-testu izraÄunamo tako imenovano **t-vrednost**, ki kaÅ¾e razliko med povpreÄji ob upoÅ¡tevanju variance. Dokazano je, da t-vrednost sledi **Studentovi porazdelitvi**, kar nam omogoÄa pridobitev mejne vrednosti za dano raven zaupanja **p** (to lahko izraÄunamo ali poiÅ¡Äemo v numeriÄnih tabelah). Nato primerjamo t-vrednost s to mejo, da potrdimo ali zavrnemo hipotezo.

V Pythonu lahko uporabimo paket **SciPy**, ki vkljuÄuje funkcijo `ttest_ind` (poleg mnogih drugih uporabnih statistiÄnih funkcij!). Ta funkcija za nas izraÄuna t-vrednost in tudi obratno poiÅ¡Äe p-vrednost zaupanja, tako da lahko preprosto pogledamo zaupanje za sklepanje.

Na primer, naÅ¡a primerjava med viÅ¡inami prvih in drugih baznih igralcev nam daje naslednje rezultate: 
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
V naÅ¡em primeru je p-vrednost zelo nizka, kar pomeni, da obstajajo moÄni dokazi, ki podpirajo, da so prvi bazni igralci viÅ¡ji.

Obstajajo tudi razliÄne druge vrste hipotez, ki jih morda Å¾elimo testirati, na primer:
* Dokazati, da dani vzorec sledi neki porazdelitvi. V naÅ¡em primeru smo predpostavili, da so viÅ¡ine normalno porazdeljene, vendar to zahteva formalno statistiÄno preverjanje.
* Dokazati, da povpreÄna vrednost vzorca ustreza neki predhodno doloÄeni vrednosti
* Primerjati povpreÄja veÄ vzorcev (npr. kakÅ¡na je razlika v ravni sreÄe med razliÄnimi starostnimi skupinami)

## Zakon velikih Å¡tevil in centralni limitni izrek

Eden od razlogov, zakaj je normalna porazdelitev tako pomembna, je tako imenovani **centralni limitni izrek**. Predpostavimo, da imamo velik vzorec neodvisnih N vrednosti X<sub>1</sub>, ..., X<sub>N</sub>, vzorÄenih iz katere koli porazdelitve s povpreÄjem Î¼ in varianco Ïƒ<sup>2</sup>. Nato, za dovolj velik N (z drugimi besedami, ko Nâ†’âˆ), bo povpreÄje Î£<sub>i</sub>X<sub>i</sub> normalno porazdeljeno, s povpreÄjem Î¼ in varianco Ïƒ<sup>2</sup>/N.

> Drug naÄin interpretacije centralnega limitnega izreka je reÄi, da ne glede na porazdelitev, ko izraÄunate povpreÄje vsote vrednosti katere koli nakljuÄne spremenljivke, dobite normalno porazdelitev.

Iz centralnega limitnega izreka prav tako sledi, da, ko Nâ†’âˆ, verjetnost, da bo vzorÄno povpreÄje enako Î¼, postane 1. To je znano kot **zakon velikih Å¡tevil**.

## Kovarianca in korelacija

Ena od stvari, ki jih poÄne podatkovna znanost, je iskanje povezav med podatki. Pravimo, da se dve zaporedji **korelirata**, ko kaÅ¾eta podobno vedenje ob istem Äasu, tj. se hkrati dvigujeta/padata ali eno zaporedje naraÅ¡Äa, ko drugo pada in obratno. Z drugimi besedami, zdi se, da obstaja neka povezava med dvema zaporedjema.

> Korelacija ne pomeni nujno vzroÄne povezave med dvema zaporedjema; vÄasih obe spremenljivki lahko odvisni od nekega zunanjega vzroka ali pa je zgolj nakljuÄje, da se dve zaporedji korelirata. Vendar moÄna matematiÄna korelacija dobro nakazuje, da sta dve spremenljivki nekako povezani.

MatematiÄno je glavni koncept, ki kaÅ¾e povezavo med dvema nakljuÄnima spremenljivkama, **kovarianca**, ki se izraÄuna takole: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. IzraÄunamo odstopanje obeh spremenljivk od njihovih povpreÄnih vrednosti in nato produkt teh odstopanj. ÄŒe obe spremenljivki odstopata skupaj, bo produkt vedno pozitivna vrednost, ki bo prispevala k pozitivni kovarianci. ÄŒe obe spremenljivki odstopata nesinhrono (tj. ena pade pod povpreÄje, ko druga naraste nad povpreÄje), bomo vedno dobili negativne Å¡tevilke, ki bodo prispevale k negativni kovarianci. ÄŒe odstopanja niso odvisna, se bodo pribliÅ¾no seÅ¡tela na niÄ.

Absolutna vrednost kovariance nam ne pove veliko o tem, kako velika je korelacija, ker je odvisna od velikosti dejanskih vrednosti. Da jo normaliziramo, lahko kovarianco delimo s standardnim odklonom obeh spremenljivk, da dobimo **korelacijo**. Dobro je, da je korelacija vedno v razponu [-1,1], kjer 1 oznaÄuje moÄno pozitivno korelacijo med vrednostmi, -1 moÄno negativno korelacijo, in 0 - brez korelacije (spremenljivki sta neodvisni).

**Primer**: Korelacijo med teÅ¾o in viÅ¡ino igralcev baseballa iz zgoraj omenjenega nabora podatkov lahko izraÄunamo:
```python
print(np.corrcoef(weights,heights))
```
Rezultat je **korelacijska matrika**, kot je ta:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> Korelacijsko matriko C lahko izraÄunamo za poljubno Å¡tevilo vhodnih zaporedij S<sub>1</sub>, ..., S<sub>n</sub>. Vrednost C<sub>ij</sub> je korelacija med S<sub>i</sub> in S<sub>j</sub>, diagonalni elementi pa so vedno 1 (kar je tudi samokorelacija S<sub>i</sub>).

V naÅ¡em primeru vrednost 0.53 kaÅ¾e, da obstaja neka korelacija med teÅ¾o in viÅ¡ino osebe. Prav tako lahko naredimo razprÅ¡eni graf ene vrednosti proti drugi, da vizualno vidimo povezavo:

![Povezava med teÅ¾o in viÅ¡ino](../../../../1-Introduction/04-stats-and-probability/images/weight-height-relationship.png)

> VeÄ primerov korelacije in kovariance najdete v [priloÅ¾enem zvezku](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb).

## ZakljuÄek

V tem poglavju smo se nauÄili:

* osnovnih statistiÄnih lastnosti podatkov, kot so povpreÄje, varianca, modus in kvartili
* razliÄnih porazdelitev nakljuÄnih spremenljivk, vkljuÄno z normalno porazdelitvijo
* kako najti korelacijo med razliÄnimi lastnostmi
* kako uporabiti matematiÄni in statistiÄni aparat za dokazovanje hipotez
* kako izraÄunati intervale zaupanja za nakljuÄno spremenljivko glede na vzorec podatkov

ÄŒeprav to ni izÄrpen seznam tem, ki obstajajo znotraj verjetnosti in statistike, bi moral zadostovati za dober zaÄetek tega teÄaja.

## ğŸš€ Izziv

Uporabite vzorÄno kodo v zvezku za testiranje drugih hipotez:
1. Prvi bazni igralci so starejÅ¡i od drugih baznih igralcev
2. Prvi bazni igralci so viÅ¡ji od tretjih baznih igralcev
3. Kratki igralci so viÅ¡ji od drugih baznih igralcev

## [Kvizi po predavanju](https://ff-quizzes.netlify.app/en/ds/quiz/7)

## Pregled in samostojno uÄenje

Verjetnost in statistika sta tako Å¡iroki temi, da si zasluÅ¾ita svoj teÄaj. ÄŒe Å¾elite iti globlje v teorijo, lahko nadaljujete z branjem nekaterih naslednjih knjig:

1. [Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/) z Univerze v New Yorku ima odliÄne zapiske predavanj [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (na voljo na spletu)
1. [Peter in Andrew Bruce. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[vzorec kode v R](https://github.com/andrewgbruce/statistics-for-data-scientists)]. 
1. [James D. Miller. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[vzorec kode v R](https://github.com/PacktPublishing/Statistics-for-Data-Science)]

## Naloga

[Majhna Å¡tudija o diabetesu](assignment.md)

## Zasluge

To lekcijo je z ljubeznijo napisal [Dmitry Soshnikov](http://soshnikov.com)

---

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). ÄŒeprav si prizadevamo za natanÄnost, vas prosimo, da upoÅ¡tevate, da lahko avtomatizirani prevodi vsebujejo napake ali netoÄnosti. Izvirni dokument v njegovem maternem jeziku je treba obravnavati kot avtoritativni vir. Za kljuÄne informacije priporoÄamo profesionalni ÄloveÅ¡ki prevod. Ne prevzemamo odgovornosti za morebitna nesporazumevanja ali napaÄne razlage, ki bi nastale zaradi uporabe tega prevoda.