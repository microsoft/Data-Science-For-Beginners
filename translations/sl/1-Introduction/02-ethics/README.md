<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3a34157cc63516eba97c89a0b2f8c3e6",
  "translation_date": "2025-09-03T21:54:57+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "sl"
}
-->
# Uvod v podatkovno etiko

|![ Sketchnote avtorja [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Etika podatkovne znanosti - _Sketchnote avtorja [@nitya](https://twitter.com/nitya)_ |

---

Vsi smo podatkovni dr쬬vljani, ki 쬴vimo v svetu, pre쬰tem s podatki.

Tr쬹i trendi ka쬰jo, da bo do leta 2022 1 od 3 velikih organizacij kupovala in prodajala svoje podatke prek spletnih [tr쬹ic in izmenjav](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Kot **razvijalci aplikacij** bomo la쬵e in ceneje vklju캜ili vpoglede, ki temeljijo na podatkih, ter avtomatizacijo, ki jo poganjajo algoritmi, v vsakodnevne uporabni코ke izku코nje. Toda z raz코irjenostjo umetne inteligence bomo morali razumeti tudi potencialne 코kodljive u캜inke [uporabe algoritmov kot oro쬵a](https://www.youtube.com/watch?v=TQHs8SA1qpk) v velikem obsegu.

Trend ka쬰 tudi, da bomo do leta 2025 ustvarili in porabili ve캜 kot [180 zettabajtov](https://www.statista.com/statistics/871513/worldwide-data-created/) podatkov. Kot **podatkovni znanstveniki** bomo imeli neprimerljivo raven dostopa do osebnih podatkov. To nam omogo캜a gradnjo vedenjskih profilov uporabnikov in vplivanje na sprejemanje odlo캜itev na na캜ine, ki ustvarjajo [iluzijo svobodne izbire](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice), hkrati pa potencialno usmerjajo uporabnike k izidom, ki jih sami preferiramo. To pa odpira 코ir코a vpra코anja o zasebnosti podatkov in za코캜iti uporabnikov.

Podatkovna etika je zdaj _nujna varovalka_ za podatkovno znanost in in쬰niring, ki nam pomaga zmanj코ati potencialne 코kodljive u캜inke in nenamerne posledice na코ih dejanj, ki temeljijo na podatkih. [Gartnerjev Hype Cycle za AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) identificira relevantne trende v digitalni etiki, odgovorni AI in upravljanju AI kot klju캜ne dejavnike ve캜jih megatrendov okoli _demokratizacije_ in _industrializacije_ umetne inteligence.

![Gartnerjev Hype Cycle za AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

V tej lekciji bomo raziskali fascinantno podro캜je podatkovne etike - od osnovnih konceptov in izzivov do 코tudij primerov in uporabljenih konceptov AI, kot je upravljanje, ki pomagajo vzpostaviti kulturo etike v ekipah in organizacijah, ki delajo s podatki in umetno inteligenco.

## [Predhodni kviz](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/2) 游꿢

## Osnovne definicije

Za캜nimo z razumevanjem osnovne terminologije.

Beseda "etika" izhaja iz [gr코ke besede "ethikos"](https://en.wikipedia.org/wiki/Ethics) (in njenega korena "ethos"), ki pomeni _zna캜aj ali moralna narava_.

**Etika** se nana코a na skupne vrednote in moralna na캜ela, ki usmerjajo na코e vedenje v dru쬭i. Etika temelji ne na zakonih, temve캜 na splo코no sprejetih normah, kaj je "prav vs. narobe". Vendar pa lahko eti캜ne premisleke vplivajo na pobude korporativnega upravljanja in vladne regulacije, ki ustvarjajo ve캜 spodbud za skladnost.

**Podatkovna etika** je [nova veja etike](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1), ki "preu캜uje in ocenjuje moralne probleme, povezane s _podatki, algoritmi in ustreznimi praksami_". Tukaj se **"podatki"** osredoto캜ajo na dejanja, povezana z generiranjem, bele쬰njem, kuriranjem, obdelavo, raz코irjanjem, deljenjem in uporabo, **"algoritmi"** se osredoto캜ajo na AI, agente, strojno u캜enje in robote, medtem ko se **"prakse"** osredoto캜ajo na teme, kot so odgovorne inovacije, programiranje, hekanje in kodeks etike.

**Uporabljena etika** je [prakti캜na uporaba moralnih premislekov](https://en.wikipedia.org/wiki/Applied_ethics). Gre za proces aktivnega raziskovanja eti캜nih vpra코anj v kontekstu _dejanskih dejanj, izdelkov in procesov_ ter sprejemanja korektivnih ukrepov, da ostanejo skladni z na코imi opredeljenimi eti캜nimi vrednotami.

**Kultura etike** se nana코a na [_operacionalizacijo_ uporabljene etike](https://hbr.org/2019/05/how-to-design-an-ethical-organization), da zagotovimo, da so na코a eti캜na na캜ela in prakse sprejeta na dosleden in raz코irljiv na캜in po celotni organizaciji. Uspe코ne kulture etike opredelijo organizacijsko 코iroka eti캜na na캜ela, zagotavljajo smiselne spodbude za skladnost in krepijo eti캜ne norme z vzpodbujanjem in amplifikacijo 쬰lenih vedenj na vseh ravneh organizacije.

## Koncepti etike

V tem razdelku bomo razpravljali o konceptih, kot so **skupne vrednote** (na캜ela) in **eti캜ni izzivi** (problemi) za podatkovno etiko - ter raziskali **코tudije primerov**, ki vam pomagajo razumeti te koncepte v realnih kontekstih.

### 1. Na캜ela etike

Vsaka strategija podatkovne etike se za캜ne z opredelitvijo _eti캜nih na캜el_ - "skupnih vrednot", ki opisujejo sprejemljiva vedenja in usmerjajo skladna dejanja v na코ih projektih, povezanih s podatki in AI. Ta na캜ela lahko opredelite na individualni ali skupinski ravni. Vendar pa ve캜ina velikih organizacij opredeli ta na캜ela v _eti캜nem AI_ misijskem izjavi ali okviru, ki je opredeljen na korporativni ravni in dosledno uveljavljen v vseh ekipah.

**Primer:** Microsoftova [Odgovorna AI](https://www.microsoft.com/en-us/ai/responsible-ai) misijska izjava se glasi: _"Zavezani smo k napredku AI, ki ga vodijo eti캜na na캜ela, ki postavljajo ljudi na prvo mesto"_ - opredeljuje 6 eti캜nih na캜el v spodnjem okviru:

![Odgovorna AI pri Microsoftu](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

Na kratko razi코캜imo ta na캜ela. _Transparentnost_ in _odgovornost_ sta temeljni vrednoti, na katerih temeljijo druga na캜ela - zato za캜nimo tam:

* [**Odgovornost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) zahteva, da so praktiki _odgovorni_ za svoje podatkovne in AI operacije ter skladnost s temi eti캜nimi na캜eli.
* [**Transparentnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) zagotavlja, da so dejanja, povezana s podatki in AI, _razumljiva_ (interpretabilna) za uporabnike, pojasnjujo캜 kaj in zakaj za odlo캜itvami.
* [**Pravi캜nost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - se osredoto캜a na zagotavljanje, da AI _vse ljudi_ obravnava pravi캜no, obravnavajo캜 sistemske ali implicitne socio-tehni캜ne pristranskosti v podatkih in sistemih.
* [**Zanesljivost in varnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - zagotavlja, da AI deluje _dosledno_ z opredeljenimi vrednotami, zmanj코uje potencialne 코kodljive u캜inke ali nenamerne posledice.
* [**Zasebnost in varnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - se nana코a na razumevanje izvora podatkov ter zagotavljanje _zasebnosti podatkov in povezanih za코캜it_ za uporabnike.
* [**Vklju캜enost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - se nana코a na oblikovanje AI re코itev z namenom, prilagajanje za izpolnjevanje _코irokega spektra 캜love코kih potreb_ in sposobnosti.

> 游뚿 Razmislite, kak코na bi lahko bila va코a misijska izjava o podatkovni etiki. Razi코캜ite eti캜ne AI okvire drugih organizacij - tukaj so primeri od [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles) in [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Katere skupne vrednote imajo? Kako se ta na캜ela nana코ajo na AI izdelke ali industrijo, v kateri delujejo?

### 2. Eti캜ni izzivi

Ko imamo opredeljena eti캜na na캜ela, je naslednji korak oceniti na코a dejanja, povezana s podatki in AI, da vidimo, ali so skladna s temi skupnimi vrednotami. Razmislite o svojih dejanjih v dveh kategorijah: _zbiranje podatkov_ in _oblikovanje algoritmov_.

Pri zbiranju podatkov bodo dejanja verjetno vklju캜evala **osebne podatke** ali osebno prepoznavne informacije (PII) za prepoznavne 쬴ve posameznike. To vklju캜uje [raznolike elemente neosebnih podatkov](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en), ki _skupno_ identificirajo posameznika. Eti캜ni izzivi se lahko nana코ajo na _zasebnost podatkov_, _lastni코tvo podatkov_ in povezana vpra코anja, kot so _informirano soglasje_ ter _pravice intelektualne lastnine_ za uporabnike.

Pri oblikovanju algoritmov bodo dejanja vklju캜evala zbiranje in kuriranje **naborov podatkov**, nato pa njihovo uporabo za treniranje in uvajanje **podatkovnih modelov**, ki napovedujejo izide ali avtomatizirajo odlo캜itve v realnih kontekstih. Eti캜ni izzivi se lahko pojavijo zaradi _pristranskosti nabora podatkov_, _te쬬v s kakovostjo podatkov_, _nepravi캜nosti_ in _napa캜ne predstavitve_ v algoritmih - vklju캜no z nekaterimi vpra코anji, ki so sistemske narave.

V obeh primerih eti캜ni izzivi izpostavljajo podro캜ja, kjer lahko na코a dejanja naletijo na konflikt z na코imi skupnimi vrednotami. Da bi zaznali, ubla쬴li, zmanj코ali ali odpravili te skrbi, moramo zastaviti moralna "da/ne" vpra코anja, povezana z na코imi dejanji, nato pa po potrebi sprejeti korektivne ukrepe. Poglejmo si nekaj eti캜nih izzivov in moralnih vpra코anj, ki jih spro쬬jo:

#### 2.1 Lastni코tvo podatkov

Zbiranje podatkov pogosto vklju캜uje osebne podatke, ki lahko identificirajo podatkovne subjekte. [Lastni코tvo podatkov](https://permission.io/blog/data-ownership) se nana코a na _nadzor_ in [_pravice uporabnikov_](https://permission.io/blog/data-ownership), povezane z ustvarjanjem, obdelavo in raz코irjanjem podatkov.

Moralna vpra코anja, ki jih moramo zastaviti, so:
 * Kdo je lastnik podatkov? (uporabnik ali organizacija)
 * Katere pravice imajo podatkovni subjekti? (npr. dostop, izbris, prenosljivost)
 * Katere pravice imajo organizacije? (npr. popravljanje zlonamernih uporabni코kih ocen)

#### 2.2 Informirano soglasje

[Informirano soglasje](https://legaldictionary.net/informed-consent/) opredeljuje dejanje, ko uporabniki privolijo v dejanje (npr. zbiranje podatkov) z _polnim razumevanjem_ relevantnih dejstev, vklju캜no z namenom, potencialnimi tveganji in alternativami.

Vpra코anja za raziskovanje tukaj so:
 * Ali je uporabnik (podatkovni subjekt) dal dovoljenje za zajemanje in uporabo podatkov?
 * Ali je uporabnik razumel namen, za katerega so bili podatki zajeti?
 * Ali je uporabnik razumel potencialna tveganja zaradi svoje udele쬭e?

#### 2.3 Intelektualna lastnina

[Intelektualna lastnina](https://en.wikipedia.org/wiki/Intellectual_property) se nana코a na nematerialne stvaritve, ki izhajajo iz 캜love코ke pobude in lahko _imajo ekonomsko vrednost_ za posameznike ali podjetja.

Vpra코anja za raziskovanje tukaj so:
 * Ali imajo zbrani podatki ekonomsko vrednost za uporabnika ali podjetje?
 * Ali ima **uporabnik** tukaj intelektualno lastnino?
 * Ali ima **organizacija** tukaj intelektualno lastnino?
 * 캛e te pravice obstajajo, kako jih 코캜itimo?

#### 2.4 Zasebnost podatkov

[Zasebnost podatkov](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) ali informacijska zasebnost se nana코a na ohranjanje zasebnosti uporabnikov in za코캜ito identitete uporabnikov glede osebno prepoznavnih informacij.

Vpra코anja za raziskovanje tukaj so:
 * Ali so uporabnikovi (osebni) podatki za코캜iteni pred vdori in uhajanjem?
 * Ali so uporabnikovi podatki dostopni le poobla코캜enim uporabnikom in kontekstom?
 * Ali je uporabnikova anonimnost ohranjena, ko so podatki deljeni ali raz코irjeni?
 * Ali je mogo캜e uporabnika de-identificirati iz anonimiziranih naborov podatkov?

#### 2.5 Pravica do pozabe

[Pravica do pozabe](https://en.wikipedia.org/wiki/Right_to_be_forgotten) ali [pravica do izbrisa](https://www.gdpreu.org/right-to-be-forgotten/) zagotavlja dodatno za코캜ito osebnih podatkov uporabnikom. Konkretno, daje uporabnikom pravico zahtevati izbris ali odstranitev osebnih podatkov iz internetnih iskanj in drugih lokacij, _pod dolo캜enimi pogoji_ - kar jim omogo캜a nov za캜etek na spletu brez preteklih dejanj, ki bi jih bremenila.

Vpra코anja za raziskovanje tukaj so:
 * Ali sistem omogo캜a podatkovnim subjektom zahtevo za izbris?
 * Ali bi morala umaknitev uporabni코kega soglasja spro쬴ti avtomatiziran izbris?
 * Ali so bili podatki zbrani brez soglasja ali na nezakonit na캜in?
 * Ali smo skladni z vladnimi regulacijami za zasebnost podatkov?

#### 2.6 Pristranskost nabora podatkov

Pristranskost nabora podatkov ali [pristranskost zbiranja](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) se nana코a na izbiro _nereprezentativnega_ podnabora podatkov za razvoj algoritmov, kar lahko povzro캜i potencialno nepravi캜nost v rezultatih za raznolike skupine. Vrste pristranskosti vklju캜ujejo pristranskost izbire ali vzor캜enja, pristranskost prostovoljcev in pristranskost instrumentov.

Vpra코anja za raziskovanje tukaj so:
 * Ali smo pridobili reprezentativen nabor podatkovnih subjektov?
 * Ali smo testirali na코 zbrani ali kurirani nabor podatkov za razli캜ne pristranskosti?
 * Ali lahko ubla쬴mo ali odstranimo odkrite pristranskosti?

#### 2.7 Kakovost podatkov

[Kakovost podatkov](https://lakefs.io/data-quality-testing/) preverja veljavnost kuriranega nabora podatkov, uporabljenega za razvoj na코ih algoritmov, preverja, ali zna캜ilnosti in zapisi izpolnjujejo zahteve za raven natan캜nosti in doslednosti, ki je potrebna za na코 AI namen.

Vpra코anja za raziskovanje tukaj so:
 * Ali smo zajeli veljavne _zna캜ilnosti_ za na코 primer uporabe?
 * Ali so bili podatki zajeti _dosledno_ iz raznolikih virov podatkov?
 * Ali je nabor podatkov _popoln_ za raznolike pogoje ali scenarije?
 * Ali so informacije zajete _natan캜no_
[Algorithm Fairness](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) preverja, ali zasnova algoritma sistemati캜no diskriminira dolo캜ene podskupine podatkovnih subjektov, kar lahko vodi do [potencialnih 코kod](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) pri _dodeljevanju_ (kjer so sredstva zavrnjena ali zadr쬬na za to skupino) in _kakovosti storitev_ (kjer AI ni tako natan캜en za nekatere podskupine kot za druge).

Vpra코anja, ki jih je treba raziskati:
 * Ali smo ocenili natan캜nost modela za razli캜ne podskupine in pogoje?
 * Ali smo sistem preverili glede potencialnih 코kod (npr. stereotipiziranje)?
 * Ali lahko spremenimo podatke ali ponovno usposobimo modele za zmanj코anje ugotovljenih 코kod?

Raziskujte vire, kot so [AI Fairness checklists](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA), da izveste ve캜.

#### 2.9 Napa캜na predstavitev

[Napa캜na predstavitev podatkov](https://www.sciencedirect.com/topics/computer-science/misrepresentation) se nana코a na vpra코anje, ali sporo캜amo vpoglede iz po코teno poro캜anih podatkov na zavajajo캜 na캜in, da podpiramo 쬰leno pripoved.

Vpra코anja, ki jih je treba raziskati:
 * Ali poro캜amo o nepopolnih ali neto캜nih podatkih?
 * Ali vizualiziramo podatke na na캜in, ki vodi do zavajajo캜ih zaklju캜kov?
 * Ali uporabljamo selektivne statisti캜ne tehnike za manipulacijo rezultatov?
 * Ali obstajajo alternativne razlage, ki bi lahko ponudile druga캜en zaklju캜ek?

#### 2.10 Svobodna izbira
[Iluzija svobodne izbire](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) se pojavi, ko "arhitekture izbire" sistema uporabljajo algoritme za sprejemanje odlo캜itev, da ljudi usmerijo k 쬰lenemu izidu, medtem ko jim dajejo ob캜utek mo쬹osti in nadzora. Ti [temni vzorci](https://www.darkpatterns.org/) lahko povzro캜ijo socialno in ekonomsko 코kodo uporabnikom. Ker odlo캜itve uporabnikov vplivajo na vedenjske profile, lahko te akcije potencialno poganjajo prihodnje izbire, ki lahko okrepijo ali podalj코ajo vpliv teh 코kod.

Vpra코anja, ki jih je treba raziskati:
 * Ali je uporabnik razumel posledice sprejemanja te izbire?
 * Ali je bil uporabnik seznanjen z (alternativnimi) izbirami in prednostmi ter slabostmi vsake?
 * Ali lahko uporabnik kasneje razveljavi avtomatizirano ali vplivano izbiro?

### 3. 맚udije primerov

Da bi te eti캜ne izzive postavili v kontekst resni캜nega sveta, je koristno pogledati 코tudije primerov, ki poudarjajo potencialne 코kode in posledice za posameznike in dru쬭o, kadar se tak코ne kr코itve etike prezrejo.

Tukaj je nekaj primerov:

| Eti캜ni izziv | 맚udija primera | 
|--- |--- |
| **Informirano soglasje** | 1972 - [맚udija sifilisa Tuskegee](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - Afroameri코kim mo코kim, ki so sodelovali v 코tudiji, so obljubili brezpla캜no zdravstveno oskrbo, _vendar so jih raziskovalci zavajali_, saj jim niso povedali za diagnozo ali razpolo쬷jivost zdravljenja. Veliko udele쬰ncev je umrlo, prizadeti pa so bili tudi partnerji in otroci; 코tudija je trajala 40 let. | 
| **Zasebnost podatkov** | 2007 - [Netflixova nagrada za podatke](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) je raziskovalcem zagotovila _10M anonimiziranih ocen filmov od 50K strank_, da bi izbolj코ali algoritme priporo캜anja. Vendar so raziskovalci uspeli povezati anonimizirane podatke z osebnimi podatki v _zunanjih zbirkah podatkov_ (npr. komentarji na IMDb) - u캜inkovito "deanonimizirali" nekatere naro캜nike Netflixa.|
| **Pristranskost pri zbiranju podatkov** | 2013 - Mesto Boston je [razvilo Street Bump](https://www.boston.gov/transportation/street-bump), aplikacijo, ki je dr쬬vljanom omogo캜ila prijavo lukenj na cestah, kar je mestu zagotovilo bolj코e podatke o cestah za odpravljanje te쬬v. Vendar pa [ljudje z ni쬵imi dohodki niso imeli enakega dostopa do avtomobilov in telefonov](https://hbr.org/2013/04/the-hidden-biases-in-big-data), zaradi 캜esar so bile njihove te쬬ve na cestah nevidne v tej aplikaciji. Razvijalci so sodelovali z akademiki pri re코evanju vpra코anj _enakopravnega dostopa in digitalnih vrzeli_ za pravi캜nost. |
| **Pravi캜nost algoritmov** | 2018 - MIT [Gender Shades Study](http://gendershades.org/overview.html) je ocenila natan캜nost AI produktov za klasifikacijo spola, razkrivajo캜 vrzeli v natan캜nosti za 쬰nske in osebe barve. [Apple Card iz leta 2019](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) je o캜itno ponujala manj kreditov 쬰nskam kot mo코kim. Obe 코tudiji sta pokazali te쬬ve pristranskosti algoritmov, ki vodijo do socio-ekonomskih 코kod.|
| **Napa캜na predstavitev podatkov** | 2020 - [Oddelek za javno zdravje Georgie je objavil COVID-19 grafe](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening), ki so zavajali dr쬬vljane glede trendov potrjenih primerov z ne-kronolo코kim razvr코캜anjem na x-osi. To ponazarja napa캜no predstavitev s triki vizualizacije. |
| **Iluzija svobodne izbire** | 2020 - U캜na aplikacija [ABCmouse je pla캜ala 10M za poravnavo prito쬭e FTC](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/), kjer so bili star코i ujeti v pla캜evanje naro캜nin, ki jih niso mogli preklicati. To ponazarja temne vzorce v arhitekturah izbire, kjer so bili uporabniki usmerjeni k potencialno 코kodljivim odlo캜itvam. |
| **Zasebnost podatkov in pravice uporabnikov** | 2021 - Facebook [kr코itev podatkov](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) je razkrila podatke 530M uporabnikov, kar je privedlo do poravnave v vi코ini 5B z FTC. Vendar pa ni obvestil uporabnikov o kr코itvi, kar je kr코ilo pravice uporabnikov glede transparentnosti podatkov in dostopa. |

콯elite raziskati ve캜 코tudij primerov? Oglejte si te vire:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - eti캜ne dileme v razli캜nih industrijah. 
* [Te캜aj o etiki podatkovne znanosti](https://www.coursera.org/learn/data-science-ethics#syllabus) - raziskane klju캜ne 코tudije primerov.
* [Kje so stvari 코le narobe](https://deon.drivendata.org/examples/) - kontrolni seznam Deon z primeri.

> 游뚿 Razmislite o 코tudijah primerov, ki ste jih videli - ali ste do쬴veli ali bili prizadeti zaradi podobnega eti캜nega izziva v svojem 쬴vljenju? Ali lahko pomislite na vsaj eno drugo 코tudijo primera, ki ponazarja enega od eti캜nih izzivov, o katerih smo razpravljali v tem razdelku?

## Uporabna etika

Pogovarjali smo se o konceptih etike, izzivih in 코tudijah primerov v kontekstih resni캜nega sveta. Toda kako za캜eti _uporabljati_ eti캜na na캜ela in prakse v svojih projektih? In kako _operacionalizirati_ te prakse za bolj코e upravljanje? Raziskujmo nekaj re코itev iz resni캜nega sveta:

### 1. Profesionalni kodeksi

Profesionalni kodeksi ponujajo eno mo쬹ost za organizacije, da "spodbujajo" 캜lane k podpori njihovih eti캜nih na캜el in poslanstva. Kodeksi so _moralne smernice_ za profesionalno vedenje, ki pomagajo zaposlenim ali 캜lanom sprejemati odlo캜itve, ki so skladne z na캜eli njihove organizacije. Njihova u캜inkovitost je odvisna od prostovoljne skladnosti 캜lanov; vendar pa mnoge organizacije ponujajo dodatne nagrade in kazni za motivacijo skladnosti 캜lanov.

Primeri vklju캜ujejo:

 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Kodeks etike
 * [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Kodeks ravnanja (ustvarjen leta 2013)
 * [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (od leta 1993)

> 游뚿 Ali pripadate profesionalni in쬰nirski ali podatkovno-znanstveni organizaciji? Raziskujte njihovo spletno stran, da vidite, ali definirajo profesionalni kodeks etike. Kaj to pove o njihovih eti캜nih na캜elih? Kako "spodbujajo" 캜lane k upo코tevanju kodeksa?

### 2. Eti캜ni kontrolni seznami

Medtem ko profesionalni kodeksi definirajo zahtevano _eti캜no vedenje_ od praktikov, imajo [znane omejitve](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) pri izvajanju, zlasti pri velikih projektih. Namesto tega mnogi strokovnjaki za podatkovno znanost [zagovarjajo kontrolne sezname](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), ki lahko **pove쬰jo na캜ela s praksami** na bolj deterministi캜en in izvedljiv na캜in.

Kontrolni seznami pretvorijo vpra코anja v "da/ne" naloge, ki jih je mogo캜e operacionalizirati, kar omogo캜a njihovo sledenje kot del standardnih delovnih tokov za izdajo izdelkov.

Primeri vklju캜ujejo:
 * [Deon](https://deon.drivendata.org/) - splo코ni kontrolni seznam etike podatkov, ustvarjen iz [priporo캜il industrije](https://deon.drivendata.org/#checklist-citations) z orodjem ukazne vrstice za enostavno integracijo.
 * [Kontrolni seznam za revizijo zasebnosti](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - zagotavlja splo코ne smernice za ravnanje z informacijami z vidika pravne in socialne izpostavljenosti.
 * [Kontrolni seznam pravi캜nosti AI](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - ustvarjen s strani AI praktikov za podporo sprejemanju in integraciji preverjanj pravi캜nosti v razvojne cikle AI.
 * [22 vpra코anj za etiko v podatkih in AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - bolj odprt okvir, strukturiran za za캜etno raziskovanje eti캜nih vpra코anj v oblikovanju, izvajanju in organizacijskih kontekstih.

### 3. Etika in regulacije

Etika je o definiranju skupnih vrednot in prostovoljnem ravnanju _pravilno_. **Skladnost** je o _upo코tevanju zakonov_, 캜e in kjer so opredeljeni. **Upravljanje** na splo코no zajema vse na캜ine, kako organizacije delujejo za uveljavljanje eti캜nih na캜el in skladnost z uveljavljenimi zakoni.

Danes upravljanje poteka v dveh oblikah znotraj organizacij. Prvi캜, gre za definiranje **eti캜nih AI** na캜el in vzpostavitev praks za operacionalizacijo sprejemanja v vseh projektih, povezanih z AI, v organizaciji. Drugi캜, gre za skladnost z vsemi vladno dolo캜enimi **regulacijami za코캜ite podatkov** za regije, v katerih deluje.

Primeri regulacij za코캜ite podatkov in zasebnosti:

 * `1974`, [Zakon o zasebnosti ZDA](https://www.justice.gov/opcl/privacy-act-1974) - ureja _zbiranje, uporabo in razkritje osebnih podatkov_ s strani zvezne vlade.
 * `1996`, [Zakon o prenosljivosti in odgovornosti zdravstvenega zavarovanja ZDA (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - 코캜iti osebne zdravstvene podatke.
 * `1998`, [Zakon o zasebnosti otrok na spletu ZDA (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - 코캜iti zasebnost podatkov otrok, mlaj코ih od 13 let.
 * `2018`, [Splo코na uredba o varstvu podatkov (GDPR)](https://gdpr-info.eu/) - zagotavlja pravice uporabnikov, za코캜ito podatkov in zasebnost.
 * `2018`, [Kalifornijski zakon o zasebnosti potro코nikov (CCPA)](https://www.oag.ca.gov/privacy/ccpa) daje potro코nikom ve캜 _pravic_ nad njihovimi (osebnimi) podatki.
 * `2021`, Kitajska [Zakon o za코캜iti osebnih podatkov](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) je pravkar sprejet, kar ustvarja eno najmo캜nej코ih regulacij zasebnosti podatkov na spletu na svetu.

> 游뚿 Evropska unija je definirala GDPR (Splo코na uredba o varstvu podatkov), ki ostaja ena najvplivnej코ih regulacij zasebnosti podatkov danes. Ali ste vedeli, da definira tudi [8 pravic uporabnikov](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) za za코캜ito digitalne zasebnosti in osebnih podatkov dr쬬vljanov? Nau캜ite se, kaj so te pravice in zakaj so pomembne.

### 4. Kultura etike

Upo코tevajte, da ostaja neoprijemljiva vrzel med _skladnostjo_ (narediti dovolj, da izpolnimo "캜rko zakona") in obravnavanjem [sistemskih vpra코anj](https://www.coursera.org/learn/data-science-ethics/home/week/4) (kot so okostenelost, asimetrija informacij in distribucijska nepravi캜nost), ki lahko pospe코ijo oro쬴tev AI.

Za slednje so potrebni [sodelovalni pristopi k definiranju kultur etike](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f), ki gradijo 캜ustvene povezave in dosledne skupne vrednote _med organizacijami_ v industriji. To zahteva bolj [formalizirane kulture etike podatkov](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) v organizacijah - omogo캜anje _komurkoli_, da [potegne Andon vrv](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (za zgodnje opozarjanje na eti캜ne pomisleke) in postavljanje _eti캜nih ocen_ (npr. pri zaposlovanju) kot klju캜nega kriterija za oblikovanje ekip v AI projektih.

---
## [Kvizi po predavanju](https://ff-quizzes.netlify.app/en/ds/) 游꿢
## Pregled in samostojno u캜enje

Te캜aji in knjige pomagajo pri razumevanju osnovnih konceptov etike in izzivov, medtem ko 코tudije primerov in orodja pomagajo pri uporabi eti캜nih praks v kontekstih resni캜nega sveta. Tukaj je nekaj virov za za캜etek.

* [Strojno u캜enje za za캜etnike](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - lekcija o pravi캜nosti, Microsoft.
* [Na캜ela odgovorne umetne inteligence](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - brezpla캜na u캜na pot na Microsoft Learn.
* [Etika in podatkovna znanost](https://resources.oreilly.com/examples/0636920203964) - O'Reilly EBook (M. Loukides, H. Mason in drugi)
* [Etika podatkovne znanosti](https://www.coursera.org/learn/data-science-ethics#syllabus) - spletni te캜aj Univerze v Michiganu.
* [Etika razkrita](https://ethicsunwrapped.utexas.edu/case-studies) - 코tudije primerov Univerze v Teksasu.

# Naloga

[Napi코ite 코tudijo primera o etiki podatkov](assignment.md)

---

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). 캛eprav si prizadevamo za natan캜nost, vas prosimo, da upo코tevate, da lahko avtomatizirani prevodi vsebujejo napake ali neto캜nosti. Izvirni dokument v njegovem maternem jeziku je treba obravnavati kot avtoritativni vir. Za klju캜ne informacije priporo캜amo profesionalni 캜love코ki prevod. Ne prevzemamo odgovornosti za morebitna nesporazume ali napa캜ne razlage, ki bi nastale zaradi uporabe tega prevoda.