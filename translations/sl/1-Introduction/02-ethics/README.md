<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "58860ce9a4b8a564003d2752f7c72851",
  "translation_date": "2025-10-03T17:04:57+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "sl"
}
-->
# Uvod v podatkovno etiko

|![ Sketchnote avtorja [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Etika podatkovne znanosti - _Sketchnote avtorja [@nitya](https://twitter.com/nitya)_ |

---

Vsi smo podatkovni drÅ¾avljani, ki Å¾ivimo v svetu, preÅ¾etem s podatki.

TrÅ¾ni trendi kaÅ¾ejo, da bo do leta 2022 ena od treh velikih organizacij kupovala in prodajala svoje podatke prek spletnih [trÅ¾nic in izmenjav](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Kot **razvijalci aplikacij** bomo laÅ¾je in ceneje vkljuÄili vpoglede, ki temeljijo na podatkih, ter avtomatizacijo, ki jo poganjajo algoritmi, v vsakodnevne uporabniÅ¡ke izkuÅ¡nje. Toda z naraÅ¡ÄajoÄo prisotnostjo umetne inteligence bomo morali razumeti tudi potencialne Å¡kodljive uÄinke [uporabe algoritmov v Å¡kodljive namene](https://www.youtube.com/watch?v=TQHs8SA1qpk) v velikem obsegu.

Trend kaÅ¾e, da bomo do leta 2025 ustvarili in porabili veÄ kot [180 zettabajtov](https://www.statista.com/statistics/871513/worldwide-data-created/) podatkov. Za **podatkovne znanstvenike** ta eksplozija informacij ponuja neprimerljiv dostop do osebnih in vedenjskih podatkov. S tem prihaja moÄ za gradnjo podrobnih uporabniÅ¡kih profilov in subtilno vplivanje na odloÄanjeâ€”pogosto na naÄin, ki ustvarja [iluzijo svobodne izbire](https://www.datasciencecentral.com/the-pareto-set-and-the-paradox-of-choice/). ÄŒeprav to lahko uporabimo za usmerjanje uporabnikov k Å¾elenim rezultatom, pa odpira tudi kljuÄna vpraÅ¡anja o zasebnosti podatkov, avtonomiji in etiÄnih mejah algoritmiÄnega vpliva.

Podatkovna etika je zdaj _nujna varovalka_ za podatkovno znanost in inÅ¾eniring, ki nam pomaga zmanjÅ¡ati potencialne Å¡kodljive uÄinke in nenamerne posledice naÅ¡ih dejanj, ki temeljijo na podatkih. [Gartnerjev Hype Cycle za AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) identificira pomembne trende v digitalni etiki, odgovorni AI in upravljanju AI kot kljuÄne gonilnike veÄjih megatrendov okoli _demokratizacije_ in _industrializacije_ umetne inteligence.

![Gartnerjev Hype Cycle za AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

V tej lekciji bomo raziskali fascinantno podroÄje podatkovne etikeâ€”od osnovnih konceptov in izzivov do Å¡tudij primerov in uporabljenih konceptov AI, kot je upravljanjeâ€”ki pomagajo vzpostaviti kulturo etike v ekipah in organizacijah, ki delajo s podatki in umetno inteligenco.




## [Predhodni kviz](https://ff-quizzes.netlify.app/en/ds/quiz/2) ğŸ¯

## Osnovne definicije

ZaÄnimo z razumevanjem osnovne terminologije.

Beseda "etika" izhaja iz [grÅ¡ke besede "ethikos"](https://en.wikipedia.org/wiki/Ethics) (in njenega korena "ethos"), ki pomeni _znaÄaj ali moralna narava_. 

**Etika** se nanaÅ¡a na skupne vrednote in moralna naÄela, ki usmerjajo naÅ¡e vedenje v druÅ¾bi. Etika ne temelji na zakonih, temveÄ na sploÅ¡no sprejetih normah, kaj je "prav vs. narobe". Vendar pa lahko etiÄne premisleke vplivajo na pobude korporativnega upravljanja in vladne regulacije, ki ustvarjajo veÄ spodbud za skladnost.

**Podatkovna etika** je [nova veja etike](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1), ki "preuÄuje in ocenjuje moralne probleme, povezane s _podatki, algoritmi in ustreznimi praksami_". Tukaj se **"podatki"** osredotoÄajo na dejanja, povezana z ustvarjanjem, beleÅ¾enjem, kuriranjem, obdelavo, razÅ¡irjanjem, deljenjem in uporabo, **"algoritmi"** osredotoÄajo na AI, agente, strojno uÄenje in robote, ter **"prakse"** osredotoÄajo na teme, kot so odgovorne inovacije, programiranje, hekanje in kodeks etike.

**Uporabljena etika** je [praktiÄna uporaba moralnih premislekov](https://en.wikipedia.org/wiki/Applied_ethics). Gre za proces aktivnega raziskovanja etiÄnih vpraÅ¡anj v kontekstu _dejanskih dejanj, izdelkov in procesov_ ter sprejemanja korektivnih ukrepov, da ostanejo skladni z naÅ¡imi opredeljenimi etiÄnimi vrednotami.

**Kultura etike** se nanaÅ¡a na [_operacionalizacijo_ uporabljene etike](https://hbr.org/2019/05/how-to-design-an-ethical-organization), da zagotovimo, da so naÅ¡a etiÄna naÄela in prakse dosledno in razÅ¡irljivo sprejeta po celotni organizaciji. UspeÅ¡ne kulture etike opredelijo organizacijsko Å¡iroka etiÄna naÄela, zagotavljajo smiselne spodbude za skladnost ter krepijo norme etike z vzpodbujanjem in amplifikacijo Å¾elenih vedenj na vseh ravneh organizacije.


## Koncepti etike

V tem razdelku bomo obravnavali koncepte, kot so **skupne vrednote** (naÄela) in **etiÄni izzivi** (problemi) za podatkovno etikoâ€”ter raziskali **Å¡tudije primerov**, ki vam pomagajo razumeti te koncepte v realnih kontekstih.

### 1. NaÄela etike

Vsaka strategija podatkovne etike se zaÄne z opredelitvijo _etiÄnih naÄel_â€”"skupnih vrednot", ki opisujejo sprejemljiva vedenja in usmerjajo skladna dejanja v naÅ¡ih projektih, povezanih s podatki in umetno inteligenco. Ta lahko opredelite na individualni ali skupinski ravni. Vendar pa veÄina velikih organizacij te opredeli v _etiÄnem AI_ misijskem izjavi ali okviru, ki je opredeljen na korporativni ravni in dosledno uveljavljen v vseh ekipah.

**Primer:** Microsoftova [Odgovorna AI](https://www.microsoft.com/en-us/ai/responsible-ai) misijska izjava se glasi: _"Zavezani smo k napredku AI, ki ga vodijo etiÄna naÄela, ki postavljajo ljudi na prvo mesto"_â€”opredeljuje 6 etiÄnih naÄel v spodnjem okviru:

![Odgovorna AI pri Microsoftu](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

Na kratko raziÅ¡Äimo ta naÄela. _Transparentnost_ in _odgovornost_ sta temeljni vrednoti, na katerih so zgrajena druga naÄelaâ€”zaÄnimo torej tukaj:

* [**Odgovornost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) zahteva, da so praktiki _odgovorni_ za svoje podatkovne in AI operacije ter skladnost s temi etiÄnimi naÄeli.
* [**Transparentnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) zagotavlja, da so dejanja, povezana s podatki in AI, _razumljiva_ (interpretabilna) za uporabnike, pojasnjujoÄ kaj in zakaj za odloÄitvami.
* [**PraviÄnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) se osredotoÄa na zagotavljanje, da AI obravnava _vse ljudi_ praviÄno, obravnavajoÄ sistemske ali implicitne socio-tehniÄne pristranskosti v podatkih in sistemih.
* [**Zanesljivost in varnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) zagotavlja, da AI deluje _dosledno_ z opredeljenimi vrednotami, zmanjÅ¡uje potencialne Å¡kodljive uÄinke ali nenamerne posledice.
* [**Zasebnost in varnost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) se nanaÅ¡a na razumevanje izvora podatkov ter zagotavljanje _zasebnosti podatkov in povezanih zaÅ¡Äit_ za uporabnike.
* [**VkljuÄenost**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) se nanaÅ¡a na naÄrtovanje AI reÅ¡itev z namenom, prilagajanje za izpolnjevanje _Å¡irokega spektra ÄloveÅ¡kih potreb_ in sposobnosti.

> ğŸš¨ Razmislite, kaj bi lahko bila vaÅ¡a misijska izjava o podatkovni etiki. RaziÅ¡Äite etiÄne AI okvire drugih organizacijâ€”tukaj so primeri iz [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles) in [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Katere skupne vrednote imajo? Kako se ta naÄela nanaÅ¡ajo na AI izdelke ali industrijo, v kateri delujejo?

### 2. EtiÄni izzivi

Ko imamo opredeljena etiÄna naÄela, je naslednji korak oceniti naÅ¡a dejanja, povezana s podatki in AI, da vidimo, ali so skladna s temi skupnimi vrednotami. Razmislite o svojih dejanjih v dveh kategorijah: _zbiranje podatkov_ in _oblikovanje algoritmov_. 

Pri zbiranju podatkov bodo dejanja verjetno vkljuÄevala **osebne podatke** ali osebno prepoznavne informacije (PII) za prepoznavanje Å¾ivih posameznikov. To vkljuÄuje [razliÄne vrste neosebnih podatkov](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en), ki _skupno_ identificirajo posameznika. EtiÄni izzivi se lahko nanaÅ¡ajo na _zasebnost podatkov_, _lastniÅ¡tvo podatkov_ in povezana vpraÅ¡anja, kot so _informirano soglasje_ ter _pravice intelektualne lastnine_ za uporabnike.

Pri oblikovanju algoritmov bodo dejanja vkljuÄevala zbiranje in kuriranje **naborov podatkov**, nato pa njihovo uporabo za treniranje in implementacijo **modelov podatkov**, ki napovedujejo rezultate ali avtomatizirajo odloÄitve v realnih kontekstih. EtiÄni izzivi se lahko pojavijo zaradi _pristranskosti nabora podatkov_, _teÅ¾av s kakovostjo podatkov_, _nepraviÄnosti_ in _napaÄne predstavitve_ v algoritmihâ€”vkljuÄno z nekaterimi sistemskimi vpraÅ¡anji.

V obeh primerih etiÄni izzivi izpostavljajo podroÄja, kjer lahko naÅ¡a dejanja naletijo na konflikt s skupnimi vrednotami. Za zaznavanje, ublaÅ¾itev, zmanjÅ¡anje ali odpravo teh skrbi moramo postavljati moralna "da/ne" vpraÅ¡anja, povezana z naÅ¡imi dejanji, nato pa po potrebi sprejeti korektivne ukrepe. Poglejmo si nekaj etiÄnih izzivov in moralna vpraÅ¡anja, ki jih sproÅ¾ajo:


#### 2.1 LastniÅ¡tvo podatkov

Zbiranje podatkov pogosto vkljuÄuje osebne podatke, ki lahko identificirajo podatkovne subjekte. [LastniÅ¡tvo podatkov](https://permission.io/blog/data-ownership) se nanaÅ¡a na _nadzor_ in [_pravice uporabnikov_](https://permission.io/blog/data-ownership), povezane z ustvarjanjem, obdelavo in razÅ¡irjanjem podatkov. 

Moralna vpraÅ¡anja, ki jih moramo zastaviti, so: 
 * Kdo je lastnik podatkov? (uporabnik ali organizacija)
 * Katere pravice imajo podatkovni subjekti? (npr. dostop, izbris, prenosljivost)
 * Katere pravice imajo organizacije? (npr. popravljanje zlonamernih uporabniÅ¡kih ocen)

#### 2.2 Informirano soglasje

[Informirano soglasje](https://legaldictionary.net/informed-consent/) opredeljuje dejanje, ko uporabniki privolijo v dejanje (kot je zbiranje podatkov) z _polnim razumevanjem_ relevantnih dejstev, vkljuÄno z namenom, potencialnimi tveganji in alternativami. 

VpraÅ¡anja, ki jih je treba raziskati, so:
 * Ali je uporabnik (podatkovni subjekt) dal dovoljenje za zajemanje in uporabo podatkov?
 * Ali je uporabnik razumel namen, za katerega so bili podatki zajeti?
 * Ali je uporabnik razumel potencialna tveganja zaradi svoje udeleÅ¾be?

#### 2.3 Intelektualna lastnina

[Intelektualna lastnina](https://en.wikipedia.org/wiki/Intellectual_property) se nanaÅ¡a na nematerialne stvaritve, ki izhajajo iz ÄloveÅ¡ke pobude in lahko _imajo ekonomsko vrednost_ za posameznike ali podjetja. 

VpraÅ¡anja, ki jih je treba raziskati, so:
 * Ali imajo zbrani podatki ekonomsko vrednost za uporabnika ali podjetje?
 * Ali ima **uporabnik** tukaj intelektualno lastnino?
 * Ali ima **organizacija** tukaj intelektualno lastnino?
 * ÄŒe te pravice obstajajo, kako jih Å¡Äitimo?

#### 2.4 Zasebnost podatkov

[Zasebnost podatkov](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) ali informacijska zasebnost se nanaÅ¡a na ohranjanje zasebnosti uporabnikov in zaÅ¡Äito identitete uporabnikov glede osebno prepoznavnih informacij. 

VpraÅ¡anja, ki jih je treba raziskati, so:
 * Ali so uporabnikovi (osebni) podatki zaÅ¡Äiteni pred vdori in uhajanjem?
 * Ali so uporabnikovi podatki dostopni le pooblaÅ¡Äenim uporabnikom in kontekstom?
 * Ali je uporabnikova anonimnost ohranjena, ko so podatki deljeni ali razÅ¡irjeni?
 * Ali je mogoÄe uporabnika de-identificirati iz anonimiziranih naborov podatkov?


#### 2.5 Pravica do pozabe

[Pravica do pozabe](https://en.wikipedia.org/wiki/Right_to_be_forgotten) ali [pravica do izbrisa](https://www.gdpreu.org/right-to-be-forgotten/) zagotavlja dodatno zaÅ¡Äito osebnih podatkov uporabnikom. Konkretno, daje uporabnikom pravico zahtevati izbris ali odstranitev osebnih podatkov iz internetnih iskanj in drugih lokacij, _pod doloÄenimi pogoji_â€”kar jim omogoÄa nov zaÄetek na spletu brez preteklih dejanj, ki bi jih bremenila.

VpraÅ¡anja, ki jih je treba raziskati, so:
 * Ali sistem omogoÄa podatkovnim subjektom zahtevo za izbris?
 * Ali bi morala umaknitev uporabniÅ¡kega soglasja sproÅ¾iti avtomatiziran izbris?
 * Ali so bili podatki zbrani brez soglasja ali na nezakonit naÄin?
 * Ali smo skladni z vladnimi regulacijami za zasebnost podatkov?


#### 2.6 Pristranskost nabora podatkov

Nabor podatkov ali [pristranskost zbiranja](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) se nanaÅ¡a na izbiro _nereprezentativnega_ podnabora podatkov za razvoj algoritmov, kar ustvarja potencialno nepraviÄnost v rezultatih za razliÄne skupine. Vrste pristranskosti vkljuÄujejo pristranskost izbire ali vzorÄenja, pristranskost prostovoljcev in pristranskost instrumentov. 

VpraÅ¡anja, ki jih je treba raziskati, so:
 * Ali smo pridobili reprezentativen nabor podatkovnih subjektov?
 * Ali smo testirali naÅ¡ zbrani ali kurirani nabor podatkov za razliÄne pristranskosti?
 * Ali lahko ublaÅ¾imo ali odstranimo odkrite pristranskosti?

#### 2.7 Kakovost podatkov

[Kakovost podatkov](https://lakefs.io/data-quality-testing/) preuÄuje veljavnost kuriranega nabora podatkov, uporabljenega za razvoj naÅ¡ih algoritmov, preverja, ali znaÄilnosti in zapisi izpolnjujejo zahteve za raven natanÄnosti in doslednosti, ki je potrebna za naÅ¡ AI namen.

VpraÅ¡anja, ki jih je treba raziskati, so:
 * Ali smo zajeli veljavne _znaÄilnosti_ za naÅ¡ primer uporabe?
 * Ali so bili podatki zajeti _dosledno_ iz razliÄnih virov podatkov?
 * Ali je nabor podatkov _popoln_ za razliÄne pogoje ali scenar
* Ali so informacije zajete _natanÄno_ in odraÅ¾ajo resniÄnost?

#### 2.8 PraviÄnost algoritmov

[PraviÄnost algoritmov](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) preverja, ali zasnova algoritma sistematiÄno diskriminira doloÄene podskupine podatkovnih subjektov, kar vodi do [potencialnih Å¡kod](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) pri _dodeljevanju_ (kjer so sredstva zavrnjena ali zadrÅ¾ana za to skupino) in _kakovosti storitev_ (kjer AI ni tako natanÄen za nekatere podskupine kot za druge).

VpraÅ¡anja, ki jih je treba raziskati:
* Ali smo ocenili natanÄnost modela za razliÄne podskupine in pogoje?
* Ali smo podrobno preuÄili sistem glede potencialnih Å¡kod (npr. stereotipiziranje)?
* Ali lahko spremenimo podatke ali ponovno usposobimo modele za zmanjÅ¡anje ugotovljenih Å¡kod?

Raziskujte vire, kot so [kontrolni seznami za praviÄnost AI](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA), da izveste veÄ.

#### 2.9 NapaÄna predstavitev

[NapaÄna predstavitev podatkov](https://www.sciencedirect.com/topics/computer-science/misrepresentation) se nanaÅ¡a na vpraÅ¡anje, ali sporoÄamo vpoglede iz poÅ¡teno poroÄanih podatkov na zavajajoÄ naÄin, da podpiramo Å¾eleno pripoved.

VpraÅ¡anja, ki jih je treba raziskati:
* Ali poroÄamo o nepopolnih ali netoÄnih podatkih?
* Ali vizualiziramo podatke na naÄin, ki vodi do zavajajoÄih zakljuÄkov?
* Ali uporabljamo selektivne statistiÄne tehnike za manipulacijo rezultatov?
* Ali obstajajo alternativne razlage, ki bi lahko ponudile drugaÄen zakljuÄek?

#### 2.10 Svobodna izbira

[Iluzija svobodne izbire](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) se pojavi, ko "arhitekture izbire" sistema uporabljajo algoritme za sprejemanje odloÄitev, da ljudi usmerijo k Å¾elenemu izidu, medtem ko jim dajejo obÄutek, da imajo moÅ¾nosti in nadzor. Ti [temni vzorci](https://www.darkpatterns.org/) lahko povzroÄijo socialno in ekonomsko Å¡kodo uporabnikom. Ker odloÄitve uporabnikov vplivajo na vedenjske profile, te akcije potencialno usmerjajo prihodnje izbire, ki lahko okrepijo ali podaljÅ¡ajo vpliv teh Å¡kod.

VpraÅ¡anja, ki jih je treba raziskati:
* Ali je uporabnik razumel posledice sprejemanja te odloÄitve?
* Ali je bil uporabnik seznanjen z (alternativnimi) moÅ¾nostmi in prednostmi ter slabostmi vsake?
* Ali lahko uporabnik kasneje razveljavi avtomatizirano ali vplivano izbiro?

### 3. Å tudije primerov

Da bi te etiÄne izzive postavili v kontekst resniÄnega sveta, je koristno pogledati Å¡tudije primerov, ki poudarjajo potencialne Å¡kode in posledice za posameznike in druÅ¾bo, kadar se takÅ¡ne krÅ¡itve etike prezrejo.

Tukaj je nekaj primerov:

| EtiÄni izziv | Å tudija primera | 
|--- |--- |
| **Informirano soglasje** | 1972 - [Å tudija sifilisa v Tuskegeeju](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - AfroameriÅ¡kim moÅ¡kim, ki so sodelovali v Å¡tudiji, so obljubili brezplaÄno zdravstveno oskrbo, _vendar so jih raziskovalci zavajali_, saj jih niso obvestili o njihovi diagnozi ali o razpoloÅ¾ljivosti zdravljenja. Mnogi udeleÅ¾enci so umrli, partnerji in otroci pa so bili prizadeti; Å¡tudija je trajala 40 let. | 
| **Zasebnost podatkov** | 2007 - [Netflixova nagrada za podatke](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) je raziskovalcem zagotovila _10M anonimiziranih ocen filmov od 50K strank_, da bi izboljÅ¡ali algoritme priporoÄanja. Vendar so raziskovalci uspeli povezati anonimizirane podatke z osebnimi podatki v _zunanjih zbirkah podatkov_ (npr. komentarji na IMDb) - uÄinkovito "deanonimizirali" nekatere naroÄnike Netflixa.|
| **Pristranskost pri zbiranju podatkov** | 2013 - Mesto Boston je [razvilo Street Bump](https://www.boston.gov/transportation/street-bump), aplikacijo, ki je prebivalcem omogoÄila prijavo lukenj na cestah, kar je mestu zagotovilo boljÅ¡e podatke o cestah za iskanje in odpravljanje teÅ¾av. Vendar pa [ljudje v niÅ¾jih dohodkovnih skupinah niso imeli enakega dostopa do avtomobilov in telefonov](https://hbr.org/2013/04/the-hidden-biases-in-big-data), zaradi Äesar so njihove teÅ¾ave na cestah ostale nevidne v tej aplikaciji. Razvijalci so sodelovali z akademiki pri reÅ¡evanju vpraÅ¡anj _enakopravnega dostopa in digitalnih vrzeli_ za praviÄnost. |
| **PraviÄnost algoritmov** | 2018 - MIT [Å tudija Gender Shades](http://gendershades.org/overview.html) je ocenila natanÄnost AI produktov za klasifikacijo spola, razkrivajoÄ vrzeli v natanÄnosti za Å¾enske in osebe barve. [Apple Card iz leta 2019](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) je oÄitno ponujala manj kreditov Å¾enskam kot moÅ¡kim. Obe Å¡tudiji sta pokazali teÅ¾ave algoritmiÄne pristranskosti, ki vodijo do socio-ekonomskih Å¡kod.|
| **NapaÄna predstavitev podatkov** | 2020 - [Oddelek za javno zdravje Georgie je objavil COVID-19 grafe](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening), ki so zavajali drÅ¾avljane glede trendov potrjenih primerov z ne-kronoloÅ¡kim razvrÅ¡Äanjem na x-osi. To ponazarja napaÄno predstavitev skozi vizualizacijske trike. |
| **Iluzija svobodne izbire** | 2020 - UÄna aplikacija [ABCmouse je plaÄala 10M USD za poravnavo pritoÅ¾be FTC](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/), kjer so bili starÅ¡i ujeti v plaÄevanje naroÄnin, ki jih niso mogli preklicati. To ponazarja temne vzorce v arhitekturah izbire, kjer so bili uporabniki usmerjeni k potencialno Å¡kodljivim odloÄitvam. |
| **Zasebnost podatkov in pravice uporabnikov** | 2021 - Facebook [krÅ¡itev podatkov](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) je razkrila podatke 530M uporabnikov, kar je privedlo do poravnave v viÅ¡ini 5B USD z FTC. Vendar pa ni obvestil uporabnikov o krÅ¡itvi, kar je krÅ¡ilo pravice uporabnikov glede preglednosti podatkov in dostopa. |

Å½elite raziskati veÄ Å¡tudij primerov? Oglejte si te vire:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - etiÄne dileme v razliÄnih industrijah.
* [TeÄaj etike podatkovne znanosti](https://www.coursera.org/learn/data-science-ethics#syllabus) - raziskane kljuÄne Å¡tudije primerov.
* [Kje so stvari Å¡le narobe](https://deon.drivendata.org/examples/) - kontrolni seznam Deon z zgledi.

> ğŸš¨ Razmislite o Å¡tudijah primerov, ki ste jih videli - ali ste doÅ¾iveli ali bili prizadeti zaradi podobnega etiÄnega izziva v svojem Å¾ivljenju? Ali lahko pomislite na vsaj eno drugo Å¡tudijo primera, ki ponazarja enega od etiÄnih izzivov, o katerih smo razpravljali v tem razdelku?

## Uporabna etika

Govorili smo o konceptih etike, izzivih in Å¡tudijah primerov v kontekstih resniÄnega sveta. Toda kako zaÄeti _uporabljati_ etiÄna naÄela in prakse v naÅ¡ih projektih? In kako _operacionalizirati_ te prakse za boljÅ¡e upravljanje? Raziskujmo nekaj reÅ¡itev iz resniÄnega sveta:

### 1. Profesionalni kodeksi

Profesionalni kodeksi ponujajo eno moÅ¾nost za organizacije, da "spodbujajo" Älane k podpori njihovih etiÄnih naÄel in poslanstva. Kodeksi so _moralne smernice_ za profesionalno vedenje, ki pomagajo zaposlenim ali Älanom sprejemati odloÄitve, ki so skladne z naÄeli njihove organizacije. UÄinkovitost kodeksov je odvisna od prostovoljne skladnosti Älanov; vendar pa mnoge organizacije ponujajo dodatne nagrade in kazni za motivacijo skladnosti Älanov.

Primeri vkljuÄujejo:

* [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Kodeks etike
* [ZdruÅ¾enje podatkovne znanosti](http://datascienceassn.org/code-of-conduct.html) Kodeks ravnanja (ustvarjen leta 2013)
* [ACM Kodeks etike in profesionalnega ravnanja](https://www.acm.org/code-of-ethics) (od leta 1993)

> ğŸš¨ Ali pripadate profesionalni inÅ¾enirski ali podatkovno-znanstveni organizaciji? RaziÅ¡Äite njihovo spletno stran, da vidite, ali opredeljujejo profesionalni kodeks etike. Kaj to pove o njihovih etiÄnih naÄelih? Kako "spodbujajo" Älane k upoÅ¡tevanju kodeksa?

### 2. Etika kontrolni seznami

Medtem ko profesionalni kodeksi opredeljujejo zahtevano _etiÄno vedenje_ od praktikov, imajo [znane omejitve](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) pri uveljavljanju, zlasti pri velikih projektih. Namesto tega mnogi strokovnjaki za podatkovno znanost [zagovarjajo kontrolne sezname](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), ki lahko **poveÅ¾ejo naÄela s praksami** na bolj deterministiÄne in izvedljive naÄine.

Kontrolni seznami pretvorijo vpraÅ¡anja v naloge "da/ne", ki jih je mogoÄe operacionalizirati, kar omogoÄa njihovo sledenje kot del standardnih delovnih tokov za izdajo izdelkov.

Primeri vkljuÄujejo:
* [Deon](https://deon.drivendata.org/) - sploÅ¡ni kontrolni seznam etike podatkov, ustvarjen iz [priporoÄil industrije](https://deon.drivendata.org/#checklist-citations) z orodjem ukazne vrstice za enostavno integracijo.
* [Kontrolni seznam za revizijo zasebnosti](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - zagotavlja sploÅ¡ne smernice za prakse ravnanja z informacijami z vidika pravnih in socialnih izpostavljenosti.
* [Kontrolni seznam za praviÄnost AI](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - ustvarjen s strani AI praktikov za podporo sprejemanju in integraciji preverjanj praviÄnosti v razvojne cikle AI.
* [22 vpraÅ¡anj za etiko v podatkih in AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - bolj odprt okvir, strukturiran za zaÄetno raziskovanje etiÄnih vpraÅ¡anj v oblikovanju, implementaciji in organizacijskih kontekstih.

### 3. Etika in regulacije

Etika je o opredeljevanju skupnih vrednot in prostovoljnem ravnanju _pravilno_. **Skladnost** je o _upoÅ¡tevanju zakonov_, Äe in kjer so opredeljeni. **Upravljanje** na sploÅ¡no zajema vse naÄine, kako organizacije delujejo za uveljavljanje etiÄnih naÄel in skladnost z uveljavljenimi zakoni.

Danes upravljanje poteka v dveh oblikah znotraj organizacij. PrviÄ, gre za opredelitev **etiÄnih AI** naÄel in vzpostavitev praks za operacionalizacijo sprejemanja v vseh projektih, povezanih z AI, v organizaciji. DrugiÄ, gre za skladnost z vsemi vladno doloÄenimi **regulacijami varstva podatkov** za regije, v katerih deluje.

Primeri regulacij varstva podatkov in zasebnosti:

* `1974`, [Zakon o zasebnosti ZDA](https://www.justice.gov/opcl/privacy-act-1974) - ureja _zbiranje, uporabo in razkritje osebnih podatkov_ s strani zvezne vlade.
* `1996`, [Zakon o prenosljivosti in odgovornosti zdravstvenega zavarovanja ZDA (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - Å¡Äiti osebne zdravstvene podatke.
* `1998`, [Zakon o zasebnosti otrok na spletu ZDA (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - Å¡Äiti zasebnost podatkov otrok, mlajÅ¡ih od 13 let.
* `2018`, [SploÅ¡na uredba o varstvu podatkov (GDPR)](https://gdpr-info.eu/) - zagotavlja pravice uporabnikov, varstvo podatkov in zasebnost.
* `2018`, [Kalifornijski zakon o zasebnosti potroÅ¡nikov (CCPA)](https://www.oag.ca.gov/privacy/ccpa) daje potroÅ¡nikom veÄ _pravic_ nad njihovimi (osebnimi) podatki.
* `2021`, Kitajska [Zakon o varstvu osebnih podatkov](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) je bil pravkar sprejet, kar ustvarja eno najmoÄnejÅ¡ih regulacij zasebnosti podatkov na spletu po vsem svetu.

> ğŸš¨ Evropska unija je opredelila GDPR (SploÅ¡na uredba o varstvu podatkov), ki ostaja ena najbolj vplivnih regulacij zasebnosti podatkov danes. Ali ste vedeli, da opredeljuje tudi [8 pravic uporabnikov](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) za zaÅ¡Äito digitalne zasebnosti in osebnih podatkov drÅ¾avljanov? Spoznajte, kaj so te pravice in zakaj so pomembne.

### 4. Kultura etike

UpoÅ¡tevajte, da ostaja neoprijemljiva vrzel med _skladnostjo_ (narediti dovolj za izpolnjevanje "Ärke zakona") in obravnavanjem [sistemskih vpraÅ¡anj](https://www.coursera.org/learn/data-science-ethics/home/week/4) (kot so okostenelost, asimetrija informacij in distribucijska nepraviÄnost), ki lahko pospeÅ¡ijo oroÅ¾itev AI.

Slednje zahteva [sodelovalne pristope k opredeljevanju kultur etike](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f), ki gradijo Äustvene povezave in dosledne skupne vrednote _med organizacijami_ v industriji. To zahteva bolj [formalizirane kulture etike podatkov](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) v organizacijah - omogoÄanje _komurkoli_, da [potegne Andon vrv](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (za zgodnje opozarjanje na etiÄne pomisleke) in postavljanje _etiÄnih ocen_ (npr. pri zaposlovanju) kot kljuÄnega kriterija za oblikovanje ekip v AI projektih.

---
## [Kvizi po predavanju](https://ff-quizzes.netlify.app/en/ds/quiz/3) ğŸ¯
## Pregled in samostojno uÄenje

TeÄaji in knjige pomagajo pri razumevanju osnovnih konceptov etike in izzivov, medtem ko Å¡tudije primerov in orodja pomagajo pri uporabi etiÄnih praks v resniÄnih kontekstih. Tukaj je nekaj virov za zaÄetek.
* [Strojno uÄenje za zaÄetnike](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - lekcija o praviÄnosti, Microsoft.
* [NaÄela odgovorne umetne inteligence](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - brezplaÄna uÄna pot na Microsoft Learn.
* [Etika in podatkovna znanost](https://resources.oreilly.com/examples/0636920203964) - O'Reilly e-knjiga (M. Loukides, H. Mason idr.)
* [Etika podatkovne znanosti](https://www.coursera.org/learn/data-science-ethics#syllabus) - spletni teÄaj Univerze v Michiganu.
* [Razkrita etika](https://ethicsunwrapped.utexas.edu/case-studies) - Å¡tudije primerov Univerze v Teksasu.

# Naloga

[NapiÅ¡ite Å¡tudijo primera o etiki podatkov](assignment.md)

---

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). ÄŒeprav si prizadevamo za natanÄnost, vas prosimo, da upoÅ¡tevate, da lahko avtomatizirani prevodi vsebujejo napake ali netoÄnosti. Izvirni dokument v njegovem izvirnem jeziku je treba obravnavati kot avtoritativni vir. Za kljuÄne informacije priporoÄamo profesionalni ÄloveÅ¡ki prevod. Ne prevzemamo odgovornosti za morebitne nesporazume ali napaÄne razlage, ki bi nastale zaradi uporabe tega prevoda.