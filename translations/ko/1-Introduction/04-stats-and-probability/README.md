<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b706a07cfa87ba091cbb91e0aa775600",
  "translation_date": "2025-08-24T12:48:10+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "ko"
}
-->
# 통계와 확률에 대한 간략한 소개

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| 통계와 확률 - _스케치노트 by [@nitya](https://twitter.com/nitya)_ |

통계와 확률 이론은 데이터 과학에서 매우 중요한 수학의 두 가지 밀접한 분야입니다. 수학에 대한 깊은 지식 없이도 데이터를 다룰 수 있지만, 기본 개념을 어느 정도 알고 있는 것이 더 좋습니다. 여기서는 시작하는 데 도움이 되는 간단한 소개를 제공합니다.

[![Intro Video](../../../../1-Introduction/04-stats-and-probability/images/video-prob-and-stats.png)](https://youtu.be/Z5Zy85g4Yjw)

## [강의 전 퀴즈](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/6)

## 확률과 랜덤 변수

**확률**은 0과 1 사이의 숫자로, 특정 **사건**이 발생할 가능성을 나타냅니다. 이는 긍정적인 결과(사건으로 이어지는 결과)의 수를 모든 결과의 수로 나눈 값으로 정의됩니다. 모든 결과가 동일한 확률을 가진다고 가정할 때 말입니다. 예를 들어, 주사위를 굴릴 때 짝수가 나올 확률은 3/6 = 0.5입니다.

사건에 대해 이야기할 때 우리는 **랜덤 변수**를 사용합니다. 예를 들어, 주사위를 굴릴 때 나오는 숫자를 나타내는 랜덤 변수는 1에서 6까지의 값을 가집니다. 1에서 6까지의 숫자 집합은 **표본 공간**이라고 합니다. 우리는 랜덤 변수가 특정 값을 가질 확률에 대해 이야기할 수 있습니다. 예를 들어 P(X=3)=1/6입니다.

이전 예에서의 랜덤 변수는 **이산형**이라고 불리며, 이는 셀 수 있는 표본 공간을 가지며, 즉 나열할 수 있는 개별 값이 있다는 것을 의미합니다. 표본 공간이 실수의 범위 또는 전체 실수 집합인 경우도 있습니다. 이러한 변수는 **연속형**이라고 합니다. 좋은 예는 버스가 도착하는 시간입니다.

## 확률 분포

이산형 랜덤 변수의 경우, 각 사건의 확률을 함수 P(X)로 쉽게 설명할 수 있습니다. 표본 공간 *S*의 각 값 *s*에 대해 0에서 1 사이의 숫자를 제공하며, 모든 사건에 대해 P(X=s)의 값의 합은 1이 됩니다.

가장 잘 알려진 이산형 분포는 **균등 분포**로, N개의 요소로 이루어진 표본 공간에서 각 요소의 확률이 1/N로 동일합니다.

연속형 변수의 확률 분포를 설명하는 것은 더 어렵습니다. 값이 [a,b]와 같은 유한한 구간 또는 전체 실수 집합 ℝ에서 추출되는 경우를 생각해 보세요. 버스 도착 시간을 예로 들어보면, 실제로 특정 도착 시간 *t*에 버스가 정확히 그 시간에 도착할 확률은 0입니다!

> 이제 확률이 0인 사건도 발생하며, 매우 자주 발생한다는 것을 알게 되었습니다! 적어도 버스가 도착할 때마다요!

우리는 변수 값이 특정 구간에 속할 확률에 대해서만 이야기할 수 있습니다. 예를 들어 P(t<sub>1</sub>≤X<t<sub>2</sub>). 이 경우, 확률 분포는 **확률 밀도 함수** p(x)로 설명됩니다. 이는 다음과 같습니다:

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../1-Introduction/04-stats-and-probability/images/probability-density.png)

연속형 균등 분포는 유한한 구간에서 정의되며, 값 X가 길이 l의 구간에 속할 확률은 l에 비례하며 최대 1까지 증가합니다.

또 다른 중요한 분포는 **정규 분포**로, 아래에서 더 자세히 설명하겠습니다.

## 평균, 분산 및 표준 편차

랜덤 변수 X의 n개의 샘플 시퀀스를 추출한다고 가정해 봅시다: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. 시퀀스의 **평균**(또는 **산술 평균**) 값은 전통적인 방식으로 (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n으로 정의할 수 있습니다. 샘플 크기를 늘리면(즉, n→∞로 한계를 취하면), 분포의 평균(또는 **기대값**)을 얻을 수 있습니다. 기대값은 **E**(x)로 표시합니다.

> 모든 이산형 분포에서 값 {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>}와 해당 확률 p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>에 대해 기대값은 E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>와 같다는 것을 증명할 수 있습니다.

값이 얼마나 퍼져 있는지 확인하려면 분산 σ<sup>2</sup> = ∑(x<sub>i</sub> - μ)<sup>2</sup>/n을 계산할 수 있습니다. 여기서 μ는 시퀀스의 평균입니다. 값 σ는 **표준 편차**라고 하며, σ<sup>2</sup>는 **분산**이라고 합니다.

## 최빈값, 중앙값 및 사분위수

때로는 평균이 데이터의 "전형적인" 값을 적절히 나타내지 못할 수 있습니다. 예를 들어, 몇 가지 극단적인 값이 범위를 완전히 벗어나면 평균에 영향을 미칠 수 있습니다. 또 다른 좋은 지표는 **중앙값**으로, 데이터 포인트의 절반이 이 값보다 낮고 나머지 절반이 이 값보다 높은 값을 말합니다.

데이터 분포를 이해하는 데 도움이 되는 개념은 **사분위수**입니다:

* 첫 번째 사분위수(Q1)는 데이터의 25%가 이 값보다 낮은 값입니다.
* 세 번째 사분위수(Q3)는 데이터의 75%가 이 값보다 낮은 값입니다.

중앙값과 사분위수 간의 관계를 그래픽으로 나타내는 **박스 플롯**이라는 다이어그램이 있습니다:

<img src="images/boxplot_explanation.png" width="50%"/>

여기서 우리는 **사분위 범위** IQR=Q3-Q1을 계산하고, [Q1-1.5*IQR,Q3+1.5*IQR] 경계를 벗어나는 값을 **이상치**라고 부릅니다.

가능한 값이 적은 유한 분포에서는 가장 자주 나타나는 값이 "전형적인" 값으로 간주되며, 이를 **최빈값**이라고 합니다. 이는 색상과 같은 범주형 데이터에 자주 적용됩니다. 예를 들어, 빨간색을 선호하는 그룹과 파란색을 선호하는 그룹이 있다고 가정해 봅시다. 색상을 숫자로 코딩하면 선호 색상의 평균 값은 주황색-녹색 스펙트럼 어딘가에 있을 수 있으며, 이는 두 그룹의 실제 선호도를 나타내지 않습니다. 그러나 최빈값은 빨간색 또는 파란색이 될 수 있으며, 두 색상을 선호하는 사람 수가 같다면 샘플을 **다중 최빈값**이라고 부릅니다.

## 실제 데이터

실제 데이터를 분석할 때, 데이터는 실험 결과가 불확실한 랜덤 변수와는 다를 수 있습니다. 예를 들어, 야구 선수 팀과 그들의 신체 데이터(키, 몸무게, 나이)를 생각해 보세요. 이러한 숫자는 정확히 랜덤하지는 않지만 동일한 수학적 개념을 적용할 수 있습니다. 예를 들어, 사람들의 몸무게 시퀀스는 특정 랜덤 변수에서 추출된 값의 시퀀스로 간주될 수 있습니다. 아래는 [메이저 리그 야구](http://mlb.mlb.com/index.jsp)의 실제 야구 선수들의 몸무게 시퀀스입니다. [이 데이터셋](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights)에서 가져왔으며, 편의를 위해 처음 20개의 값만 표시합니다:

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **참고**: 이 데이터셋을 사용하는 예제를 보려면 [관련 노트북](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb)을 확인하세요. 이 강의에는 여러 도전 과제가 포함되어 있으며, 해당 노트북에 코드를 추가하여 완료할 수 있습니다. 데이터를 다루는 방법을 잘 모른다면 걱정하지 마세요. 나중에 Python을 사용하여 데이터를 다루는 방법으로 돌아올 것입니다. Jupyter Notebook에서 코드를 실행하는 방법을 모른다면 [이 기사](https://soshnikov.com/education/how-to-execute-notebooks-from-github/)를 참조하세요.

다음은 평균, 중앙값 및 사분위수를 보여주는 박스 플롯입니다:

![Weight Box Plot](../../../../1-Introduction/04-stats-and-probability/images/weight-boxplot.png)

우리 데이터에는 다양한 선수 **역할**에 대한 정보가 포함되어 있으므로 역할별로 박스 플롯을 만들 수도 있습니다. 이를 통해 매개변수 값이 역할에 따라 어떻게 다른지 알 수 있습니다. 이번에는 키를 고려해 보겠습니다:

![Box plot by role](../../../../1-Introduction/04-stats-and-probability/images/boxplot_byrole.png)

이 다이어그램은 평균적으로 1루수의 키가 2루수의 키보다 높다는 것을 시사합니다. 이 강의 후반부에서는 이 가설을 더 공식적으로 테스트하는 방법과 데이터가 통계적으로 유의미하다는 것을 보여주는 방법을 배울 것입니다.

> 실제 데이터를 다룰 때, 모든 데이터 포인트가 특정 확률 분포에서 추출된 샘플이라고 가정합니다. 이 가정은 머신 러닝 기술을 적용하고 작동하는 예측 모델을 구축할 수 있게 해줍니다.

우리 데이터의 분포를 확인하려면 **히스토그램**이라는 그래프를 그릴 수 있습니다. X축에는 다양한 몸무게 구간(소위 **빈**)이 포함되고, Y축에는 랜덤 변수 샘플이 해당 구간에 속한 횟수를 표시합니다.

![Histogram of real world data](../../../../1-Introduction/04-stats-and-probability/images/weight-histogram.png)

이 히스토그램에서 모든 값이 특정 평균 몸무게를 중심으로 집중되어 있으며, 평균 몸무게에서 멀어질수록 해당 값의 몸무게가 적게 나타나는 것을 볼 수 있습니다. 즉, 야구 선수의 몸무게가 평균 몸무게와 크게 다를 가능성은 매우 낮습니다. 몸무게의 분산은 몸무게가 평균과 얼마나 다를 가능성이 있는지를 보여줍니다.

> 다른 사람들, 예를 들어 대학생들의 몸무게를 측정하면 분포가 다를 가능성이 높습니다. 그러나 분포의 형태는 동일하지만 평균과 분산은 달라질 것입니다. 따라서 야구 선수 데이터를 기반으로 모델을 훈련하면 대학생들에게 적용할 때 잘못된 결과를 제공할 가능성이 높습니다. 이는 기본 분포가 다르기 때문입니다.

## 정규 분포

위에서 본 몸무게 분포는 매우 일반적이며, 실제 세계의 많은 측정값이 동일한 유형의 분포를 따르지만 평균과 분산은 다릅니다. 이 분포는 **정규 분포**라고 하며, 통계에서 매우 중요한 역할을 합니다.

정규 분포를 사용하는 것은 잠재적인 야구 선수의 랜덤 몸무게를 생성하는 올바른 방법입니다. 평균 몸무게 `mean`과 표준 편차 `std`를 알고 있다면 다음과 같이 1000개의 몸무게 샘플을 생성할 수 있습니다:
```python
samples = np.random.normal(mean,std,1000)
``` 

생성된 샘플의 히스토그램을 그리면 위에서 본 그림과 매우 유사한 그림을 볼 수 있습니다. 샘플 수와 빈 수를 늘리면 이상적인 정규 분포에 더 가까운 그림을 생성할 수 있습니다:

![Normal Distribution with mean=0 and std.dev=1](../../../../1-Introduction/04-stats-and-probability/images/normal-histogram.png)

*평균=0, 표준 편차=1인 정규 분포*

## 신뢰 구간

야구 선수의 몸무게에 대해 이야기할 때, 모든 야구 선수의 몸무게에 대한 이상적인 확률 분포(소위 **모집단**)를 나타내는 **랜덤 변수 W**가 있다고 가정합니다. 우리의 몸무게 시퀀스는 **샘플**이라고 부르는 모집단의 일부에 해당합니다. 흥미로운 질문은 모집단 W의 분포 매개변수, 즉 모집단의 평균과 분산을 알 수 있는지입니다.

가장 쉬운 답은 샘플의 평균과 분산을 계산하는 것입니다. 그러나 우리의 랜덤 샘플이 전체 모집단을 정확히 대표하지 않을 수 있습니다. 따라서 **신뢰 구간**에 대해 이야기하는 것이 합리적입니다.
> **신뢰 구간**은 표본을 바탕으로 모집단의 실제 평균을 추정하는 것으로, 특정 확률(또는 **신뢰 수준**) 내에서 정확합니다.
X<sub>1</sub>, ..., X<sub>n</sub> 샘플이 주어진 분포에서 추출되었다고 가정해봅시다. 분포에서 샘플을 추출할 때마다 평균값 μ는 달라질 수 있습니다. 따라서 μ는 랜덤 변수로 간주될 수 있습니다. **신뢰구간**은 신뢰도 p를 가지는 값의 쌍 (L<sub>p</sub>, R<sub>p</sub>)로 정의되며, **P**(L<sub>p</sub>≤μ≤R<sub>p</sub>) = p, 즉 측정된 평균값이 해당 구간 내에 속할 확률이 p와 같다는 것을 의미합니다.

이 신뢰구간이 어떻게 계산되는지에 대한 자세한 논의는 간단한 소개를 넘어섭니다. 더 많은 정보는 [위키피디아](https://en.wikipedia.org/wiki/Confidence_interval)에서 찾을 수 있습니다. 간단히 말해, 모집단의 실제 평균에 대한 계산된 샘플 평균의 분포를 정의하며, 이를 **스튜던트 분포**라고 합니다.

> **흥미로운 사실**: 스튜던트 분포는 수학자 William Sealy Gosset의 이름을 따서 명명되었습니다. 그는 "Student"라는 필명으로 논문을 발표했으며, 기네스 맥주 공장에서 일했습니다. 한 가지 설에 따르면 그의 고용주는 원재료 품질을 결정하기 위해 통계적 테스트를 사용하고 있다는 사실이 대중에게 알려지기를 원하지 않았다고 합니다.

모집단의 평균 μ를 신뢰도 p로 추정하려면 스튜던트 분포 A의 *(1-p)/2-백분위수*를 가져와야 합니다. 이는 표에서 가져오거나 Python, R 등 통계 소프트웨어의 내장 함수를 사용하여 계산할 수 있습니다. 그런 다음 μ의 구간은 X±A*D/√n로 주어지며, 여기서 X는 샘플에서 얻은 평균값이고 D는 표준편차입니다.

> **참고**: 스튜던트 분포와 관련하여 중요한 개념인 [자유도](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics))에 대한 논의는 생략합니다. 이 개념을 더 깊이 이해하려면 통계학에 대한 보다 완전한 책을 참조하십시오.

체중과 키에 대한 신뢰구간 계산 예는 [첨부된 노트북](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb)에 제공됩니다.

| p | 체중 평균 |
|-----|-----------|
| 0.85 | 201.73±0.94 |
| 0.90 | 201.73±1.08 |
| 0.95 | 201.73±1.28 |

신뢰 확률이 높을수록 신뢰구간이 넓어진다는 점에 주목하십시오.

## 가설 검정

야구 선수 데이터셋에는 다양한 선수 역할이 있으며, 아래와 같이 요약할 수 있습니다 ([첨부된 노트북](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb)을 참조하여 이 표를 계산하는 방법을 확인하십시오):

| 역할 | 키 | 체중 | 개수 |
|------|--------|--------|-------|
| 포수 | 72.723684 | 204.328947 | 76 |
| 지명타자 | 74.222222 | 220.888889 | 18 |
| 1루수 | 74.000000 | 213.109091 | 55 |
| 외야수 | 73.010309 | 199.113402 | 194 |
| 구원투수 | 74.374603 | 203.517460 | 315 |
| 2루수 | 71.362069 | 184.344828 | 58 |
| 유격수 | 71.903846 | 182.923077 | 52 |
| 선발투수 | 74.719457 | 205.163636 | 221 |
| 3루수 | 73.044444 | 200.955556 | 45 |

1루수의 평균 키가 2루수의 평균 키보다 높다는 점을 알 수 있습니다. 따라서 **1루수가 2루수보다 키가 크다**는 결론을 내리고 싶을 수 있습니다.

> 이 진술은 **가설**이라고 불리며, 실제로 사실인지 아닌지 알 수 없기 때문입니다.

그러나 이 결론을 내릴 수 있는지 항상 명확하지는 않습니다. 위의 논의에서 각 평균에는 관련된 신뢰구간이 있으며, 따라서 이 차이는 단순히 통계적 오류일 수 있습니다. 우리는 가설을 검증하기 위한 보다 공식적인 방법이 필요합니다.

1루수와 2루수의 키에 대해 신뢰구간을 별도로 계산해 봅시다:

| 신뢰도 | 1루수 | 2루수 |
|------------|---------------|----------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

어떤 신뢰도에서도 구간이 겹치지 않는다는 것을 알 수 있습니다. 이는 1루수가 2루수보다 키가 크다는 우리의 가설을 입증합니다.

보다 공식적으로, 우리가 해결하려는 문제는 **두 확률 분포가 동일한지**, 또는 적어도 동일한 매개변수를 가지는지 확인하는 것입니다. 분포에 따라 이를 위해 다른 테스트를 사용해야 합니다. 분포가 정규분포임을 알고 있다면 **[스튜던트 t-검정](https://en.wikipedia.org/wiki/Student%27s_t-test)**을 적용할 수 있습니다.

스튜던트 t-검정에서는 평균 간의 차이를 분산을 고려하여 나타내는 **t-값**을 계산합니다. t-값은 **스튜던트 분포**를 따르며, 이를 통해 주어진 신뢰도 **p**에 대한 임계값을 얻을 수 있습니다(계산하거나 수치 표에서 확인 가능). 그런 다음 t-값을 이 임계값과 비교하여 가설을 승인하거나 기각합니다.

Python에서는 `ttest_ind` 함수를 포함한 **SciPy** 패키지를 사용할 수 있습니다(다른 유용한 통계 함수도 포함되어 있음). 이 함수는 t-값을 계산하고 신뢰도 p-값의 역 조회도 수행하므로 신뢰도를 확인하여 결론을 내릴 수 있습니다.

예를 들어, 1루수와 2루수의 키 비교는 다음과 같은 결과를 제공합니다:
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
이 경우 p-값이 매우 낮아, 1루수가 더 크다는 강력한 증거가 있음을 나타냅니다.

또한 우리가 테스트하고자 하는 다른 유형의 가설도 있습니다. 예를 들어:
* 주어진 샘플이 특정 분포를 따르는지 증명하기. 우리의 경우 키가 정규분포를 따른다고 가정했지만, 이는 공식적인 통계 검증이 필요합니다.
* 샘플의 평균값이 미리 정의된 값과 일치하는지 증명하기
* 여러 샘플의 평균값을 비교하기(예: 연령 그룹 간 행복 수준의 차이)

## 대수의 법칙과 중심극한정리

정규분포가 중요한 이유 중 하나는 **중심극한정리**입니다. 독립적인 N개의 값 X<sub>1</sub>, ..., X<sub>N</sub>이 평균 μ와 분산 σ<sup>2</sup>를 가지는 임의의 분포에서 샘플링되었다고 가정해봅시다. 그러면 충분히 큰 N(즉, N→∞일 때)에 대해 평균 Σ<sub>i</sub>X<sub>i</sub>는 평균 μ와 분산 σ<sup>2</sup>/N을 가지는 정규분포를 따릅니다.

> 중심극한정리를 다른 방식으로 해석하면, 분포에 관계없이 임의의 랜덤 변수 값의 합의 평균을 계산하면 정규분포를 얻게 된다는 것을 의미합니다.

중심극한정리에서 또한 N→∞일 때 샘플 평균이 μ와 같아질 확률이 1이 된다는 결론을 얻을 수 있습니다. 이는 **대수의 법칙**으로 알려져 있습니다.

## 공분산과 상관관계

데이터 과학이 하는 일 중 하나는 데이터 간의 관계를 찾는 것입니다. 두 시퀀스가 동시에 비슷한 행동을 보일 때, 즉 동시에 상승/하락하거나 한 시퀀스가 상승할 때 다른 시퀀스가 하락하는 경우, 우리는 두 시퀀스가 **상관관계**가 있다고 말합니다. 즉, 두 시퀀스 간에 어떤 관계가 있는 것처럼 보입니다.

> 상관관계는 두 시퀀스 간의 인과 관계를 반드시 나타내는 것은 아닙니다. 때로는 두 변수 모두 외부 원인에 의존할 수 있으며, 두 시퀀스가 상관관계를 가지는 것이 순전히 우연일 수도 있습니다. 그러나 강한 수학적 상관관계는 두 변수가 어떤 식으로든 연결되어 있다는 좋은 지표입니다.

수학적으로 두 랜덤 변수 간의 관계를 나타내는 주요 개념은 **공분산**입니다. 이는 다음과 같이 계산됩니다: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. 두 변수의 평균값에서의 편차를 계산한 다음, 그 편차의 곱을 계산합니다. 두 변수가 함께 편차를 보이면 곱은 항상 양수가 되어 양의 공분산으로 합산됩니다. 두 변수가 비동기적으로 편차를 보이면(즉, 하나가 평균 이하로 떨어질 때 다른 하나가 평균 이상으로 상승하는 경우) 항상 음수를 얻어 음의 공분산으로 합산됩니다. 편차가 독립적이라면 대략 0으로 합산됩니다.

공분산의 절대값은 실제 값의 크기에 따라 달라지므로 상관관계의 크기를 많이 알려주지 않습니다. 이를 정규화하기 위해 공분산을 두 변수의 표준편차로 나누어 **상관관계**를 얻을 수 있습니다. 상관관계는 항상 [-1,1] 범위 내에 있으며, 1은 값 간의 강한 양의 상관관계를, -1은 강한 음의 상관관계를, 0은 상관관계가 없음을(변수가 독립적임을) 나타냅니다.

**예제**: 위에서 언급한 야구 선수 데이터셋에서 체중과 키 간의 상관관계를 계산할 수 있습니다:
```python
print(np.corrcoef(weights,heights))
```
결과적으로 다음과 같은 **상관관계 행렬**을 얻습니다:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> 상관관계 행렬 C는 S<sub>1</sub>, ..., S<sub>n</sub>의 입력 시퀀스에 대해 계산할 수 있습니다. C<sub>ij</sub> 값은 S<sub>i</sub>와 S<sub>j</sub> 간의 상관관계를 나타내며, 대각 요소는 항상 1입니다(S<sub>i</sub>의 자기 상관관계).

우리의 경우 값 0.53은 사람의 체중과 키 간에 어느 정도 상관관계가 있음을 나타냅니다. 또한 한 값에 대해 다른 값을 시각적으로 관계를 확인하기 위해 산점도를 만들 수 있습니다:

![체중과 키 간의 관계](../../../../1-Introduction/04-stats-and-probability/images/weight-height-relationship.png)

> 상관관계와 공분산의 더 많은 예는 [첨부된 노트북](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb)에서 찾을 수 있습니다.

## 결론

이 섹션에서는 다음을 배웠습니다:

* 평균, 분산, 최빈값 및 사분위수와 같은 데이터의 기본 통계적 속성
* 정규분포를 포함한 랜덤 변수의 다양한 분포
* 서로 다른 속성 간의 상관관계를 찾는 방법
* 가설을 증명하기 위해 수학과 통계의 견고한 도구를 사용하는 방법
* 데이터 샘플을 기반으로 랜덤 변수의 신뢰구간을 계산하는 방법

확률과 통계 내에 존재하는 주제의 포괄적인 목록은 아니지만, 이 과정에 대한 좋은 시작점을 제공하기에 충분해야 합니다.

## 🚀 도전

노트북의 샘플 코드를 사용하여 다음 가설을 테스트해보세요:
1. 1루수가 2루수보다 나이가 많다.
2. 1루수가 3루수보다 키가 크다.
3. 유격수가 2루수보다 키가 크다.

## [강의 후 퀴즈](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/7)

## 복습 및 자기 학습

확률과 통계는 매우 광범위한 주제이므로 별도의 과정이 필요합니다. 이론을 더 깊이 탐구하고 싶다면 다음 책을 읽어보는 것이 좋습니다:

1. 뉴욕대학교의 [Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/)가 작성한 훌륭한 강의 노트 [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (온라인에서 이용 가능)
1. [Peter and Andrew Bruce. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[R 샘플 코드](https://github.com/andrewgbruce/statistics-for-data-scientists)].
1. [James D. Miller. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[R 샘플 코드](https://github.com/PacktPublishing/Statistics-for-Data-Science)]

## 과제

[소규모 당뇨병 연구](assignment.md)

## 크레딧

이 강의는 [Dmitry Soshnikov](http://soshnikov.com)가 ♥️로 작성했습니다.

**면책 조항**:  
이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 정확성을 위해 최선을 다하고 있지만, 자동 번역에는 오류나 부정확성이 포함될 수 있습니다. 원본 문서의 원어 버전을 권위 있는 출처로 간주해야 합니다. 중요한 정보의 경우, 전문적인 인간 번역을 권장합니다. 이 번역 사용으로 인해 발생하는 오해나 잘못된 해석에 대해 책임을 지지 않습니다.