{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducere în Probabilitate și Statistică\n",
    "În acest caiet, ne vom juca cu unele dintre conceptele pe care le-am discutat anterior. Multe concepte din probabilitate și statistică sunt bine reprezentate în biblioteci majore pentru procesarea datelor în Python, precum `numpy` și `pandas`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variabile aleatorii și distribuții\n",
    "Să începem prin a extrage un eșantion de 30 de valori dintr-o distribuție uniformă de la 0 la 9. Vom calcula, de asemenea, media și varianța.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [ random.randint(0,10) for _ in range(30) ]\n",
    "print(f\"Sample: {sample}\")\n",
    "print(f\"Mean = {np.mean(sample)}\")\n",
    "print(f\"Variance = {np.var(sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru a estima vizual câte valori diferite există în eșantion, putem realiza un **histogramă**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza datelor reale\n",
    "\n",
    "Media și varianța sunt foarte importante atunci când se analizează date din lumea reală. Să încărcăm datele despre jucătorii de baseball de la [SOCR MLB Height/Weight Data](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/SOCR_MLB.tsv\",sep='\\t', header=None, names=['Name','Team','Role','Weight','Height','Age'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Folosim un pachet numit [**Pandas**](https://pandas.pydata.org/) aici pentru analiza datelor. Vom vorbi mai multe despre Pandas și lucrul cu date în Python mai târziu în acest curs.\n",
    "\n",
    "Să calculăm valorile medii pentru vârstă, înălțime și greutate:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Age','Height','Weight']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acum să ne concentrăm pe înălțime și să calculăm deviația standard și varianța:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df['Height'])[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df['Height'].mean()\n",
    "var = df['Height'].var()\n",
    "std = df['Height'].std()\n",
    "print(f\"Mean = {mean}\\nVariance = {var}\\nStandard Deviation = {std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pe lângă medie, este util să analizăm valoarea mediană și categoriile quartile. Acestea pot fi vizualizate utilizând un **diagramă cutie**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2))\n",
    "plt.boxplot(df['Height'].ffill(), vert=False, showmeans=True)\n",
    "plt.grid(color='gray', linestyle='dotted')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putem, de asemenea, să realizăm diagrame box-plot pentru subseturi ale setului nostru de date, de exemplu, grupate după rolul jucătorului.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='Height', by='Role', figsize=(10,8))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Notă**: Acest diagram sugerează că, în medie, înălțimile primilor basiști sunt mai mari decât înălțimile celor de la al doilea bază. Mai târziu vom învăța cum putem testa această ipoteză mai formal și cum să demonstrăm că datele noastre sunt statistic semnificative pentru a arăta acest lucru.\n",
    "\n",
    "Vârsta, înălțimea și greutatea sunt toate variabile aleatoare continue. Ce crezi că este distribuția lor? O metodă bună de a afla este să reprezentăm histograma valorilor:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weight'].hist(bins=15, figsize=(10,6))\n",
    "plt.suptitle('Weight distribution of MLB Players')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuția Normală\n",
    "\n",
    "Să creăm un eșantion artificial de greutăți care urmează o distribuție normală cu aceeași medie și variață ca și datele noastre reale:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = np.random.normal(mean, std, 1000)\n",
    "generated[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(generated, bins=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(np.random.normal(0,1,50000), bins=300)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deoarece majoritatea valorilor în viața reală sunt distribuite normal, nu ar trebui să folosim un generator de numere aleatoare uniforme pentru a genera date de probă. Iată ce se întâmplă dacă încercăm să generăm greutăți cu o distribuție uniformă (generată de `np.random.rand`):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_sample = np.random.rand(1000)*2*std+mean-std\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(wrong_sample)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervale de încredere\n",
    "\n",
    "Să calculăm acum intervalele de încredere pentru greutățile și înălțimile jucătorilor de baseball. Vom folosi codul [din această discuție pe stackoverflow](https://stackoverflow.com/questions/15033511/compute-a-confidence-interval-from-sample-data):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, h\n",
    "\n",
    "for p in [0.85, 0.9, 0.95]:\n",
    "    m, h = mean_confidence_interval(df['Weight'].fillna(method='pad'),p)\n",
    "    print(f\"p={p:.2f}, mean = {m:.2f} ± {h:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testarea ipotezelor\n",
    "\n",
    "Să explorăm diferite roluri în setul nostru de date al jucătorilor de baseball:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Role').agg({ 'Weight' : 'mean', 'Height' : 'mean', 'Age' : 'count'}).rename(columns={ 'Age' : 'Count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Să testăm ipoteza că Prima bază este mai înaltă decât a Doua bază. Cel mai simplu mod de a face acest lucru este să testăm intervalele de încredere:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [0.85,0.9,0.95]:\n",
    "    m1, h1 = mean_confidence_interval(df.loc[df['Role']=='First_Baseman',['Height']],p)\n",
    "    m2, h2 = mean_confidence_interval(df.loc[df['Role']=='Second_Baseman',['Height']],p)\n",
    "    print(f'Conf={p:.2f}, 1st basemen height: {m1-h1[0]:.2f}..{m1+h1[0]:.2f}, 2nd basemen height: {m2-h2[0]:.2f}..{m2+h2[0]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putem vedea că intervalele nu se suprapun.\n",
    "\n",
    "O metodă statistic mai corectă de a demonstra ipoteza este să folosim un **test t Student**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Second_Baseman',['Height']],equal_var=False)\n",
    "print(f\"T-value = {tval[0]:.2f}\\nP-value: {pval[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cele două valori returnate de funcția `ttest_ind` sunt:\n",
    "* valoarea p poate fi considerată ca probabilitatea ca două distribuții să aibă aceeași medie. În cazul nostru, este foarte mică, ceea ce înseamnă că există dovezi puternice care susțin că jucătorii de primă bază sunt mai înalți.\n",
    "* valoarea t este valoarea intermediară a diferenței normale a mediilor utilizată în testul t și este comparată cu o valoare prag pentru un anumit nivel de încredere.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simularea unei distribuții normale cu Teorema Limitei Centrale\n",
    "\n",
    "Generatorul pseudo-aleator din Python este conceput să ne ofere o distribuție uniformă. Dacă vrem să creăm un generator pentru distribuția normală, putem folosi teorema limitei centrale. Pentru a obține o valoare distribuită normal, vom calcula pur și simplu media unui eșantion generat uniform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_random(sample_size=100):\n",
    "    sample = [random.uniform(0,1) for _ in range(sample_size) ]\n",
    "    return sum(sample)/sample_size\n",
    "\n",
    "sample = [normal_random() for _ in range(100)]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(sample)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corelație și Evil Baseball Corp\n",
    "\n",
    "Corelația ne permite să găsim relații între secvențe de date. În exemplul nostru simplu, să presupunem că există o corporație malefică de baseball care plătește jucătorii în funcție de înălțimea lor - cu cât jucătorul este mai înalt, cu atât primește mai mulți bani. Să presupunem că există un salariu de bază de 1000 USD, și o primă suplimentară de la 0 la 100 USD, în funcție de înălțime. Vom lua jucătorii reali din MLB și vom calcula salariile lor imaginare:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = df['Height'].fillna(method='pad')\n",
    "salaries = 1000+(heights-heights.min())/(heights.max()-heights.mean())*100\n",
    "print(list(zip(heights, salaries))[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Să calculăm acum covarianța și corelația acelor secvențe. `np.cov` ne va oferi o așa-numită **matrice de covarianță**, care este o extensie a covarianței pentru variabile multiple. Elementul $M_{ij}$ al matricei de covarianță $M$ este o corelație între variabilele de intrare $X_i$ și $X_j$, iar valorile de pe diagonală $M_{ii}$ reprezintă varianța lui $X_{i}$. În mod similar, `np.corrcoef` ne va oferi **matricea de corelație**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Covariance matrix:\\n{np.cov(heights, salaries)}\")\n",
    "print(f\"Covariance = {np.cov(heights, salaries)[0,1]}\")\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O corelație egală cu 1 înseamnă că există o **relație liniară** puternică între două variabile. Putem vedea vizual relația liniară prin trasarea unui grafic cu o valoare în funcție de cealaltă:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(heights,salaries)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Să vedem ce se întâmplă dacă relația nu este liniară. Să presupunem că corporația noastră a decis să ascundă dependența liniară evidentă dintre înălțimi și salarii și a introdus o anumită non-liniaritate în formulă, cum ar fi `sin`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = 1000+np.sin((heights-heights.min())/(heights.max()-heights.mean()))*100\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În acest caz, corelația este puțin mai mică, dar este totuși destul de ridicată. Acum, pentru a face relația și mai puțin evidentă, am putea dori să adăugăm o oarecare aleatorietate suplimentară prin adăugarea unei variabile aleatoare la salariu. Să vedem ce se întâmplă:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = 1000+np.sin((heights-heights.min())/(heights.max()-heights.mean()))*100+np.random.random(size=len(heights))*20-10\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(heights, salaries)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Poți ghici de ce punctele se aliniază în linii verticale astfel?\n",
    "\n",
    "Am observat corelația dintre un concept supus unui proces artificial, precum salariul, și variabila observată *înălțimea*. Să vedem dacă cele două variabile observate, cum ar fi înălțimea și greutatea, sunt corelate:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df['Height'].ffill(),df['Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Din păcate, nu am obținut niciun rezultat - doar câteva valori ciudate `nan`. Acest lucru se datorează faptului că unele dintre valorile din seria noastră sunt nedefinite, reprezentate ca `nan`, ceea ce face ca rezultatul operației să fie de asemenea nedefinit. Privind matricea putem vedea că `Weight` este coloana problematică, deoarece a fost calculată autocorelarea între valorile `Height`.\n",
    "\n",
    "> Acest exemplu evidențiază importanța **pregătirii datelor** și **curățării**. Fără date corespunzătoare nu putem calcula nimic.\n",
    "\n",
    "Să folosim metoda `fillna` pentru a completa valorile lipsă și să calculăm corelația: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df['Height'].fillna(method='pad'), df['Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Există într-adevăr o corelație, dar nu atât de puternică ca în exemplul nostru artificial. Într-adevăr, dacă ne uităm la diagrama de dispersie a unei valori față de cealaltă, relația ar fi mult mai puțin evidentă:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(df['Weight'],df['Height'])\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Height')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concluzie\n",
    "\n",
    "În acest caiet am învățat cum să efectuăm operații de bază asupra datelor pentru a calcula funcții statistice. Acum știm cum să folosim un aparat solid de matematică și statistică pentru a demonstra unele ipoteze și cum să calculăm intervale de încredere pentru variabile arbitrare date un eșantion de date.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Declinare a responsabilității**:  \nAcest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). Deși ne străduim pentru acuratețe, vă rugăm să rețineți că traducerile automate pot conține erori sau inexactități. Documentul original, în limba sa nativă, trebuie considerat sursa oficială. Pentru informații critice, se recomandă traducerea profesională realizată de un specialist uman. Nu ne asumăm răspunderea pentru eventuale neînțelegeri sau interpretări greșite rezultate din folosirea acestei traduceri.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86193a1ab0ba47eac1c69c1756090baa3b420b3eea7d4aafab8b85f8b312f0c5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "coopTranslator": {
   "original_hash": "0f899e3c5019f948e7c787b22f3b2304",
   "translation_date": "2026-01-16T19:33:16+00:00",
   "source_file": "1-Introduction/04-stats-and-probability/notebook.ipynb",
   "language_code": "ro"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}