<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "58860ce9a4b8a564003d2752f7c72851",
  "translation_date": "2025-10-03T16:57:37+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "ro"
}
-->
# Introducere Ã®n Etica Datelor

|![ Sketchnote de [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Etica Ã®n È˜tiinÈ›a Datelor - _Sketchnote de [@nitya](https://twitter.com/nitya)_ |

---

Suntem cu toÈ›ii cetÄƒÈ›eni ai datelor, trÄƒind Ã®ntr-o lume dominatÄƒ de informaÈ›ii.

TendinÈ›ele pieÈ›ei ne aratÄƒ cÄƒ, pÃ¢nÄƒ Ã®n 2022, 1 din 3 organizaÈ›ii mari va cumpÄƒra È™i vinde date prin intermediul [PiaÈ›elor È™i Schimburilor Online](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Ca **Dezvoltatori de AplicaÈ›ii**, vom gÄƒsi mai uÈ™or È™i mai ieftin sÄƒ integrÄƒm informaÈ›ii bazate pe date È™i automatizÄƒri bazate pe algoritmi Ã®n experienÈ›ele zilnice ale utilizatorilor. Dar, pe mÄƒsurÄƒ ce AI devine omniprezent, va trebui sÄƒ Ã®nÈ›elegem È™i potenÈ›ialele daune cauzate de [utilizarea abuzivÄƒ](https://www.youtube.com/watch?v=TQHs8SA1qpk) a acestor algoritmi la scarÄƒ largÄƒ.

TendinÈ›ele sugereazÄƒ cÄƒ, pÃ¢nÄƒ Ã®n 2025, vom genera È™i consuma peste [180 zettabytes](https://www.statista.com/statistics/871513/worldwide-data-created/) de date. Pentru **Oamenii de È˜tiinÈ›Äƒ Ã®n Date**, aceastÄƒ explozie de informaÈ›ii oferÄƒ acces fÄƒrÄƒ precedent la date personale È™i comportamentale. OdatÄƒ cu aceasta vine puterea de a construi profiluri detaliate ale utilizatorilor È™i de a influenÈ›a subtil luarea deciziilorâ€”adesea Ã®n moduri care creeazÄƒ o [iluzie de alegere liberÄƒ](https://www.datasciencecentral.com/the-pareto-set-and-the-paradox-of-choice/). DeÈ™i acest lucru poate fi utilizat pentru a ghida utilizatorii cÄƒtre rezultate preferate, ridicÄƒ È™i Ã®ntrebÄƒri critice despre confidenÈ›ialitatea datelor, autonomia È™i limitele etice ale influenÈ›ei algoritmice.

Etica datelor reprezintÄƒ acum _balustradele necesare_ pentru È™tiinÈ›a È™i ingineria datelor, ajutÃ¢ndu-ne sÄƒ minimizÄƒm potenÈ›ialele daune È™i consecinÈ›ele neintenÈ›ionate ale acÈ›iunilor noastre bazate pe date. [Ciclul de Hype Gartner pentru AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) identificÄƒ tendinÈ›e relevante Ã®n etica digitalÄƒ, AI responsabil È™i guvernanÈ›a AI ca factori cheie pentru megatendinÈ›ele mai mari legate de _democratizarea_ È™i _industrializarea_ AI.

![Ciclul de Hype Gartner pentru AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

Ãn aceastÄƒ lecÈ›ie, vom explora domeniul fascinant al eticii datelor - de la concepte de bazÄƒ È™i provocÄƒri, la studii de caz È™i concepte aplicate de AI, cum ar fi guvernanÈ›a - care ajutÄƒ la stabilirea unei culturi etice Ã®n echipele È™i organizaÈ›iile care lucreazÄƒ cu date È™i AI.




## [Chestionar Ã®nainte de lecÈ›ie](https://ff-quizzes.netlify.app/en/ds/quiz/2) ğŸ¯

## DefiniÈ›ii de bazÄƒ

SÄƒ Ã®ncepem prin a Ã®nÈ›elege terminologia de bazÄƒ.

CuvÃ¢ntul "eticÄƒ" provine din [cuvÃ¢ntul grecesc "ethikos"](https://en.wikipedia.org/wiki/Ethics) (È™i rÄƒdÄƒcina sa "ethos") care Ã®nseamnÄƒ _caracter sau naturÄƒ moralÄƒ_. 

**Etica** se referÄƒ la valorile comune È™i principiile morale care guverneazÄƒ comportamentul nostru Ã®n societate. Etica nu se bazeazÄƒ pe legi, ci pe norme larg acceptate despre ceea ce este "corect vs. greÈ™it". TotuÈ™i, consideraÈ›iile etice pot influenÈ›a iniÈ›iativele de guvernanÈ›Äƒ corporativÄƒ È™i reglementÄƒrile guvernamentale care creeazÄƒ mai multe stimulente pentru conformitate.

**Etica Datelor** este o [ramurÄƒ nouÄƒ a eticii](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1) care "studiazÄƒ È™i evalueazÄƒ problemele morale legate de _date, algoritmi È™i practicile corespunzÄƒtoare_". Aici, **"datele"** se concentreazÄƒ pe acÈ›iuni legate de generare, Ã®nregistrare, curare, procesare, diseminare, partajare È™i utilizare, **"algoritmii"** se concentreazÄƒ pe AI, agenÈ›i, Ã®nvÄƒÈ›are automatÄƒ È™i roboÈ›i, iar **"practicile"** se concentreazÄƒ pe subiecte precum inovaÈ›ia responsabilÄƒ, programarea, hacking-ul È™i codurile de eticÄƒ.

**Etica AplicatÄƒ** este [aplicarea practicÄƒ a consideraÈ›iilor morale](https://en.wikipedia.org/wiki/Applied_ethics). Este procesul de investigare activÄƒ a problemelor etice Ã®n contextul _acÈ›iunilor, produselor È™i proceselor din lumea realÄƒ_, È™i de luare a mÄƒsurilor corective pentru a ne asigura cÄƒ acestea rÄƒmÃ¢n aliniate cu valorile noastre etice definite.

**Cultura Eticii** se referÄƒ la [_operaÈ›ionalizarea_ eticii aplicate](https://hbr.org/2019/05/how-to-design-an-ethical-organization) pentru a ne asigura cÄƒ principiile È™i practicile noastre etice sunt adoptate Ã®ntr-un mod consistent È™i scalabil Ã®n Ã®ntreaga organizaÈ›ie. Culturile etice de succes definesc principii etice la nivel organizaÈ›ional, oferÄƒ stimulente semnificative pentru conformitate È™i Ã®ntÄƒresc normele etice prin Ã®ncurajarea È™i amplificarea comportamentelor dorite la fiecare nivel al organizaÈ›iei.


## Concepte de EticÄƒ

Ãn aceastÄƒ secÈ›iune, vom discuta concepte precum **valori comune** (principii) È™i **provocÄƒri etice** (probleme) pentru etica datelor - È™i vom explora **studii de caz** care te ajutÄƒ sÄƒ Ã®nÈ›elegi aceste concepte Ã®n contexte reale.

### 1. Principii Etice

Fiecare strategie de eticÄƒ a datelor Ã®ncepe prin definirea _principiilor etice_ - "valorile comune" care descriu comportamentele acceptabile È™i ghideazÄƒ acÈ›iunile conforme Ã®n proiectele noastre de date È™i AI. Le poÈ›i defini la nivel individual sau de echipÄƒ. TotuÈ™i, majoritatea organizaÈ›iilor mari le contureazÄƒ Ã®ntr-o declaraÈ›ie de misiune sau cadru de _AI etic_ definit la nivel corporativ È™i aplicat Ã®n mod consistent Ã®n toate echipele.

**Exemplu:** DeclaraÈ›ia de misiune [AI Responsabil](https://www.microsoft.com/en-us/ai/responsible-ai) de la Microsoft spune: _"Suntem dedicaÈ›i avansÄƒrii AI ghidatÄƒ de principii etice care pun oamenii pe primul loc"_ - identificÃ¢nd 6 principii etice Ã®n cadrul de mai jos:

![AI Responsabil la Microsoft](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

SÄƒ explorÄƒm pe scurt aceste principii. _TransparenÈ›a_ È™i _responsabilitatea_ sunt valori fundamentale pe care se construiesc celelalte principii - aÈ™a cÄƒ sÄƒ Ã®ncepem cu acestea:

* [**Responsabilitatea**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) face ca practicienii sÄƒ fie _responsabili_ pentru operaÈ›iunile lor de date È™i AI È™i pentru conformitatea cu aceste principii etice.
* [**TransparenÈ›a**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) asigurÄƒ cÄƒ acÈ›iunile legate de date È™i AI sunt _uÈ™or de Ã®nÈ›eles_ (interpretabile) pentru utilizatori, explicÃ¢nd ce È™i de ce Ã®n spatele deciziilor.
* [**Echitatea**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - se concentreazÄƒ pe asigurarea cÄƒ AI trateazÄƒ _toÈ›i oamenii_ Ã®n mod echitabil, abordÃ¢nd orice prejudecÄƒÈ›i socio-tehnice sistemice sau implicite Ã®n date È™i sisteme.
* [**Fiabilitatea È™i SiguranÈ›a**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - asigurÄƒ cÄƒ AI se comportÄƒ _consistent_ cu valorile definite, minimizÃ¢nd potenÈ›ialele daune sau consecinÈ›ele neintenÈ›ionate.
* [**ConfidenÈ›ialitatea È™i Securitatea**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - se referÄƒ la Ã®nÈ›elegerea provenienÈ›ei datelor È™i la oferirea de _protecÈ›ii legate de confidenÈ›ialitatea datelor_ utilizatorilor.
* [**Incluziunea**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - se referÄƒ la proiectarea soluÈ›iilor AI cu intenÈ›ie, adaptÃ¢ndu-le pentru a rÄƒspunde unei _game largi de nevoi È™i capacitÄƒÈ›i umane_.

> ğŸš¨ GÃ¢ndeÈ™te-te la ce ar putea fi declaraÈ›ia ta de misiune pentru etica datelor. ExploreazÄƒ cadrele de AI etic de la alte organizaÈ›ii - iatÄƒ exemple de la [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles), È™i [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Ce valori comune au Ã®n comun? Cum se raporteazÄƒ aceste principii la produsul sau industria AI Ã®n care opereazÄƒ?

### 2. ProvocÄƒri Etice

OdatÄƒ ce avem principiile etice definite, urmÄƒtorul pas este sÄƒ evaluÄƒm acÈ›iunile noastre legate de date È™i AI pentru a vedea dacÄƒ se aliniazÄƒ cu acele valori comune. GÃ¢ndeÈ™te-te la acÈ›iunile tale Ã®n douÄƒ categorii: _colectarea datelor_ È™i _designul algoritmilor_. 

Ãn cazul colectÄƒrii datelor, acÈ›iunile vor implica probabil **date personale** sau informaÈ›ii personale identificabile (PII) pentru indivizi identificabili. Acestea includ [diverse elemente de date non-personale](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) care _Ã®n mod colectiv_ identificÄƒ un individ. ProvocÄƒrile etice pot fi legate de _confidenÈ›ialitatea datelor_, _proprietatea datelor_ È™i subiecte conexe precum _consimÈ›ÄƒmÃ¢ntul informat_ È™i _drepturile de proprietate intelectualÄƒ_ ale utilizatorilor.

Ãn cazul designului algoritmilor, acÈ›iunile vor implica colectarea È™i curarea **seturilor de date**, apoi utilizarea acestora pentru a antrena È™i implementa **modele de date** care prezic rezultate sau automatizeazÄƒ decizii Ã®n contexte reale. ProvocÄƒrile etice pot apÄƒrea din _prejudecÄƒÈ›i Ã®n seturile de date_, probleme de _calitate a datelor_, _inechitate_ È™i _reprezentare greÈ™itÄƒ_ Ã®n algoritmi - inclusiv unele probleme care sunt de naturÄƒ sistemicÄƒ.

Ãn ambele cazuri, provocÄƒrile etice evidenÈ›iazÄƒ zonele Ã®n care acÈ›iunile noastre pot intra Ã®n conflict cu valorile noastre comune. Pentru a detecta, atenua, minimiza sau elimina aceste preocupÄƒri - trebuie sÄƒ punem Ã®ntrebÄƒri morale "da/nu" legate de acÈ›iunile noastre, apoi sÄƒ luÄƒm mÄƒsuri corective, dupÄƒ cum este necesar. SÄƒ aruncÄƒm o privire asupra unor provocÄƒri etice È™i Ã®ntrebÄƒrile morale pe care le ridicÄƒ:


#### 2.1 Proprietatea Datelor

Colectarea datelor implicÄƒ adesea date personale care pot identifica subiecÈ›ii datelor. [Proprietatea datelor](https://permission.io/blog/data-ownership) se referÄƒ la _control_ È™i [_drepturile utilizatorilor_](https://permission.io/blog/data-ownership) legate de crearea, procesarea È™i diseminarea datelor. 

ÃntrebÄƒrile morale pe care trebuie sÄƒ le punem sunt: 
 * Cine deÈ›ine datele? (utilizator sau organizaÈ›ie)
 * Ce drepturi au subiecÈ›ii datelor? (ex: acces, È™tergere, portabilitate)
 * Ce drepturi au organizaÈ›iile? (ex: rectificarea recenziilor utilizatorilor maliÈ›ioase)

#### 2.2 ConsimÈ›ÄƒmÃ¢ntul Informat

[ConsimÈ›ÄƒmÃ¢ntul informat](https://legaldictionary.net/informed-consent/) defineÈ™te actul utilizatorilor de a fi de acord cu o acÈ›iune (cum ar fi colectarea datelor) cu o _Ã®nÈ›elegere completÄƒ_ a faptelor relevante, inclusiv scopul, riscurile potenÈ›iale È™i alternativele. 

ÃntrebÄƒrile de explorat aici sunt:
 * Utilizatorul (subiectul datelor) È™i-a dat permisiunea pentru captarea È™i utilizarea datelor?
 * Utilizatorul a Ã®nÈ›eles scopul pentru care au fost capturate acele date?
 * Utilizatorul a Ã®nÈ›eles riscurile potenÈ›iale ale participÄƒrii sale?

#### 2.3 Proprietatea IntelectualÄƒ

[Proprietatea intelectualÄƒ](https://en.wikipedia.org/wiki/Intellectual_property) se referÄƒ la creaÈ›ii intangibile rezultate din iniÈ›iativa umanÄƒ, care pot _avea valoare economicÄƒ_ pentru indivizi sau afaceri. 

ÃntrebÄƒrile de explorat aici sunt:
 * Datele colectate aveau valoare economicÄƒ pentru un utilizator sau o afacere?
 * Utilizatorul are proprietate intelectualÄƒ aici?
 * OrganizaÈ›ia are proprietate intelectualÄƒ aici?
 * DacÄƒ aceste drepturi existÄƒ, cum le protejÄƒm?

#### 2.4 ConfidenÈ›ialitatea Datelor

[ConfidenÈ›ialitatea datelor](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) sau confidenÈ›ialitatea informaÈ›iilor se referÄƒ la pÄƒstrarea confidenÈ›ialitÄƒÈ›ii utilizatorilor È™i protecÈ›ia identitÄƒÈ›ii utilizatorilor Ã®n ceea ce priveÈ™te informaÈ›iile personale identificabile. 

ÃntrebÄƒrile de explorat aici sunt:
 * Datele (personale) ale utilizatorilor sunt securizate Ã®mpotriva atacurilor È™i scurgerilor?
 * Datele utilizatorilor sunt accesibile doar utilizatorilor È™i contextelor autorizate?
 * Anonimitatea utilizatorilor este pÄƒstratÄƒ atunci cÃ¢nd datele sunt partajate sau diseminate?
 * Poate un utilizator fi de-identificat din seturi de date anonimizate?


#### 2.5 Dreptul de a Fi Uitat

[Dreptul de a Fi Uitat](https://en.wikipedia.org/wiki/Right_to_be_forgotten) sau [Dreptul la È˜tergere](https://www.gdpreu.org/right-to-be-forgotten/) oferÄƒ protecÈ›ie suplimentarÄƒ datelor personale ale utilizatorilor. Ãn mod specific, oferÄƒ utilizatorilor dreptul de a solicita È™tergerea sau eliminarea datelor personale din cÄƒutÄƒrile pe Internet È™i alte locaÈ›ii, _Ã®n anumite circumstanÈ›e_ - permiÈ›Ã¢ndu-le un nou Ã®nceput online fÄƒrÄƒ ca acÈ›iunile din trecut sÄƒ fie folosite Ã®mpotriva lor.

ÃntrebÄƒrile de explorat aici sunt:
 * Sistemul permite subiecÈ›ilor datelor sÄƒ solicite È™tergerea?
 * Retragerea consimÈ›ÄƒmÃ¢ntului utilizatorului ar trebui sÄƒ declanÈ™eze È™tergerea automatÄƒ?
 * Datele au fost colectate fÄƒrÄƒ consimÈ›ÄƒmÃ¢nt sau prin mijloace ilegale?
 * Suntem conformi cu reglementÄƒrile guvernamentale privind confidenÈ›ialitatea datelor?


#### 2.6 PrejudecÄƒÈ›i Ã®n Seturile de Date

PrejudecÄƒÈ›ile Ã®n seturile de date sau [PrejudecÄƒÈ›ile de Colectare](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) se referÄƒ la selectarea unui subset _nereprezentativ_ de date pentru dezvoltarea algoritmilor, creÃ¢nd potenÈ›ial inechitate Ã®n rezultatele pentru grupuri diverse. Tipurile de prejudecÄƒÈ›i includ prejudecÄƒÈ›i de selecÈ›ie sau eÈ™antionare, prejudecÄƒÈ›i ale voluntarilor È™i prejudecÄƒÈ›i ale instrumentelor. 

ÃntrebÄƒrile de explorat aici sunt:
 * Am recrutat un set reprezentativ de subiecÈ›i ai datelor?
 * Am testat setul nostru de date colectat sau curat pentru diverse prejudecÄƒÈ›i?
 * Putem atenua sau elimina prejudecÄƒÈ›ile descoperite?

#### 2.7 Calitatea Datelor

[Calitatea Datelor](https://lakefs.io/data-quality-testing/) analizeazÄƒ validitatea setului de date curat utilizat pentru dezvoltarea algoritmilor noÈ™tri, verificÃ¢nd dacÄƒ caracteristicile È™i Ã®nregistrÄƒrile Ã®ndeplinesc cerinÈ›ele pentru nivelul de acurateÈ›e È™i consistenÈ›Äƒ necesar scopului nostru AI.

ÃntrebÄƒrile de explorat aici sunt:
 * Am capturat caracteristici valide pentru cazul nostru de utilizare?
 * Datele au fost capturate Ã®n mod _consistent_ din surse de date diverse?
 * Setul de date este _complet_ pentru condiÈ›ii sau scenarii diverse?
* Este informaÈ›ia capturatÄƒ _corect_ Ã®n reflectarea realitÄƒÈ›ii?

#### 2.8 Corectitudinea algoritmului

[Corectitudinea algoritmului](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) verificÄƒ dacÄƒ designul algoritmului discrimineazÄƒ sistematic anumite subgrupuri de subiecÈ›i de date, conducÃ¢nd la [posibile prejudicii](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) Ã®n _alocare_ (unde resursele sunt refuzate sau reÈ›inute de la acel grup) È™i _calitatea serviciului_ (unde AI nu este la fel de precis pentru unele subgrupuri comparativ cu altele).

ÃntrebÄƒri de explorat aici:
* Am evaluat acurateÈ›ea modelului pentru diverse subgrupuri È™i condiÈ›ii?
* Am analizat sistemul pentru posibile prejudicii (de exemplu, stereotipuri)?
* Putem revizui datele sau reantrena modelele pentru a reduce prejudiciile identificate?

ExploraÈ›i resurse precum [listele de verificare pentru corectitudinea AI](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) pentru a afla mai multe.

#### 2.9 Denaturarea datelor

[Denaturarea datelor](https://www.sciencedirect.com/topics/computer-science/misrepresentation) implicÄƒ Ã®ntrebarea dacÄƒ comunicÄƒm informaÈ›ii din date raportate onest Ã®ntr-un mod Ã®nÈ™elÄƒtor pentru a susÈ›ine o naraÈ›iune doritÄƒ.

ÃntrebÄƒri de explorat aici:
* RaportÄƒm date incomplete sau inexacte?
* VizualizÄƒm datele Ã®ntr-un mod care conduce la concluzii Ã®nÈ™elÄƒtoare?
* Folosim tehnici statistice selective pentru a manipula rezultatele?
* ExistÄƒ explicaÈ›ii alternative care ar putea oferi o concluzie diferitÄƒ?

#### 2.10 Alegerea liberÄƒ

[Iluzia alegerii libere](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) apare atunci cÃ¢nd "arhitecturile de alegere" ale sistemului folosesc algoritmi de luare a deciziilor pentru a influenÈ›a oamenii sÄƒ ia un rezultat preferat, Ã®n timp ce par sÄƒ le ofere opÈ›iuni È™i control. Aceste [pattern-uri Ã®ntunecate](https://www.darkpatterns.org/) pot provoca prejudicii sociale È™i economice utilizatorilor. Deoarece deciziile utilizatorilor influenÈ›eazÄƒ profilurile de comportament, aceste acÈ›iuni pot conduce la alegeri viitoare care amplificÄƒ sau extind impactul acestor prejudicii.

ÃntrebÄƒri de explorat aici:
* Utilizatorul a Ã®nÈ›eles implicaÈ›iile luÄƒrii acelei decizii?
* Utilizatorul era conÈ™tient de (alternativele) opÈ›iuni È™i de avantajele È™i dezavantajele fiecÄƒreia?
* Utilizatorul poate inversa o alegere automatÄƒ sau influenÈ›atÄƒ ulterior?

### 3. Studii de caz

Pentru a pune aceste provocÄƒri etice Ã®n contexte reale, este util sÄƒ analizÄƒm studii de caz care evidenÈ›iazÄƒ prejudiciile È™i consecinÈ›ele potenÈ›iale asupra indivizilor È™i societÄƒÈ›ii atunci cÃ¢nd astfel de Ã®ncÄƒlcÄƒri etice sunt ignorate.

IatÄƒ cÃ¢teva exemple:

| Provocare eticÄƒ | Studiu de caz | 
|--- |--- |
| **ConsimÈ›ÄƒmÃ¢nt informat** | 1972 - [Studiul Tuskegee privind sifilisul](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - BÄƒrbaÈ›ii afro-americani care au participat la studiu au fost promiÈ™i Ã®ngrijire medicalÄƒ gratuitÄƒ _dar au fost Ã®nÈ™elaÈ›i_ de cercetÄƒtori care nu le-au informat despre diagnostic sau despre disponibilitatea tratamentului. MulÈ›i subiecÈ›i au murit, iar partenerii sau copiii au fost afectaÈ›i; studiul a durat 40 de ani. | 
| **ConfidenÈ›ialitatea datelor** | 2007 - [Premiul Netflix pentru date](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) a oferit cercetÄƒtorilor _10M de evaluÄƒri anonimizate de filme de la 50K de clienÈ›i_ pentru a ajuta la Ã®mbunÄƒtÄƒÈ›irea algoritmilor de recomandare. Cu toate acestea, cercetÄƒtorii au reuÈ™it sÄƒ coreleze datele anonimizate cu date identificabile personal din _seturi de date externe_ (de exemplu, comentarii IMDb) - efectiv "de-anonimizÃ¢nd" unii abonaÈ›i Netflix. |
| **Bias Ã®n colectare** | 2013 - OraÈ™ul Boston [a dezvoltat Street Bump](https://www.boston.gov/transportation/street-bump), o aplicaÈ›ie care permite cetÄƒÈ›enilor sÄƒ raporteze gropi, oferind oraÈ™ului date mai bune despre drumuri pentru a identifica È™i repara problemele. Cu toate acestea, [persoanele din grupuri cu venituri mai mici aveau acces redus la maÈ™ini È™i telefoane](https://hbr.org/2013/04/the-hidden-biases-in-big-data), fÄƒcÃ¢nd problemele lor de drum invizibile Ã®n aceastÄƒ aplicaÈ›ie. Dezvoltatorii au colaborat cu academicieni pentru a aborda _problemele de acces echitabil È™i diviziuni digitale_ pentru corectitudine. |
| **Corectitudinea algoritmului** | 2018 - Studiul MIT [Gender Shades](http://gendershades.org/overview.html) a evaluat acurateÈ›ea produselor AI de clasificare a genului, expunÃ¢nd lacunele de acurateÈ›e pentru femei È™i persoane de culoare. Un [Card Apple din 2019](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) pÄƒrea sÄƒ ofere mai puÈ›in credit femeilor decÃ¢t bÄƒrbaÈ›ilor. Ambele au ilustrat probleme de bias algoritmic care conduc la prejudicii socio-economice. |
| **Denaturarea datelor** | 2020 - [Departamentul de SÄƒnÄƒtate PublicÄƒ din Georgia a lansat grafice COVID-19](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) care pÄƒreau sÄƒ inducÄƒ Ã®n eroare cetÄƒÈ›enii cu privire la tendinÈ›ele cazurilor confirmate prin ordonarea non-cronologicÄƒ pe axa x. Acest lucru ilustreazÄƒ denaturarea prin trucuri de vizualizare. |
| **Iluzia alegerii libere** | 2020 - AplicaÈ›ia de Ã®nvÄƒÈ›are [ABCmouse a plÄƒtit 10M pentru a soluÈ›iona o plÃ¢ngere FTC](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/) Ã®n care pÄƒrinÈ›ii au fost blocaÈ›i sÄƒ plÄƒteascÄƒ pentru abonamente pe care nu le puteau anula. Acest lucru ilustreazÄƒ pattern-uri Ã®ntunecate Ã®n arhitecturile de alegere, unde utilizatorii au fost influenÈ›aÈ›i sÄƒ facÄƒ alegeri potenÈ›ial dÄƒunÄƒtoare. |
| **ConfidenÈ›ialitatea datelor È™i drepturile utilizatorilor** | 2021 - [BreÈ™a de date Facebook](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) a expus datele a 530M de utilizatori, rezultÃ¢nd Ã®ntr-o soluÈ›ionare de 5B cÄƒtre FTC. Cu toate acestea, Facebook a refuzat sÄƒ notifice utilizatorii despre breÈ™Äƒ, Ã®ncÄƒlcÃ¢nd drepturile utilizatorilor privind transparenÈ›a È™i accesul la date. |

DoriÈ›i sÄƒ exploraÈ›i mai multe studii de caz? ConsultaÈ›i aceste resurse:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - dileme etice din diverse industrii.
* [Cursul de eticÄƒ Ã®n È™tiinÈ›a datelor](https://www.coursera.org/learn/data-science-ethics#syllabus) - studii de caz de referinÈ›Äƒ explorate.
* [Unde lucrurile au mers prost](https://deon.drivendata.org/examples/) - checklist-ul Deon cu exemple.

> ğŸš¨ GÃ¢ndiÈ›i-vÄƒ la studiile de caz pe care le-aÈ›i vÄƒzut - aÈ›i experimentat sau aÈ›i fost afectaÈ›i de o provocare eticÄƒ similarÄƒ Ã®n viaÈ›a voastrÄƒ? PuteÈ›i sÄƒ vÄƒ gÃ¢ndiÈ›i la cel puÈ›in un alt studiu de caz care ilustreazÄƒ una dintre provocÄƒrile etice discutate Ã®n aceastÄƒ secÈ›iune?

## EticÄƒ aplicatÄƒ

Am discutat despre concepte etice, provocÄƒri È™i studii de caz Ã®n contexte reale. Dar cum Ã®ncepem sÄƒ _aplicÄƒm_ principiile È™i practicile etice Ã®n proiectele noastre? È˜i cum _operaÈ›ionalizÄƒm_ aceste practici pentru o guvernanÈ›Äƒ mai bunÄƒ? SÄƒ explorÄƒm cÃ¢teva soluÈ›ii reale:

### 1. Coduri profesionale

Codurile profesionale oferÄƒ o opÈ›iune pentru organizaÈ›ii de a "motiva" membrii sÄƒ susÈ›inÄƒ principiile etice È™i declaraÈ›ia de misiune. Codurile sunt _ghiduri morale_ pentru comportamentul profesional, ajutÃ¢nd angajaÈ›ii sau membrii sÄƒ ia decizii care se aliniazÄƒ cu principiile organizaÈ›iei lor. Ele sunt eficiente doar Ã®n mÄƒsura Ã®n care membrii le respectÄƒ voluntar; cu toate acestea, multe organizaÈ›ii oferÄƒ recompense È™i penalitÄƒÈ›i suplimentare pentru a motiva respectarea codurilor.

Exemple includ:

* [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Cod de EticÄƒ
* [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Cod de ConduitÄƒ (creat Ã®n 2013)
* [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (din 1993)

> ğŸš¨ FaceÈ›i parte dintr-o organizaÈ›ie profesionalÄƒ de inginerie sau È™tiinÈ›a datelor? ExploraÈ›i site-ul lor pentru a vedea dacÄƒ definesc un cod profesional de eticÄƒ. Ce spune acesta despre principiile lor etice? Cum "motiveazÄƒ" membrii sÄƒ respecte codul?

### 2. Liste de verificare eticÄƒ

Ãn timp ce codurile profesionale definesc comportamentul _etic_ necesar de la practicieni, ele [au limitÄƒri cunoscute](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) Ã®n aplicare, Ã®n special Ã®n proiectele de mare amploare. Ãn schimb, mulÈ›i experÈ›i Ã®n È™tiinÈ›a datelor [pledeazÄƒ pentru liste de verificare](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), care pot **conecta principiile cu practicile** Ã®ntr-un mod mai determinist È™i acÈ›ionabil.

Listele de verificare transformÄƒ Ã®ntrebÄƒrile Ã®n sarcini "da/nu" care pot fi operaÈ›ionalizate, permiÈ›Ã¢ndu-le sÄƒ fie urmÄƒrite ca parte a fluxurilor de lucru standard pentru lansarea produselor.

Exemple includ:
* [Deon](https://deon.drivendata.org/) - o listÄƒ generalÄƒ de verificare pentru etica datelor creatÄƒ din [recomandÄƒri din industrie](https://deon.drivendata.org/#checklist-citations) cu un instrument de linie de comandÄƒ pentru integrare uÈ™oarÄƒ.
* [Lista de verificare pentru auditul confidenÈ›ialitÄƒÈ›ii](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - oferÄƒ orientÄƒri generale pentru practicile de manipulare a informaÈ›iilor din perspective legale È™i sociale.
* [Lista de verificare pentru corectitudinea AI](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - creatÄƒ de practicieni AI pentru a sprijini adoptarea È™i integrarea verificÄƒrilor de corectitudine Ã®n ciclurile de dezvoltare AI.
* [22 de Ã®ntrebÄƒri pentru etica Ã®n date È™i AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - cadru mai deschis, structurat pentru explorarea iniÈ›ialÄƒ a problemelor etice Ã®n design, implementare È™i contexte organizaÈ›ionale.

### 3. ReglementÄƒri etice

Etica Ã®nseamnÄƒ definirea valorilor comune È™i a acÈ›iunilor corecte _voluntar_. **Conformitatea** Ã®nseamnÄƒ _respectarea legii_ acolo unde este definitÄƒ. **GuvernanÈ›a** acoperÄƒ Ã®n general toate modalitÄƒÈ›ile prin care organizaÈ›iile opereazÄƒ pentru a aplica principiile etice È™i pentru a respecta legile stabilite.

AstÄƒzi, guvernanÈ›a ia douÄƒ forme Ã®n cadrul organizaÈ›iilor. Ãn primul rÃ¢nd, este vorba despre definirea principiilor **AI etice** È™i stabilirea practicilor pentru a operaÈ›ionaliza adoptarea Ã®n toate proiectele legate de AI din organizaÈ›ie. Ãn al doilea rÃ¢nd, este vorba despre respectarea tuturor reglementÄƒrilor guvernamentale **privind protecÈ›ia datelor** pentru regiunile Ã®n care opereazÄƒ.

Exemple de reglementÄƒri privind protecÈ›ia datelor È™i confidenÈ›ialitatea:
* `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - reglementeazÄƒ colectarea, utilizarea È™i divulgarea informaÈ›iilor personale de cÄƒtre _guvernul federal_.
* `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - protejeazÄƒ datele personale de sÄƒnÄƒtate.
* `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - protejeazÄƒ confidenÈ›ialitatea datelor copiilor sub 13 ani.
* `2018`, [Regulamentul General privind ProtecÈ›ia Datelor (GDPR)](https://gdpr-info.eu/) - oferÄƒ drepturi utilizatorilor, protecÈ›ia datelor È™i confidenÈ›ialitate.
* `2018`, [California Consumer Privacy Act (CCPA)](https://www.oag.ca.gov/privacy/ccpa) oferÄƒ consumatorilor mai multe _drepturi_ asupra datelor lor (personale).
* `2021`, [Legea privind protecÈ›ia informaÈ›iilor personale](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) din China tocmai a fost adoptatÄƒ, creÃ¢nd una dintre cele mai puternice reglementÄƒri privind confidenÈ›ialitatea datelor online la nivel mondial.

> ğŸš¨ Uniunea EuropeanÄƒ a definit GDPR (Regulamentul General privind ProtecÈ›ia Datelor), care rÄƒmÃ¢ne una dintre cele mai influente reglementÄƒri privind confidenÈ›ialitatea datelor astÄƒzi. È˜tiaÈ›i cÄƒ defineÈ™te È™i [8 drepturi ale utilizatorilor](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) pentru a proteja confidenÈ›ialitatea digitalÄƒ È™i datele personale ale cetÄƒÈ›enilor? AflaÈ›i care sunt acestea È™i de ce conteazÄƒ.

### 4. Cultura eticÄƒ

ReÈ›ineÈ›i cÄƒ existÄƒ un decalaj intangibil Ã®ntre _conformitate_ (a face suficient pentru a respecta "litera legii") È™i abordarea [problemelor sistemice](https://www.coursera.org/learn/data-science-ethics/home/week/4) (cum ar fi osificarea, asimetria informaÈ›iilor È™i nedreptatea distribuÈ›ionalÄƒ) care pot accelera utilizarea abuzivÄƒ a AI.

Acesta din urmÄƒ necesitÄƒ [abordÄƒri colaborative pentru definirea culturilor etice](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f) care construiesc conexiuni emoÈ›ionale È™i valori comune consistente _Ã®n cadrul organizaÈ›iilor_ din industrie. Acest lucru necesitÄƒ mai multe [culturi etice formalizate](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) Ã®n organizaÈ›ii - permiÈ›Ã¢nd _oricui_ sÄƒ [tragÄƒ cordonul Andon](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (pentru a ridica preocupÄƒri etice devreme Ã®n proces) È™i fÄƒcÃ¢nd _evaluÄƒrile etice_ (de exemplu, Ã®n angajare) un criteriu de bazÄƒ pentru formarea echipelor Ã®n proiectele AI.

---
## [Quiz post-lecturÄƒ](https://ff-quizzes.netlify.app/en/ds/quiz/3) ğŸ¯
## Recapitulare È™i studiu individual

Cursurile È™i cÄƒrÈ›ile ajutÄƒ la Ã®nÈ›elegerea conceptelor È™i provocÄƒrilor etice de bazÄƒ, Ã®n timp ce studiile de caz È™i instrumentele ajutÄƒ la practicile de eticÄƒ aplicatÄƒ Ã®n contexte reale. IatÄƒ cÃ¢teva resurse pentru a Ã®ncepe.
* [Machine Learning For Beginners](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - lecÈ›ie despre Echitate, de la Microsoft.  
* [Principiile InteligenÈ›ei Artificiale Responsabile](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - parcurs de Ã®nvÄƒÈ›are gratuit de la Microsoft Learn.  
* [EticÄƒ È™i È˜tiinÈ›a Datelor](https://resources.oreilly.com/examples/0636920203964) - EBook O'Reilly (M. Loukides, H. Mason È™i alÈ›ii).  
* [Etica È˜tiinÈ›ei Datelor](https://www.coursera.org/learn/data-science-ethics#syllabus) - curs online de la Universitatea din Michigan.  
* [Etica ExplicatÄƒ](https://ethicsunwrapped.utexas.edu/case-studies) - studii de caz de la Universitatea din Texas.  

# TemÄƒ  

[Scrie un Studiu de Caz despre Etica Datelor](assignment.md)  

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim sÄƒ asigurÄƒm acurateÈ›ea, vÄƒ rugÄƒm sÄƒ fiÈ›i conÈ™tienÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original Ã®n limba sa natalÄƒ ar trebui considerat sursa autoritarÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea profesionalÄƒ realizatÄƒ de un specialist. Nu ne asumÄƒm responsabilitatea pentru eventualele neÃ®nÈ›elegeri sau interpretÄƒri greÈ™ite care pot apÄƒrea din utilizarea acestei traduceri.