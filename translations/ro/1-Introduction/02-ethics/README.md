<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8796f41f566a0a8ebb72863a83d558ed",
  "translation_date": "2025-08-26T15:09:53+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "ro"
}
-->
# Introducere Ã®n Etica Datelor

|![ Sketchnote de [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Etica Ã®n È˜tiinÈ›a Datelor - _Sketchnote de [@nitya](https://twitter.com/nitya)_ |

---

Suntem cu toÈ›ii cetÄƒÈ›eni ai datelor, trÄƒind Ã®ntr-o lume dominatÄƒ de acestea.

TendinÈ›ele pieÈ›ei ne aratÄƒ cÄƒ, pÃ¢nÄƒ Ã®n 2022, 1 din 3 organizaÈ›ii mari va cumpÄƒra È™i vinde date prin intermediul [PieÈ›elor È™i Schimburilor online](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Ca **Dezvoltatori de AplicaÈ›ii**, vom gÄƒsi mai uÈ™or È™i mai ieftin sÄƒ integrÄƒm perspective bazate pe date È™i automatizÄƒri bazate pe algoritmi Ã®n experienÈ›ele zilnice ale utilizatorilor. Dar, pe mÄƒsurÄƒ ce AI devine omniprezent, va trebui sÄƒ Ã®nÈ›elegem È™i potenÈ›ialele daune cauzate de [utilizarea abuzivÄƒ](https://www.youtube.com/watch?v=TQHs8SA1qpk) a acestor algoritmi la scarÄƒ largÄƒ.

TendinÈ›ele indicÄƒ, de asemenea, cÄƒ vom crea È™i consuma peste [180 de zettabytes](https://www.statista.com/statistics/871513/worldwide-data-created/) de date pÃ¢nÄƒ Ã®n 2025. Ca **Oameni de È˜tiinÈ›Äƒ ai Datelor**, acest lucru ne oferÄƒ un acces fÄƒrÄƒ precedent la date personale. Aceasta Ã®nseamnÄƒ cÄƒ putem construi profiluri comportamentale ale utilizatorilor È™i influenÈ›a luarea deciziilor Ã®ntr-un mod care creeazÄƒ o [iluzie a alegerii libere](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice), Ã®n timp ce, posibil, Ã®i ghidÄƒm pe utilizatori cÄƒtre rezultate pe care le preferÄƒm. De asemenea, ridicÄƒ Ã®ntrebÄƒri mai ample despre confidenÈ›ialitatea datelor È™i protecÈ›ia utilizatorilor.

Etica datelor reprezintÄƒ acum _ghiduri necesare_ pentru È™tiinÈ›a È™i ingineria datelor, ajutÃ¢ndu-ne sÄƒ minimizÄƒm potenÈ›ialele daune È™i consecinÈ›ele neintenÈ›ionate ale acÈ›iunilor noastre bazate pe date. [Ciclul de Hype Gartner pentru AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) identificÄƒ tendinÈ›e relevante Ã®n etica digitalÄƒ, AI responsabil È™i guvernanÈ›a AI ca factori cheie pentru megatendinÈ›ele mai mari legate de _democratizarea_ È™i _industrializarea_ AI.

![Ciclul de Hype Gartner pentru AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

Ãn aceastÄƒ lecÈ›ie, vom explora domeniul fascinant al eticii datelor - de la concepte È™i provocÄƒri de bazÄƒ, la studii de caz È™i concepte aplicate de AI, cum ar fi guvernanÈ›a - care ajutÄƒ la stabilirea unei culturi etice Ã®n echipele È™i organizaÈ›iile care lucreazÄƒ cu date È™i AI.

## [Chestionar Ã®nainte de lecÈ›ie](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/2) ğŸ¯

## DefiniÈ›ii de BazÄƒ

SÄƒ Ã®ncepem prin a Ã®nÈ›elege terminologia de bazÄƒ.

CuvÃ¢ntul "eticÄƒ" provine din [cuvÃ¢ntul grecesc "ethikos"](https://en.wikipedia.org/wiki/Ethics) (È™i rÄƒdÄƒcina sa "ethos"), care Ã®nseamnÄƒ _caracter sau naturÄƒ moralÄƒ_.

**Etica** se referÄƒ la valorile comune È™i principiile morale care ne guverneazÄƒ comportamentul Ã®n societate. Etica nu se bazeazÄƒ pe legi, ci pe norme larg acceptate despre ceea ce este "corect vs. greÈ™it". TotuÈ™i, consideraÈ›iile etice pot influenÈ›a iniÈ›iativele de guvernanÈ›Äƒ corporativÄƒ È™i reglementÄƒrile guvernamentale care creeazÄƒ mai multe stimulente pentru conformitate.

**Etica Datelor** este o [ramurÄƒ nouÄƒ a eticii](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1) care "studiazÄƒ È™i evalueazÄƒ problemele morale legate de _date, algoritmi È™i practicile corespunzÄƒtoare_". Aici, **"datele"** se concentreazÄƒ pe acÈ›iuni legate de generare, Ã®nregistrare, curare, procesare, diseminare, partajare È™i utilizare, **"algoritmii"** se concentreazÄƒ pe AI, agenÈ›i, Ã®nvÄƒÈ›are automatÄƒ È™i roboÈ›i, iar **"practicile"** se concentreazÄƒ pe subiecte precum inovaÈ›ia responsabilÄƒ, programarea, hacking-ul È™i codurile de eticÄƒ.

**Etica AplicatÄƒ** este [aplicarea practicÄƒ a consideraÈ›iilor morale](https://en.wikipedia.org/wiki/Applied_ethics). Este procesul de investigare activÄƒ a problemelor etice Ã®n contextul _acÈ›iunilor, produselor È™i proceselor din lumea realÄƒ_ È™i de luare a mÄƒsurilor corective pentru a ne asigura cÄƒ acestea rÄƒmÃ¢n aliniate cu valorile noastre etice definite.

**Cultura Eticii** se referÄƒ la [_operaÈ›ionalizarea_ eticii aplicate](https://hbr.org/2019/05/how-to-design-an-ethical-organization) pentru a ne asigura cÄƒ principiile È™i practicile noastre etice sunt adoptate Ã®ntr-un mod consecvent È™i scalabil Ã®n Ã®ntreaga organizaÈ›ie. Culturile etice de succes definesc principii etice la nivel organizaÈ›ional, oferÄƒ stimulente semnificative pentru conformitate È™i Ã®ntÄƒresc normele etice prin Ã®ncurajarea È™i amplificarea comportamentelor dorite la fiecare nivel al organizaÈ›iei.

## Concepte de EticÄƒ

Ãn aceastÄƒ secÈ›iune, vom discuta concepte precum **valori comune** (principii) È™i **provocÄƒri etice** (probleme) pentru etica datelor - È™i vom explora **studii de caz** care te ajutÄƒ sÄƒ Ã®nÈ›elegi aceste concepte Ã®n contexte din lumea realÄƒ.

### 1. Principiile Eticii

Fiecare strategie de eticÄƒ a datelor Ã®ncepe prin definirea _principiilor etice_ - "valorile comune" care descriu comportamentele acceptabile È™i ghideazÄƒ acÈ›iunile conforme Ã®n proiectele noastre de date È™i AI. Acestea pot fi definite la nivel individual sau de echipÄƒ. TotuÈ™i, majoritatea organizaÈ›iilor mari le contureazÄƒ Ã®ntr-o declaraÈ›ie de misiune sau un cadru de _AI etic_ definit la nivel corporativ È™i aplicat consecvent Ã®n toate echipele.

**Exemplu:** DeclaraÈ›ia de misiune [AI Responsabil](https://www.microsoft.com/en-us/ai/responsible-ai) a Microsoft spune: _"Suntem dedicaÈ›i avansÄƒrii AI ghidatÄƒ de principii etice care pun oamenii pe primul loc"_ - identificÃ¢nd 6 principii etice Ã®n cadrul de mai jos:

![AI Responsabil la Microsoft](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

SÄƒ explorÄƒm pe scurt aceste principii. _TransparenÈ›a_ È™i _responsabilitatea_ sunt valori fundamentale pe care se construiesc celelalte principii - aÈ™a cÄƒ sÄƒ Ã®ncepem cu acestea:

* [**Responsabilitate**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) face practicienii _responsabili_ pentru operaÈ›iunile lor de date È™i AI È™i pentru conformitatea cu aceste principii etice.
* [**TransparenÈ›Äƒ**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) asigurÄƒ cÄƒ acÈ›iunile bazate pe date È™i AI sunt _uÈ™or de Ã®nÈ›eles_ (interpretabile) pentru utilizatori, explicÃ¢nd ce È™i de ce Ã®n spatele deciziilor.
* [**Corectitudine**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - se concentreazÄƒ pe asigurarea faptului cÄƒ AI trateazÄƒ _toÈ›i oamenii_ Ã®n mod echitabil, abordÃ¢nd orice prejudecÄƒÈ›i sistemice sau implicite Ã®n date È™i sisteme.
* [**Fiabilitate È™i SiguranÈ›Äƒ**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - asigurÄƒ cÄƒ AI se comportÄƒ _conform_ valorilor definite, minimizÃ¢nd potenÈ›ialele daune sau consecinÈ›e neintenÈ›ionate.
* [**ConfidenÈ›ialitate È™i Securitate**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - se referÄƒ la Ã®nÈ›elegerea provenienÈ›ei datelor È™i la oferirea de _protecÈ›ii legate de confidenÈ›ialitatea datelor_ utilizatorilor.
* [**Incluziune**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - se referÄƒ la proiectarea soluÈ›iilor AI cu intenÈ›ie, adaptÃ¢ndu-le pentru a rÄƒspunde unei _gama largÄƒ de nevoi È™i capacitÄƒÈ›i umane_.

> ğŸš¨ GÃ¢ndeÈ™te-te la ce ar putea fi declaraÈ›ia ta de misiune pentru etica datelor. ExploreazÄƒ cadrele de AI etic ale altor organizaÈ›ii - iatÄƒ exemple de la [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles) È™i [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Ce valori comune au Ã®n comun? Cum se raporteazÄƒ aceste principii la produsul AI sau industria Ã®n care opereazÄƒ?

### 2. ProvocÄƒri Etice

OdatÄƒ ce avem definite principiile etice, urmÄƒtorul pas este sÄƒ evaluÄƒm acÈ›iunile noastre legate de date È™i AI pentru a vedea dacÄƒ acestea se aliniazÄƒ cu valorile comune. GÃ¢ndeÈ™te-te la acÈ›iunile tale Ã®n douÄƒ categorii: _colectarea datelor_ È™i _proiectarea algoritmilor_.

Ãn cazul colectÄƒrii datelor, acÈ›iunile vor implica probabil **date personale** sau informaÈ›ii de identificare personalÄƒ (PII) pentru indivizi identificabili. Acestea includ [diverse elemente de date non-personale](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) care, _Ã®mpreunÄƒ_, identificÄƒ un individ. ProvocÄƒrile etice pot fi legate de _confidenÈ›ialitatea datelor_, _proprietatea datelor_ È™i subiecte conexe precum _consimÈ›ÄƒmÃ¢ntul informat_ È™i _drepturile de proprietate intelectualÄƒ_ ale utilizatorilor.

Ãn cazul proiectÄƒrii algoritmilor, acÈ›iunile vor implica colectarea È™i curarea **seturilor de date**, apoi utilizarea acestora pentru a antrena È™i implementa **modele de date** care prezic rezultate sau automatizeazÄƒ decizii Ã®n contexte din lumea realÄƒ. ProvocÄƒrile etice pot apÄƒrea din _prejudecÄƒÈ›i Ã®n seturile de date_, probleme de _calitate a datelor_, _inechitate_ È™i _reprezentare greÈ™itÄƒ_ Ã®n algoritmi - inclusiv unele probleme care sunt sistemice.

Ãn ambele cazuri, provocÄƒrile etice evidenÈ›iazÄƒ zonele Ã®n care acÈ›iunile noastre pot intra Ã®n conflict cu valorile comune. Pentru a detecta, atenua, minimiza sau elimina aceste preocupÄƒri, trebuie sÄƒ punem Ã®ntrebÄƒri morale de tip "da/nu" legate de acÈ›iunile noastre, apoi sÄƒ luÄƒm mÄƒsuri corective, dupÄƒ caz. SÄƒ analizÄƒm cÃ¢teva provocÄƒri etice È™i Ã®ntrebÄƒrile morale pe care le ridicÄƒ:

#### 2.1 Proprietatea Datelor

Colectarea datelor implicÄƒ adesea date personale care pot identifica subiecÈ›ii datelor. [Proprietatea datelor](https://permission.io/blog/data-ownership) se referÄƒ la _controlul_ È™i [_drepturile utilizatorilor_](https://permission.io/blog/data-ownership) legate de crearea, procesarea È™i diseminarea datelor.

ÃntrebÄƒrile morale pe care trebuie sÄƒ le punem sunt:
 * Cine deÈ›ine datele? (utilizatorul sau organizaÈ›ia)
 * Ce drepturi au subiecÈ›ii datelor? (ex: acces, È™tergere, portabilitate)
 * Ce drepturi au organizaÈ›iile? (ex: rectificarea recenziilor utilizatorilor maliÈ›ioase)

#### 2.2 ConsimÈ›ÄƒmÃ¢ntul Informat

[ConsimÈ›ÄƒmÃ¢ntul informat](https://legaldictionary.net/informed-consent/) defineÈ™te actul prin care utilizatorii sunt de acord cu o acÈ›iune (cum ar fi colectarea datelor) cu o _Ã®nÈ›elegere completÄƒ_ a faptelor relevante, inclusiv scopul, riscurile potenÈ›iale È™i alternativele.

ÃntrebÄƒrile de explorat aici sunt:
 * A oferit utilizatorul (subiectul datelor) permisiunea pentru captarea È™i utilizarea datelor?
 * A Ã®nÈ›eles utilizatorul scopul pentru care au fost capturate datele?
 * A Ã®nÈ›eles utilizatorul riscurile potenÈ›iale ale participÄƒrii lor?

#### 2.3 Proprietatea IntelectualÄƒ

[Proprietatea intelectualÄƒ](https://en.wikipedia.org/wiki/Intellectual_property) se referÄƒ la creaÈ›ii intangibile rezultate din iniÈ›iativa umanÄƒ, care pot _avea valoare economicÄƒ_ pentru indivizi sau afaceri.

ÃntrebÄƒrile de explorat aici sunt:
 * Datele colectate aveau valoare economicÄƒ pentru un utilizator sau o afacere?
 * Are **utilizatorul** drepturi de proprietate intelectualÄƒ aici?
 * Are **organizaÈ›ia** drepturi de proprietate intelectualÄƒ aici?
 * DacÄƒ aceste drepturi existÄƒ, cum le protejÄƒm?

#### 2.4 ConfidenÈ›ialitatea Datelor

[ConfidenÈ›ialitatea datelor](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) sau confidenÈ›ialitatea informaÈ›iilor se referÄƒ la pÄƒstrarea confidenÈ›ialitÄƒÈ›ii utilizatorilor È™i protecÈ›ia identitÄƒÈ›ii acestora Ã®n ceea ce priveÈ™te informaÈ›iile de identificare personalÄƒ.

ÃntrebÄƒrile de explorat aici sunt:
 * Sunt datele (personale) ale utilizatorilor securizate Ã®mpotriva atacurilor È™i scurgerilor?
 * Sunt datele utilizatorilor accesibile doar utilizatorilor È™i contextelor autorizate?
 * Este pÄƒstratÄƒ anonimitatea utilizatorilor atunci cÃ¢nd datele sunt partajate sau diseminate?
 * Poate un utilizator fi de-identificat din seturi de date anonimizate?

#### 2.5 Dreptul de a Fi Uitati

[Dreptul de a Fi Uitati](https://en.wikipedia.org/wiki/Right_to_be_forgotten) sau [Dreptul la È˜tergere](https://www.gdpreu.org/right-to-be-forgotten/) oferÄƒ protecÈ›ie suplimentarÄƒ datelor personale ale utilizatorilor. Ãn mod specific, oferÄƒ utilizatorilor dreptul de a solicita È™tergerea sau eliminarea datelor personale din cÄƒutÄƒrile pe Internet È™i alte locaÈ›ii, _Ã®n anumite circumstanÈ›e_ - permiÈ›Ã¢ndu-le un nou Ã®nceput online fÄƒrÄƒ ca acÈ›iunile trecute sÄƒ fie folosite Ã®mpotriva lor.

ÃntrebÄƒrile de explorat aici sunt:
 * Permite sistemul subiecÈ›ilor datelor sÄƒ solicite È™tergerea?
 * Ar trebui retragerea consimÈ›ÄƒmÃ¢ntului utilizatorului sÄƒ declanÈ™eze È™tergerea automatÄƒ?
 * Au fost datele colectate fÄƒrÄƒ consimÈ›ÄƒmÃ¢nt sau prin mijloace ilegale?
 * Suntem conformi cu reglementÄƒrile guvernamentale privind confidenÈ›ialitatea datelor?

#### 2.6 PrejudecÄƒÈ›i Ã®n Seturile de Date

PrejudecÄƒÈ›ile Ã®n seturile de date sau [PrejudecÄƒÈ›ile de Colectare](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) se referÄƒ la selectarea unui subset _nereprezentativ_ de date pentru dezvoltarea algoritmilor, creÃ¢nd potenÈ›ial inechitÄƒÈ›i Ã®n rezultatele pentru grupuri diverse. Tipurile de prejudecÄƒÈ›i includ prejudecÄƒÈ›i de selecÈ›ie sau eÈ™antionare, prejudecÄƒÈ›i ale voluntarilor È™i prejudecÄƒÈ›i ale instrumentelor.

ÃntrebÄƒrile de explorat aici sunt:
 * Am recrutat un set reprezentativ de subiecÈ›i ai datelor?
 * Am testat setul nostru de date colectat sau curat pentru diverse prejudecÄƒÈ›i?
 * Putem atenua sau elimina prejudecÄƒÈ›ile descoperite?

#### 2.7 Calitatea Datelor

[Calitatea Datelor](https://lakefs.io/data-quality-testing/) analizeazÄƒ validitatea setului de date curat utilizat pentru dezvoltarea algoritmilor noÈ™tri, verificÃ¢nd dacÄƒ caracteristicile È™i Ã®nregistrÄƒrile Ã®ndeplinesc cerinÈ›ele pentru nivelul de acurateÈ›e È™i consistenÈ›Äƒ necesar scopului nostru AI.

ÃntrebÄƒrile de explorat aici sunt:
 * Am capturat caracteristici valide pentru cazul nostru de utilizare?
 * Au fost datele capturate Ã®n mod _consistent_ din surse de date diverse?
 * Este setul de date _complet_ pentru condiÈ›ii sau scenarii diverse?
 * Este informaÈ›ia capturatÄƒ _exactÄƒ_ Ã®n reflectarea realitÄƒÈ›ii?

#### 2.8 Corectitudinea Algorit
[Algorithm Fairness](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) verificÄƒ dacÄƒ designul algoritmului discrimineazÄƒ sistematic Ã®mpotriva unor subgrupuri specifice de subiecÈ›i de date, conducÃ¢nd la [posibile prejudicii](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) Ã®n _alocare_ (unde resursele sunt refuzate sau reÈ›inute de la acel grup) È™i _calitatea serviciului_ (unde AI nu este la fel de precis pentru unele subgrupuri ca pentru altele).

ÃntrebÄƒri de explorat aici sunt:
 * Am evaluat acurateÈ›ea modelului pentru subgrupuri È™i condiÈ›ii diverse?
 * Am analizat sistemul pentru posibile prejudicii (de exemplu, stereotipuri)?
 * Putem revizui datele sau reantrena modelele pentru a atenua prejudiciile identificate?

ExploraÈ›i resurse precum [listele de verificare pentru echitatea AI](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) pentru a afla mai multe.

#### 2.9 Denaturarea datelor

[Denaturarea datelor](https://www.sciencedirect.com/topics/computer-science/misrepresentation) se referÄƒ la Ã®ntrebarea dacÄƒ comunicÄƒm informaÈ›ii din date raportate onest Ã®ntr-un mod Ã®nÈ™elÄƒtor pentru a susÈ›ine o naraÈ›iune doritÄƒ.

ÃntrebÄƒri de explorat aici sunt:
 * RaportÄƒm date incomplete sau inexacte?
 * VizualizÄƒm datele Ã®ntr-un mod care conduce la concluzii Ã®nÈ™elÄƒtoare?
 * Folosim tehnici statistice selective pentru a manipula rezultatele?
 * ExistÄƒ explicaÈ›ii alternative care ar putea oferi o concluzie diferitÄƒ?

#### 2.10 Alegerea liberÄƒ
[Iluzia alegerii libere](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) apare atunci cÃ¢nd â€arhitecturile de alegereâ€ ale sistemului folosesc algoritmi de luare a deciziilor pentru a influenÈ›a oamenii sÄƒ ia un rezultat preferat, Ã®n timp ce par sÄƒ le ofere opÈ›iuni È™i control. Aceste [modele Ã®ntunecate](https://www.darkpatterns.org/) pot provoca prejudicii sociale È™i economice utilizatorilor. Deoarece deciziile utilizatorilor influenÈ›eazÄƒ profilurile comportamentale, aceste acÈ›iuni potenÈ›ial conduc la alegeri viitoare care amplificÄƒ sau extind impactul acestor prejudicii.

ÃntrebÄƒri de explorat aici sunt:
 * A Ã®nÈ›eles utilizatorul implicaÈ›iile luÄƒrii acelei decizii?
 * Era utilizatorul conÈ™tient de (alte) opÈ›iuni È™i de avantajele È™i dezavantajele fiecÄƒreia?
 * Poate utilizatorul sÄƒ revoce o alegere automatÄƒ sau influenÈ›atÄƒ ulterior?

### 3. Studii de caz

Pentru a pune aceste provocÄƒri etice Ã®n contexte din lumea realÄƒ, este util sÄƒ analizÄƒm studii de caz care evidenÈ›iazÄƒ posibilele prejudicii È™i consecinÈ›e asupra indivizilor È™i societÄƒÈ›ii atunci cÃ¢nd astfel de Ã®ncÄƒlcÄƒri etice sunt trecute cu vederea.

IatÄƒ cÃ¢teva exemple:

| Provocare eticÄƒ | Studiu de caz  | 
|--- |--- |
| **ConsimÈ›ÄƒmÃ¢nt informat** | 1972 - [Studiul Tuskegee despre sifilis](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - BÄƒrbaÈ›i afro-americani care au participat la studiu au fost promiÈ™i Ã®ngrijire medicalÄƒ gratuitÄƒ, _dar au fost Ã®nÈ™elaÈ›i_ de cercetÄƒtori care nu i-au informat despre diagnostic sau despre disponibilitatea tratamentului. MulÈ›i subiecÈ›i au murit, iar partenerii sau copiii lor au fost afectaÈ›i; studiul a durat 40 de ani. | 
| **ConfidenÈ›ialitatea datelor** |  2007 - [Premiul pentru date Netflix](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) a oferit cercetÄƒtorilor _10 milioane de evaluÄƒri anonimizate de filme de la 50.000 de clienÈ›i_ pentru a Ã®mbunÄƒtÄƒÈ›i algoritmii de recomandare. TotuÈ™i, cercetÄƒtorii au reuÈ™it sÄƒ coreleze datele anonimizate cu date identificabile personal din _seturi de date externe_ (de exemplu, comentarii IMDb) - â€de-anonimizÃ¢ndâ€ efectiv unii abonaÈ›i Netflix.|
| **PÄƒrtinire Ã®n colectarea datelor**  | 2013 - OraÈ™ul Boston a [dezvoltat Street Bump](https://www.boston.gov/transportation/street-bump), o aplicaÈ›ie care permitea cetÄƒÈ›enilor sÄƒ raporteze gropi, oferind oraÈ™ului date mai bune despre drumuri pentru a identifica È™i repara problemele. TotuÈ™i, [persoanele din grupuri cu venituri mai mici aveau mai puÈ›in acces la maÈ™ini È™i telefoane](https://hbr.org/2013/04/the-hidden-biases-in-big-data), fÄƒcÃ¢nd problemele lor de infrastructurÄƒ invizibile Ã®n aceastÄƒ aplicaÈ›ie. Dezvoltatorii au colaborat cu academicieni pentru a aborda problemele de _acces echitabil È™i diviziuni digitale_ pentru echitate. |
| **Echitatea algoritmicÄƒ**  | 2018 - Studiul MIT [Gender Shades](http://gendershades.org/overview.html) a evaluat acurateÈ›ea produselor AI de clasificare a genului, expunÃ¢nd lacunele Ã®n acurateÈ›e pentru femei È™i persoane de culoare. Un [card Apple din 2019](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) pÄƒrea sÄƒ ofere mai puÈ›in credit femeilor decÃ¢t bÄƒrbaÈ›ilor. Ambele au ilustrat probleme de pÄƒrtinire algoritmicÄƒ care duc la prejudicii socio-economice.|
| **Denaturarea datelor** | 2020 - [Departamentul de SÄƒnÄƒtate PublicÄƒ din Georgia a publicat grafice COVID-19](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) care pÄƒreau sÄƒ inducÄƒ Ã®n eroare cetÄƒÈ›enii despre tendinÈ›ele cazurilor confirmate prin ordonarea necronologicÄƒ pe axa x. Acest lucru ilustreazÄƒ denaturarea prin trucuri de vizualizare. |
| **Iluzia alegerii libere** | 2020 - AplicaÈ›ia educaÈ›ionalÄƒ [ABCmouse a plÄƒtit 10 milioane de dolari pentru a soluÈ›iona o plÃ¢ngere FTC](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/) Ã®n care pÄƒrinÈ›ii au fost prinÈ™i Ã®n abonamente pe care nu le puteau anula. Acest lucru ilustreazÄƒ modelele Ã®ntunecate Ã®n arhitecturile de alegere, unde utilizatorii au fost influenÈ›aÈ›i spre alegeri potenÈ›ial dÄƒunÄƒtoare. |
| **ConfidenÈ›ialitatea datelor È™i drepturile utilizatorilor** | 2021 - [Scurgerea de date Facebook](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) a expus datele a 530 de milioane de utilizatori, rezultÃ¢nd Ã®ntr-o amendÄƒ de 5 miliarde de dolari cÄƒtre FTC. TotuÈ™i, compania a refuzat sÄƒ notifice utilizatorii despre breÈ™Äƒ, Ã®ncÄƒlcÃ¢nd drepturile utilizatorilor privind transparenÈ›a È™i accesul la date. |

DoriÈ›i sÄƒ exploraÈ›i mai multe studii de caz? ConsultaÈ›i aceste resurse:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - dileme etice din diverse industrii. 
* [Cursul de eticÄƒ Ã®n È™tiinÈ›a datelor](https://www.coursera.org/learn/data-science-ethics#syllabus) - studii de caz emblematice explorate.
* [Unde lucrurile au mers prost](https://deon.drivendata.org/examples/) - lista de verificare Deon cu exemple.

> ğŸš¨ GÃ¢ndiÈ›i-vÄƒ la studiile de caz pe care le-aÈ›i vÄƒzut - aÈ›i experimentat sau aÈ›i fost afectaÈ›i de o provocare eticÄƒ similarÄƒ Ã®n viaÈ›a dumneavoastrÄƒ? PuteÈ›i sÄƒ vÄƒ gÃ¢ndiÈ›i la cel puÈ›in un alt studiu de caz care ilustreazÄƒ una dintre provocÄƒrile etice discutate Ã®n aceastÄƒ secÈ›iune?

## EticÄƒ aplicatÄƒ

Am discutat despre concepte etice, provocÄƒri È™i studii de caz Ã®n contexte din lumea realÄƒ. Dar cum Ã®ncepem sÄƒ _aplicÄƒm_ principiile È™i practicile etice Ã®n proiectele noastre? È˜i cum _operaÈ›ionalizÄƒm_ aceste practici pentru o mai bunÄƒ guvernanÈ›Äƒ? SÄƒ explorÄƒm cÃ¢teva soluÈ›ii din lumea realÄƒ:

### 1. Coduri profesionale

Codurile profesionale oferÄƒ o opÈ›iune pentru organizaÈ›ii de a â€stimulaâ€ membrii sÄƒ susÈ›inÄƒ principiile etice È™i declaraÈ›ia de misiune. Codurile sunt _ghiduri morale_ pentru comportamentul profesional, ajutÃ¢nd angajaÈ›ii sau membrii sÄƒ ia decizii care se aliniazÄƒ cu principiile organizaÈ›iei lor. Ele sunt eficiente doar Ã®n mÄƒsura Ã®n care membrii le respectÄƒ voluntar; totuÈ™i, multe organizaÈ›ii oferÄƒ recompense È™i penalitÄƒÈ›i suplimentare pentru a motiva conformarea.

Exemple includ:

 * [Codul de eticÄƒ Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/)
 * [Codul de conduitÄƒ al AsociaÈ›iei de È˜tiinÈ›a Datelor](http://datascienceassn.org/code-of-conduct.html) (creat Ã®n 2013)
 * [Codul de eticÄƒ È™i conduitÄƒ profesionalÄƒ ACM](https://www.acm.org/code-of-ethics) (din 1993)

> ğŸš¨ FaceÈ›i parte dintr-o organizaÈ›ie profesionalÄƒ de inginerie sau È™tiinÈ›a datelor? ExploraÈ›i site-ul lor pentru a vedea dacÄƒ definesc un cod profesional de eticÄƒ. Ce spune acesta despre principiile lor etice? Cum â€stimuleazÄƒâ€ membrii sÄƒ respecte codul?

### 2. Liste de verificare eticÄƒ

Ãn timp ce codurile profesionale definesc comportamentul _etic_ necesar practicienilor, ele [au limitÄƒri cunoscute](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) Ã®n aplicare, Ã®n special Ã®n proiectele de mare amploare. Ãn schimb, mulÈ›i experÈ›i Ã®n È™tiinÈ›a datelor [pledeazÄƒ pentru liste de verificare](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), care pot **conecta principiile la practici** Ã®ntr-un mod mai determinist È™i acÈ›ionabil.

Listele de verificare transformÄƒ Ã®ntrebÄƒrile Ã®n sarcini â€da/nuâ€ care pot fi operaÈ›ionalizate, permiÈ›Ã¢ndu-le sÄƒ fie urmÄƒrite ca parte a fluxurilor de lucru standard pentru lansarea produselor.

Exemple includ:
 * [Deon](https://deon.drivendata.org/) - o listÄƒ de verificare generalÄƒ pentru etica datelor creatÄƒ din [recomandÄƒri din industrie](https://deon.drivendata.org/#checklist-citations) cu un instrument de linie de comandÄƒ pentru integrare uÈ™oarÄƒ.
 * [Lista de verificare pentru auditul confidenÈ›ialitÄƒÈ›ii](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - oferÄƒ Ã®ndrumÄƒri generale pentru practicile de manipulare a informaÈ›iilor din perspective legale È™i sociale.
 * [Lista de verificare pentru echitatea AI](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - creatÄƒ de practicieni AI pentru a sprijini adoptarea È™i integrarea verificÄƒrilor de echitate Ã®n ciclurile de dezvoltare AI.
 * [22 de Ã®ntrebÄƒri pentru etica Ã®n date È™i AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - un cadru mai deschis, structurat pentru explorarea iniÈ›ialÄƒ a problemelor etice Ã®n design, implementare È™i contexte organizaÈ›ionale.

### 3. ReglementÄƒri etice

Etica se referÄƒ la definirea valorilor comune È™i la a face ceea ce este corect _voluntar_. **Conformitatea** se referÄƒ la _respectarea legii_ acolo unde este definitÄƒ. **GuvernanÈ›a** acoperÄƒ Ã®n general toate modurile Ã®n care organizaÈ›iile opereazÄƒ pentru a aplica principiile etice È™i pentru a respecta legile stabilite.

AstÄƒzi, guvernanÈ›a ia douÄƒ forme Ã®n cadrul organizaÈ›iilor. Ãn primul rÃ¢nd, este vorba despre definirea principiilor **AI etice** È™i stabilirea practicilor pentru a operaÈ›ionaliza adoptarea lor Ã®n toate proiectele AI ale organizaÈ›iei. Ãn al doilea rÃ¢nd, este vorba despre respectarea tuturor reglementÄƒrilor guvernamentale privind **protecÈ›ia datelor** pentru regiunile Ã®n care opereazÄƒ.

Exemple de reglementÄƒri privind protecÈ›ia È™i confidenÈ›ialitatea datelor:

 * `1974`, [Legea privind confidenÈ›ialitatea din SUA](https://www.justice.gov/opcl/privacy-act-1974) - reglementeazÄƒ colectarea, utilizarea È™i divulgarea informaÈ›iilor personale de cÄƒtre _guvernul federal_.
 * `1996`, [Legea privind portabilitatea È™i responsabilitatea asigurÄƒrilor de sÄƒnÄƒtate din SUA (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - protejeazÄƒ datele personale de sÄƒnÄƒtate.
 * `1998`, [Legea privind protecÈ›ia confidenÈ›ialitÄƒÈ›ii online a copiilor din SUA (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - protejeazÄƒ confidenÈ›ialitatea datelor copiilor sub 13 ani.
 * `2018`, [Regulamentul general privind protecÈ›ia datelor (GDPR)](https://gdpr-info.eu/) - oferÄƒ drepturi utilizatorilor, protecÈ›ia datelor È™i confidenÈ›ialitate.
 * `2018`, [Legea privind confidenÈ›ialitatea consumatorilor din California (CCPA)](https://www.oag.ca.gov/privacy/ccpa) oferÄƒ consumatorilor mai multe _drepturi_ asupra datelor lor (personale).
 * `2021`, [Legea privind protecÈ›ia informaÈ›iilor personale din China](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) tocmai a fost adoptatÄƒ, creÃ¢nd una dintre cele mai puternice reglementÄƒri privind confidenÈ›ialitatea datelor online la nivel mondial.

> ğŸš¨ Uniunea EuropeanÄƒ a definit GDPR (Regulamentul general privind protecÈ›ia datelor), care rÄƒmÃ¢ne una dintre cele mai influente reglementÄƒri privind confidenÈ›ialitatea datelor astÄƒzi. È˜tiaÈ›i cÄƒ defineÈ™te È™i [8 drepturi ale utilizatorilor](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) pentru a proteja confidenÈ›ialitatea digitalÄƒ È™i datele personale ale cetÄƒÈ›enilor? AflaÈ›i care sunt acestea È™i de ce conteazÄƒ.

### 4. Cultura eticii

ReÈ›ineÈ›i cÄƒ existÄƒ un decalaj intangibil Ã®ntre _conformitate_ (a face suficient pentru a respecta â€litera legiiâ€) È™i abordarea [problemelor sistemice](https://www.coursera.org/learn/data-science-ethics/home/week/4) (cum ar fi osificarea, asimetria informaÈ›ionalÄƒ È™i inechitatea distribuÈ›ionalÄƒ) care pot accelera utilizarea abuzivÄƒ a AI.

Acestea din urmÄƒ necesitÄƒ [abordÄƒri colaborative pentru definirea culturilor etice](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f) care construiesc conexiuni emoÈ›ionale È™i valori comune consistente _Ã®n cadrul organizaÈ›iilor_ din industrie. Acest lucru solicitÄƒ mai multe [culturi etice formalizate ale datelor](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) Ã®n organizaÈ›ii - permiÈ›Ã¢nd _oricui_ sÄƒ [tragÄƒ cablul Andon](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (pentru a ridica preocupÄƒri etice devreme Ã®n proces) È™i fÄƒcÃ¢nd _evaluÄƒrile etice_ (de exemplu, Ã®n angajare) un criteriu de bazÄƒ pentru formarea echipelor Ã®n proiectele AI.

---
## [Chestionar post-lecturÄƒ](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/3) ğŸ¯
## Recapitulare È™i studiu individual 

Cursurile È™i cÄƒrÈ›ile ajutÄƒ la Ã®nÈ›elegerea conceptelor È™i provocÄƒrilor etice de bazÄƒ, Ã®n timp ce studiile de caz È™i instrumentele ajutÄƒ la practicile de eticÄƒ aplicatÄƒ Ã®n contexte din lumea realÄƒ. IatÄƒ cÃ¢teva resurse pentru a Ã®ncepe.

* [Machine Learning For Beginners](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - lecÈ›ie despre echitate, de la Microsoft.
* [Principiile InteligenÈ›ei Artificiale Responsabile](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - parcurs de Ã®nvÄƒÈ›are gratuit de la Microsoft Learn.  
* [EticÄƒ È™i È˜tiinÈ›a Datelor](https://resources.oreilly.com/examples/0636920203964) - EBook O'Reilly (M. Loukides, H. Mason È™i alÈ›ii)  
* [Etica Ã®n È˜tiinÈ›a Datelor](https://www.coursera.org/learn/data-science-ethics#syllabus) - curs online de la Universitatea din Michigan.  
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - studii de caz de la Universitatea din Texas.  

# TemÄƒ  

[Scrie un Studiu de Caz despre Etica Datelor](assignment.md)  

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim sÄƒ asigurÄƒm acurateÈ›ea, vÄƒ rugÄƒm sÄƒ fiÈ›i conÈ™tienÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original Ã®n limba sa natalÄƒ ar trebui considerat sursa autoritarÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea profesionalÄƒ realizatÄƒ de un specialist uman. Nu ne asumÄƒm responsabilitatea pentru eventualele neÃ®nÈ›elegeri sau interpretÄƒri greÈ™ite care pot apÄƒrea din utilizarea acestei traduceri.