<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3a34157cc63516eba97c89a0b2f8c3e6",
  "translation_date": "2025-09-03T21:47:57+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "ro"
}
-->
# Introducere 칥n Etica Datelor

|![ Sketchnote de [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Etica 칥n 탲tiin탵a Datelor - _Sketchnote de [@nitya](https://twitter.com/nitya)_ |

---

Suntem cu to탵ii cet캒탵eni ai datelor, tr캒ind 칥ntr-o lume dominat캒 de acestea.

Tendin탵ele pie탵ei ne arat캒 c캒, p칙n캒 칥n 2022, 1 din 3 organiza탵ii mari va cump캒ra 탳i vinde date prin intermediul [Pia탵elor 탳i Schimburilor online](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Ca **Dezvoltatori de Aplica탵ii**, vom g캒si mai u탳or 탳i mai ieftin s캒 integr캒m perspective bazate pe date 탳i automatiz캒ri bazate pe algoritmi 칥n experien탵ele zilnice ale utilizatorilor. Dar, pe m캒sur캒 ce AI devine omniprezent, va trebui s캒 칥n탵elegem 탳i poten탵ialele daune cauzate de [utilizarea abuziv캒](https://www.youtube.com/watch?v=TQHs8SA1qpk) a acestor algoritmi la scar캒 larg캒.

Tendin탵ele indic캒, de asemenea, c캒 vom crea 탳i consuma peste [180 zettabytes](https://www.statista.com/statistics/871513/worldwide-data-created/) de date p칙n캒 칥n 2025. Ca **Oameni de 탲tiin탵a Datelor**, acest lucru ne ofer캒 un acces f캒r캒 precedent la datele personale. Aceasta 칥nseamn캒 c캒 putem construi profiluri comportamentale ale utilizatorilor 탳i influen탵a luarea deciziilor 칥n moduri care creeaz캒 o [iluzie de alegere liber캒](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice), 칥n timp ce 칥i 칥ndrum캒m, posibil, c캒tre rezultate pe care le prefer캒m. De asemenea, ridic캒 칥ntreb캒ri mai ample despre confiden탵ialitatea datelor 탳i protec탵ia utilizatorilor.

Etica datelor devine acum _un ghid necesar_ pentru 탳tiin탵a 탳i ingineria datelor, ajut칙ndu-ne s캒 minimiz캒m poten탵ialele daune 탳i consecin탵ele neinten탵ionate ale ac탵iunilor noastre bazate pe date. [Ciclul de Hype Gartner pentru AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) identific캒 tendin탵e relevante 칥n etica digital캒, AI responsabil캒 탳i guvernan탵a AI ca factori cheie pentru megatendin탵ele mai mari legate de _democratizarea_ 탳i _industrializarea_ AI.

![Ciclul de Hype Gartner pentru AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

칉n aceast캒 lec탵ie, vom explora domeniul fascinant al eticii datelor - de la concepte 탳i provoc캒ri de baz캒, la studii de caz 탳i concepte aplicate de AI, cum ar fi guvernan탵a - care ajut캒 la stabilirea unei culturi etice 칥n echipele 탳i organiza탵iile care lucreaz캒 cu date 탳i AI.

## [Chestionar 칥nainte de lec탵ie](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/2) 游꿢

## Defini탵ii de baz캒

S캒 칥ncepem prin a 칥n탵elege terminologia de baz캒.

Cuv칙ntul "etic캒" provine din [cuv칙ntul grecesc "ethikos"](https://en.wikipedia.org/wiki/Ethics) (탳i r캒d캒cina sa "ethos"), care 칥nseamn캒 _caracter sau natur캒 moral캒_.

**Etica** se refer캒 la valorile comune 탳i principiile morale care guverneaz캒 comportamentul nostru 칥n societate. Etica nu se bazeaz캒 pe legi, ci pe norme larg acceptate despre ceea ce este "corect vs. gre탳it". Totu탳i, considera탵iile etice pot influen탵a ini탵iativele de guvernan탵캒 corporativ캒 탳i reglement캒rile guvernamentale care creeaz캒 mai multe stimulente pentru conformitate.

**Etica Datelor** este o [ramur캒 nou캒 a eticii](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1) care "studiaz캒 탳i evalueaz캒 problemele morale legate de _date, algoritmi 탳i practici corespunz캒toare_". Aici, **"datele"** se concentreaz캒 pe ac탵iuni legate de generare, 칥nregistrare, curare, procesare, diseminare, partajare 탳i utilizare, **"algoritmii"** se concentreaz캒 pe AI, agen탵i, 칥nv캒탵are automat캒 탳i robo탵i, iar **"practicile"** se concentreaz캒 pe subiecte precum inova탵ia responsabil캒, programarea, hacking-ul 탳i codurile etice.

**Etica Aplicat캒** este [aplicarea practic캒 a considera탵iilor morale](https://en.wikipedia.org/wiki/Applied_ethics). Este procesul de investigare activ캒 a problemelor etice 칥n contextul _ac탵iunilor, produselor 탳i proceselor din lumea real캒_ 탳i de luare a m캒surilor corective pentru a ne asigura c캒 acestea r캒m칙n aliniate cu valorile noastre etice definite.

**Cultura Eticii** se refer캒 la [_opera탵ionalizarea_ eticii aplicate](https://hbr.org/2019/05/how-to-design-an-ethical-organization) pentru a ne asigura c캒 principiile 탳i practicile noastre etice sunt adoptate 칥ntr-un mod consistent 탳i scalabil 칥n 칥ntreaga organiza탵ie. Culturile etice de succes definesc principii etice la nivel organiza탵ional, ofer캒 stimulente semnificative pentru conformitate 탳i 칥nt캒resc normele etice prin 칥ncurajarea 탳i amplificarea comportamentelor dorite la fiecare nivel al organiza탵iei.

## Concepte Etice

칉n aceast캒 sec탵iune, vom discuta concepte precum **valori comune** (principii) 탳i **provoc캒ri etice** (probleme) pentru etica datelor - 탳i vom explora **studii de caz** care te ajut캒 s캒 칥n탵elegi aceste concepte 칥n contexte reale.

### 1. Principii Etice

Fiecare strategie de etic캒 a datelor 칥ncepe prin definirea _principiilor etice_ - "valorile comune" care descriu comportamentele acceptabile 탳i ghideaz캒 ac탵iunile conforme 칥n proiectele noastre de date 탳i AI. Acestea pot fi definite la nivel individual sau de echip캒. Totu탳i, majoritatea organiza탵iilor mari le contureaz캒 칥ntr-o declara탵ie de misiune sau cadru de _AI etic캒_ definit la nivel corporativ 탳i aplicat 칥n mod consistent 칥n toate echipele.

**Exemplu:** Declara탵ia de misiune [AI Responsabil캒](https://www.microsoft.com/en-us/ai/responsible-ai) de la Microsoft spune: _"Suntem dedica탵i avans캒rii AI ghidat캒 de principii etice care pun oamenii pe primul loc"_ - identific칙nd 6 principii etice 칥n cadrul de mai jos:

![AI Responsabil캒 la Microsoft](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

S캒 explor캒m pe scurt aceste principii. _Transparen탵a_ 탳i _responsabilitatea_ sunt valori fundamentale pe care se construiesc celelalte principii - a탳a c캒 s캒 칥ncepem cu acestea:

* [**Responsabilitatea**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) face ca practicienii s캒 fie _responsabili_ pentru opera탵iunile lor de date 탳i AI 탳i pentru conformitatea cu aceste principii etice.
* [**Transparen탵a**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) asigur캒 c캒 ac탵iunile legate de date 탳i AI sunt _u탳or de 칥n탵eles_ (interpretabile) pentru utilizatori, explic칙nd ce 탳i de ce 칥n spatele deciziilor.
* [**Corectitudinea**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - se concentreaz캒 pe asigurarea c캒 AI trateaz캒 _to탵i oamenii_ 칥n mod echitabil, abord칙nd orice prejudec캒탵i socio-tehnice sistemice sau implicite 칥n date 탳i sisteme.
* [**Fiabilitatea 탳i Siguran탵a**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - asigur캒 c캒 AI se comport캒 _consistent_ cu valorile definite, minimiz칙nd poten탵ialele daune sau consecin탵e neinten탵ionate.
* [**Confiden탵ialitatea 탳i Securitatea**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - se refer캒 la 칥n탵elegerea provenien탵ei datelor 탳i la oferirea de _protec탵ii legate de confiden탵ialitatea datelor_ utilizatorilor.
* [**Incluziunea**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - se refer캒 la proiectarea solu탵iilor AI cu inten탵ie, adapt칙ndu-le pentru a r캒spunde unei _game largi de nevoi 탳i capacit캒탵i umane_.

> 游뚿 G칙nde탳te-te la ce ar putea fi declara탵ia ta de misiune pentru etica datelor. Exploreaz캒 cadrele de AI etic캒 de la alte organiza탵ii - iat캒 exemple de la [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles) 탳i [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Ce valori comune au 칥n comun? Cum se raporteaz캒 aceste principii la produsul sau industria AI 칥n care opereaz캒?

### 2. Provoc캒ri Etice

Odat캒 ce am definit principiile etice, urm캒torul pas este s캒 evalu캒m ac탵iunile noastre legate de date 탳i AI pentru a vedea dac캒 acestea se aliniaz캒 cu valorile comune. G칙nde탳te-te la ac탵iunile tale 칥n dou캒 categorii: _colectarea datelor_ 탳i _proiectarea algoritmilor_.

칉n cazul colect캒rii datelor, ac탵iunile vor implica probabil **date personale** sau informa탵ii personale identificabile (PII) pentru indivizi identificabili. Acestea includ [diverse elemente de date non-personale](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en) care, _칥mpreun캒_, identific캒 un individ. Provoc캒rile etice pot fi legate de _confiden탵ialitatea datelor_, _proprietatea datelor_ 탳i subiecte conexe precum _consim탵캒m칙ntul informat_ 탳i _drepturile de proprietate intelectual캒_ ale utilizatorilor.

칉n cazul proiect캒rii algoritmilor, ac탵iunile vor implica colectarea 탳i curarea **seturilor de date**, apoi utilizarea acestora pentru a antrena 탳i implementa **modele de date** care prezic rezultate sau automatizeaz캒 decizii 칥n contexte reale. Provoc캒rile etice pot ap캒rea din _prejudec캒탵i 칥n seturile de date_, probleme de _calitate a datelor_, _inechitate_ 탳i _reprezentare gre탳it캒_ 칥n algoritmi - inclusiv unele probleme care sunt de natur캒 sistemic캒.

칉n ambele cazuri, provoc캒rile etice eviden탵iaz캒 zonele 칥n care ac탵iunile noastre pot intra 칥n conflict cu valorile comune. Pentru a detecta, atenua, minimiza sau elimina aceste preocup캒ri, trebuie s캒 punem 칥ntreb캒ri morale "da/nu" legate de ac탵iunile noastre, apoi s캒 lu캒m m캒suri corective, dup캒 cum este necesar. S캒 analiz캒m c칙teva provoc캒ri etice 탳i 칥ntreb캒rile morale pe care le ridic캒:

#### 2.1 Proprietatea Datelor

Colectarea datelor implic캒 adesea date personale care pot identifica subiec탵ii datelor. [Proprietatea datelor](https://permission.io/blog/data-ownership) se refer캒 la _controlul_ 탳i [_drepturile utilizatorilor_](https://permission.io/blog/data-ownership) legate de crearea, procesarea 탳i diseminarea datelor.

칉ntreb캒rile morale pe care trebuie s캒 le punem sunt:
 * Cine de탵ine datele? (utilizator sau organiza탵ie)
 * Ce drepturi au subiec탵ii datelor? (ex: acces, 탳tergere, portabilitate)
 * Ce drepturi au organiza탵iile? (ex: rectificarea recenziilor utilizatorilor mali탵ioase)

#### 2.2 Consim탵캒m칙ntul Informat

[Consim탵캒m칙ntul informat](https://legaldictionary.net/informed-consent/) define탳te actul utilizatorilor de a fi de acord cu o ac탵iune (cum ar fi colectarea datelor) cu o _칥n탵elegere complet캒_ a faptelor relevante, inclusiv scopul, riscurile poten탵iale 탳i alternativele.

칉ntreb캒rile de explorat aici sunt:
 * Utilizatorul (subiectul datelor) 탳i-a dat permisiunea pentru captarea 탳i utilizarea datelor?
 * Utilizatorul a 칥n탵eles scopul pentru care au fost capturate datele?
 * Utilizatorul a 칥n탵eles riscurile poten탵iale ale particip캒rii sale?

#### 2.3 Proprietatea Intelectual캒

[Proprietatea intelectual캒](https://en.wikipedia.org/wiki/Intellectual_property) se refer캒 la crea탵ii intangibile rezultate din ini탵iativa uman캒, care pot _avea valoare economic캒_ pentru indivizi sau afaceri.

칉ntreb캒rile de explorat aici sunt:
 * Datele colectate aveau valoare economic캒 pentru un utilizator sau o afacere?
 * Utilizatorul are proprietate intelectual캒 aici?
 * Organiza탵ia are proprietate intelectual캒 aici?
 * Dac캒 aceste drepturi exist캒, cum le protej캒m?

#### 2.4 Confiden탵ialitatea Datelor

[Confiden탵ialitatea datelor](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) sau confiden탵ialitatea informa탵iilor se refer캒 la p캒strarea confiden탵ialit캒탵ii utilizatorilor 탳i protec탵ia identit캒탵ii utilizatorilor 칥n raport cu informa탵iile personale identificabile.

칉ntreb캒rile de explorat aici sunt:
 * Datele (personale) ale utilizatorilor sunt securizate 칥mpotriva atacurilor 탳i scurgerilor?
 * Datele utilizatorilor sunt accesibile doar utilizatorilor 탳i contextelor autorizate?
 * Anonimitatea utilizatorilor este p캒strat캒 atunci c칙nd datele sunt partajate sau diseminate?
 * Poate un utilizator fi de-identificat din seturi de date anonimizate?

#### 2.5 Dreptul de a Fi Uitat

[Dreptul de a Fi Uitat](https://en.wikipedia.org/wiki/Right_to_be_forgotten) sau [Dreptul la 탲tergere](https://www.gdpreu.org/right-to-be-forgotten/) ofer캒 protec탵ie suplimentar캒 datelor personale ale utilizatorilor. 칉n mod specific, le ofer캒 utilizatorilor dreptul de a solicita 탳tergerea sau eliminarea datelor personale din c캒ut캒rile pe Internet 탳i alte loca탵ii, _칥n anumite circumstan탵e_ - permi탵칙ndu-le un nou 칥nceput online f캒r캒 ca ac탵iunile din trecut s캒 fie folosite 칥mpotriva lor.

칉ntreb캒rile de explorat aici sunt:
 * Sistemul permite subiec탵ilor datelor s캒 solicite 탳tergerea?
 * Retragerea consim탵캒m칙ntului utilizatorului ar trebui s캒 declan탳eze 탳tergerea automat캒?
 * Datele au fost colectate f캒r캒 consim탵캒m칙nt sau prin mijloace ilegale?
 * Suntem conformi cu reglement캒rile guvernamentale privind confiden탵ialitatea datelor?

#### 2.6 Prejudec캒탵i 칥n Seturile de Date

Prejudec캒탵ile 칥n seturile de date sau [Prejudec캒탵ile de Colectare](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) se refer캒 la selectarea unui subset _nereprezentativ_ de date pentru dezvoltarea algoritmilor, cre칙nd poten탵ial inechitate 칥n rezultatele pentru grupuri diverse. Tipurile de prejudec캒탵i includ prejudec캒탵i de selec탵ie sau e탳antionare, prejudec캒탵i ale voluntarilor 탳i prejudec캒탵i ale instrumentelor.

칉ntreb캒rile de explorat aici sunt:
 * Am recrutat un set reprezentativ de subiec탵i ai datelor?
 * Am testat setul nostru de date colectat sau curat pentru diverse prejudec캒탵i?
 * Putem atenua sau elimina prejudec캒탵ile descoperite?

#### 2.7 Calitatea Datelor

[Calitatea Datelor](https://lakefs.io/data-quality-testing/) analizeaz캒 validitatea setului de date curat utilizat pentru dezvoltarea algoritmilor no탳tri, verific칙nd dac캒 caracteristicile 탳i 칥nregistr캒rile 칥ndeplinesc cerin탵ele pentru nivelul de acurate탵e 탳i consisten탵캒 necesar scopului nostru AI.

칉ntreb캒rile de explorat aici sunt:
 * Am capturat caracteristici valide pentru cazul nostru de utilizare?
 * Datele au fost capturate 칥n mod consistent din surse de date diverse?
 * Setul de date este complet pentru condi탵ii sau scenarii diverse?
 * Informa탵iile capturate reflect캒 realitatea cu acurate탵e?
[Algorithm Fairness](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) verific캒 dac캒 designul algoritmului discrimineaz캒 sistematic anumite subgrupuri de persoane, conduc칙nd la [posibile prejudicii](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) 칥n _alocare_ (unde resursele sunt refuzate sau re탵inute de la acel grup) 탳i _calitatea serviciului_ (unde AI nu este la fel de precis pentru unele subgrupuri comparativ cu altele).

칉ntreb캒ri de explorat aici:
 * Am evaluat acurate탵ea modelului pentru subgrupuri 탳i condi탵ii diverse?
 * Am analizat sistemul pentru posibile prejudicii (de exemplu, stereotipuri)?
 * Putem revizui datele sau reantrena modelele pentru a reduce prejudiciile identificate?

Explora탵i resurse precum [AI Fairness checklists](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) pentru a afla mai multe.

#### 2.9 Denaturarea datelor

[Denaturarea datelor](https://www.sciencedirect.com/topics/computer-science/misrepresentation) se refer캒 la 칥ntrebarea dac캒 comunic캒m informa탵ii din date raportate onest 칥ntr-un mod 칥n탳el캒tor pentru a sus탵ine o nara탵iune dorit캒.

칉ntreb캒ri de explorat aici:
 * Raport캒m date incomplete sau inexacte?
 * Vizualiz캒m datele 칥ntr-un mod care conduce la concluzii 칥n탳el캒toare?
 * Folosim tehnici statistice selective pentru a manipula rezultatele?
 * Exist캒 explica탵ii alternative care ar putea oferi o concluzie diferit캒?

#### 2.10 Alegerea liber캒
[Iluzia alegerii libere](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) apare atunci c칙nd "arhitecturile de alegere" ale sistemului folosesc algoritmi de luare a deciziilor pentru a influen탵a oamenii s캒 ia un rezultat preferat, 칥n timp ce par s캒 le ofere op탵iuni 탳i control. Aceste [dark patterns](https://www.darkpatterns.org/) pot provoca prejudicii sociale 탳i economice utilizatorilor. Deoarece deciziile utilizatorilor influen탵eaz캒 profilurile de comportament, aceste ac탵iuni pot conduce la alegeri viitoare care amplific캒 sau extind impactul acestor prejudicii.

칉ntreb캒ri de explorat aici:
 * Utilizatorul a 칥n탵eles implica탵iile alegerii f캒cute?
 * Utilizatorul era con탳tient de (alternativele) op탵iuni 탳i de avantajele 탳i dezavantajele fiec캒reia?
 * Utilizatorul poate inversa o alegere automat캒 sau influen탵at캒 ulterior?

### 3. Studii de caz

Pentru a pune aceste provoc캒ri etice 칥n contexte reale, este util s캒 analiz캒m studii de caz care eviden탵iaz캒 prejudiciile 탳i consecin탵ele poten탵iale asupra indivizilor 탳i societ캒탵ii atunci c칙nd astfel de 칥nc캒lc캒ri etice sunt ignorate.

Iat캒 c칙teva exemple:

| Provocare etic캒 | Studiu de caz  | 
|--- |--- |
| **Consim탵캒m칙nt informat** | 1972 - [Tuskegee Syphilis Study](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - B캒rba탵ii afro-americani care au participat la studiu au fost promi탳i 칥ngrijire medical캒 gratuit캒 _dar au fost 칥n탳ela탵i_ de cercet캒tori care nu le-au informat despre diagnostic sau despre disponibilitatea tratamentului. Mul탵i subiec탵i au murit, iar partenerii sau copiii au fost afecta탵i; studiul a durat 40 de ani. | 
| **Confiden탵ialitatea datelor** |  2007 - [Premiul Netflix pentru date](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) a oferit cercet캒torilor _10M de evalu캒ri anonimizate de filme de la 50K de clien탵i_ pentru a 칥mbun캒t캒탵i algoritmii de recomandare. Totu탳i, cercet캒torii au reu탳it s캒 coreleze datele anonimizate cu date identificabile personal din _seturi de date externe_ (de exemplu, comentarii IMDb) - efectiv "de-anonimiz칙nd" unii abona탵i Netflix.|
| **Bias 칥n colectare**  | 2013 - Ora탳ul Boston [a dezvoltat Street Bump](https://www.boston.gov/transportation/street-bump), o aplica탵ie care permite cet캒탵enilor s캒 raporteze gropi, oferind ora탳ului date mai bune despre drumuri pentru a identifica 탳i rezolva problemele. Totu탳i, [persoanele din grupuri cu venituri mai mici aveau acces redus la ma탳ini 탳i telefoane](https://hbr.org/2013/04/the-hidden-biases-in-big-data), f캒c칙nd problemele lor de drum invizibile 칥n aceast캒 aplica탵ie. Dezvoltatorii au colaborat cu academicieni pentru a aborda _accesul echitabil 탳i diviziunile digitale_ pentru corectitudine. |
| **Corectitudinea algoritmic캒**  | 2018 - Studiul MIT [Gender Shades](http://gendershades.org/overview.html) a evaluat acurate탵ea produselor AI de clasificare a genului, expun칙nd lacunele de acurate탵e pentru femei 탳i persoane de culoare. Un [Apple Card din 2019](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) p캒rea s캒 ofere mai pu탵in credit femeilor dec칙t b캒rba탵ilor. Ambele au ilustrat probleme de bias algoritmic care conduc la prejudicii socio-economice.|
| **Denaturarea datelor** | 2020 - [Departamentul de S캒n캒tate Public캒 din Georgia a lansat grafice COVID-19](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) care p캒reau s캒 induc캒 칥n eroare cet캒탵enii despre tendin탵ele cazurilor confirmate prin ordonarea non-cronologic캒 pe axa x. Acest lucru ilustreaz캒 denaturarea prin trucuri de vizualizare. |
| **Iluzia alegerii libere** | 2020 - Aplica탵ia de 칥nv캒탵are [ABCmouse a pl캒tit 10M pentru a solu탵iona o pl칙ngere FTC](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/) unde p캒rin탵ii au fost bloca탵i 칥n plata abonamentelor pe care nu le puteau anula. Acest lucru ilustreaz캒 dark patterns 칥n arhitecturile de alegere, unde utilizatorii au fost influen탵a탵i spre alegeri poten탵ial d캒un캒toare. |
| **Confiden탵ialitatea datelor 탳i drepturile utilizatorilor** | 2021 - [Bre탳a de date Facebook](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) a expus datele a 530M de utilizatori, rezult칙nd 칥ntr-o amend캒 de 5B c캒tre FTC. Totu탳i, compania a refuzat s캒 notifice utilizatorii despre bre탳캒, 칥nc캒lc칙nd drepturile utilizatorilor privind transparen탵a 탳i accesul la date. |

Dori탵i s캒 explora탵i mai multe studii de caz? Consulta탵i aceste resurse:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - dileme etice din diverse industrii. 
* [Cursul de etic캒 칥n 탳tiin탵a datelor](https://www.coursera.org/learn/data-science-ethics#syllabus) - studii de caz de referin탵캒 explorate.
* [Unde lucrurile au mers prost](https://deon.drivendata.org/examples/) - checklist-ul Deon cu exemple.

> 游뚿 G칙ndi탵i-v캒 la studiile de caz pe care le-a탵i v캒zut - a탵i experimentat sau a탵i fost afecta탵i de o provocare etic캒 similar캒 칥n via탵a voastr캒? Pute탵i s캒 v캒 g칙ndi탵i la cel pu탵in un alt studiu de caz care ilustreaz캒 una dintre provoc캒rile etice discutate 칥n aceast캒 sec탵iune?

## Etica aplicat캒

Am discutat despre concepte etice, provoc캒ri 탳i studii de caz 칥n contexte reale. Dar cum 칥ncepem s캒 _aplic캒m_ principiile 탳i practicile etice 칥n proiectele noastre? 탲i cum _opera탵ionaliz캒m_ aceste practici pentru o guvernan탵캒 mai bun캒? S캒 explor캒m c칙teva solu탵ii reale:

### 1. Coduri profesionale

Codurile profesionale ofer캒 o op탵iune pentru organiza탵ii de a "motiva" membrii s캒 sus탵in캒 principiile etice 탳i declara탵ia de misiune. Codurile sunt _ghiduri morale_ pentru comportamentul profesional, ajut칙nd angaja탵ii sau membrii s캒 ia decizii care se aliniaz캒 cu principiile organiza탵iei lor. Ele sunt eficiente doar 칥n m캒sura 칥n care membrii le respect캒 voluntar; totu탳i, multe organiza탵ii ofer캒 recompense 탳i penalit캒탵i suplimentare pentru a motiva respectarea codurilor.

Exemple includ:

 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Cod de Etic캒
 * [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Cod de Conduit캒 (creat 칥n 2013)
 * [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (din 1993)

> 游뚿 Face탵i parte dintr-o organiza탵ie profesional캒 de inginerie sau 탳tiin탵a datelor? Explora탵i site-ul lor pentru a vedea dac캒 definesc un cod profesional de etic캒. Ce spune acesta despre principiile lor etice? Cum "motiveaz캒" membrii s캒 urmeze codul?

### 2. Liste de verificare etic캒

칉n timp ce codurile profesionale definesc comportamentul _etic necesar_ de la practicieni, ele [au limit캒ri cunoscute](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) 칥n aplicare, 칥n special 칥n proiectele de mare amploare. 칉n schimb, mul탵i exper탵i 칥n 탳tiin탵a datelor [pledeaz캒 pentru liste de verificare](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), care pot **conecta principiile la practici** 칥ntr-un mod mai determinist 탳i ac탵ionabil.

Listele de verificare transform캒 칥ntreb캒rile 칥n sarcini "da/nu" care pot fi opera탵ionalizate, permi탵칙ndu-le s캒 fie urm캒rite ca parte a fluxurilor de lucru standard pentru lansarea produselor.

Exemple includ:
 * [Deon](https://deon.drivendata.org/) - o list캒 general캒 de verificare pentru etica datelor creat캒 din [recomand캒ri din industrie](https://deon.drivendata.org/#checklist-citations) cu un instrument de linie de comand캒 pentru integrare u탳oar캒.
 * [Lista de verificare pentru auditul confiden탵ialit캒탵ii](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - ofer캒 orient캒ri generale pentru practicile de manipulare a informa탵iilor din perspective legale 탳i sociale.
 * [Lista de verificare pentru corectitudinea AI](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - creat캒 de practicieni AI pentru a sprijini adoptarea 탳i integrarea verific캒rilor de corectitudine 칥n ciclurile de dezvoltare AI.
 * [22 de 칥ntreb캒ri pentru etica 칥n date 탳i AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - cadru mai deschis, structurat pentru explorarea ini탵ial캒 a problemelor etice 칥n design, implementare 탳i contexte organiza탵ionale.

### 3. Reglement캒ri etice

Etica se refer캒 la definirea valorilor comune 탳i la a face ceea ce este corect _voluntar_. **Conformitatea** se refer캒 la _respectarea legii_ acolo unde este definit캒. **Guvernan탵a** acoper캒 칥n general toate modurile 칥n care organiza탵iile opereaz캒 pentru a aplica principiile etice 탳i pentru a respecta legile stabilite.

Ast캒zi, guvernan탵a ia dou캒 forme 칥n cadrul organiza탵iilor. 칉n primul r칙nd, este vorba despre definirea principiilor **AI etice** 탳i stabilirea practicilor pentru a opera탵ionaliza adoptarea 칥n toate proiectele AI din organiza탵ie. 칉n al doilea r칙nd, este vorba despre respectarea tuturor reglement캒rilor guvernamentale **privind protec탵ia datelor** pentru regiunile 칥n care opereaz캒.

Exemple de reglement캒ri privind protec탵ia 탳i confiden탵ialitatea datelor:

 * `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - reglementeaz캒 colectarea, utilizarea 탳i divulgarea informa탵iilor personale de c캒tre _guvernul federal_.
 * `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - protejeaz캒 datele personale de s캒n캒tate.
 * `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - protejeaz캒 confiden탵ialitatea datelor copiilor sub 13 ani.
 * `2018`, [Regulamentul General privind Protec탵ia Datelor (GDPR)](https://gdpr-info.eu/) - ofer캒 drepturi utilizatorilor, protec탵ia datelor 탳i confiden탵ialitate.
 * `2018`, [California Consumer Privacy Act (CCPA)](https://www.oag.ca.gov/privacy/ccpa) ofer캒 consumatorilor mai multe _drepturi_ asupra datelor lor (personale).
 * `2021`, Legea Chinei privind [Protec탵ia Informa탵iilor Personale](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) tocmai a fost adoptat캒, cre칙nd una dintre cele mai puternice reglement캒ri privind confiden탵ialitatea datelor online la nivel mondial.

> 游뚿 Uniunea European캒 a definit GDPR (Regulamentul General privind Protec탵ia Datelor), care r캒m칙ne una dintre cele mai influente reglement캒ri privind confiden탵ialitatea datelor ast캒zi. 탲tia탵i c캒 define탳te 탳i [8 drepturi ale utilizatorilor](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) pentru a proteja confiden탵ialitatea digital캒 탳i datele personale ale cet캒탵enilor? Afla탵i care sunt acestea 탳i de ce conteaz캒.

### 4. Cultura etic캒

Re탵ine탵i c캒 exist캒 un decalaj intangibil 칥ntre _conformitate_ (a face suficient pentru a respecta "litera legii") 탳i abordarea [problemelor sistemice](https://www.coursera.org/learn/data-science-ethics/home/week/4) (cum ar fi osificarea, asimetria informa탵iilor 탳i nedreptatea distribu탵ional캒) care pot accelera utilizarea abuziv캒 a AI.

Acesta din urm캒 necesit캒 [abord캒ri colaborative pentru definirea culturilor etice](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f) care construiesc conexiuni emo탵ionale 탳i valori comune consistente _칥n cadrul organiza탵iilor_ din industrie. Acest lucru solicit캒 mai multe [culturi etice formalizate](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) 칥n organiza탵ii - permi탵칙nd _oricui_ s캒 [trag캒 cordonul Andon](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (pentru a ridica preocup캒ri etice devreme 칥n proces) 탳i f캒c칙nd _evalu캒rile etice_ (de exemplu, 칥n angajare) un criteriu esen탵ial pentru formarea echipelor 칥n proiectele AI.

---
## [Quiz post-lectur캒](https://ff-quizzes.netlify.app/en/ds/) 游꿢
## Recapitulare 탳i auto-studiu 

Cursurile 탳i c캒r탵ile ajut캒 la 칥n탵elegerea conceptelor etice de baz캒 탳i a provoc캒rilor, 칥n timp ce studiile de caz 탳i instrumentele ajut캒 la practicile etice aplicate 칥n contexte reale. Iat캒 c칙teva resurse pentru a 칥ncepe:

* [Machine Learning For Beginners](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - lec탵ie despre corectitudine, de la Microsoft.
* [Principiile AI Responsabil](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - parcurs de 칥nv캒탵are gratuit de la Microsoft Learn.
* [Etic캒 탳i 탲tiin탵a Datelor](https://resources.oreilly.com/examples/0636920203964) - EBook O'Reilly (M. Loukides, H. Mason 탳i al탵ii)
* [Etica 칥n 탲tiin탵a Datelor](https://www.coursera.org/learn/data-science-ethics#syllabus) - curs online de la Universitatea din Michigan.
* [Etica Explicat캒](https://ethicsunwrapped.utexas.edu/case-studies) - studii de caz de la Universitatea din Texas.

# Tem캒

[Scrie un Studiu de Caz despre Etica Datelor](assignment.md)

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). De탳i ne str캒duim s캒 asigur캒m acurate탵ea, v캒 rug캒m s캒 fi탵i con탳tien탵i c캒 traducerile automate pot con탵ine erori sau inexactit캒탵i. Documentul original 칥n limba sa natal캒 ar trebui considerat sursa autoritar캒. Pentru informa탵ii critice, se recomand캒 traducerea profesional캒 realizat캒 de un specialist uman. Nu ne asum캒m responsabilitatea pentru eventualele ne칥n탵elegeri sau interpret캒ri gre탳ite care pot ap캒rea din utilizarea acestei traduceri.