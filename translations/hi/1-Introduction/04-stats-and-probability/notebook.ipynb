{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# संभावना और सांख्यिकी का परिचय\n",
    "इस नोटबुक में, हम कुछ उन अवधारणाओं के साथ प्रयोग करेंगे जिन पर हमने पहले चर्चा की है। संभावना और सांख्यिकी की कई अवधारणाएं पाइथन में डेटा प्रोसेसिंग के लिए प्रमुख लाइब्रेरियों जैसे `numpy` और `pandas` में अच्छी तरह से प्रस्तुत हैं।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## रैंडम वेरिएबल्स और वितरण\n",
    "चलो 0 से 9 तक के यूनिफ़ॉर्म वितरण से 30 मानों का एक नमूना बनाते हैं। हम साथ ही माध्य और और मापांक भी गणना करेंगे।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [ random.randint(0,10) for _ in range(30) ]\n",
    "print(f\"Sample: {sample}\")\n",
    "print(f\"Mean = {np.mean(sample)}\")\n",
    "print(f\"Variance = {np.var(sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "नमूने में कितनी विभिन्न मान हैं, यह दृश्य रूप से अनुमान लगाने के लिए, हम **हिस्टोग्राम** बना सकते हैं:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## वास्तविक डेटा का विश्लेषण करना\n",
    "\n",
    "मीन और विचरण वास्तविक दुनिया के डेटा का विश्लेषण करते समय बहुत महत्वपूर्ण होते हैं। आइए बेसबॉल खिलाड़ियों के डेटा को [SOCR MLB Height/Weight Data](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) से लोड करें।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/SOCR_MLB.tsv\",sep='\\t', header=None, names=['Name','Team','Role','Weight','Height','Age'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> हम डेटा विश्लेषण के लिए यहाँ [**Pandas**](https://pandas.pydata.org/) नामक एक पैकेज का उपयोग कर रहे हैं। हम इस कोर्स में बाद में Pandas और Python में डेटा के साथ काम करने के बारे में अधिक चर्चा करेंगे।\n",
    "\n",
    "आइए आयु, ऊंचाई और वजन के औसत मान का गणना करें:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Age','Height','Weight']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "अब चलिए ऊंचाई पर ध्यान केंद्रित करते हैं, और मानक विचलन और परिवर्तन गणना करते हैं:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df['Height'])[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df['Height'].mean()\n",
    "var = df['Height'].var()\n",
    "std = df['Height'].std()\n",
    "print(f\"Mean = {mean}\\nVariance = {var}\\nStandard Deviation = {std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "औसत के अतिरिक्त, मध्यिका मान और क्वार्टाइल पर भी ध्यान देना समझदारी है। इन्हें **बॉक्स प्लॉट** का उपयोग करके चित्रित किया जा सकता है:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2))\n",
    "plt.boxplot(df['Height'].ffill(), vert=False, showmeans=True)\n",
    "plt.grid(color='gray', linestyle='dotted')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "हम अपने डेटासेट के उपसमूहों के बॉक्स प्लॉट भी बना सकते हैं, उदाहरण के लिए, खिलाड़ी की भूमिका के अनुसार समूहित।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='Height', by='Role', figsize=(10,8))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ध्यान दें**: यह चित्र सुझाव देता है कि औसतन, पहले बेसमैन की ऊँचाई दूसरे बेसमैन की ऊँचाई से अधिक होती है। बाद में हम सीखेंगे कि हम इस परिकल्पना का अधिक औपचारिक रूप से परीक्षण कैसे कर सकते हैं, और कैसे यह दर्शा सकते हैं कि हमारा डेटा सांख्यिकीय रूप से महत्वपूर्ण है।  \n",
    "\n",
    "आयु, ऊंचाई और वजन सभी निरंतर यादृच्छिक चर हैं। आपको क्या लगता है कि उनका वितरण क्या है? यह पता लगाने का एक अच्छा तरीका है मानों का हिस्टोग्राम बनाना: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weight'].hist(bins=15, figsize=(10,6))\n",
    "plt.suptitle('Weight distribution of MLB Players')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## सामान्य वितरण\n",
    "\n",
    "आइए एक कृत्रिम वजन नमूना बनाते हैं जो हमारे वास्तविक डेटा के समान माध्य और विचरण के साथ सामान्य वितरण का पालन करता है:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = np.random.normal(mean, std, 1000)\n",
    "generated[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(generated, bins=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(np.random.normal(0,1,50000), bins=300)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "चूंकि वास्तविक जीवन में अधिकांश मान सामान्य वितरण के होते हैं, हमें नमूना डेटा उत्पन्न करने के लिए एक समान यादृच्छिक संख्या जनरेटर का उपयोग नहीं करना चाहिए। यहां यह है कि अगर हम समान वितरण (जो `np.random.rand` द्वारा उत्पन्न होता है) के साथ वजन उत्पन्न करने की कोशिश करें तो क्या होता है:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_sample = np.random.rand(1000)*2*std+mean-std\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(wrong_sample)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## विश्वास अंतराल\n",
    "\n",
    "अब आइए बेसबॉल खिलाड़ियों के वजन और कद के लिए विश्वास अंतराल की गणना करते हैं। हम इस कोड का उपयोग करेंगे [इस stackoverflow चर्चा से](https://stackoverflow.com/questions/15033511/compute-a-confidence-interval-from-sample-data):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, h\n",
    "\n",
    "for p in [0.85, 0.9, 0.95]:\n",
    "    m, h = mean_confidence_interval(df['Weight'].fillna(method='pad'),p)\n",
    "    print(f\"p={p:.2f}, mean = {m:.2f} ± {h:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## परिकल्पना परीक्षण\n",
    "\n",
    "आइए हमारे बेसबॉल खिलाड़ियों के डेटासेट में विभिन्न भूमिकाओं का पता लगाएं:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Role').agg({ 'Weight' : 'mean', 'Height' : 'mean', 'Age' : 'count'}).rename(columns={ 'Age' : 'Count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आइए यह परीक्षण करते हैं कि क्या पहला बेसमैन दूसरे बेसमैन से लंबा होता है। इसे जांचने का सबसे सरल तरीका है विश्वास अंतराल का परीक्षण करना:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [0.85,0.9,0.95]:\n",
    "    m1, h1 = mean_confidence_interval(df.loc[df['Role']=='First_Baseman',['Height']],p)\n",
    "    m2, h2 = mean_confidence_interval(df.loc[df['Role']=='Second_Baseman',['Height']],p)\n",
    "    print(f'Conf={p:.2f}, 1st basemen height: {m1-h1[0]:.2f}..{m1+h1[0]:.2f}, 2nd basemen height: {m2-h2[0]:.2f}..{m2+h2[0]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "हम देख सकते हैं कि इंटरवल ओवरलैप नहीं होते हैं।\n",
    "\n",
    "सिद्धांत को प्रमाणित करने का एक सांख्यिकीय रूप से अधिक सही तरीका **Student t-test** का उपयोग करना है:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Second_Baseman',['Height']],equal_var=False)\n",
    "print(f\"T-value = {tval[0]:.2f}\\nP-value: {pval[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ttest_ind` फ़ंक्शन द्वारा लौटाए गए दो मान हैं:\n",
    "* p-मूल्य को दो वितरणों के समान माध्य होने की संभावना के रूप में माना जा सकता है। हमारे मामले में, यह बहुत कम है, जिसका मतलब है कि पहले बेसमैन लंबे होने का मजबूत साक्ष्य है।\n",
    "* t-मूल्य सामान्यीकृत माध्य अंतर का मध्यवर्ती मान है जिसका उपयोग t-परीक्षण में किया जाता है, और इसे एक दिए गए विश्वसनीयता मान के लिए एक सीमा मान के खिलाफ तुलना किया जाता है।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## केंद्रीय सीमा प्रमेय के साथ सामान्य वितरण का अनुकरण\n",
    "\n",
    "Python में छद्म-संयोजक जनरेटर हमें समान वितरण प्रदान करने के लिए डिज़ाइन किया गया है। यदि हम सामान्य वितरण के लिए एक जनरेटर बनाना चाहते हैं, तो हम केंद्रीय सीमा प्रमेय का उपयोग कर सकते हैं। सामान्य वितरण मान प्राप्त करने के लिए हम समान-जनित नमूने का औसत ही गणना करेंगे।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_random(sample_size=100):\n",
    "    sample = [random.uniform(0,1) for _ in range(sample_size) ]\n",
    "    return sum(sample)/sample_size\n",
    "\n",
    "sample = [normal_random() for _ in range(100)]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(sample)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## सहसंबंध और ईविल बेसबॉल कॉर्प\n",
    "\n",
    "सहसंबंध हमें डेटा अनुक्रमों के बीच संबंध खोजने की अनुमति देता है। हमारे खिलौने के उदाहरण में, चलिए कल्पना करते हैं कि एक ईविल बेसबॉल कॉर्पोरेशन है जो अपने खिलाड़ियों को उनकी ऊँचाई के अनुसार भुगतान करता है - खिलाड़ी जितना लंबा होगा, उसे उतनी अधिक राशि मिलेगी। मान लीजिए कि एक मूल वेतन $1000 है, और ऊँचाई के आधार पर $0 से $100 तक का अतिरिक्त बोनस है। हम MLB के असली खिलाड़ियों को लेंगे, और उनकी काल्पनिक सैलरी की गणना करेंगे:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = df['Height'].fillna(method='pad')\n",
    "salaries = 1000+(heights-heights.min())/(heights.max()-heights.mean())*100\n",
    "print(list(zip(heights, salaries))[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "अब आइए उन अनुक्रमों का सह-प्रवणता (covariance) और सहसंबंध (correlation) निकालते हैं। `np.cov` हमें तथाकथित **covariance matrix** देगा, जो कई चरों के लिए सह-प्रवणता का विस्तार है। सह-प्रवणता मैट्रिक्स $M$ का तत्व $M_{ij}$ इनपुट चरों $X_i$ और $X_j$ के बीच सहसंबंध होता है, और मुख्य विकर्ण के मान $M_{ii}$ $X_{i}$ का विचलन (variance) होता है। इसी तरह, `np.corrcoef` हमें **correlation matrix** देगा।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Covariance matrix:\\n{np.cov(heights, salaries)}\")\n",
    "print(f\"Covariance = {np.cov(heights, salaries)[0,1]}\")\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "संबंध का मान 1 होना यह दर्शाता है कि दो चर के बीच एक मजबूत **रेखीय संबंध** है। हम एक मान को दूसरे के खिलाफ प्लॉट करके रेखीय संबंध को दृश्य रूप से देख सकते हैं:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(heights,salaries)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आइए देखते हैं कि अगर संबंध रैखिक न हो तो क्या होता है। मान लीजिए कि हमारी कंपनी ने ऊंचाई और वेतन के बीच स्पष्ट रैखिक निर्भरता को छिपाने का निर्णय लिया, और सूत्र में कुछ गैर-रैखिकता शामिल की, जैसे कि `sin`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = 1000+np.sin((heights-heights.min())/(heights.max()-heights.mean()))*100\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "इस मामले में, सहसंबंध थोड़ा कम है, लेकिन यह अभी भी काफी उच्च है। अब, संबंध को और भी कम स्पष्ट बनाने के लिए, हम वेतन में कुछ यादृच्छिक परिवर्तन जोड़ सकते हैं। देखते हैं क्या होता है:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = 1000+np.sin((heights-heights.min())/(heights.max()-heights.mean()))*100+np.random.random(size=len(heights))*20-10\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(heights, salaries)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> क्या आप अंदाजा लगा सकते हैं कि डॉट्स इस तरह लंबवत रेखाओं में क्यों सजी हुई हैं?\n",
    "\n",
    "हमने एक कृत्रिम रूप से निर्मित अवधारणा जैसे वेतन और देखे गए चर *ऊंचाई* के बीच सहसंबंध देखा है। आइए देखें कि क्या दो देखे गए चर, जैसे ऊंचाई और वजन, भी सहसंबंधित हैं:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df['Height'].ffill(),df['Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "दुर्भाग्यवश, हमें कोई परिणाम नहीं मिला - केवल कुछ अजीब `nan` मान। इसका कारण यह है कि हमारी सीरीज के कुछ मान अपरिभाषित हैं, जिन्हें `nan` के रूप में दर्शाया गया है, जो ऑपरेशन के परिणाम को भी अपरिभाषित बना देता है। मैट्रिक्स को देखकर हम देख सकते हैं कि `Weight` समस्या वाला कॉलम है, क्योंकि `Height` मानों के बीच स्वयं सहसंबंध की गणना की गई है।\n",
    "\n",
    "> यह उदाहरण **डेटा तैयारी** और **सफाई** के महत्व को दर्शाता है। सही डेटा के बिना हम कुछ भी गणना नहीं कर सकते।\n",
    "\n",
    "आइए `fillna` मेथड का उपयोग करके गायब मानों को भरें, और सहसंबंध की गणना करें:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df['Height'].fillna(method='pad'), df['Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "वास्तव में एक सहसंबंध है, लेकिन हमारे कृत्रिम उदाहरण जितना मजबूत नहीं है। वास्तव में, यदि हम एक मान की तुलना दूसरे मान से स्कैटर प्लॉट में देखें, तो संबंध उतना स्पष्ट नहीं होगा:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(df['Weight'],df['Height'])\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Height')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## निष्कर्ष\n",
    "\n",
    "इस नोटबुक में हमने सीखा कि आंकड़ों पर आधारभूत क्रियाएं कैसे करें ताकि सांख्यिकीय कार्यों की गणना की जा सके। अब हम जानते हैं कि कुछ अनुमानों को साबित करने के लिए गणित और सांख्यिकी के एक मजबूत उपकरण का उपयोग कैसे करें, और एक डेटा नमूने के आधार पर मनमाने चर के लिए विश्वास अंतराल कैसे गणना करें।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**अस्वीकरण**:  \nइस दस्तावेज़ का अनुवाद AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके किया गया है। जबकि हम सटीकता के लिए प्रयासरत हैं, कृपया ध्यान रखें कि स्वचालित अनुवाद में त्रुटियाँ या गलतियाँ हो सकती हैं। मूल भाषा में उपलब्ध दस्तावेज़ को आधिकारिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी भ्रामकता या गलतफहमी के लिए हम जिम्मेदार नहीं हैं।\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86193a1ab0ba47eac1c69c1756090baa3b420b3eea7d4aafab8b85f8b312f0c5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "coopTranslator": {
   "original_hash": "0f899e3c5019f948e7c787b22f3b2304",
   "translation_date": "2026-01-16T11:01:38+00:00",
   "source_file": "1-Introduction/04-stats-and-probability/notebook.ipynb",
   "language_code": "hi"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}