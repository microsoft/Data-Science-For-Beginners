<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1b560955ff39a2bcf2a049fce474a951",
  "translation_date": "2025-09-05T14:55:08+00:00",
  "source_file": "2-Working-With-Data/08-data-preparation/README.md",
  "language_code": "hi"
}
-->
# डेटा के साथ काम करना: डेटा तैयारी

|![ स्केच नोट [(@sketchthedocs)](https://sketchthedocs.dev) द्वारा ](../../sketchnotes/08-DataPreparation.png)|
|:---:|
|डेटा तैयारी - _[@nitya](https://twitter.com/nitya) द्वारा स्केच नोट_ |

## [प्री-लेक्चर क्विज़](https://ff-quizzes.netlify.app/en/ds/quiz/14)

डेटा के स्रोत के आधार पर, कच्चे डेटा में कुछ असंगतियां हो सकती हैं जो विश्लेषण और मॉडलिंग में चुनौतियां पैदा करेंगी। दूसरे शब्दों में, इस डेटा को "गंदा" माना जा सकता है और इसे साफ करने की आवश्यकता होगी। यह पाठ डेटा को साफ करने और बदलने की तकनीकों पर केंद्रित है ताकि गायब, गलत, या अधूरे डेटा की चुनौतियों का सामना किया जा सके। इस पाठ में शामिल विषयों का उपयोग पायथन और पांडा लाइब्रेरी के साथ किया जाएगा और इसे इस निर्देशिका के [नोटबुक](../../../../2-Working-With-Data/08-data-preparation/notebook.ipynb) में प्रदर्शित किया जाएगा।

## डेटा को साफ करने का महत्व

- **उपयोग और पुन: उपयोग में आसानी**: जब डेटा सही तरीके से व्यवस्थित और सामान्यीकृत होता है, तो इसे खोजना, उपयोग करना और दूसरों के साथ साझा करना आसान हो जाता है।

- **संगति**: डेटा विज्ञान में अक्सर एक से अधिक डेटा सेट के साथ काम करना पड़ता है, जहां विभिन्न स्रोतों से डेटा सेट को एक साथ जोड़ा जाना होता है। यह सुनिश्चित करना कि प्रत्येक व्यक्तिगत डेटा सेट में सामान्य मानकीकरण है, यह सुनिश्चित करेगा कि जब वे सभी एक डेटा सेट में विलय किए जाते हैं, तो डेटा अभी भी उपयोगी है।

- **मॉडल की सटीकता**: साफ किया गया डेटा उन मॉडलों की सटीकता में सुधार करता है जो उस पर निर्भर करते हैं।

## सामान्य सफाई के लक्ष्य और रणनीतियां

- **डेटासेट का अन्वेषण**: डेटा अन्वेषण, जिसे [बाद के पाठ](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/4-Data-Science-Lifecycle/15-analyzing) में कवर किया गया है, आपको यह पता लगाने में मदद कर सकता है कि डेटा को साफ करने की आवश्यकता है। डेटासेट के भीतर मूल्यों का दृश्य अवलोकन यह अपेक्षा निर्धारित कर सकता है कि बाकी डेटा कैसा दिखेगा, या उन समस्याओं का विचार प्रदान कर सकता है जिन्हें हल किया जा सकता है। अन्वेषण में बुनियादी क्वेरी, विज़ुअलाइज़ेशन और सैंपलिंग शामिल हो सकते हैं।

- **स्वरूपण**: स्रोत के आधार पर, डेटा में इसे प्रस्तुत करने के तरीके में असंगतियां हो सकती हैं। यह डेटासेट में मूल्य को खोजने और प्रस्तुत करने में समस्याएं पैदा कर सकता है, जहां इसे देखा जाता है लेकिन विज़ुअलाइज़ेशन या क्वेरी परिणामों में सही ढंग से प्रस्तुत नहीं किया जाता है। सामान्य स्वरूपण समस्याओं में व्हाइटस्पेस, तिथियों और डेटा प्रकारों को हल करना शामिल है। स्वरूपण समस्याओं को हल करना आमतौर पर उन लोगों पर निर्भर करता है जो डेटा का उपयोग कर रहे हैं। उदाहरण के लिए, तिथियों और संख्याओं को प्रस्तुत करने के मानक देश के अनुसार भिन्न हो सकते हैं।

- **डुप्लिकेशन**: डेटा जिसमें एक से अधिक घटनाएं होती हैं, गलत परिणाम उत्पन्न कर सकता है और आमतौर पर इसे हटा दिया जाना चाहिए। यह तब आम हो सकता है जब दो या अधिक डेटा सेट को एक साथ जोड़ा जाता है। हालांकि, ऐसे उदाहरण हैं जहां संयुक्त डेटा सेट में डुप्लिकेशन में ऐसी जानकारी हो सकती है जिसे संरक्षित करने की आवश्यकता हो सकती है।

- **गायब डेटा**: गायब डेटा गलतियों के साथ-साथ कमजोर या पक्षपाती परिणाम पैदा कर सकता है। कभी-कभी इन्हें डेटा को "पुनः लोड" करके, पायथन जैसी गणना और कोड के साथ गायब मूल्यों को भरकर, या बस मूल्य और संबंधित डेटा को हटा कर हल किया जा सकता है। डेटा के गायब होने के कई कारण हो सकते हैं और इन गायब मूल्यों को हल करने के लिए उठाए गए कार्य इस बात पर निर्भर कर सकते हैं कि वे पहले स्थान पर कैसे और क्यों गायब हुए।

## डेटा फ्रेम जानकारी का अन्वेषण
> **सीखने का लक्ष्य:** इस उपखंड के अंत तक, आपको पांडा डेटा फ्रेम में संग्रहीत डेटा के बारे में सामान्य जानकारी प्राप्त करने में सहज होना चाहिए।

एक बार जब आप अपना डेटा पांडा में लोड कर लेते हैं, तो यह अधिक संभावना है कि यह एक डेटा फ्रेम में होगा (विस्तृत अवलोकन के लिए पिछले [पाठ](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/2-Working-With-Data/07-python#dataframe) को देखें)। हालांकि, यदि आपके डेटा फ्रेम में 60,000 पंक्तियां और 400 कॉलम हैं, तो आप यह समझने की शुरुआत कैसे करेंगे कि आप किसके साथ काम कर रहे हैं? सौभाग्य से, [पांडा](https://pandas.pydata.org/) डेटा फ्रेम के बारे में समग्र जानकारी को जल्दी से देखने के लिए कुछ सुविधाजनक उपकरण प्रदान करता है, साथ ही पहले और अंतिम कुछ पंक्तियों को भी।

इस कार्यक्षमता का अन्वेषण करने के लिए, हम पायथन स्की-किट-लर्न लाइब्रेरी आयात करेंगे और एक प्रसिद्ध डेटासेट का उपयोग करेंगे: **आईरिस डेटा सेट**।

```python
import pandas as pd
from sklearn.datasets import load_iris

iris = load_iris()
iris_df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])
```
|                                        |sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|
|----------------------------------------|-----------------|----------------|-----------------|----------------|
|0                                       |5.1              |3.5             |1.4              |0.2             |
|1                                       |4.9              |3.0             |1.4              |0.2             |
|2                                       |4.7              |3.2             |1.3              |0.2             |
|3                                       |4.6              |3.1             |1.5              |0.2             |
|4                                       |5.0              |3.6             |1.4              |0.2             |

- **DataFrame.info**: शुरुआत करने के लिए, `info()` विधि का उपयोग `DataFrame` में मौजूद सामग्री का सारांश प्रिंट करने के लिए किया जाता है। आइए देखें कि इस डेटासेट में हमारे पास क्या है:
```python
iris_df.info()
```
```
RangeIndex: 150 entries, 0 to 149
Data columns (total 4 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   sepal length (cm)  150 non-null    float64
 1   sepal width (cm)   150 non-null    float64
 2   petal length (cm)  150 non-null    float64
 3   petal width (cm)   150 non-null    float64
dtypes: float64(4)
memory usage: 4.8 KB
```
इससे, हमें पता चलता है कि *आईरिस* डेटासेट में चार कॉलम में 150 प्रविष्टियां हैं और कोई भी शून्य प्रविष्टियां नहीं हैं। सभी डेटा 64-बिट फ्लोटिंग-पॉइंट नंबर के रूप में संग्रहीत हैं।

- **DataFrame.head()**: इसके बाद, `DataFrame` की वास्तविक सामग्री की जांच करने के लिए, हम `head()` विधि का उपयोग करते हैं। आइए देखें कि हमारे `iris_df` की पहली कुछ पंक्तियां कैसी दिखती हैं:
```python
iris_df.head()
```
```
   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
0                5.1               3.5                1.4               0.2
1                4.9               3.0                1.4               0.2
2                4.7               3.2                1.3               0.2
3                4.6               3.1                1.5               0.2
4                5.0               3.6                1.4               0.2
```
- **DataFrame.tail()**: इसके विपरीत, `DataFrame` की अंतिम कुछ पंक्तियों की जांच करने के लिए, हम `tail()` विधि का उपयोग करते हैं:
```python
iris_df.tail()
```
```
     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
145                6.7               3.0                5.2               2.3
146                6.3               2.5                5.0               1.9
147                6.5               3.0                5.2               2.0
148                6.2               3.4                5.4               2.3
149                5.9               3.0                5.1               1.8
```
> **निष्कर्ष:** केवल डेटा फ्रेम में जानकारी के मेटाडेटा को देखकर या पहले और अंतिम कुछ मानों को देखकर, आप तुरंत उस डेटा के आकार, संरचना और सामग्री का अंदाजा लगा सकते हैं जिसके साथ आप काम कर रहे हैं।

## गायब डेटा से निपटना
> **सीखने का लक्ष्य:** इस उपखंड के अंत तक, आपको डेटा फ्रेम से शून्य मानों को बदलने या हटाने का तरीका पता होना चाहिए।

अधिकांश समय, जिन डेटासेट्स का आप उपयोग करना चाहते हैं (या उपयोग करना पड़ता है) उनमें गायब मान होते हैं। गायब डेटा को संभालने का तरीका सूक्ष्म समझौतों के साथ आता है जो आपके अंतिम विश्लेषण और वास्तविक दुनिया के परिणामों को प्रभावित कर सकता है।

पांडा गायब मानों को दो तरीकों से संभालता है। पहला आपने पिछले खंडों में पहले देखा है: `NaN`, या नॉट ए नंबर। यह वास्तव में एक विशेष मान है जो IEEE फ्लोटिंग-पॉइंट विनिर्देश का हिस्सा है और इसका उपयोग केवल गायब फ्लोटिंग-पॉइंट मानों को इंगित करने के लिए किया जाता है।

फ्लोट्स के अलावा गायब मानों के लिए, पांडा पायथन `None` ऑब्जेक्ट का उपयोग करता है। जबकि यह भ्रमित करने वाला लग सकता है कि आप दो अलग-अलग प्रकार के मानों का सामना करेंगे जो मूल रूप से एक ही बात कहते हैं, इस डिज़ाइन विकल्प के लिए ठोस प्रोग्रामेटिक कारण हैं और, व्यवहार में, इस मार्ग पर जाने से पांडा अधिकांश मामलों के लिए एक अच्छा समझौता प्रदान करता है। इसके बावजूद, `None` और `NaN` दोनों में प्रतिबंध हैं जिनके बारे में आपको यह ध्यान रखना होगा कि उनका उपयोग कैसे किया जा सकता है।

`NaN` और `None` के बारे में अधिक जानकारी के लिए [नोटबुक](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/4-Data-Science-Lifecycle/15-analyzing/notebook.ipynb) देखें!

- **शून्य मानों का पता लगाना**: `pandas` में, `isnull()` और `notnull()` विधियां शून्य डेटा का पता लगाने के लिए आपकी प्राथमिक विधियां हैं। दोनों आपके डेटा पर बूलियन मास्क लौटाते हैं। हम `NaN` मानों के लिए `numpy` का उपयोग करेंगे:
```python
import numpy as np

example1 = pd.Series([0, np.nan, '', None])
example1.isnull()
```
```
0    False
1     True
2    False
3     True
dtype: bool
```
आउटपुट को ध्यान से देखें। क्या इसमें से कुछ आपको आश्चर्यचकित करता है? जबकि `0` एक अंकगणितीय शून्य है, यह फिर भी एक पूरी तरह से अच्छा पूर्णांक है और पांडा इसे ऐसा ही मानता है। `''` थोड़ा अधिक सूक्ष्म है। जबकि हमने इसे खंड 1 में एक खाली स्ट्रिंग मान का प्रतिनिधित्व करने के लिए उपयोग किया, यह फिर भी एक स्ट्रिंग ऑब्जेक्ट है और पांडा के अनुसार शून्य का प्रतिनिधित्व नहीं है।

अब, आइए इसे पलटें और इन विधियों का उपयोग उस तरीके से करें जैसे आप व्यावहारिक रूप से उनका उपयोग करेंगे। आप बूलियन मास्क का सीधे ``Series`` या ``DataFrame`` इंडेक्स के रूप में उपयोग कर सकते हैं, जो गायब (या मौजूद) मानों के साथ काम करने की कोशिश करते समय उपयोगी हो सकता है।

> **निष्कर्ष:** `isnull()` और `notnull()` दोनों विधियां `DataFrame` में उपयोग किए जाने पर समान परिणाम उत्पन्न करती हैं: वे परिणाम और उन परिणामों के इंडेक्स दिखाती हैं, जो आपके डेटा के साथ काम करते समय आपके लिए बेहद सहायक होंगे।

- **शून्य मानों को हटाना**: गायब मानों की पहचान करने के अलावा, पांडा `Series` और `DataFrame` से शून्य मानों को हटाने का एक सुविधाजनक साधन प्रदान करता है। (विशेष रूप से बड़े डेटा सेट पर, विश्लेषण से गायब [NA] मानों को हटाना अन्य तरीकों से निपटने की तुलना में अधिक सलाहनीय होता है।) इसे क्रियान्वित रूप में देखने के लिए, आइए `example1` पर लौटें:
```python
example1 = example1.dropna()
example1
```
```
0    0
2     
dtype: object
```
ध्यान दें कि यह आपके `example3[example3.notnull()]` के आउटपुट जैसा दिखना चाहिए। यहां अंतर यह है कि, केवल मास्क किए गए मानों पर इंडेक्सिंग करने के बजाय, `dropna` ने `Series` `example1` से गायब मानों को हटा दिया है।

क्योंकि `DataFrame` में दो आयाम होते हैं, वे डेटा को हटाने के लिए अधिक विकल्प प्रदान करते हैं।

```python
example2 = pd.DataFrame([[1,      np.nan, 7], 
                         [2,      5,      8], 
                         [np.nan, 6,      9]])
example2
```
|      | 0 | 1 | 2 |
|------|---|---|---|
|0     |1.0|NaN|7  |
|1     |2.0|5.0|8  |
|2     |NaN|6.0|9  |

(क्या आपने देखा कि पांडा ने `NaN` को समायोजित करने के लिए दो कॉलम को फ्लोट्स में बदल दिया?)

आप `DataFrame` से एकल मान को हटा नहीं सकते, इसलिए आपको पूरी पंक्तियों या कॉलम को हटाना होगा। आप जो कर रहे हैं उसके आधार पर, आप एक या दूसरे को हटाना चाह सकते हैं, और इसलिए पांडा आपको दोनों के लिए विकल्प देता है। चूंकि डेटा विज्ञान में, कॉलम आमतौर पर वेरिएबल्स का प्रतिनिधित्व करते हैं और पंक्तियां अवलोकनों का प्रतिनिधित्व करती हैं, आप डेटा की पंक्तियों को हटाने की अधिक संभावना रखते हैं; `dropna()` के लिए डिफ़ॉल्ट सेटिंग यह है कि उन सभी पंक्तियों को हटा दें जिनमें कोई भी शून्य मान हो:

```python
example2.dropna()
```
```
	0	1	2
1	2.0	5.0	8
```
यदि आवश्यक हो, तो आप कॉलम से NA मानों को हटा सकते हैं। ऐसा करने के लिए `axis=1` का उपयोग करें:
```python
example2.dropna(axis='columns')
```
```
	2
0	7
1	8
2	9
```
ध्यान दें कि यह बहुत सारे डेटा को हटा सकता है जिसे आप रखना चाह सकते हैं, विशेष रूप से छोटे डेटासेट में। क्या होगा यदि आप केवल उन पंक्तियों या कॉलम को हटाना चाहते हैं जिनमें कई या यहां तक कि सभी शून्य मान हैं? आप `dropna` में `how` और `thresh` पैरामीटर के साथ उन सेटिंग्स को निर्दिष्ट करते हैं।

डिफ़ॉल्ट रूप से, `how='any'` (यदि आप स्वयं जांचना चाहते हैं या देखना चाहते हैं कि इस विधि में अन्य पैरामीटर क्या हैं, तो `example4.dropna?` कोड सेल में चलाएं)। आप वैकल्पिक रूप से `how='all'` निर्दिष्ट कर सकते हैं ताकि केवल उन पंक्तियों या कॉलम को हटाया जा सके जिनमें सभी शून्य मान हों। आइए इस उदाहरण `DataFrame` का विस्तार करें ताकि इसे क्रियान्वित रूप में देखा जा सके।

```python
example2[3] = np.nan
example2
```
|      |0  |1  |2  |3  |
|------|---|---|---|---|
|0     |1.0|NaN|7  |NaN|
|1     |2.0|5.0|8  |NaN|
|2     |NaN|6.0|9  |NaN|

`thresh` पैरामीटर आपको अधिक सूक्ष्म नियंत्रण देता है: आप उन *गैर-शून्य* मानों की संख्या सेट करते हैं जो किसी पंक्ति या कॉलम को बनाए रखने के लिए आवश्यक हैं:
```python
example2.dropna(axis='rows', thresh=3)
```
```
	0	1	2	3
1	2.0	5.0	8	NaN
```
यहां, पहली और अंतिम पंक्तियां हटा दी गई हैं, क्योंकि उनमें केवल दो गैर-शून्य मान हैं।

- **शून्य मानों को भरना**: आपके डेटासेट के आधार पर, कभी-कभी शून्य मानों को वैध मानों से भरना अधिक समझदारी हो सकता है बजाय उन्हें हटाने के। आप इसे इन-प्लेस करने के लिए `isnull` का उपयोग कर सकते हैं, लेकिन यह श्रमसाध्य हो सकता है, विशेष रूप से यदि आपके पास भरने के लिए बहुत सारे मान हैं। चूंकि यह डेटा विज्ञान में एक सामान्य कार्य है, पांडा `fillna` प्रदान करता है, जो आपके द्वारा चुने गए मानों के साथ गायब मानों को बदलकर `Series` या `DataFrame` की एक प्रति लौटाता है। आइए देखें कि यह व्यवहार में कैसे काम करता है।
```python
example3 = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))
example3
```
```
a    1.0
b    NaN
c    2.0
d    NaN
e    3.0
dtype: float64
```
आप सभी शून्य प्रविष्टियों को एक ही मान, जैसे `0` से भर सकते हैं:
```python
example3.fillna(0)
```
```
a    1.0
b    0.0
c    2.0
d    0.0
e    3.0
dtype: float64
```
आप शून्य मानों को **आगे-भर** सकते हैं, यानी पिछले वैध मान का उपयोग करके शून्य को भर सकते हैं:
```python
example3.fillna(method='ffill')
```
```
a    1.0
b    1.0
c    2.0
d    2.0
e    3.0
dtype: float64
```
आप **पीछे-भर** भी कर सकते हैं ताकि अगले वैध मान को पीछे की ओर फैलाकर शून्य को भरा जा सके:
```python
example3.fillna(method='bfill')
```
```
a    1.0
b    2.0
c    2.0
d    3.0
e    3.0
dtype: float64
```
जैसा कि आप अनुमान लगा सकते हैं, यह `DataFrame` के साथ भी उसी तरह काम करता है, लेकिन आप शून्य मानों को भरने के लिए एक `axis` निर्दिष्ट कर सकते हैं। पहले उपयोग किए गए `example2` को फिर से लें:
```python
example2.fillna(method='ffill', axis=1)
```
```
	0	1	2	3
0	1.0	1.0	7.0	7.0
1	2.0	5.0	8.0	8.0
2	NaN	6.0	9.0	9.0
```
ध्यान दें कि जब पिछले मान उपलब्ध नहीं होता है, तो आगे-भरने के लिए, शून्य मान बना रहता है।
> **मुख्य बात:** आपके डेटा सेट्स में गायब मानों से निपटने के कई तरीके हैं। आप जो विशेष रणनीति अपनाते हैं (उन्हें हटाना, बदलना, या यहां तक कि कैसे बदलना) वह उस डेटा की विशेषताओं पर निर्भर होना चाहिए। जितना अधिक आप डेटा सेट्स के साथ काम करेंगे और उन्हें समझेंगे, उतना ही बेहतर आप गायब मानों से निपटने का तरीका विकसित करेंगे।
## डुप्लीकेट डेटा हटाना

> **लक्ष्य:** इस अनुभाग के अंत तक, आप DataFrames से डुप्लीकेट मानों की पहचान करने और उन्हें हटाने में सहज हो जाएंगे।

गायब डेटा के अलावा, वास्तविक दुनिया के डेटा सेट्स में अक्सर डुप्लीकेट डेटा भी मिलता है। सौभाग्य से, `pandas` डुप्लीकेट एंट्रीज़ का पता लगाने और उन्हें हटाने का एक आसान तरीका प्रदान करता है।

- **डुप्लीकेट की पहचान: `duplicated`**: आप `pandas` में `duplicated` मेथड का उपयोग करके आसानी से डुप्लीकेट मानों को पहचान सकते हैं, जो एक Boolean मास्क लौटाता है जो यह दर्शाता है कि `DataFrame` में कोई एंट्री पहले की एंट्री का डुप्लीकेट है या नहीं। इसे क्रियान्वित करने के लिए आइए एक और उदाहरण `DataFrame` बनाते हैं।
```python
example4 = pd.DataFrame({'letters': ['A','B'] * 2 + ['B'],
                         'numbers': [1, 2, 1, 3, 3]})
example4
```
|      |letters|numbers|
|------|-------|-------|
|0     |A      |1      |
|1     |B      |2      |
|2     |A      |1      |
|3     |B      |3      |
|4     |B      |3      |

```python
example4.duplicated()
```
```
0    False
1    False
2     True
3    False
4     True
dtype: bool
```
- **डुप्लीकेट हटाना: `drop_duplicates`:** यह केवल उन डेटा की एक कॉपी लौटाता है जिनके सभी `duplicated` मान `False` हैं:
```python
example4.drop_duplicates()
```
```
	letters	numbers
0	A	1
1	B	2
3	B	3
```
`duplicated` और `drop_duplicates` दोनों डिफ़ॉल्ट रूप से सभी कॉलम्स को ध्यान में रखते हैं, लेकिन आप यह निर्दिष्ट कर सकते हैं कि वे आपके `DataFrame` में केवल कॉलम्स के एक उपसमूह की जांच करें:
```python
example4.drop_duplicates(['letters'])
```
```
letters	numbers
0	A	1
1	B	2
```

> **निष्कर्ष:** डुप्लीकेट डेटा हटाना लगभग हर डेटा-साइंस प्रोजेक्ट का एक महत्वपूर्ण हिस्सा है। डुप्लीकेट डेटा आपके विश्लेषण के परिणामों को बदल सकता है और आपको गलत परिणाम दे सकता है।


## 🚀 चुनौती

सभी चर्चा की गई सामग्री [Jupyter Notebook](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/2-Working-With-Data/08-data-preparation/notebook.ipynb) के रूप में उपलब्ध है। इसके अलावा, प्रत्येक अनुभाग के बाद अभ्यास दिए गए हैं, उन्हें आज़माएं!

## [पोस्ट-लेक्चर क्विज़](https://ff-quizzes.netlify.app/en/ds/quiz/15)



## समीक्षा और स्व-अध्ययन

अपने डेटा को विश्लेषण और मॉडलिंग के लिए तैयार करने के कई तरीके हैं, और डेटा को साफ करना एक महत्वपूर्ण कदम है जो "हैंड्स ऑन" अनुभव है। Kaggle से इन चुनौतियों को आज़माएं ताकि उन तकनीकों का पता लगाया जा सके जो इस पाठ में शामिल नहीं थीं।

- [डेटा क्लीनिंग चुनौती: डेट्स को पार्स करना](https://www.kaggle.com/rtatman/data-cleaning-challenge-parsing-dates/)

- [डेटा क्लीनिंग चुनौती: डेटा को स्केल और नॉर्मलाइज़ करना](https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data)


## असाइनमेंट

[फॉर्म से डेटा का मूल्यांकन करना](assignment.md)

---

**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता सुनिश्चित करने का प्रयास करते हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियां या अशुद्धियां हो सकती हैं। मूल भाषा में उपलब्ध मूल दस्तावेज़ को प्रामाणिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।