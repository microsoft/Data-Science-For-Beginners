{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Ciência de Dados na Nuvem: O caminho do \"Azure ML SDK\"\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Neste notebook, vamos aprender a usar o Azure ML SDK para treinar, implementar e consumir um modelo através do Azure ML.\n",
    "\n",
    "Pré-requisitos:  \n",
    "1. Criou um workspace do Azure ML.  \n",
    "2. Carregou o [conjunto de dados de Insuficiência Cardíaca](https://www.kaggle.com/andrewmvd/heart-failure-clinical-data) no Azure ML.  \n",
    "3. Carregou este notebook no Azure ML Studio.  \n",
    "\n",
    "Os próximos passos são:\n",
    "\n",
    "1. Criar uma Experiência num Workspace existente.  \n",
    "2. Criar um cluster de Computação.  \n",
    "3. Carregar o conjunto de dados.  \n",
    "4. Configurar o AutoML usando AutoMLConfig.  \n",
    "5. Executar a experiência AutoML.  \n",
    "6. Explorar os resultados e obter o melhor modelo.  \n",
    "7. Registar o melhor modelo.  \n",
    "8. Implementar o melhor modelo.  \n",
    "9. Consumir o endpoint.  \n",
    "\n",
    "## Importações específicas do Azure Machine Learning SDK  \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import AciWebservice"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inicializar Espaço de Trabalho\n",
    "Inicialize um objeto de espaço de trabalho a partir de uma configuração persistente. Certifique-se de que o ficheiro de configuração está presente em .\\config.json\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Criar uma experiência no Azure ML\n",
    "\n",
    "Vamos criar uma experiência chamada 'aml-experiment' no espaço de trabalho que acabámos de inicializar.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "experiment_name = 'aml-experiment'\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "experiment"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Criar um Cluster de Computação\n",
    "Será necessário criar um [alvo de computação](https://docs.microsoft.com/azure/machine-learning/concept-azure-machine-learning-architecture#compute-target) para a sua execução do AutoML.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "aml_name = \"heart-f-cluster\"\n",
    "try:\n",
    "    aml_compute = AmlCompute(ws, aml_name)\n",
    "    print('Found existing AML compute context.')\n",
    "except:\n",
    "    print('Creating new AML compute context.')\n",
    "    aml_config = AmlCompute.provisioning_configuration(vm_size = \"Standard_D2_v2\", min_nodes=1, max_nodes=3)\n",
    "    aml_compute = AmlCompute.create(ws, name = aml_name, provisioning_configuration = aml_config)\n",
    "    aml_compute.wait_for_completion(show_output = True)\n",
    "\n",
    "cts = ws.compute_targets\n",
    "compute_target = cts[aml_name]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dados\n",
    "Certifique-se de que carregou o conjunto de dados para o Azure ML e que a chave tem o mesmo nome que o conjunto de dados.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "key = 'heart-failure-records'\n",
    "dataset = ws.datasets[key]\n",
    "df = dataset.to_pandas_dataframe()\n",
    "df.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configuração AutoML\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\": 20,\n",
    "    \"max_concurrent_iterations\": 3,\n",
    "    \"primary_metric\" : 'AUC_weighted'\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(compute_target=compute_target,\n",
    "                             task = \"classification\",\n",
    "                             training_data=dataset,\n",
    "                             label_column_name=\"DEATH_EVENT\",\n",
    "                             enable_early_stopping= True,\n",
    "                             featurization= 'auto',\n",
    "                             debug_log = \"automl_errors.log\",\n",
    "                             **automl_settings\n",
    "                            )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Execução AutoML\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "remote_run = experiment.submit(automl_config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "RunDetails(remote_run).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_run, fitted_model = remote_run.get_output()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_run.get_properties()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_name = best_run.properties['model_name']\n",
    "script_file_name = 'inference/score.py'\n",
    "best_run.download_file('outputs/scoring_file_v_1_0_0.py', 'inference/score.py')\n",
    "description = \"aml heart failure project sdk\"\n",
    "model = best_run.register_model(model_name = model_name,\n",
    "                                description = description,\n",
    "                                tags = None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementar o Melhor Modelo\n",
    "\n",
    "Execute o seguinte código para implementar o melhor modelo. Pode verificar o estado da implementação no portal do Azure ML. Este passo pode demorar alguns minutos.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "inference_config = InferenceConfig(entry_script=script_file_name, environment=best_run.get_environment())\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
    "                                               memory_gb = 1,\n",
    "                                               tags = {'type': \"automl-heart-failure-prediction\"},\n",
    "                                               description = 'Sample service for AutoML Heart Failure Prediction')\n",
    "\n",
    "aci_service_name = 'automl-hf-sdk'\n",
    "aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Consumir o Endpoint\n",
    "Pode adicionar entradas ao exemplo de entrada abaixo.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = {\n",
    "    \"data\":\n",
    "    [\n",
    "        {\n",
    "            'age': \"60\",\n",
    "            'anaemia': \"false\",\n",
    "            'creatinine_phosphokinase': \"500\",\n",
    "            'diabetes': \"false\",\n",
    "            'ejection_fraction': \"38\",\n",
    "            'high_blood_pressure': \"false\",\n",
    "            'platelets': \"260000\",\n",
    "            'serum_creatinine': \"1.40\",\n",
    "            'serum_sodium': \"137\",\n",
    "            'sex': \"false\",\n",
    "            'smoking': \"false\",\n",
    "            'time': \"130\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "test_sample = str.encode(json.dumps(data))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "response = aci_service.run(input_data=test_sample)\n",
    "response"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Aviso Legal**:  \nEste documento foi traduzido utilizando o serviço de tradução automática [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precisão, esteja ciente de que traduções automáticas podem conter erros ou imprecisões. O documento original na sua língua nativa deve ser considerado a fonte oficial. Para informações críticas, recomenda-se a tradução profissional realizada por humanos. Não nos responsabilizamos por quaisquer mal-entendidos ou interpretações incorretas resultantes do uso desta tradução.\n"
   ]
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  },
  "coopTranslator": {
   "original_hash": "af42669556d5dc19fc4cc3866f7d2597",
   "translation_date": "2025-09-02T05:39:32+00:00",
   "source_file": "5-Data-Science-In-Cloud/19-Azure/notebook.ipynb",
   "language_code": "pt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}