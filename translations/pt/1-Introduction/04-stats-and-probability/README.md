<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1cf49f029ba1f25a54f0d5bc2fa575fc",
  "translation_date": "2025-09-05T13:25:46+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "pt"
}
-->
# Uma Breve Introdu√ß√£o √† Estat√≠stica e Probabilidade

|![ Sketchnote por [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| Estat√≠stica e Probabilidade - _Sketchnote por [@nitya](https://twitter.com/nitya)_ |

A Teoria da Estat√≠stica e Probabilidade s√£o duas √°reas altamente relacionadas da Matem√°tica que t√™m grande relev√¢ncia para a Ci√™ncia de Dados. √â poss√≠vel trabalhar com dados sem um conhecimento profundo de matem√°tica, mas √© sempre melhor conhecer pelo menos alguns conceitos b√°sicos. Aqui apresentaremos uma breve introdu√ß√£o que o ajudar√° a come√ßar.

[![V√≠deo de Introdu√ß√£o](../../../../1-Introduction/04-stats-and-probability/images/video-prob-and-stats.png)](https://youtu.be/Z5Zy85g4Yjw)

## [Question√°rio pr√©-aula](https://ff-quizzes.netlify.app/en/ds/quiz/6)

## Probabilidade e Vari√°veis Aleat√≥rias

**Probabilidade** √© um n√∫mero entre 0 e 1 que expressa qu√£o prov√°vel √© que um **evento** ocorra. √â definida como o n√∫mero de resultados positivos (que levam ao evento), dividido pelo n√∫mero total de resultados, assumindo que todos os resultados s√£o igualmente prov√°veis. Por exemplo, ao lan√ßar um dado, a probabilidade de obter um n√∫mero par √© 3/6 = 0.5.

Quando falamos de eventos, usamos **vari√°veis aleat√≥rias**. Por exemplo, a vari√°vel aleat√≥ria que representa o n√∫mero obtido ao lan√ßar um dado pode assumir valores de 1 a 6. O conjunto de n√∫meros de 1 a 6 √© chamado de **espa√ßo amostral**. Podemos falar sobre a probabilidade de uma vari√°vel aleat√≥ria assumir um determinado valor, por exemplo, P(X=3)=1/6.

A vari√°vel aleat√≥ria no exemplo anterior √© chamada de **discreta**, porque tem um espa√ßo amostral cont√°vel, ou seja, h√° valores separados que podem ser enumerados. Existem casos em que o espa√ßo amostral √© um intervalo de n√∫meros reais ou o conjunto completo de n√∫meros reais. Essas vari√°veis s√£o chamadas de **cont√≠nuas**. Um bom exemplo √© o hor√°rio de chegada de um autocarro.

## Distribui√ß√£o de Probabilidade

No caso de vari√°veis aleat√≥rias discretas, √© f√°cil descrever a probabilidade de cada evento por uma fun√ß√£o P(X). Para cada valor *s* do espa√ßo amostral *S*, ela fornecer√° um n√∫mero entre 0 e 1, de forma que a soma de todos os valores de P(X=s) para todos os eventos seja igual a 1.

A distribui√ß√£o discreta mais conhecida √© a **distribui√ß√£o uniforme**, na qual h√° um espa√ßo amostral de N elementos, com probabilidade igual de 1/N para cada um deles.

√â mais dif√≠cil descrever a distribui√ß√£o de probabilidade de uma vari√°vel cont√≠nua, com valores retirados de algum intervalo [a,b], ou do conjunto completo de n√∫meros reais ‚Ñù. Considere o caso do hor√°rio de chegada de um autocarro. Na verdade, para cada hor√°rio exato de chegada *t*, a probabilidade de o autocarro chegar exatamente nesse hor√°rio √© 0!

> Agora sabe que eventos com probabilidade 0 acontecem, e com muita frequ√™ncia! Pelo menos sempre que o autocarro chega!

S√≥ podemos falar sobre a probabilidade de uma vari√°vel cair em um determinado intervalo de valores, por exemplo, P(t<sub>1</sub>‚â§X<t<sub>2</sub>). Nesse caso, a distribui√ß√£o de probabilidade √© descrita por uma **fun√ß√£o densidade de probabilidade** p(x), tal que

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../1-Introduction/04-stats-and-probability/images/probability-density.png)

Um an√°logo cont√≠nuo da distribui√ß√£o uniforme √© chamado de **uniforme cont√≠nua**, que √© definido em um intervalo finito. A probabilidade de o valor X cair em um intervalo de comprimento l √© proporcional a l, e aumenta at√© 1.

Outra distribui√ß√£o importante √© a **distribui√ß√£o normal**, sobre a qual falaremos mais detalhadamente abaixo.

## M√©dia, Vari√¢ncia e Desvio Padr√£o

Suponha que retiramos uma sequ√™ncia de n amostras de uma vari√°vel aleat√≥ria X: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. Podemos definir o valor **m√©dio** (ou **m√©dia aritm√©tica**) da sequ√™ncia da maneira tradicional como (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n. √Ä medida que aumentamos o tamanho da amostra (ou seja, tomamos o limite com n‚Üí‚àû), obtemos a m√©dia (tamb√©m chamada de **expectativa**) da distribui√ß√£o. Denotaremos a expectativa por **E**(x).

> Pode-se demonstrar que, para qualquer distribui√ß√£o discreta com valores {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} e probabilidades correspondentes p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, a expectativa seria igual a E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>.

Para identificar o qu√£o dispersos est√£o os valores, podemos calcular a vari√¢ncia œÉ<sup>2</sup> = ‚àë(x<sub>i</sub> - Œº)<sup>2</sup>/n, onde Œº √© a m√©dia da sequ√™ncia. O valor œÉ √© chamado de **desvio padr√£o**, e œÉ<sup>2</sup> √© chamado de **vari√¢ncia**.

## Moda, Mediana e Quartis

√Äs vezes, a m√©dia n√£o representa adequadamente o valor "t√≠pico" dos dados. Por exemplo, quando h√° alguns valores extremos que est√£o completamente fora do intervalo, eles podem afetar a m√©dia. Outra boa indica√ß√£o √© a **mediana**, um valor tal que metade dos pontos de dados s√£o menores que ele, e a outra metade - maiores.

Para nos ajudar a entender a distribui√ß√£o dos dados, √© √∫til falar sobre **quartis**:

* Primeiro quartil, ou Q1, √© um valor tal que 25% dos dados est√£o abaixo dele
* Terceiro quartil, ou Q3, √© um valor tal que 75% dos dados est√£o abaixo dele

Graficamente, podemos representar a rela√ß√£o entre mediana e quartis em um diagrama chamado **box plot**:

<img src="images/boxplot_explanation.png" width="50%"/>

Aqui tamb√©m calculamos o **intervalo interquartil** IQR=Q3-Q1, e os chamados **outliers** - valores que est√£o fora dos limites [Q1-1.5*IQR,Q3+1.5*IQR].

Para uma distribui√ß√£o finita que cont√©m um pequeno n√∫mero de valores poss√≠veis, um bom valor "t√≠pico" √© aquele que aparece com mais frequ√™ncia, chamado de **moda**. √â frequentemente aplicado a dados categ√≥ricos, como cores. Considere uma situa√ß√£o em que temos dois grupos de pessoas - algumas que preferem fortemente vermelho, e outras que preferem azul. Se codificarmos as cores por n√∫meros, o valor m√©dio para a cor favorita estaria em algum lugar no espectro laranja-verde, o que n√£o indica a prefer√™ncia real de nenhum dos grupos. No entanto, a moda seria uma das cores ou ambas, se o n√∫mero de pessoas que votam por elas for igual (nesse caso, chamamos a amostra de **multimodal**).

## Dados do Mundo Real

Quando analisamos dados da vida real, eles frequentemente n√£o s√£o vari√°veis aleat√≥rias propriamente ditas, no sentido de que n√£o realizamos experimentos com resultados desconhecidos. Por exemplo, considere uma equipa de jogadores de basebol e seus dados corporais, como altura, peso e idade. Esses n√∫meros n√£o s√£o exatamente aleat√≥rios, mas ainda podemos aplicar os mesmos conceitos matem√°ticos. Por exemplo, uma sequ√™ncia de pesos de pessoas pode ser considerada uma sequ√™ncia de valores retirados de alguma vari√°vel aleat√≥ria. Abaixo est√° a sequ√™ncia de pesos de jogadores reais de basebol da [Major League Baseball](http://mlb.mlb.com/index.jsp), retirada deste [conjunto de dados](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) (para sua conveni√™ncia, apenas os primeiros 20 valores s√£o mostrados):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Nota**: Para ver o exemplo de trabalho com este conjunto de dados, veja o [notebook associado](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb). H√° tamb√©m v√°rios desafios ao longo desta li√ß√£o, e pode complet√°-los adicionando algum c√≥digo a esse notebook. Se n√£o souber como operar com dados, n√£o se preocupe - voltaremos a trabalhar com dados usando Python mais tarde. Se n√£o sabe como executar c√≥digo no Jupyter Notebook, veja [este artigo](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

Aqui est√° o box plot mostrando m√©dia, mediana e quartis para os nossos dados:

![Box Plot de Peso](../../../../1-Introduction/04-stats-and-probability/images/weight-boxplot.png)

Como os nossos dados cont√™m informa√ß√µes sobre diferentes **fun√ß√µes** dos jogadores, tamb√©m podemos fazer o box plot por fun√ß√£o - isso permitir√° que tenhamos uma ideia de como os valores dos par√¢metros diferem entre as fun√ß√µes. Desta vez, consideraremos a altura:

![Box plot por fun√ß√£o](../../../../1-Introduction/04-stats-and-probability/images/boxplot_byrole.png)

Este diagrama sugere que, em m√©dia, a altura dos jogadores de primeira base √© maior do que a altura dos jogadores de segunda base. Mais tarde nesta li√ß√£o, aprenderemos como podemos testar esta hip√≥tese de forma mais formal e como demonstrar que os nossos dados s√£o estatisticamente significativos para mostrar isso.

> Ao trabalhar com dados do mundo real, assumimos que todos os pontos de dados s√£o amostras retiradas de alguma distribui√ß√£o de probabilidade. Esta suposi√ß√£o permite-nos aplicar t√©cnicas de aprendizagem autom√°tica e construir modelos preditivos funcionais.

Para ver qual √© a distribui√ß√£o dos nossos dados, podemos tra√ßar um gr√°fico chamado **histograma**. O eixo X conter√° um n√∫mero de diferentes intervalos de peso (os chamados **bins**), e o eixo vertical mostrar√° o n√∫mero de vezes que a amostra da vari√°vel aleat√≥ria esteve dentro de um determinado intervalo.

![Histograma de dados do mundo real](../../../../1-Introduction/04-stats-and-probability/images/weight-histogram.png)

A partir deste histograma, pode ver que todos os valores est√£o centrados em torno de um determinado peso m√©dio, e quanto mais nos afastamos desse peso, menos pesos desse valor s√£o encontrados. Ou seja, √© muito improv√°vel que o peso de um jogador de basebol seja muito diferente do peso m√©dio. A vari√¢ncia dos pesos mostra a extens√£o em que os pesos provavelmente diferem da m√©dia.

> Se considerarmos os pesos de outras pessoas, n√£o da liga de basebol, a distribui√ß√£o provavelmente ser√° diferente. No entanto, o formato da distribui√ß√£o ser√° o mesmo, mas a m√©dia e a vari√¢ncia mudariam. Assim, se treinarmos o nosso modelo com jogadores de basebol, √© prov√°vel que ele produza resultados errados quando aplicado a estudantes de uma universidade, porque a distribui√ß√£o subjacente √© diferente.

## Distribui√ß√£o Normal

A distribui√ß√£o de pesos que vimos acima √© muito t√≠pica, e muitas medi√ß√µes do mundo real seguem o mesmo tipo de distribui√ß√£o, mas com diferentes m√©dias e vari√¢ncias. Esta distribui√ß√£o √© chamada de **distribui√ß√£o normal**, e desempenha um papel muito importante na estat√≠stica.

Usar a distribui√ß√£o normal √© uma forma correta de gerar pesos aleat√≥rios de potenciais jogadores de basebol. Uma vez que sabemos o peso m√©dio `mean` e o desvio padr√£o `std`, podemos gerar 1000 amostras de peso da seguinte forma:
```python
samples = np.random.normal(mean,std,1000)
``` 

Se tra√ßarmos o histograma das amostras geradas, veremos uma imagem muito semelhante √† mostrada acima. E se aumentarmos o n√∫mero de amostras e o n√∫mero de bins, podemos gerar uma imagem de uma distribui√ß√£o normal mais pr√≥xima do ideal:

![Distribui√ß√£o Normal com m√©dia=0 e desvio padr√£o=1](../../../../1-Introduction/04-stats-and-probability/images/normal-histogram.png)

*Distribui√ß√£o Normal com m√©dia=0 e desvio padr√£o=1*

## Intervalos de Confian√ßa

Quando falamos sobre os pesos dos jogadores de basebol, assumimos que existe uma **vari√°vel aleat√≥ria W** que corresponde √† distribui√ß√£o de probabilidade ideal dos pesos de todos os jogadores de basebol (o chamado **popula√ß√£o**). A nossa sequ√™ncia de pesos corresponde a um subconjunto de todos os jogadores de basebol que chamamos de **amostra**. Uma quest√£o interessante √©: podemos conhecer os par√¢metros da distribui√ß√£o de W, ou seja, a m√©dia e a vari√¢ncia da popula√ß√£o?

A resposta mais simples seria calcular a m√©dia e a vari√¢ncia da nossa amostra. No entanto, pode acontecer que a nossa amostra aleat√≥ria n√£o represente com precis√£o a popula√ß√£o completa. Assim, faz sentido falar sobre **intervalo de confian√ßa**.

> **Intervalo de confian√ßa** √© a estimativa da verdadeira m√©dia da popula√ß√£o dada a nossa amostra, que √© precisa com uma certa probabilidade (ou **n√≠vel de confian√ßa**).

Suponha que temos uma amostra X

1</sub>, ..., X<sub>n</sub> da nossa distribui√ß√£o. Cada vez que extra√≠mos uma amostra da nossa distribui√ß√£o, acabamos com um valor m√©dio diferente Œº. Assim, Œº pode ser considerado uma vari√°vel aleat√≥ria. Um **intervalo de confian√ßa** com confian√ßa p √© um par de valores (L<sub>p</sub>,R<sub>p</sub>), tal que **P**(L<sub>p</sub>‚â§Œº‚â§R<sub>p</sub>) = p, ou seja, a probabilidade de o valor m√©dio medido estar dentro do intervalo √© igual a p.

Vai al√©m da nossa breve introdu√ß√£o discutir em detalhe como esses intervalos de confian√ßa s√£o calculados. Mais detalhes podem ser encontrados [na Wikip√©dia](https://en.wikipedia.org/wiki/Confidence_interval). Em resumo, definimos a distribui√ß√£o da m√©dia amostral calculada em rela√ß√£o √† verdadeira m√©dia da popula√ß√£o, que √© chamada de **distribui√ß√£o t de Student**.

> **Fato interessante**: A distribui√ß√£o t de Student foi nomeada em homenagem ao matem√°tico William Sealy Gosset, que publicou seu artigo sob o pseud√¥nimo "Student". Ele trabalhava na cervejaria Guinness e, segundo uma das vers√µes, seu empregador n√£o queria que o p√∫blico soubesse que estavam usando testes estat√≠sticos para determinar a qualidade das mat√©rias-primas.

Se quisermos estimar a m√©dia Œº da nossa popula√ß√£o com confian√ßa p, precisamos pegar o *(1-p)/2-th percentil* de uma distribui√ß√£o t de Student A, que pode ser obtido em tabelas ou calculado usando fun√ß√µes integradas de software estat√≠stico (por exemplo, Python, R, etc.). Ent√£o, o intervalo para Œº seria dado por X¬±A*D/‚àön, onde X √© a m√©dia obtida da amostra, D √© o desvio padr√£o.

> **Nota**: Tamb√©m omitimos a discuss√£o de um conceito importante de [graus de liberdade](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)), que √© relevante em rela√ß√£o √† distribui√ß√£o t de Student. Pode consultar livros mais completos sobre estat√≠stica para entender este conceito mais profundamente.

Um exemplo de c√°lculo de intervalo de confian√ßa para pesos e alturas √© dado nos [notebooks associados](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb).

| p    | M√©dia do peso |
|------|---------------|
| 0.85 | 201.73¬±0.94   |
| 0.90 | 201.73¬±1.08   |
| 0.95 | 201.73¬±1.28   |

Note que quanto maior a probabilidade de confian√ßa, mais amplo √© o intervalo de confian√ßa.

## Teste de Hip√≥teses

No nosso conjunto de dados de jogadores de beisebol, existem diferentes fun√ß√µes de jogadores, que podem ser resumidas abaixo (veja o [notebook associado](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) para ver como esta tabela pode ser calculada):

| Fun√ß√£o             | Altura    | Peso      | Contagem |
|--------------------|-----------|-----------|----------|
| Catcher           | 72.723684 | 204.328947 | 76       |
| Designated_Hitter | 74.222222 | 220.888889 | 18       |
| First_Baseman     | 74.000000 | 213.109091 | 55       |
| Outfielder        | 73.010309 | 199.113402 | 194      |
| Relief_Pitcher    | 74.374603 | 203.517460 | 315      |
| Second_Baseman    | 71.362069 | 184.344828 | 58       |
| Shortstop         | 71.903846 | 182.923077 | 52       |
| Starting_Pitcher  | 74.719457 | 205.163636 | 221      |
| Third_Baseman     | 73.044444 | 200.955556 | 45       |

Podemos notar que a m√©dia das alturas dos jogadores da primeira base √© maior do que a dos jogadores da segunda base. Assim, podemos ser tentados a concluir que **os jogadores da primeira base s√£o mais altos do que os da segunda base**.

> Esta afirma√ß√£o √© chamada de **hip√≥tese**, porque n√£o sabemos se o fato √© realmente verdadeiro ou n√£o.

No entanto, nem sempre √© √≥bvio se podemos tirar essa conclus√£o. Pela discuss√£o acima, sabemos que cada m√©dia tem um intervalo de confian√ßa associado, e, portanto, essa diferen√ßa pode ser apenas um erro estat√≠stico. Precisamos de uma forma mais formal de testar nossa hip√≥tese.

Vamos calcular os intervalos de confian√ßa separadamente para as alturas dos jogadores da primeira e da segunda base:

| Confian√ßa | Primeira Base | Segunda Base |
|-----------|---------------|--------------|
| 0.85      | 73.62..74.38  | 71.04..71.69 |
| 0.90      | 73.56..74.44  | 70.99..71.73 |
| 0.95      | 73.47..74.53  | 70.92..71.81 |

Podemos ver que, em nenhuma confian√ßa, os intervalos se sobrep√µem. Isso prova nossa hip√≥tese de que os jogadores da primeira base s√£o mais altos do que os da segunda base.

Mais formalmente, o problema que estamos resolvendo √© verificar se **duas distribui√ß√µes de probabilidade s√£o iguais**, ou pelo menos t√™m os mesmos par√¢metros. Dependendo da distribui√ß√£o, precisamos usar diferentes testes para isso. Se sabemos que nossas distribui√ß√µes s√£o normais, podemos aplicar o **[teste t de Student](https://en.wikipedia.org/wiki/Student%27s_t-test)**.

No teste t de Student, calculamos o chamado **valor t**, que indica a diferen√ßa entre as m√©dias, levando em conta a vari√¢ncia. √â demonstrado que o valor t segue a **distribui√ß√£o t de Student**, o que nos permite obter o valor limite para um n√≠vel de confian√ßa **p** dado (isso pode ser calculado ou consultado em tabelas num√©ricas). Em seguida, comparamos o valor t com esse limite para aprovar ou rejeitar a hip√≥tese.

Em Python, podemos usar o pacote **SciPy**, que inclui a fun√ß√£o `ttest_ind` (al√©m de muitas outras fun√ß√µes estat√≠sticas √∫teis!). Ele calcula o valor t para n√≥s e tamb√©m faz a consulta reversa do valor de confian√ßa p, para que possamos apenas olhar para a confian√ßa e tirar a conclus√£o.

Por exemplo, nossa compara√ß√£o entre as alturas dos jogadores da primeira e da segunda base nos d√° os seguintes resultados: 
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
No nosso caso, o valor p √© muito baixo, o que significa que h√° fortes evid√™ncias de que os jogadores da primeira base s√£o mais altos.

Existem tamb√©m outros tipos de hip√≥teses que podemos querer testar, por exemplo:
* Provar que uma amostra segue alguma distribui√ß√£o. No nosso caso, assumimos que as alturas t√™m distribui√ß√£o normal, mas isso precisa de verifica√ß√£o estat√≠stica formal.
* Provar que o valor m√©dio de uma amostra corresponde a algum valor pr√©-definido.
* Comparar as m√©dias de v√°rias amostras (por exemplo, qual √© a diferen√ßa nos n√≠veis de felicidade entre diferentes faixas et√°rias).

## Lei dos Grandes N√∫meros e Teorema Central do Limite

Uma das raz√µes pelas quais a distribui√ß√£o normal √© t√£o importante √© o chamado **teorema central do limite**. Suponha que temos uma grande amostra de N valores independentes X<sub>1</sub>, ..., X<sub>N</sub>, amostrados de qualquer distribui√ß√£o com m√©dia Œº e vari√¢ncia œÉ<sup>2</sup>. Ent√£o, para N suficientemente grande (em outras palavras, quando N‚Üí‚àû), a m√©dia Œ£<sub>i</sub>X<sub>i</sub> ser√° normalmente distribu√≠da, com m√©dia Œº e vari√¢ncia œÉ<sup>2</sup>/N.

> Outra forma de interpretar o teorema central do limite √© dizer que, independentemente da distribui√ß√£o, quando calculamos a m√©dia de uma soma de valores de qualquer vari√°vel aleat√≥ria, acabamos com uma distribui√ß√£o normal.

Do teorema central do limite tamb√©m se segue que, quando N‚Üí‚àû, a probabilidade de a m√©dia da amostra ser igual a Œº torna-se 1. Isso √© conhecido como **a lei dos grandes n√∫meros**.

## Covari√¢ncia e Correla√ß√£o

Uma das coisas que a Ci√™ncia de Dados faz √© encontrar rela√ß√µes entre dados. Dizemos que duas sequ√™ncias **correlacionam** quando exibem comportamento semelhante ao mesmo tempo, ou seja, elas sobem/descem simultaneamente, ou uma sequ√™ncia sobe quando outra desce e vice-versa. Em outras palavras, parece haver alguma rela√ß√£o entre duas sequ√™ncias.

> Correla√ß√£o n√£o indica necessariamente uma rela√ß√£o causal entre duas sequ√™ncias; √†s vezes, ambas as vari√°veis podem depender de alguma causa externa, ou pode ser puramente por acaso que as duas sequ√™ncias se correlacionam. No entanto, uma forte correla√ß√£o matem√°tica √© uma boa indica√ß√£o de que duas vari√°veis est√£o de alguma forma conectadas.

Matematicamente, o principal conceito que mostra a rela√ß√£o entre duas vari√°veis aleat√≥rias √© a **covari√¢ncia**, que √© calculada assim: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. Calculamos o desvio de ambas as vari√°veis em rela√ß√£o aos seus valores m√©dios e, em seguida, o produto desses desvios. Se ambas as vari√°veis se desviam juntas, o produto ser√° sempre um valor positivo, que se somar√° a uma covari√¢ncia positiva. Se ambas as vari√°veis se desviam fora de sincronia (ou seja, uma cai abaixo da m√©dia quando outra sobe acima da m√©dia), sempre obteremos n√∫meros negativos, que se somar√£o a uma covari√¢ncia negativa. Se os desvios n√£o forem dependentes, eles se somar√£o a aproximadamente zero.

O valor absoluto da covari√¢ncia n√£o nos diz muito sobre o qu√£o grande √© a correla√ß√£o, porque depende da magnitude dos valores reais. Para normaliz√°-lo, podemos dividir a covari√¢ncia pelo desvio padr√£o de ambas as vari√°veis, para obter a **correla√ß√£o**. A vantagem √© que a correla√ß√£o est√° sempre no intervalo de [-1,1], onde 1 indica forte correla√ß√£o positiva entre os valores, -1 - forte correla√ß√£o negativa, e 0 - nenhuma correla√ß√£o (as vari√°veis s√£o independentes).

**Exemplo**: Podemos calcular a correla√ß√£o entre os pesos e alturas dos jogadores de beisebol do conjunto de dados mencionado acima:
```python
print(np.corrcoef(weights,heights))
```
Como resultado, obtemos uma **matriz de correla√ß√£o** como esta:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> A matriz de correla√ß√£o C pode ser calculada para qualquer n√∫mero de sequ√™ncias de entrada S<sub>1</sub>, ..., S<sub>n</sub>. O valor de C<sub>ij</sub> √© a correla√ß√£o entre S<sub>i</sub> e S<sub>j</sub>, e os elementos diagonais s√£o sempre 1 (que √© tamb√©m a autocorrela√ß√£o de S<sub>i</sub>).

No nosso caso, o valor 0.53 indica que h√° alguma correla√ß√£o entre o peso e a altura de uma pessoa. Tamb√©m podemos fazer o gr√°fico de dispers√£o de um valor contra o outro para ver a rela√ß√£o visualmente:

![Rela√ß√£o entre peso e altura](../../../../1-Introduction/04-stats-and-probability/images/weight-height-relationship.png)

> Mais exemplos de correla√ß√£o e covari√¢ncia podem ser encontrados no [notebook associado](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb).

## Conclus√£o

Nesta se√ß√£o, aprendemos:

* propriedades estat√≠sticas b√°sicas dos dados, como m√©dia, vari√¢ncia, moda e quartis
* diferentes distribui√ß√µes de vari√°veis aleat√≥rias, incluindo a distribui√ß√£o normal
* como encontrar correla√ß√£o entre diferentes propriedades
* como usar ferramentas matem√°ticas e estat√≠sticas para provar algumas hip√≥teses
* como calcular intervalos de confian√ßa para uma vari√°vel aleat√≥ria dada uma amostra de dados

Embora esta n√£o seja uma lista exaustiva de t√≥picos que existem dentro de probabilidade e estat√≠stica, deve ser suficiente para lhe dar um bom in√≠cio neste curso.

## üöÄ Desafio

Use o c√≥digo de exemplo no notebook para testar outras hip√≥teses:
1. Os jogadores da primeira base s√£o mais velhos do que os da segunda base.
2. Os jogadores da primeira base s√£o mais altos do que os da terceira base.
3. Os shortstops s√£o mais altos do que os jogadores da segunda base.

## [Question√°rio p√≥s-aula](https://ff-quizzes.netlify.app/en/ds/quiz/7)

## Revis√£o e Autoestudo

Probabilidade e estat√≠stica √© um t√≥pico t√£o amplo que merece seu pr√≥prio curso. Se estiver interessado em aprofundar-se na teoria, pode continuar lendo alguns dos seguintes livros:

1. [Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/) da Universidade de Nova Iorque tem √≥timos apontamentos [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (dispon√≠vel online).
1. [Peter e Andrew Bruce. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[c√≥digo de exemplo em R](https://github.com/andrewgbruce/statistics-for-data-scientists)].
1. [James D. Miller. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[c√≥digo de exemplo em R](https://github.com/PacktPublishing/Statistics-for-Data-Science)].

## Tarefa

[Pequeno Estudo sobre Diabetes](assignment.md)

## Cr√©ditos

Esta li√ß√£o foi criada com ‚ô•Ô∏è por [Dmitry Soshnikov](http://soshnikov.com)

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, √© importante notar que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorit√°ria. Para informa√ß√µes cr√≠ticas, recomenda-se uma tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.