<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1341f6da63d434f5ba31b08ea951b02c",
  "translation_date": "2025-09-05T18:16:10+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "sk"
}
-->
# 칔vod do d치tovej etiky

|![ Sketchnote od [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Etika d치tovej vedy - _Sketchnote od [@nitya](https://twitter.com/nitya)_ |

---

Sme v코etci d치tov칤 ob캜ania 쬴j칰ci v d치tovom svete.

Trhov칠 trendy nazna캜uj칰, 쬰 do roku 2022 bude 1 z 3 ve쬶칳ch organiz치ci칤 kupova콘 a pred치va콘 svoje d치ta prostredn칤ctvom online [trhov a v칳men](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Ako **v칳voj치ri aplik치ci칤** zist칤me, 쬰 je jednoduch코ie a lacnej코ie integrova콘 poznatky zalo쬰n칠 na d치tach a automatiz치ciu riaden칰 algoritmami do ka쬯odenn칳ch pou쮂셨ate쬽k칳ch sk칰senost칤. Ale ako sa AI st치va v코adepr칤tomnou, budeme musie콘 pochopi콘 aj potenci치lne 코kody sp칪soben칠 [zbra켿ovan칤m](https://www.youtube.com/watch?v=TQHs8SA1qpk) tak칳chto algoritmov vo ve쬶om rozsahu.

Trendy tie nazna캜uj칰, 쬰 do roku 2025 vytvor칤me a spotrebujeme viac ako [180 zettabajtov](https://www.statista.com/statistics/871513/worldwide-data-created/) d치t. Ako **d치tov칤 vedci** z칤skame bezprecedentn칳 pr칤stup k osobn칳m 칰dajom. To znamen치, 쬰 m칪쬰me vytv치ra콘 behavior치lne profily pou쮂셨ate쬺v a ovplyv켿ova콘 rozhodovanie sp칪sobmi, ktor칠 vytv치raj칰 [il칰ziu vo쬭y](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice), pri캜om potenci치lne pos칰vame pou쮂셨ate쬺v k v칳sledkom, ktor칠 preferujeme. To tie otv치ra 코ir코ie ot치zky o ochrane s칰kromia a pr치v pou쮂셨ate쬺v.

D치tov치 etika je teraz _nevyhnutn칳m ochrann칳m mechanizmom_ pre d치tov칰 vedu a in쬴nierstvo, pom치haj칰c n치m minimalizova콘 potenci치lne 코kody a ne칰myseln칠 d칪sledky na코ich rozhodnut칤 zalo쬰n칳ch na d치tach. [Gartnerov Hype Cycle pre AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) identifikuje relevantn칠 trendy v digit치lnej etike, zodpovednej AI a spr치ve AI ako k쮂줷꼂v칠 faktory pre v칛캜코ie megatrendy okolo _demokratiz치cie_ a _industrializ치cie_ AI.

![Gartnerov Hype Cycle pre AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

V tejto lekcii presk칰mame fascinuj칰cu oblas콘 d치tovej etiky - od z치kladn칳ch konceptov a v칳ziev, cez pr칤padov칠 코t칰die a po aplikovan칠 koncepty AI, ako je spr치va - ktor칠 pom치haj칰 vytv치ra콘 kult칰ru etiky v t칤moch a organiz치ci치ch pracuj칰cich s d치tami a AI.

## [Kv칤z pred predn치코kou](https://ff-quizzes.netlify.app/en/ds/quiz/2) 游꿢

## Z치kladn칠 defin칤cie

Za캜nime pochopen칤m z치kladnej terminol칩gie.

Slovo "etika" poch치dza z [gr칠ckeho slova "ethikos"](https://en.wikipedia.org/wiki/Ethics) (a jeho kore켿a "ethos"), 캜o znamen치 _charakter alebo mor치lna povaha_. 

**Etika** sa t칳ka spolo캜n칳ch hodn칪t a mor치lnych princ칤pov, ktor칠 riadia na코e spr치vanie v spolo캜nosti. Etika nie je zalo쬰n치 na z치konoch, ale na v코eobecne akceptovan칳ch norm치ch toho, 캜o je "spr치vne vs. nespr치vne". Etick칠 칰vahy v코ak m칪쬿 ovplyvni콘 iniciat칤vy korpor치tneho riadenia a vl치dne regul치cie, ktor칠 vytv치raj칰 viac stimulov na dodr쬴avanie pravidiel.

**D치tov치 etika** je [nov치 oblas콘 etiky](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1), ktor치 "코tuduje a hodnot칤 mor치lne probl칠my s칰visiace s _d치tami, algoritmami a zodpovedaj칰cimi praktikami_". Tu sa **"d치ta"** zameriavaj칰 na akcie s칰visiace s generovan칤m, zaznamen치van칤m, kur치ciou, spracovan칤m, 코칤ren칤m, zdie쬬n칤m a pou쮂셨an칤m, **"algoritmy"** sa zameriavaj칰 na AI, agentov, strojov칠 u캜enie a roboty, a **"praktiky"** sa zameriavaj칰 na t칠my ako zodpovedn치 inov치cia, programovanie, hacking a etick칠 k칩dy.

**Aplikovan치 etika** je [praktick치 aplik치cia mor치lnych 칰vah](https://en.wikipedia.org/wiki/Applied_ethics). Ide o proces akt칤vneho sk칰mania etick칳ch ot치zok v kontexte _re치lnych akci칤, produktov a procesov_ a prij칤mania n치pravn칳ch opatren칤 na zabezpe캜enie toho, 쬰 zostan칰 v s칰lade s na코imi definovan칳mi etick칳mi hodnotami.

**Kult칰ra etiky** sa t칳ka [_operacionaliz치cie_ aplikovanej etiky](https://hbr.org/2019/05/how-to-design-an-ethical-organization), aby sa zabezpe캜ilo, 쬰 na코e etick칠 princ칤py a praktiky bud칰 prijat칠 konzistentne a 코k치lovate쬹e naprie캜 celou organiz치ciou. 칔spe코n칠 kult칰ry etiky definuj칰 etick칠 princ칤py na 칰rovni celej organiz치cie, poskytuj칰 zmyslupln칠 stimuly na dodr쬴avanie pravidiel a posil켿uj칰 normy etiky podporovan칤m a amplifik치ciou po쬬dovan칠ho spr치vania na ka쬯ej 칰rovni organiz치cie.

## Koncepty etiky

V tejto sekcii sa budeme zaobera콘 konceptmi ako **spolo캜n칠 hodnoty** (princ칤py) a **etick칠 v칳zvy** (probl칠my) v d치tovej etike - a presk칰mame **pr칤padov칠 코t칰die**, ktor칠 v치m pom칪쬿 pochopi콘 tieto koncepty v re치lnych kontextoch.

### 1. Princ칤py etiky

Ka쬯치 strat칠gia d치tovej etiky za캜칤na definovan칤m _etick칳ch princ칤pov_ - "spolo캜n칳ch hodn칪t", ktor칠 opisuj칰 prijate쬹칠 spr치vanie a usmer켿uj칰 s칰ladn칠 akcie v na코ich d치tov칳ch a AI projektoch. M칪쬰te ich definova콘 na individu치lnej alebo t칤movej 칰rovni. V칛캜코ina ve쬶칳ch organiz치ci칤 v코ak tieto princ칤py uv치dza v _misijnom vyhl치sen칤 alebo r치mci etickej AI_, ktor칳 je definovan칳 na korpor치tnej 칰rovni a d칪sledne presadzovan칳 naprie캜 v코etk칳mi t칤mami.

**Pr칤klad:** Misijn칠 vyhl치senie Microsoftu [Zodpovedn치 AI](https://www.microsoft.com/en-us/ai/responsible-ai) znie: _"Sme odhodlan칤 k pokroku AI riaden칠mu etick칳mi princ칤pmi, ktor칠 klad칰 쬿d칤 na prv칠 miesto"_ - identifikuj칰c 6 etick칳ch princ칤pov v r치mci ni쮄멸e:

![Zodpovedn치 AI v Microsoft](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

Po캞me si stru캜ne presk칰ma콘 tieto princ칤py. _Transparentnos콘_ a _zodpovednos콘_ s칰 z치kladn칠 hodnoty, na ktor칳ch s칰 postaven칠 ostatn칠 princ칤py - za캜nime teda nimi:

* [**Zodpovednos콘**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) rob칤 praktikov _zodpovedn칳mi_ za ich d치tov칠 a AI oper치cie a s칰lad s t칳mito etick칳mi princ칤pmi.
* [**Transparentnos콘**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) zabezpe캜uje, 쬰 akcie d치t a AI s칰 _pochopite쬹칠_ (interpretovate쬹칠) pre pou쮂셨ate쬺v, vysvet쬿j칰c 캜o a pre캜o za rozhodnutiami.
* [**Spravodlivos콘**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - zameriava sa na zabezpe캜enie, 쬰 AI zaobch치dza _so v코etk칳mi 쬿캞mi_ spravodlivo, rie코iac ak칠ko쭀ek syst칠mov칠 alebo implicitn칠 soci치lno-technick칠 predsudky v d치tach a syst칠moch.
* [**Spo쬬hlivos콘 a bezpe캜nos콘**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - zabezpe캜uje, 쬰 AI sa spr치va _konzistentne_ s definovan칳mi hodnotami, minimalizuj칰c potenci치lne 코kody alebo ne칰myseln칠 d칪sledky.
* [**S칰kromie a bezpe캜nos콘**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - ide o pochopenie p칪vodu d치t a poskytovanie _ochrany s칰kromia a s칰visiacich pr치v_ pou쮂셨ate쬺m.
* [**Inkluz칤vnos콘**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - ide o navrhovanie AI rie코en칤 s 칰myslom, prisp칪sobuj칰c ich na splnenie _코irok칠ho spektra 쬿dsk칳ch potrieb_ a schopnost칤.

> 游뚿 Zamyslite sa nad t칳m, ak칠 by mohlo by콘 va코e misijn칠 vyhl치senie d치tovej etiky. Presk칰majte r치mce etickej AI od in칳ch organiz치ci칤 - tu s칰 pr칤klady od [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles) a [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Ak칠 spolo캜n칠 hodnoty maj칰? Ako sa tieto princ칤py vz콘ahuj칰 na AI produkt alebo odvetvie, v ktorom p칪sobia?

### 2. V칳zvy etiky

Ke캞 m치me definovan칠 etick칠 princ칤py, 캞al코칤m krokom je vyhodnotenie na코ich d치tov칳ch a AI akci칤, aby sme zistili, 캜i s칰 v s칰lade s t칳mito spolo캜n칳mi hodnotami. Zamyslite sa nad svojimi akciami v dvoch kateg칩ri치ch: _zber d치t_ a _n치vrh algoritmov_.

Pri zbere d치t bud칰 akcie pravdepodobne zah콋켿a콘 **osobn칠 칰daje** alebo osobne identifikovate쬹칠 inform치cie (PII) pre identifikovate쬹칠 쬴v칠 osoby. To zah콋켿a [r칪zne polo쬶y neosobn칳ch 칰dajov](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en), ktor칠 _spolo캜ne_ identifikuj칰 jednotlivca. Etick칠 v칳zvy sa m칪쬿 t칳ka콘 _ochrany s칰kromia_, _vlastn칤ctva d치t_ a s칰visiacich t칠m ako _informovan칳 s칰hlas_ a _pr치va du코evn칠ho vlastn칤ctva_ pre pou쮂셨ate쬺v.

Pri n치vrhu algoritmov bud칰 akcie zah콋켿a콘 zber a kur치ciu **datasetov**, potom ich pou쬴tie na tr칠novanie a nasadenie **d치tov칳ch modelov**, ktor칠 predpovedaj칰 v칳sledky alebo automatizuj칰 rozhodnutia v re치lnych kontextoch. Etick칠 v칳zvy m칪쬿 vznikn칰콘 z _predsudkov v datasetoch_, _probl칠mov s kvalitou d치t_, _nespravodlivosti_ a _nespr치vneho zast칰penia_ v algoritmoch - vr치tane niektor칳ch probl칠mov, ktor칠 s칰 syst칠mov칠.

V oboch pr칤padoch etick칠 v칳zvy poukazuj칰 na oblasti, kde na코e akcie m칪쬿 narazi콘 na konflikt s na코imi spolo캜n칳mi hodnotami. Na ich detekciu, zmiernenie, minimaliz치ciu alebo elimin치ciu mus칤me kl치s콘 mor치lne "치no/nie" ot치zky t칳kaj칰ce sa na코ich akci칤 a n치sledne prija콘 n치pravn칠 opatrenia pod쬬 potreby. Pozrime sa na niektor칠 etick칠 v칳zvy a mor치lne ot치zky, ktor칠 vyvol치vaj칰:

#### 2.1 Vlastn칤ctvo d치t

Zber d치t 캜asto zah콋켿a osobn칠 칰daje, ktor칠 m칪쬿 identifikova콘 subjekty d치t. [Vlastn칤ctvo d치t](https://permission.io/blog/data-ownership) sa t칳ka _kontroly_ a [_pr치v pou쮂셨ate쬺v_](https://permission.io/blog/data-ownership) s칰visiacich s vytv치ran칤m, spracovan칤m a 코칤ren칤m d치t.

Mor치lne ot치zky, ktor칠 mus칤me kl치s콘, s칰: 
 * Kto vlastn칤 d치ta? (pou쮂셨ate alebo organiz치cia)
 * Ak칠 pr치va maj칰 subjekty d치t? (napr. pr칤stup, vymazanie, prenosnos콘)
 * Ak칠 pr치va maj칰 organiz치cie? (napr. oprava 코kodliv칳ch pou쮂셨ate쬽k칳ch recenzi칤)

#### 2.2 Informovan칳 s칰hlas

[Informovan칳 s칰hlas](https://legaldictionary.net/informed-consent/) definuje akt, ke캞 pou쮂셨ate s칰hlas칤 s akciou (napr. zber d치t) s _pln칳m pochopen칤m_ relevantn칳ch faktov vr치tane 칰캜elu, potenci치lnych riz칤k a alternat칤v.

Ot치zky na presk칰manie:
 * Dal pou쮂셨ate (subjekt d치t) povolenie na zber a pou쬴tie d치t?
 * Pochopil pou쮂셨ate 칰캜el, na ktor칳 boli d치ta zhroma쬯en칠?
 * Pochopil pou쮂셨ate potenci치lne rizik치 z ich 칰캜asti?

#### 2.3 Du코evn칠 vlastn칤ctvo

[Du코evn칠 vlastn칤ctvo](https://en.wikipedia.org/wiki/Intellectual_property) sa t칳ka nehmotn칳ch v칳tvorov vypl칳vaj칰cich z 쬿dskej iniciat칤vy, ktor칠 m칪쬿 _ma콘 ekonomick칰 hodnotu_ pre jednotlivcov alebo podniky.

Ot치zky na presk칰manie:
 * Mali zhroma쬯en칠 d치ta ekonomick칰 hodnotu pre pou쮂셨ate쬬 alebo podnik?
 * M치 **pou쮂셨ate** du코evn칠 vlastn칤ctvo v tomto pr칤pade?
 * M치 **organiz치cia** du코evn칠 vlastn칤ctvo v tomto pr칤pade?
 * Ak tieto pr치va existuj칰, ako ich chr치nime?

#### 2.4 Ochrana s칰kromia d치t

[Ochrana s칰kromia d치t](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) alebo informa캜n칠 s칰kromie sa t칳ka zachovania s칰kromia pou쮂셨ate쬺v a ochrany identity pou쮂셨ate쬺v vo vz콘ahu k osobne identifikovate쬹칳m inform치ci치m.

Ot치zky na presk칰manie:
 * S칰 osobn칠 칰daje pou쮂셨ate쬺v zabezpe캜en칠 proti 칰tokom a 칰nikom?
 * S칰 칰daje pou쮂셨ate쬺v pr칤stupn칠 iba autorizovan칳m pou쮂셨ate쬺m a kontextom?
 * Je anonymita pou쮂셨ate쬺v zachovan치 pri zdie쬬n칤 alebo 코칤ren칤 d치t?
 * M칪쬰 by콘 pou쮂셨ate de-identifikovan칳 z anonymizovan칳ch datasetov?

#### 2.5 Pr치vo by콘 zabudnut칳

[Pr치vo by콘 zabudnut칳](https://en.wikipedia.org/wiki/Right_to_be_forgotten) alebo [Pr치vo na vymazanie](https://www.gdpreu.org/right-to-be-forgotten/) poskytuje pou쮂셨ate쬺m dodato캜n칰 ochranu osobn칳ch 칰dajov. Konkr칠tne d치va pou쮂셨ate쬺m pr치vo po쬴ada콘 o vymazanie alebo odstr치nenie osobn칳ch 칰dajov z internetov칳ch vyh쬬d치van칤 a in칳ch miest, _za ur캜it칳ch okolnost칤_ - umo쮄갓j칰c im nov칳 za캜iatok online bez toho, aby ich minul칠 akcie boli proti nim pou쬴t칠.

Ot치zky na presk칰manie:
 * Umo쮄갓je syst칠m subjektom d치t po쬴ada콘 o vymazanie?
 * Mal by odvolanie s칰hlasu pou쮂셨ate쬬 automaticky spusti콘 vymazanie?
 * Boli d치ta zhroma쬯en칠 bez s칰hlasu alebo nez치konn칳mi prostriedkami?
 * Sme v s칰lade s vl치dnymi regul치ciami na ochranu s칰kromia d치t?

#### 2.6 Predsudky v datasetoch

Predsudky v datasetoch alebo [Predsudky pri zbere d치t](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) sa t칳kaj칰 v칳beru _nereprezentat칤vnej_ podmno쬴ny d치t na v칳voj algoritmov, 캜o m칪쬰 vytv치ra콘 potenci치lnu nespravodlivos콘 vo v칳sledkoch pre r칪zne skupiny. Typy predsudkov zah콋켿aj칰 v칳berov칠 alebo vzorkov칠 predsudky, dobrovo쬹칤cke predsudky a n치strojov칠 predsudky.

Ot치zky na presk칰manie:
 * Rekrutovali sme reprezentat칤vnu skupinu subjektov d치t?
 * Testovali sme n치코 zhroma쬯en칳 alebo kur치tovan칳 dataset na r칪zne predsudky?
 * M칪쬰me zmierni콘 alebo odstr치ni콘 objaven칠 predsudky?

#### 2.7 Kval
[Algorithm Fairness](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) sk칰ma, 캜i n치vrh algoritmu systematicky nediskriminuje konkr칠tne podskupiny subjektov 칰dajov, 캜o vedie k [potenci치lnym 코kod치m](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) v _alok치cii_ (kde s칰 zdroje odmietnut칠 alebo zadr쬬n칠 tejto skupine) a _kvalite slu쬴eb_ (kde AI nie je tak presn치 pre niektor칠 podskupiny ako pre in칠).

Ot치zky na presk칰manie:
 * Vyhodnotili sme presnos콘 modelu pre r칪zne podskupiny a podmienky?
 * Presk칰mali sme syst칠m kv칪li potenci치lnym 코kod치m (napr. stereotypiz치cia)?
 * M칪쬰me upravi콘 칰daje alebo pre코koli콘 modely na zmiernenie identifikovan칳ch 코k칪d?

Presk칰majte zdroje ako [AI Fairness checklists](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) pre viac inform치ci칤.

#### 2.9 Skreslenie 칰dajov

[Skreslenie 칰dajov](https://www.sciencedirect.com/topics/computer-science/misrepresentation) sa t칳ka ot치zky, 캜i komunikujeme poznatky z 캜estne hl치sen칳ch 칰dajov zav치dzaj칰cim sp칪sobom na podporu po쬬dovan칠ho narat칤vu.

Ot치zky na presk칰manie:
 * Hl치sime ne칰pln칠 alebo nepresn칠 칰daje?
 * Vizualizujeme 칰daje sp칪sobom, ktor칳 vedie k zav치dzaj칰cim z치verom?
 * Pou쮂셨ame selekt칤vne 코tatistick칠 techniky na manipul치ciu v칳sledkov?
 * Existuj칰 alternat칤vne vysvetlenia, ktor칠 m칪쬿 pon칰knu콘 in칳 z치ver?

#### 2.10 Il칰zia vo쬭y
[Il칰zia vo쬭y](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) nast치va, ke캞 "architekt칰ry vo쬭y" syst칠mu pou쮂셨aj칰 algoritmy rozhodovania na ovplyvnenie 쬿d칤, aby prijali preferovan칳 v칳sledok, pri캜om im d치vaj칰 pocit mo쬹ost칤 a kontroly. Tieto [temn칠 vzory](https://www.darkpatterns.org/) m칪쬿 sp칪sobi콘 soci치lne a ekonomick칠 코kody pou쮂셨ate쬺m. Ke캞쬰 rozhodnutia pou쮂셨ate쬺v ovplyv켿uj칰 profily spr치vania, tieto akcie m칪쬿 potenci치lne poh치켿a콘 bud칰ce vo쬭y, ktor칠 m칪쬿 zosilni콘 alebo roz코칤ri콘 dopad t칳chto 코k칪d.

Ot치zky na presk칰manie:
 * Rozumel pou쮂셨ate d칪sledkom prijatia tejto vo쬭y?
 * Bol pou쮂셨ate informovan칳 o (alternat칤vnych) mo쬹ostiach a v칳hod치ch a nev칳hod치ch ka쬯ej z nich?
 * M칪쬰 pou쮂셨ate nesk칪r zvr치ti콘 automatizovan칰 alebo ovplyvnen칰 vo쬭u?

### 3. Pr칤padov칠 코t칰die

Aby sme tieto etick칠 v칳zvy zasadili do kontextu re치lneho sveta, je u쬴to캜n칠 pozrie콘 sa na pr칤padov칠 코t칰die, ktor칠 zd칪raz켿uj칰 potenci치lne 코kody a d칪sledky pre jednotlivcov a spolo캜nos콘, ke캞 sa tak칠to etick칠 poru코enia prehliadaj칰.

Tu je nieko쬶o pr칤kladov:

| Etick치 v칳zva | Pr칤padov치 코t칰dia | 
|--- |--- |
| **Informovan칳 s칰hlas** | 1972 - [Tuskegee Syphilis Study](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - Afroamerick칳m mu쬺m, ktor칤 sa z칰캜astnili 코t칰die, bola s쮂죡en치 bezplatn치 lek치rska starostlivos콘, _ale boli oklaman칤_ v칳skumn칤kmi, ktor칤 im neozn치mili diagn칩zu ani dostupnos콘 lie캜by. Mnoh칤 칰캜astn칤ci zomreli a ich partneri 캜i deti boli ovplyvnen칤; 코t칰dia trvala 40 rokov. | 
| **Ochrana 칰dajov** | 2007 - [Netflix data prize](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) poskytla v칳skumn칤kom _10M anonymizovan칳ch hodnoten칤 filmov od 50K z치kazn칤kov_ na zlep코enie odpor칰캜ac칤ch algoritmov. V칳skumn칤ci v코ak dok치zali prepoji콘 anonymizovan칠 칰daje s osobne identifikovate쬹칳mi 칰dajmi v _extern칳ch datasetoch_ (napr. koment치re na IMDb), 캜칤m efekt칤vne "de-anonymizovali" niektor칳ch predplatite쬺v Netflixu.|
| **Zber d치t s predsudkami** | 2013 - Mesto Boston [vyvinulo Street Bump](https://www.boston.gov/transportation/street-bump), aplik치ciu, ktor치 umo쬹ila ob캜anom hl치si콘 v칳tlky, 캜칤m mesto z칤skalo lep코ie 칰daje o cest치ch na identifik치ciu a opravu probl칠mov. Av코ak [쬿dia z ni쮄뫆셖h pr칤jmov칳ch skup칤n mali men코칤 pr칤stup k aut치m a telef칩nom](https://hbr.org/2013/04/the-hidden-biases-in-big-data), 캜o sp칪sobilo, 쬰 ich probl칠my s cestami boli v aplik치cii nevidite쬹칠. V칳voj치ri spolupracovali s akademikmi na rie코en칤 probl칠mov _rovnak칠ho pr칤stupu a digit치lnych rozdielov_ pre spravodlivos콘. |
| **Spravodlivos콘 algoritmov** | 2018 - MIT [Gender Shades Study](http://gendershades.org/overview.html) hodnotila presnos콘 AI produktov na klasifik치ciu pohlavia, pri캜om odhalila medzery v presnosti pre 쬰ny a osoby tmavej pleti. [Apple Card z roku 2019](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) sa zdala pon칰ka콘 menej 칰veru 쬰n치m ako mu쬺m. Obe uk치zali probl칠my s predsudkami v algoritmoch ved칰ce k socio-ekonomick칳m 코kod치m.|
| **Skreslenie 칰dajov** | 2020 - [Ministerstvo zdravotn칤ctva Georgie zverejnilo COVID-19 grafy](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening), ktor칠 sa zdali zav치dza콘 ob캜anov o trendoch potvrden칳ch pr칤padov s nechronologick칳m usporiadan칤m na osi x. Toto ilustruje skreslenie prostredn칤ctvom vizualiza캜n칳ch trikov. |
| **Il칰zia vo쬭y** | 2020 - Vzdel치vacia aplik치cia [ABCmouse zaplatila $10M na urovnanie s콘a쬹osti FTC](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/), kde boli rodi캜ia uv칛znen칤 v platen칤 za predplatn칠, ktor칠 nemohli zru코i콘. Toto ilustruje temn칠 vzory v architekt칰rach vo쬭y, kde boli pou쮂셨atelia ovplyvnen칤 k potenci치lne 코kodliv칳m rozhodnutiam. |
| **Ochrana 칰dajov a pr치va pou쮂셨ate쬺v** | 2021 - Facebook [칔nik 칰dajov](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) odhalil 칰daje 530M pou쮂셨ate쬺v, 캜o viedlo k urovnaniu vo v칳코ke $5B s FTC. Napriek tomu odmietol informova콘 pou쮂셨ate쬺v o 칰niku, 캜칤m poru코il pr치va pou쮂셨ate쬺v na transparentnos콘 a pr칤stup k 칰dajom. |

Chcete presk칰ma콘 viac pr칤padov칳ch 코t칰di칤? Pozrite si tieto zdroje:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - etick칠 dilemy naprie캜 r칪znymi odvetviami. 
* [Kurz o etike d치tovej vedy](https://www.coursera.org/learn/data-science-ethics#syllabus) - pr칤padov칠 코t칰die z praxe.
* [Kde sa veci pokazili](https://deon.drivendata.org/examples/) - kontroln칳 zoznam Deon s pr칤kladmi.

> 游뚿 Zamyslite sa nad pr칤padov칳mi 코t칰diami, ktor칠 ste videli - za쬴li ste alebo boli ovplyvnen칤 podobnou etickou v칳zvou vo svojom 쬴vote? Dok치쬰te si spomen칰콘 na aspo켿 jednu 캞al코iu pr칤padov칰 코t칰diu, ktor치 ilustruje jednu z etick칳ch v칳ziev, o ktor칳ch sme diskutovali v tejto sekcii?

## Aplikovan치 etika

Hovorili sme o etick칳ch konceptoch, v칳zvach a pr칤padov칳ch 코t칰di치ch v kontexte re치lneho sveta. Ale ako za캜a콘 _uplat켿ova콘_ etick칠 princ칤py a praktiky vo svojich projektoch? A ako _operacionalizova콘_ tieto praktiky pre lep코ie riadenie? Po캞me presk칰ma콘 niektor칠 rie코enia z praxe:

### 1. Profesion치lne k칩dexy

Profesion치lne k칩dexy pon칰kaj칰 jednu mo쬹os콘 pre organiz치cie, ako "motivova콘" 캜lenov k podpore ich etick칳ch princ칤pov a misijn칠ho vyhl치senia. K칩dexy s칰 _mor치lne usmernenia_ pre profesion치lne spr치vanie, ktor칠 pom치haj칰 zamestnancom alebo 캜lenom robi콘 rozhodnutia v s칰lade s princ칤pmi organiz치cie. S칰 v코ak 칰캜inn칠 len do miery dobrovo쬹칠ho dodr쬴avania 캜lenmi; mnoh칠 organiz치cie v코ak pon칰kaj칰 dodato캜n칠 odmeny a sankcie na motiv치ciu dodr쬴avania.

Pr칤klady zah콋켿aj칰:

 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Etick칳 k칩dex
 * [Data Science Association](http://datascienceassn.org/code-of-conduct.html) K칩dex spr치vania (vytvoren칳 v roku 2013)
 * [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (od roku 1993)

> 游뚿 Patr칤te do profesion치lnej organiz치cie pre in쬴nierov alebo d치tov칳ch vedcov? Presk칰majte ich webov칰 str치nku, 캜i definuj칰 profesion치lny etick칳 k칩dex. 캛o to hovor칤 o ich etick칳ch princ칤poch? Ako motivuj칰 캜lenov k dodr쬴avaniu k칩dexu?

### 2. Etick칠 kontroln칠 zoznamy

Zatia 캜o profesion치lne k칩dexy definuj칰 po쬬dovan칠 _etick칠 spr치vanie_ od odborn칤kov, [maj칰 zn치me obmedzenia](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) pri presadzovan칤, najm칛 vo ve쬶칳ch projektoch. Namiesto toho mnoh칤 odborn칤ci na d치tov칰 vedu [odpor칰캜aj칰 kontroln칠 zoznamy](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), ktor칠 m칪쬿 **prepoji콘 princ칤py s praxou** deterministick칳m a ak캜n칳m sp칪sobom.

Kontroln칠 zoznamy prev치dzaj칰 ot치zky na 칰lohy "치no/nie", ktor칠 m칪쬿 by콘 operacionalizovan칠, 캜o umo쮄갓je ich sledovanie ako s칰캜as콘 코tandardn칳ch pracovn칳ch postupov pri vyd치van칤 produktov.

Pr칤klady zah콋켿aj칰:
 * [Deon](https://deon.drivendata.org/) - v코eobecn칳 kontroln칳 zoznam etiky d치t vytvoren칳 na z치klade [odpor칰캜an칤 z priemyslu](https://deon.drivendata.org/#checklist-citations) s n치strojom pr칤kazov칠ho riadku pre jednoduch칰 integr치ciu.
 * [Kontroln칳 zoznam auditu ochrany s칰kromia](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - poskytuje v코eobecn칠 usmernenia pre praktiky manipul치cie s inform치ciami z pr치vneho a soci치lneho h쬬diska.
 * [Kontroln칳 zoznam spravodlivosti AI](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - vytvoren칳 odborn칤kmi na AI na podporu prijatia a integr치cie kontrol spravodlivosti do v칳vojov칳ch cyklov AI.
 * [22 ot치zok pre etiku v d치tach a AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - otvorenej코칤 r치mec, 코trukt칰rovan칳 na po캜iato캜n칠 presk칰manie etick칳ch ot치zok v dizajne, implement치cii a organiza캜n칳ch kontextoch.

### 3. Etick칠 regul치cie

Etika je o definovan칤 spolo캜n칳ch hodn칪t a dobrovo쬹om konan칤 spr치vne. **Dodr쬴avanie predpisov** je o _dodr쬴avan칤 z치kona_, ak je definovan칳. **Riadenie** zah콋켿a v코etky sp칪soby, ktor칳mi organiz치cie presadzuj칰 etick칠 princ칤py a dodr쬴avaj칰 stanoven칠 z치kony.

Dnes m치 riadenie dve formy v r치mci organiz치ci칤. Po prv칠, ide o definovanie princ칤pov **etickej AI** a zavedenie prakt칤k na operacionaliz치ciu prijatia vo v코etk칳ch projektoch s칰visiacich s AI v organiz치cii. Po druh칠, ide o dodr쬴avanie v코etk칳ch vl치dou stanoven칳ch **regul치ci칤 ochrany 칰dajov** pre regi칩ny, v ktor칳ch organiz치cia p칪sob칤.

Pr칤klady regul치ci칤 ochrany 칰dajov a s칰kromia:

 * `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - reguluje _feder치lnu vl치du_ pri zbere, pou쮂셨an칤 a zverej켿ovan칤 osobn칳ch 칰dajov.
 * `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - chr치ni osobn칠 zdravotn칠 칰daje.
 * `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - chr치ni s칰kromie 칰dajov det칤 mlad코칤ch ako 13 rokov.
 * `2018`, [General Data Protection Regulation (GDPR)](https://gdpr-info.eu/) - poskytuje pr치va pou쮂셨ate쬺v, ochranu 칰dajov a s칰kromie.
 * `2018`, [California Consumer Privacy Act (CCPA)](https://www.oag.ca.gov/privacy/ccpa) d치va spotrebite쬺m viac _pr치v_ nad ich (osobn칳mi) 칰dajmi.
 * `2021`, 캛칤na [Z치kon o ochrane osobn칳ch 칰dajov](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) pr치ve prijat칳, vytv치ra jeden z najsilnej코칤ch online regul치ci칤 ochrany 칰dajov na svete.

> 游뚿 Eur칩pska 칰nia definovala GDPR (General Data Protection Regulation), ktor칳 zost치va jedn칳m z najvplyvnej코칤ch regul치ci칤 ochrany 칰dajov dnes. Vedeli ste, 쬰 tie definuje [8 pr치v pou쮂셨ate쬺v](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) na ochranu digit치lneho s칰kromia a osobn칳ch 칰dajov ob캜anov? Zistite, 캜o to s칰 a pre캜o s칰 d칪le쬴t칠.

### 4. Kult칰ra etiky

Treba si uvedomi콘, 쬰 st치le existuje nehmotn치 medzera medzi _dodr쬴avan칤m predpisov_ (uroben칤m dostato캜n칠ho na splnenie "litery z치kona") a rie코en칤m [syst칠mov칳ch probl칠mov](https://www.coursera.org/learn/data-science-ethics/home/week/4) (ako je zakorenenie, informa캜n치 asymetria a distribu캜n치 nespravodlivos콘), ktor칠 m칪쬿 ur칳chli콘 zneu쬴tie AI.

Rie코enie t칳chto probl칠mov si vy쬬duje [spolupr치cu pri definovan칤 kult칰r etiky](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f), ktor칠 buduj칰 emocion치lne spojenia a konzistentn칠 spolo캜n칠 hodnoty _naprie캜 organiz치ciami_ v priemysle. To si vy쬬duje viac [formalizovan칳ch kult칰r etiky d치t](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) v organiz치ci치ch - umo쮄갓j칰c _komuko쭀ek_ [zatiahnu콘 Andon 코n칰ru](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (na v캜asn칠 upozornenie na etick칠 probl칠my) a robi콘 _etick칠 hodnotenia_ (napr. pri n치bore) ako z치kladn칠 krit칠rium pri formovan칤 t칤mov v AI projektoch.

---
## [Kv칤z po predn치코ke](https://ff-quizzes.netlify.app/en/ds/quiz/3) 游꿢
## Preh쬬d a samo코t칰dium 

Kurzy a knihy pom치haj칰 pochopi콘 z치kladn칠 etick칠 koncepty a v칳zvy, zatia 캜o pr칤padov칠 코t칰die a n치stroje pom치
* [Princ칤py zodpovednej AI](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - bezplatn치 vzdel치vacia cesta od Microsoft Learn.
* [Etika a d치tov치 veda](https://resources.oreilly.com/examples/0636920203964) - O'Reilly EBook (M. Loukides, H. Mason a kol.)
* [Etika d치tovej vedy](https://www.coursera.org/learn/data-science-ethics#syllabus) - online kurz z University of Michigan.
* [Etika odhalen치](https://ethicsunwrapped.utexas.edu/case-studies) - pr칤padov칠 코t칰die z University of Texas.

# Zadanie

[Nap칤코te pr칤padov칰 코t칰diu o etike d치t](assignment.md)

---

**Upozornenie**:  
Tento dokument bol prelo쬰n칳 pomocou slu쬭y AI prekladu [Co-op Translator](https://github.com/Azure/co-op-translator). Hoci sa sna쮂셠e o presnos콘, pros칤m, berte na vedomie, 쬰 automatizovan칠 preklady m칪쬿 obsahova콘 chyby alebo nepresnosti. P칪vodn칳 dokument v jeho rodnom jazyku by mal by콘 pova쬺van칳 za autoritat칤vny zdroj. Pre kritick칠 inform치cie sa odpor칰캜a profesion치lny 쬿dsk칳 preklad. Nie sme zodpovedn칤 za ak칠ko쭀ek nedorozumenia alebo nespr치vne interpret치cie vypl칳vaj칰ce z pou쬴tia tohto prekladu.