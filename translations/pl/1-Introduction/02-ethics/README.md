<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8796f41f566a0a8ebb72863a83d558ed",
  "translation_date": "2025-08-23T23:49:53+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "pl"
}
-->
# Wprowadzenie do etyki danych

|![ Sketchnote autorstwa [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Etyka danych - _Sketchnote autorstwa [@nitya](https://twitter.com/nitya)_ |

---

Wszyscy jestemy obywatelami danych 偶yjcymi w wiecie zdominowanym przez dane.

Trendy rynkowe wskazuj, 偶e do 2022 roku 1 na 3 du偶e organizacje bdzie kupowa i sprzedawa swoje dane za porednictwem internetowych [rynk贸w i gied](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Jako **tw贸rcy aplikacji**, bdziemy mieli atwiejszy i taszy dostp do integracji wniosk贸w opartych na danych oraz automatyzacji sterowanej algorytmami w codziennych dowiadczeniach u偶ytkownik贸w. Jednak wraz z coraz wikszym rozpowszechnieniem AI, musimy r贸wnie偶 zrozumie potencjalne szkody wynikajce z [uzbrojenia](https://www.youtube.com/watch?v=TQHs8SA1qpk) takich algorytm贸w na du偶 skal.

Trendy wskazuj r贸wnie偶, 偶e do 2025 roku stworzymy i zu偶yjemy ponad [180 zettabajt贸w](https://www.statista.com/statistics/871513/worldwide-data-created/) danych. Jako **naukowcy danych**, uzyskamy bezprecedensowy dostp do danych osobowych. Oznacza to, 偶e mo偶emy budowa profile behawioralne u偶ytkownik贸w i wpywa na podejmowanie decyzji w spos贸b, kt贸ry tworzy [iluzj wolnego wyboru](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice), jednoczenie potencjalnie kierujc u偶ytkownik贸w w stron preferowanych przez nas wynik贸w. To r贸wnie偶 rodzi szersze pytania dotyczce prywatnoci danych i ochrony u偶ytkownik贸w.

Etyka danych staje si teraz _niezbdnymi barierami ochronnymi_ dla nauki i in偶ynierii danych, pomagajc nam minimalizowa potencjalne szkody i niezamierzone konsekwencje wynikajce z naszych dziaa opartych na danych. [Cykl Hype Gartnera dla AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) identyfikuje istotne trendy w cyfrowej etyce, odpowiedzialnej AI i zarzdzaniu AI jako kluczowe czynniki napdzajce wiksze megatrendy wok贸 _demokratyzacji_ i _industrializacji_ AI.

![Cykl Hype Gartnera dla AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

W tej lekcji zgbimy fascynujcy obszar etyki danych - od podstawowych poj i wyzwa, przez studia przypadk贸w, a偶 po zastosowane koncepcje AI, takie jak zarzdzanie - kt贸re pomagaj ustanowi kultur etyki w zespoach i organizacjach pracujcych z danymi i AI.

## [Quiz przed wykadem](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/2) 

## Podstawowe definicje

Zacznijmy od zrozumienia podstawowej terminologii.

Sowo "etyka" pochodzi od [greckiego sowa "ethikos"](https://en.wikipedia.org/wiki/Ethics) (i jego korzenia "ethos"), kt贸re oznacza _charakter lub moraln natur_.

**Etyka** dotyczy wsp贸lnych wartoci i zasad moralnych, kt贸re reguluj nasze zachowanie w spoeczestwie. Etyka opiera si nie na prawach, ale na powszechnie akceptowanych normach tego, co jest "dobre vs. ze". Jednak rozwa偶ania etyczne mog wpywa na inicjatywy w zakresie adu korporacyjnego oraz regulacje rzdowe, kt贸re tworz wiksze zachty do przestrzegania zasad.

**Etyka danych** to [nowa ga藕 etyki](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1), kt贸ra "bada i ocenia problemy moralne zwizane z _danymi, algorytmami i odpowiadajcymi im praktykami_". Tutaj **"dane"** koncentruj si na dziaaniach zwizanych z generowaniem, rejestrowaniem, kuracj, przetwarzaniem, rozpowszechnianiem, udostpnianiem i u偶ytkowaniem, **"algorytmy"** skupiaj si na AI, agentach, uczeniu maszynowym i robotach, a **"praktyki"** dotycz takich temat贸w jak odpowiedzialna innowacja, programowanie, hakowanie i kodeksy etyczne.

**Etyka stosowana** to [praktyczne zastosowanie rozwa偶a moralnych](https://en.wikipedia.org/wiki/Applied_ethics). Jest to proces aktywnego badania kwestii etycznych w kontekcie _dziaa, produkt贸w i proces贸w w rzeczywistym wiecie_ oraz podejmowania dziaa korygujcych, aby upewni si, 偶e pozostaj one zgodne z okrelonymi wartociami etycznymi.

**Kultura etyki** dotyczy [_operacjonalizacji_ etyki stosowanej](https://hbr.org/2019/05/how-to-design-an-ethical-organization), aby upewni si, 偶e nasze zasady i praktyki etyczne s przyjmowane w spos贸b sp贸jny i skalowalny w caej organizacji. Udane kultury etyki definiuj og贸lnofirmowe zasady etyczne, zapewniaj znaczce zachty do przestrzegania zasad oraz wzmacniaj normy etyczne poprzez promowanie i amplifikacj po偶danych zachowa na ka偶dym poziomie organizacji.

## Koncepcje etyki

W tej sekcji om贸wimy koncepcje takie jak **wsp贸lne wartoci** (zasady) i **wyzwania etyczne** (problemy) w etyce danych - oraz przeanalizujemy **studia przypadk贸w**, kt贸re pomog zrozumie te koncepcje w kontekcie rzeczywistego wiata.

### 1. Zasady etyki

Ka偶da strategia etyki danych zaczyna si od zdefiniowania _zasad etycznych_ - "wsp贸lnych wartoci", kt贸re opisuj akceptowalne zachowania i kieruj zgodnymi dziaaniami w naszych projektach zwizanych z danymi i AI. Mo偶na je definiowa na poziomie indywidualnym lub zespoowym. Jednak wikszo du偶ych organizacji okrela je w ramach misji lub ram etycznych AI, kt贸re s definiowane na poziomie korporacyjnym i konsekwentnie egzekwowane we wszystkich zespoach.

**Przykad:** Misja [Odpowiedzialnej AI](https://www.microsoft.com/en-us/ai/responsible-ai) Microsoftu brzmi: _"Jestemy zaanga偶owani w rozw贸j AI napdzanej zasadami etycznymi, kt贸re stawiaj ludzi na pierwszym miejscu"_ - identyfikujc 6 zasad etycznych w poni偶szym frameworku:

![Odpowiedzialna AI w Microsoft](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

Przyjrzyjmy si kr贸tko tym zasadom. _Przejrzysto_ i _odpowiedzialno_ s wartociami podstawowymi, na kt贸rych opieraj si inne zasady - zacznijmy wic od nich:

* [**Odpowiedzialno**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) sprawia, 偶e praktycy s _odpowiedzialni_ za swoje operacje zwizane z danymi i AI oraz za zgodno z tymi zasadami etycznymi.
* [**Przejrzysto**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) zapewnia, 偶e dziaania zwizane z danymi i AI s _zrozumiae_ (interpretowalne) dla u偶ytkownik贸w, wyjaniajc co i dlaczego stoi za decyzjami.
* [**Sprawiedliwo**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - koncentruje si na zapewnieniu, 偶e AI traktuje _wszystkich ludzi_ sprawiedliwie, rozwizujc wszelkie systemowe lub ukryte techniczno-spoeczne uprzedzenia w danych i systemach.
* [**Niezawodno i bezpieczestwo**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - zapewnia, 偶e AI dziaa _sp贸jnie_ z okrelonymi wartociami, minimalizujc potencjalne szkody lub niezamierzone konsekwencje.
* [**Prywatno i bezpieczestwo**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - dotyczy zrozumienia pochodzenia danych oraz zapewnienia _prywatnoci danych i zwizanych z tym ochron_ u偶ytkownikom.
* [**Inkluzywno**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - dotyczy projektowania rozwiza AI z zamiarem, dostosowujc je do _szerokiego zakresu ludzkich potrzeb_ i mo偶liwoci.

>  Zastan贸w si, jaka mogaby by misja etyki danych w Twoim przypadku. Przeanalizuj ramy etyczne AI innych organizacji - oto przykady od [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles) i [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Jakie wsp贸lne wartoci maj? Jak te zasady odnosz si do produkt贸w AI lub bran偶y, w kt贸rej dziaaj?

### 2. Wyzwania etyczne

Gdy mamy zdefiniowane zasady etyczne, kolejnym krokiem jest ocena naszych dziaa zwizanych z danymi i AI, aby sprawdzi, czy s zgodne z tymi wsp贸lnymi wartociami. Pomyl o swoich dziaaniach w dw贸ch kategoriach: _zbieranie danych_ i _projektowanie algorytm贸w_.

W przypadku zbierania danych dziaania prawdopodobnie bd dotyczy **danych osobowych** lub danych umo偶liwiajcych identyfikacj os贸b (PII) dla identyfikowalnych 偶yjcych jednostek. Obejmuje to [r贸偶norodne elementy danych nieosobowych](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en), kt贸re _cznie_ identyfikuj jednostk. Wyzwania etyczne mog dotyczy _prywatnoci danych_, _wasnoci danych_ oraz powizanych temat贸w, takich jak _wiadoma zgoda_ i _prawa wasnoci intelektualnej_ u偶ytkownik贸w.

W przypadku projektowania algorytm贸w dziaania bd obejmowa zbieranie i kuracj **zbior贸w danych**, a nastpnie ich wykorzystanie do trenowania i wdra偶ania **modeli danych**, kt贸re przewiduj wyniki lub automatyzuj decyzje w rzeczywistych kontekstach. Wyzwania etyczne mog wynika z _uprzedze w zbiorach danych_, problem贸w z _jakoci danych_, _niesprawiedliwoci_ i _faszywego przedstawienia_ w algorytmach - w tym niekt贸rych problem贸w o charakterze systemowym.

W obu przypadkach wyzwania etyczne wskazuj obszary, w kt贸rych nasze dziaania mog by sprzeczne z naszymi wsp贸lnymi wartociami. Aby wykry, zagodzi, zminimalizowa lub wyeliminowa te obawy, musimy zadawa moralne pytania "tak/nie" dotyczce naszych dziaa, a nastpnie podejmowa odpowiednie dziaania korygujce. Przyjrzyjmy si niekt贸rym wyzwaniom etycznym i moralnym pytaniom, kt贸re si z nimi wi偶:

#### 2.1 Wasno danych

Zbieranie danych czsto obejmuje dane osobowe, kt贸re mog identyfikowa podmioty danych. [Wasno danych](https://permission.io/blog/data-ownership) dotyczy _kontroli_ i [_praw u偶ytkownik贸w_](https://permission.io/blog/data-ownership) zwizanych z tworzeniem, przetwarzaniem i rozpowszechnianiem danych.

Moralne pytania, kt贸re nale偶y zada:
 * Kto jest wacicielem danych? (u偶ytkownik czy organizacja)
 * Jakie prawa maj podmioty danych? (np. dostp, usunicie, przenoszenie)
 * Jakie prawa maj organizacje? (np. poprawianie zoliwych recenzji u偶ytkownik贸w)

#### 2.2 wiadoma zgoda

[wiadoma zgoda](https://legaldictionary.net/informed-consent/) definiuje akt zgody u偶ytkownik贸w na dziaanie (np. zbieranie danych) z _penym zrozumieniem_ istotnych fakt贸w, w tym celu, potencjalnych ryzyk i alternatyw.

Pytania do rozwa偶enia:
 * Czy u偶ytkownik (podmiot danych) wyrazi zgod na przechwytywanie i wykorzystanie danych?
 * Czy u偶ytkownik rozumia cel, dla kt贸rego dane zostay przechwycone?
 * Czy u偶ytkownik rozumia potencjalne ryzyka wynikajce z jego udziau?

#### 2.3 Wasno intelektualna

[Wasno intelektualna](https://en.wikipedia.org/wiki/Intellectual_property) odnosi si do niematerialnych wytwor贸w wynikajcych z ludzkiej inicjatywy, kt贸re mog _mie warto ekonomiczn_ dla jednostek lub firm.

Pytania do rozwa偶enia:
 * Czy zebrane dane miay warto ekonomiczn dla u偶ytkownika lub firmy?
 * Czy **u偶ytkownik** ma tutaj wasno intelektualn?
 * Czy **organizacja** ma tutaj wasno intelektualn?
 * Jeli te prawa istniej, jak je chronimy?

#### 2.4 Prywatno danych

[Prywatno danych](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) lub prywatno informacji odnosi si do zachowania prywatnoci u偶ytkownika i ochrony jego to偶samoci w odniesieniu do danych umo偶liwiajcych identyfikacj.

Pytania do rozwa偶enia:
 * Czy dane u偶ytkownik贸w (osobowe) s zabezpieczone przed atakami i wyciekami?
 * Czy dane u偶ytkownik贸w s dostpne tylko dla autoryzowanych u偶ytkownik贸w i kontekst贸w?
 * Czy anonimowo u偶ytkownik贸w jest zachowana podczas udostpniania lub rozpowszechniania danych?
 * Czy u偶ytkownik mo偶e zosta zdeidentyfikowany z anonimowych zbior贸w danych?

#### 2.5 Prawo do bycia zapomnianym

[Prawo do bycia zapomnianym](https://en.wikipedia.org/wiki/Right_to_be_forgotten) lub [Prawo do usunicia](https://www.gdpreu.org/right-to-be-forgotten/) zapewnia dodatkow ochron danych osobowych u偶ytkownikom. W szczeg贸lnoci daje u偶ytkownikom prawo do 偶dania usunicia lub usunicia danych osobowych z wyszukiwarek internetowych i innych miejsc, _w okrelonych okolicznociach_ - umo偶liwiajc im nowy start online bez trzymania ich przeszych dziaa przeciwko nim.

Pytania do rozwa偶enia:
 * Czy system pozwala podmiotom danych na 偶danie usunicia?
 * Czy wycofanie zgody u偶ytkownika powinno uruchamia automatyczne usunicie?
 * Czy dane zostay zebrane bez zgody lub w spos贸b niezgodny z prawem?
 * Czy jestemy zgodni z regulacjami rzdowymi dotyczcymi prywatnoci danych?

#### 2.6 Uprzedzenia w zbiorach danych

Uprzedzenia w zbiorach danych lub [uprzedzenia w zbieraniu danych](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) dotycz wyboru _niereprezentatywnego_ podzbioru danych do rozwoju algorytmu, co mo偶e prowadzi do potencjalnej niesprawiedliwoci w wynikach dla r贸偶nych grup. Rodzaje uprzedze obejmuj uprzedzenia w wyborze lub pr贸bkowaniu, uprzedzenia ochotnik贸w i uprzedzenia narzdzi.

Pytania do rozwa偶enia:
 * Czy zrekrutowalimy reprezentatywny zestaw podmiot贸w danych?
 * Czy przetestowalimy nasz zebrany lub kuratorowany zbi贸r danych pod ktem r贸偶nych uprzedze?
 * Czy mo偶emy zagodzi lub usun odkryte uprzedzenia?

#### 2.7 Jako danych

[Jako danych](https://lakefs.io/data-quality-testing/) odnosi si do wa偶noci kuratorowanego zbioru danych u偶ywanego do rozwoju naszych algorytm贸w, sprawdzajc, czy cechy i rekordy speniaj wymagania dotyczce poziomu dokadnoci i sp贸jnoci potrzebnego dla naszego celu AI.

Pytania do rozwa偶enia:
 * Czy przech
[Algorithmiczna Sprawiedliwo](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) sprawdza, czy projekt algorytmu systematycznie dyskryminuje okrelone podgrupy os贸b, prowadzc do [potencjalnych szk贸d](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) w zakresie _alokacji_ (gdzie zasoby s odmawiane lub wstrzymywane dla tej grupy) oraz _jakoci usug_ (gdzie AI jest mniej dokadne dla niekt贸rych podgrup ni偶 dla innych).

Pytania do rozwa偶enia:
 * Czy ocenilimy dokadno modelu dla r贸偶nych podgrup i warunk贸w?
 * Czy przeanalizowalimy system pod ktem potencjalnych szk贸d (np. stereotypizacji)?
 * Czy mo偶emy zmodyfikowa dane lub ponownie wytrenowa modele, aby zminimalizowa zidentyfikowane szkody?

Zapoznaj si z zasobami, takimi jak [listy kontrolne sprawiedliwoci AI](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA), aby dowiedzie si wicej.

#### 2.9 Faszywe przedstawienie danych

[Faszywe przedstawienie danych](https://www.sciencedirect.com/topics/computer-science/misrepresentation) dotyczy pytania, czy komunikujemy wnioski z uczciwie zgromadzonych danych w spos贸b wprowadzajcy w bd, aby wspiera po偶dany przekaz.

Pytania do rozwa偶enia:
 * Czy raportujemy niekompletne lub niedokadne dane?
 * Czy wizualizujemy dane w spos贸b prowadzcy do mylcych wniosk贸w?
 * Czy stosujemy selektywne techniki statystyczne, aby manipulowa wynikami?
 * Czy istniej alternatywne wyjanienia, kt贸re mog prowadzi do innych wniosk贸w?

#### 2.10 Iluzja wolnego wyboru

[Iluzja wolnego wyboru](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) pojawia si, gdy "architektury wyboru" systemu wykorzystuj algorytmy decyzyjne, aby skoni ludzi do podjcia preferowanego wyniku, jednoczenie sprawiajc wra偶enie, 偶e maj oni opcje i kontrol. Te [ciemne wzorce](https://www.darkpatterns.org/) mog powodowa spoeczne i ekonomiczne szkody dla u偶ytkownik贸w. Poniewa偶 decyzje u偶ytkownik贸w wpywaj na profile behawioralne, dziaania te mog potencjalnie napdza przysze wybory, wzmacniajc lub przedu偶ajc skutki tych szk贸d.

Pytania do rozwa偶enia:
 * Czy u偶ytkownik rozumia konsekwencje podjcia tej decyzji?
 * Czy u偶ytkownik by wiadomy (alternatywnych) opcji oraz ich zalet i wad?
 * Czy u偶ytkownik mo偶e p贸藕niej cofn automatyczn lub wymuszon decyzj?

### 3. Studia przypadk贸w

Aby umieci te wyzwania etyczne w kontekcie rzeczywistym, warto przyjrze si studiom przypadk贸w, kt贸re podkrelaj potencjalne szkody i konsekwencje dla jednostek i spoeczestwa, gdy naruszenia etyki s ignorowane.

Oto kilka przykad贸w:

| Wyzwanie etyczne | Studium przypadku  | 
|--- |--- |
| **wiadoma zgoda** | 1972 - [Badanie kiy w Tuskegee](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - Afroamerykascy m偶czy藕ni uczestniczcy w badaniu zostali zwabieni obietnic darmowej opieki medycznej, _ale zostali oszukani_ przez badaczy, kt贸rzy nie poinformowali ich o diagnozie ani o dostpnoci leczenia. Wielu uczestnik贸w zmaro, a ich partnerzy lub dzieci zostali dotknici; badanie trwao 40 lat. | 
| **Prywatno danych** |  2007 - [Nagroda Netflixa](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) udostpnia badaczom _10 milion贸w zanonimizowanych ocen film贸w od 50 tysicy klient贸w_, aby pom贸c ulepszy algorytmy rekomendacji. Jednak badacze byli w stanie powiza zanonimizowane dane z danymi osobowymi w _zewntrznych zbiorach danych_ (np. komentarzach na IMDb), skutecznie "deanonimizujc" niekt贸rych subskrybent贸w Netflixa.|
| **Stronniczo w zbieraniu danych**  | 2013 - Miasto Boston [opracowao aplikacj Street Bump](https://www.boston.gov/transportation/street-bump), kt贸ra pozwalaa mieszkacom zgasza dziury w drogach, dostarczajc miastu lepszych danych o drogach. Jednak [osoby z ni偶szych grup dochodowych miay mniejszy dostp do samochod贸w i telefon贸w](https://hbr.org/2013/04/the-hidden-biases-in-big-data), co sprawiao, 偶e ich problemy drogowe byy niewidoczne w tej aplikacji. Tw贸rcy wsp贸pracowali z naukowcami, aby rozwiza problemy _r贸wnego dostpu i cyfrowych podzia贸w_ dla sprawiedliwoci. |
| **Sprawiedliwo algorytmiczna**  | 2018 - MIT [Gender Shades Study](http://gendershades.org/overview.html) ocenio dokadno produkt贸w AI klasyfikujcych pe, ujawniajc luki w dokadnoci dla kobiet i os贸b o innym kolorze sk贸ry. [Karta kredytowa Apple z 2019 roku](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) wydawaa si oferowa mniejsze limity kredytowe kobietom ni偶 m偶czyznom. Oba przypadki ilustruj problemy z uprzedzeniami algorytmicznymi prowadzcymi do szk贸d spoeczno-ekonomicznych.|
| **Faszywe przedstawienie danych** | 2020 - [Departament Zdrowia Publicznego w Georgii opublikowa wykresy COVID-19](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening), kt贸re wydaway si wprowadza w bd obywateli co do trend贸w w potwierdzonych przypadkach, stosujc niechronologiczne uporzdkowanie osi x. To ilustruje faszywe przedstawienie danych za pomoc sztuczek wizualizacyjnych. |
| **Iluzja wolnego wyboru** | 2020 - Aplikacja edukacyjna [ABCmouse zapacia 10 milion贸w dolar贸w w ramach ugody z FTC](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/), gdzie rodzice byli zmuszani do pacenia za subskrypcje, kt贸rych nie mogli anulowa. To ilustruje ciemne wzorce w architekturach wyboru, gdzie u偶ytkownicy byli skaniani do potencjalnie szkodliwych decyzji. |
| **Prywatno danych i prawa u偶ytkownika** | 2021 - [Wyciek danych z Facebooka](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) ujawni dane 530 milion贸w u偶ytkownik贸w, co skutkowao ugod z FTC na kwot 5 miliard贸w dolar贸w. Jednak firma odm贸wia powiadomienia u偶ytkownik贸w o wycieku, naruszajc ich prawa dotyczce przejrzystoci i dostpu do danych. |

Chcesz pozna wicej studi贸w przypadk贸w? Sprawd藕 te zasoby:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - dylematy etyczne w r贸偶nych bran偶ach. 
* [Kurs etyki w nauce o danych](https://www.coursera.org/learn/data-science-ethics#syllabus) - analiza przeomowych studi贸w przypadk贸w.
* [Gdzie popeniono bdy](https://deon.drivendata.org/examples/) - lista kontrolna Deon z przykadami.

>  Zastan贸w si nad studiami przypadk贸w, kt贸re widziae - czy dowiadczye lub bye dotknity podobnym wyzwaniem etycznym w swoim 偶yciu? Czy mo偶esz poda przynajmniej jeden inny przykad studium przypadku ilustrujcy jedno z omawianych wyzwa etycznych?

## Etyka stosowana

Om贸wilimy koncepcje etyczne, wyzwania i studia przypadk贸w w rzeczywistych kontekstach. Ale jak zacz _stosowa_ zasady i praktyki etyczne w naszych projektach? I jak _wdro偶y_ te praktyki dla lepszego zarzdzania? Przyjrzyjmy si kilku rzeczywistym rozwizaniom:

### 1. Kodeksy zawodowe

Kodeksy zawodowe oferuj organizacjom mo偶liwo "motywowania" czonk贸w do wspierania ich zasad etycznych i misji. Kodeksy s _moralnymi wytycznymi_ dotyczcymi zachowa zawodowych, pomagajcymi pracownikom lub czonkom podejmowa decyzje zgodne z zasadami organizacji. Ich skuteczno zale偶y od dobrowolnego przestrzegania przez czonk贸w; jednak wiele organizacji oferuje dodatkowe nagrody i kary, aby zmotywowa czonk贸w do przestrzegania zasad.

Przykady:
 * [Kodeks etyki Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/)
 * [Kodeks postpowania Stowarzyszenia Nauki o Danych](http://datascienceassn.org/code-of-conduct.html) (stworzony w 2013 roku)
 * [Kodeks etyki i postpowania zawodowego ACM](https://www.acm.org/code-of-ethics) (od 1993 roku)

>  Czy nale偶ysz do organizacji zawodowej in偶ynierii lub nauki o danych? Sprawd藕 ich stron, aby zobaczy, czy definiuj kodeks etyki zawodowej. Co m贸wi on o ich zasadach etycznych? Jak "motywuj" czonk贸w do przestrzegania kodeksu?

### 2. Listy kontrolne etyki

Podczas gdy kodeksy zawodowe definiuj wymagane _zachowania etyczne_ praktyk贸w, maj [znane ograniczenia](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) w egzekwowaniu, szczeg贸lnie w du偶ych projektach. Zamiast tego wielu ekspert贸w ds. nauki o danych [zaleca stosowanie list kontrolnych](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), kt贸re mog **czy zasady z praktykami** w bardziej deterministyczny i wykonalny spos贸b.

Listy kontrolne przeksztacaj pytania w zadania "tak/nie", kt贸re mo偶na wdro偶y, umo偶liwiajc ich ledzenie jako cz standardowych proces贸w wydawniczych produkt贸w.

Przykady:
 * [Deon](https://deon.drivendata.org/) - og贸lna lista kontrolna etyki danych stworzona na podstawie [rekomendacji bran偶owych](https://deon.drivendata.org/#checklist-citations) z narzdziem wiersza polece do atwej integracji.
 * [Lista kontrolna audytu prywatnoci](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - zapewnia og贸lne wskaz贸wki dotyczce praktyk przetwarzania informacji z perspektywy prawnej i spoecznej.
 * [Lista kontrolna sprawiedliwoci AI](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - stworzona przez praktyk贸w AI, aby wspiera przyjcie i integracj sprawiedliwoci w cyklach rozwoju AI.
 * [22 pytania dotyczce etyki w danych i AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - bardziej otwarta struktura, zaprojektowana do wstpnej eksploracji problem贸w etycznych w projektowaniu, wdra偶aniu i kontekstach organizacyjnych.

### 3. Regulacje etyczne

Etyka dotyczy definiowania wsp贸lnych wartoci i dobrowolnego postpowania zgodnie z nimi. **Zgodno** dotyczy _przestrzegania prawa_, jeli jest ono zdefiniowane. **Zarzdzanie** obejmuje wszystkie sposoby, w jakie organizacje dziaaj, aby egzekwowa zasady etyczne i przestrzega ustanowionych przepis贸w.

Obecnie zarzdzanie przyjmuje dwie formy w organizacjach. Po pierwsze, chodzi o definiowanie zasad **etycznego AI** i ustanawianie praktyk, kt贸re umo偶liwiaj ich wdro偶enie we wszystkich projektach zwizanych z AI w organizacji. Po drugie, chodzi o przestrzeganie wszystkich rzdowych regulacji dotyczcych **ochrony danych** w regionach, w kt贸rych organizacja dziaa.

Przykady regulacji dotyczcych ochrony danych i prywatnoci:
 * `1974`, [Ustawa o prywatnoci w USA](https://www.justice.gov/opcl/privacy-act-1974) - reguluje _federalne_ zbieranie, wykorzystywanie i ujawnianie danych osobowych.
 * `1996`, [Ustawa o przenonoci i odpowiedzialnoci w ubezpieczeniach zdrowotnych w USA (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - chroni dane osobowe dotyczce zdrowia.
 * `1998`, [Ustawa o ochronie prywatnoci dzieci w Internecie w USA (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - chroni prywatno danych dzieci poni偶ej 13 roku 偶ycia.
 * `2018`, [Og贸lne rozporzdzenie o ochronie danych (GDPR)](https://gdpr-info.eu/) - zapewnia prawa u偶ytkownik贸w, ochron danych i prywatno.
 * `2018`, [Kalifornijska ustawa o ochronie prywatnoci konsument贸w (CCPA)](https://www.oag.ca.gov/privacy/ccpa) - daje konsumentom wiksze _prawa_ do ich danych osobowych.
 * `2021`, Chiska [Ustawa o ochronie danych osobowych](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) - jedna z najsilniejszych regulacji dotyczcych prywatnoci danych online na wiecie.

>  Unijne rozporzdzenie GDPR (Og贸lne rozporzdzenie o ochronie danych) pozostaje jednym z najbardziej wpywowych regulacji dotyczcych prywatnoci danych. Czy wiesz, 偶e definiuje r贸wnie偶 [8 praw u偶ytkownika](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr), aby chroni cyfrow prywatno i dane osobowe obywateli? Dowiedz si, czym s te prawa i dlaczego s wa偶ne.

### 4. Kultura etyki

Nale偶y zauwa偶y, 偶e istnieje niematerialna luka midzy _zgodnoci_ (robieniem wystarczajco du偶o, aby speni "liter prawa") a rozwizywaniem [systemowych problem贸w](https://www.coursera.org/learn/data-science-ethics/home/week/4) (takich jak utrwalanie si problem贸w, asymetria informacji i niesprawiedliwo dystrybucyjna), kt贸re mog przyspieszy "uzbrojenie" AI.

To drugie wymaga [wsp贸pracy w definiowaniu kultur etycznych](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f), kt贸re buduj emocjonalne wizi i sp贸jne wsp贸lne wartoci _w organizacjach_ w bran偶y. Wymaga to bardziej [sformalizowanych kultur etyki danych](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) w organizacjach - umo偶liwiajc _ka偶demu_ [pocignicie za sznur Andon](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (aby zgosi obawy etyczne na wczesnym etapie procesu) i uczynienie _ocen etycznych_ (np. przy zatrudnianiu) kluczowym kryterium formowania zespo贸w w projektach AI.

---
## [Quiz po wykadzie](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/3) 
## Przegld i samodzielna nauka

Kursy i ksi偶ki pomagaj w zrozumieniu podstawowych koncepcji i wyzwa etycznych, podczas gdy studia przypadk贸w i narzdzia pomagaj w stosowaniu praktyk etycznych w rzeczywistych kontekstach. Oto kilka zasob贸w na pocztek:

* [Uczenie maszynowe dla pocztkujcych](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - lekcja o sprawiedliwoci
* [Zasady Odpowiedzialnej AI](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - darmowy kurs edukacyjny od Microsoft Learn.
* [Etyka i Data Science](https://resources.oreilly.com/examples/0636920203964) - EBook od O'Reilly (M. Loukides, H. Mason i in.)
* [Etyka w Data Science](https://www.coursera.org/learn/data-science-ethics#syllabus) - kurs online od Uniwersytetu Michigan.
* [Etyka Rozwinita](https://ethicsunwrapped.utexas.edu/case-studies) - studia przypadk贸w od Uniwersytetu Teksasu.

# Zadanie 

[Napisz studium przypadku dotyczce etyki danych](assignment.md)

**Zastrze偶enie**:  
Ten dokument zosta przetumaczony za pomoc usugi tumaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). Chocia偶 dokadamy wszelkich stara, aby tumaczenie byo precyzyjne, prosimy pamita, 偶e automatyczne tumaczenia mog zawiera bdy lub niecisoci. Oryginalny dokument w jego rodzimym jzyku powinien by uznawany za autorytatywne 藕r贸do. W przypadku informacji o kluczowym znaczeniu zaleca si skorzystanie z profesjonalnego tumaczenia przez czowieka. Nie ponosimy odpowiedzialnoci za jakiekolwiek nieporozumienia lub bdne interpretacje wynikajce z u偶ycia tego tumaczenia.