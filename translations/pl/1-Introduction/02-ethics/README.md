<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1341f6da63d434f5ba31b08ea951b02c",
  "translation_date": "2025-09-05T14:45:33+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "pl"
}
-->
# Wprowadzenie do etyki danych

|![ Sketchnote autorstwa [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Etyka danych - _Sketchnote autorstwa [@nitya](https://twitter.com/nitya)_ |

---

Wszyscy jestemy obywatelami danych 偶yjcymi w wiecie zdominowanym przez dane.

Trendy rynkowe wskazuj, 偶e do 2022 roku 1 na 3 du偶e organizacje bdzie kupowa i sprzedawa swoje dane za porednictwem internetowych [rynk贸w i gied](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/). Jako **tw贸rcy aplikacji**, atwiej i taniej bdzie nam integrowa w codzienne dowiadczenia u偶ytkownik贸w wnioski oparte na danych oraz automatyzacj opart na algorytmach. Jednak wraz z rozpowszechnieniem si AI, bdziemy musieli zrozumie potencjalne szkody wynikajce z [militaryzacji](https://www.youtube.com/watch?v=TQHs8SA1qpk) takich algorytm贸w na du偶 skal.

Trendy wskazuj r贸wnie偶, 偶e do 2025 roku stworzymy i zu偶yjemy ponad [180 zettabajt贸w](https://www.statista.com/statistics/871513/worldwide-data-created/) danych. Jako **naukowcy danych**, uzyskamy bezprecedensowy dostp do danych osobowych. Oznacza to, 偶e mo偶emy budowa profile behawioralne u偶ytkownik贸w i wpywa na podejmowanie decyzji w spos贸b, kt贸ry tworzy [iluzj wolnego wyboru](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice), jednoczenie potencjalnie kierujc u偶ytkownik贸w w preferowane przez nas kierunki. To r贸wnie偶 rodzi szersze pytania dotyczce prywatnoci danych i ochrony u偶ytkownik贸w.

Etyka danych staje si teraz _niezbdnym zabezpieczeniem_ dla nauki i in偶ynierii danych, pomagajc nam minimalizowa potencjalne szkody i niezamierzone konsekwencje wynikajce z naszych dziaa opartych na danych. [Cykl Hype Gartnera dla AI](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) identyfikuje istotne trendy w cyfrowej etyce, odpowiedzialnej AI i zarzdzaniu AI jako kluczowe czynniki napdzajce wiksze megatrendy wok贸 _demokratyzacji_ i _industrializacji_ AI.

![Cykl Hype Gartnera dla AI - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

W tej lekcji zgbimy fascynujcy obszar etyki danych - od podstawowych poj i wyzwa, przez studia przypadk贸w, a偶 po zastosowane koncepcje AI, takie jak zarzdzanie - kt贸re pomagaj ustanowi kultur etyki w zespoach i organizacjach pracujcych z danymi i AI.

## [Quiz przed wykadem](https://ff-quizzes.netlify.app/en/ds/quiz/2) 

## Podstawowe definicje

Zacznijmy od zrozumienia podstawowej terminologii.

Sowo "etyka" pochodzi od [greckiego sowa "ethikos"](https://en.wikipedia.org/wiki/Ethics) (i jego korzenia "ethos"), kt贸re oznacza _charakter lub moraln natur_.

**Etyka** dotyczy wsp贸lnych wartoci i zasad moralnych, kt贸re reguluj nasze zachowanie w spoeczestwie. Etyka opiera si nie na prawach, ale na powszechnie akceptowanych normach tego, co jest "dobre vs. ze". Jednak rozwa偶ania etyczne mog wpywa na inicjatywy w zakresie adu korporacyjnego i regulacje rzdowe, kt贸re tworz wiksze zachty do przestrzegania zasad.

**Etyka danych** to [nowa ga藕 etyki](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1), kt贸ra "bada i ocenia problemy moralne zwizane z _danymi, algorytmami i odpowiadajcymi im praktykami_". Tutaj **"dane"** koncentruj si na dziaaniach zwizanych z generowaniem, rejestrowaniem, kuracj, przetwarzaniem, rozpowszechnianiem, udostpnianiem i u偶ytkowaniem, **"algorytmy"** skupiaj si na AI, agentach, uczeniu maszynowym i robotach, a **"praktyki"** dotycz takich temat贸w jak odpowiedzialna innowacja, programowanie, hacking i kodeksy etyczne.

**Etyka stosowana** to [praktyczne zastosowanie rozwa偶a moralnych](https://en.wikipedia.org/wiki/Applied_ethics). Jest to proces aktywnego badania kwestii etycznych w kontekcie _dziaa, produkt贸w i proces贸w w rzeczywistym wiecie_ oraz podejmowania dziaa naprawczych, aby zapewni ich zgodno z okrelonymi wartociami etycznymi.

**Kultura etyki** dotyczy [_operacjonalizacji_ etyki stosowanej](https://hbr.org/2019/05/how-to-design-an-ethical-organization), aby upewni si, 偶e nasze zasady i praktyki etyczne s przyjmowane w spos贸b sp贸jny i skalowalny w caej organizacji. Udane kultury etyki definiuj zasady etyczne na poziomie organizacyjnym, zapewniaj znaczce zachty do przestrzegania zasad i wzmacniaj normy etyczne, zachcajc i amplifikujc po偶dane zachowania na ka偶dym poziomie organizacji.

## Koncepcje etyki

W tej sekcji om贸wimy koncepcje takie jak **wsp贸lne wartoci** (zasady) i **wyzwania etyczne** (problemy) w etyce danych - oraz przeanalizujemy **studia przypadk贸w**, kt贸re pomog zrozumie te koncepcje w kontekstach rzeczywistego wiata.

### 1. Zasady etyki

Ka偶da strategia etyki danych zaczyna si od zdefiniowania _zasad etycznych_ - "wsp贸lnych wartoci", kt贸re opisuj akceptowalne zachowania i kieruj zgodnymi dziaaniami w naszych projektach zwizanych z danymi i AI. Mo偶na je definiowa na poziomie indywidualnym lub zespoowym. Jednak wikszo du偶ych organizacji okrela je w owiadczeniu misji lub ramach _etycznej AI_, kt贸re s definiowane na poziomie korporacyjnym i konsekwentnie egzekwowane we wszystkich zespoach.

**Przykad:** Owiadczenie misji [Odpowiedzialnej AI](https://www.microsoft.com/en-us/ai/responsible-ai) firmy Microsoft brzmi: _"Jestemy zaanga偶owani w rozw贸j AI kierowany przez zasady etyczne, kt贸re stawiaj ludzi na pierwszym miejscu"_ - identyfikujc 6 zasad etycznych w poni偶szych ramach:

![Odpowiedzialna AI w Microsoft](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

Przyjrzyjmy si kr贸tko tym zasadom. _Przejrzysto_ i _odpowiedzialno_ s podstawowymi wartociami, na kt贸rych opieraj si inne zasady - wic zacznijmy od nich:

* [**Odpowiedzialno**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) sprawia, 偶e praktycy s _odpowiedzialni_ za swoje operacje zwizane z danymi i AI oraz za zgodno z tymi zasadami etycznymi.
* [**Przejrzysto**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) zapewnia, 偶e dziaania zwizane z danymi i AI s _zrozumiae_ (interpretowalne) dla u偶ytkownik贸w, wyjaniajc co i dlaczego stoi za decyzjami.
* [**Sprawiedliwo**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - koncentruje si na zapewnieniu, 偶e AI traktuje _wszystkich ludzi_ sprawiedliwie, rozwizujc wszelkie systemowe lub ukryte techniczno-spoeczne uprzedzenia w danych i systemach.
* [**Niezawodno i bezpieczestwo**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - zapewnia, 偶e AI dziaa _sp贸jnie_ z okrelonymi wartociami, minimalizujc potencjalne szkody lub niezamierzone konsekwencje.
* [**Prywatno i bezpieczestwo**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - dotyczy zrozumienia pochodzenia danych oraz zapewnienia _prywatnoci danych i zwizanych z nimi ochron_ u偶ytkownikom.
* [**Inkluzywno**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - dotyczy projektowania rozwiza AI z zamiarem dostosowania ich do _szerokiego zakresu ludzkich potrzeb_ i mo偶liwoci.

>  Zastan贸w si, jakie mogoby by Twoje owiadczenie misji etyki danych. Przeanalizuj ramy etycznej AI innych organizacji - oto przykady od [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles) i [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Jakie wsp贸lne wartoci maj? Jak te zasady odnosz si do produktu AI lub bran偶y, w kt贸rej dziaaj?

### 2. Wyzwania etyczne

Gdy mamy zdefiniowane zasady etyczne, kolejnym krokiem jest ocena naszych dziaa zwizanych z danymi i AI, aby sprawdzi, czy s zgodne z tymi wsp贸lnymi wartociami. Zastan贸w si nad swoimi dziaaniami w dw贸ch kategoriach: _zbieranie danych_ i _projektowanie algorytm贸w_.

W przypadku zbierania danych dziaania prawdopodobnie bd dotyczy **danych osobowych** lub danych umo偶liwiajcych identyfikacj os贸b (PII) dla identyfikowalnych 偶yjcych jednostek. Obejmuje to [r贸偶norodne elementy danych nieosobowych](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en), kt贸re _cznie_ identyfikuj jednostk. Wyzwania etyczne mog dotyczy _prywatnoci danych_, _wasnoci danych_ i powizanych temat贸w, takich jak _wiadoma zgoda_ i _prawa wasnoci intelektualnej_ u偶ytkownik贸w.

W przypadku projektowania algorytm贸w dziaania bd obejmowa zbieranie i kuracj **zbior贸w danych**, a nastpnie ich wykorzystanie do trenowania i wdra偶ania **modeli danych**, kt贸re przewiduj wyniki lub automatyzuj decyzje w rzeczywistych kontekstach. Wyzwania etyczne mog wynika z _uprzedze w zbiorach danych_, problem贸w z _jakoci danych_, _niesprawiedliwoci_ i _faszywego przedstawienia_ w algorytmach - w tym niekt贸rych problem贸w o charakterze systemowym.

W obu przypadkach wyzwania etyczne wskazuj obszary, w kt贸rych nasze dziaania mog napotka konflikt z naszymi wsp贸lnymi wartociami. Aby wykry, zagodzi, zminimalizowa lub wyeliminowa te obawy, musimy zadawa moralne pytania "tak/nie" dotyczce naszych dziaa, a nastpnie podejmowa odpowiednie dziaania naprawcze. Przyjrzyjmy si niekt贸rym wyzwaniom etycznym i moralnym pytaniom, kt贸re si z nimi wi偶:

#### 2.1 Wasno danych

Zbieranie danych czsto obejmuje dane osobowe, kt贸re mog identyfikowa podmioty danych. [Wasno danych](https://permission.io/blog/data-ownership) dotyczy _kontroli_ i [_praw u偶ytkownik贸w_](https://permission.io/blog/data-ownership) zwizanych z tworzeniem, przetwarzaniem i rozpowszechnianiem danych.

Moralne pytania, kt贸re nale偶y zada:
 * Kto jest wacicielem danych? (u偶ytkownik czy organizacja)
 * Jakie prawa maj podmioty danych? (np. dostp, usunicie, przenoszenie)
 * Jakie prawa maj organizacje? (np. poprawa zoliwych recenzji u偶ytkownik贸w)

#### 2.2 wiadoma zgoda

[wiadoma zgoda](https://legaldictionary.net/informed-consent/) definiuje akt zgody u偶ytkownik贸w na dziaanie (np. zbieranie danych) z _penym zrozumieniem_ istotnych fakt贸w, w tym celu, potencjalnych ryzyk i alternatyw.

Pytania do rozwa偶enia:
 * Czy u偶ytkownik (podmiot danych) wyrazi zgod na przechwytywanie i wykorzystanie danych?
 * Czy u偶ytkownik rozumia cel, dla kt贸rego dane zostay przechwycone?
 * Czy u偶ytkownik rozumia potencjalne ryzyka wynikajce z jego udziau?

#### 2.3 Wasno intelektualna

[Wasno intelektualna](https://en.wikipedia.org/wiki/Intellectual_property) odnosi si do niematerialnych wytwor贸w wynikajcych z ludzkiej inicjatywy, kt贸re mog _mie warto ekonomiczn_ dla jednostek lub firm.

Pytania do rozwa偶enia:
 * Czy zebrane dane miay warto ekonomiczn dla u偶ytkownika lub firmy?
 * Czy **u偶ytkownik** ma tutaj wasno intelektualn?
 * Czy **organizacja** ma tutaj wasno intelektualn?
 * Jeli te prawa istniej, jak je chronimy?

#### 2.4 Prywatno danych

[Prywatno danych](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) lub prywatno informacji odnosi si do zachowania prywatnoci u偶ytkownika i ochrony jego to偶samoci w odniesieniu do danych umo偶liwiajcych identyfikacj.

Pytania do rozwa偶enia:
 * Czy dane u偶ytkownik贸w (osobowe) s zabezpieczone przed atakami i wyciekami?
 * Czy dane u偶ytkownik贸w s dostpne tylko dla autoryzowanych u偶ytkownik贸w i kontekst贸w?
 * Czy anonimowo u偶ytkownik贸w jest zachowana podczas udostpniania lub rozpowszechniania danych?
 * Czy u偶ytkownik mo偶e zosta zdeidentyfikowany z anonimowych zbior贸w danych?

#### 2.5 Prawo do bycia zapomnianym

[Prawo do bycia zapomnianym](https://en.wikipedia.org/wiki/Right_to_be_forgotten) lub [Prawo do usunicia](https://www.gdpreu.org/right-to-be-forgotten/) zapewnia dodatkow ochron danych osobowych u偶ytkownikom. W szczeg贸lnoci daje u偶ytkownikom prawo do 偶dania usunicia lub wymazania danych osobowych z wyszukiwarek internetowych i innych miejsc, _w okrelonych okolicznociach_ - pozwalajc im na nowy start online bez trzymania ich przeszych dziaa przeciwko nim.

Pytania do rozwa偶enia:
 * Czy system pozwala podmiotom danych na 偶danie usunicia?
 * Czy wycofanie zgody u偶ytkownika powinno uruchamia automatyczne usunicie?
 * Czy dane zostay zebrane bez zgody lub w spos贸b niezgodny z prawem?
 * Czy jestemy zgodni z regulacjami rzdowymi dotyczcymi prywatnoci danych?

#### 2.6 Uprzedzenia w zbiorach danych

Uprzedzenia w zbiorach danych lub [uprzedzenia w zbieraniu danych](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) dotycz wyboru _niereprezentatywnego_ podzbioru danych do rozwoju algorytmu, co mo偶e prowadzi do potencjalnej niesprawiedliwoci w wynikach dla r贸偶nych grup. Rodzaje uprzedze obejmuj uprzedzenia w wyborze lub pr贸bkowaniu, uprzedzenia ochotnik贸w i uprzedzenia instrument贸w.

Pytania do rozwa偶enia:
 * Czy zrekrutowalimy reprezentatywny zestaw podmiot贸w danych?
 * Czy przetestowalimy nasz zebrany lub kuratowany zbi贸r danych pod ktem r贸偶nych uprzedze?
 * Czy mo偶emy zagodzi lub usun odkryte uprzedzenia?

#### 2.7 Jako danych

[Jako danych](https://lakefs.io/data-quality-testing/) sprawdza wa偶no kuratowanego zbioru danych u偶ywanego do rozwoju naszych algorytm贸w, sprawdzajc, czy cechy i rekordy speniaj wymagania dotyczce poziomu dokadnoci i sp贸jnoci potrzebnego dla naszego celu AI.

Pytania do rozwa偶enia:
 * Czy przechwycilimy wa偶ne _cechy_ dla naszego przypadku u偶ycia?
 * Czy dane byy przechwy
[Algorithm Fairness](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) sprawdza, czy projekt algorytmu systematycznie dyskryminuje okrelone podgrupy os贸b, co prowadzi do [potencjalnych szk贸d](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) w _alokacji_ (gdzie zasoby s odmawiane lub wstrzymywane dla tej grupy) oraz _jakoci usug_ (gdzie AI jest mniej dokadne dla niekt贸rych podgrup ni偶 dla innych).

Pytania, kt贸re warto tutaj rozwa偶y:
 * Czy ocenilimy dokadno modelu dla r贸偶nych podgrup i warunk贸w?
 * Czy przeanalizowalimy system pod ktem potencjalnych szk贸d (np. stereotypizacji)?
 * Czy mo偶emy zmodyfikowa dane lub ponownie wytrenowa modele, aby zminimalizowa zidentyfikowane szkody?

Zapoznaj si z zasobami, takimi jak [AI Fairness checklists](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA), aby dowiedzie si wicej.

#### 2.9 Wprowadzenie w bd

[Wprowadzenie w bd w danych](https://www.sciencedirect.com/topics/computer-science/misrepresentation) dotyczy pytania, czy komunikujemy wnioski z uczciwie zgromadzonych danych w spos贸b zwodniczy, aby wspiera po偶dany przekaz.

Pytania, kt贸re warto tutaj rozwa偶y:
 * Czy raportujemy niekompletne lub nieprecyzyjne dane?
 * Czy wizualizujemy dane w spos贸b prowadzcy do mylcych wniosk贸w?
 * Czy stosujemy selektywne techniki statystyczne, aby manipulowa wynikami?
 * Czy istniej alternatywne wyjanienia, kt贸re mog prowadzi do innych wniosk贸w?

#### 2.10 Wolny wyb贸r
[Iluzja wolnego wyboru](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) pojawia si, gdy "architektury wyboru" systemu wykorzystuj algorytmy decyzyjne, aby nakoni ludzi do podjcia preferowanego dziaania, jednoczenie dajc im pozorn kontrol i opcje. Te [ciemne wzorce](https://www.darkpatterns.org/) mog powodowa szkody spoeczne i ekonomiczne dla u偶ytkownik贸w. Poniewa偶 decyzje u偶ytkownik贸w wpywaj na profile zachowa, te dziaania mog potencjalnie napdza przysze wybory, kt贸re wzmacniaj lub rozszerzaj skutki tych szk贸d.

Pytania, kt贸re warto tutaj rozwa偶y:
 * Czy u偶ytkownik rozumia konsekwencje podjcia tej decyzji?
 * Czy u偶ytkownik by wiadomy (alternatywnych) opcji oraz ich zalet i wad?
 * Czy u偶ytkownik mo偶e p贸藕niej cofn automatyczn lub wpynit decyzj?

### 3. Studia przypadk贸w

Aby umieci te wyzwania etyczne w kontekcie rzeczywistym, warto przyjrze si studiom przypadk贸w, kt贸re podkrelaj potencjalne szkody i konsekwencje dla jednostek i spoeczestwa, gdy naruszenia etyki s ignorowane.

Oto kilka przykad贸w:

| Wyzwanie etyczne | Studium przypadku  | 
|--- |--- |
| **wiadoma zgoda** | 1972 - [Tuskegee Syphilis Study](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - Afroamerykascy m偶czy藕ni, kt贸rzy uczestniczyli w badaniu, zostali obiecani darmow opiek medyczn, _ale zostali oszukani_ przez badaczy, kt贸rzy nie poinformowali ich o diagnozie ani o dostpnoci leczenia. Wielu uczestnik贸w zmaro, a ich partnerzy lub dzieci zostali dotknici; badanie trwao 40 lat. | 
| **Prywatno danych** |  2007 - [Netflix data prize](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) udostpnio badaczom _10M zanonimizowanych ocen film贸w od 50K klient贸w_, aby pom贸c w ulepszaniu algorytm贸w rekomendacji. Jednak badacze byli w stanie powiza zanonimizowane dane z danymi osobowymi w _zewntrznych zbiorach danych_ (np. komentarze na IMDb), skutecznie "deanonimizujc" niekt贸rych subskrybent贸w Netflixa.|
| **Stronniczo w zbieraniu danych**  | 2013 - Miasto Boston [opracowao Street Bump](https://www.boston.gov/transportation/street-bump), aplikacj pozwalajc obywatelom zgasza dziury w drogach, dostarczajc miastu lepszych danych o drogach. Jednak [osoby z ni偶szych grup dochodowych miay mniejszy dostp do samochod贸w i telefon贸w](https://hbr.org/2013/04/the-hidden-biases-in-big-data), co sprawio, 偶e ich problemy drogowe byy niewidoczne w tej aplikacji. Tw贸rcy wsp贸pracowali z akademikami, aby rozwiza problemy _r贸wnego dostpu i cyfrowych podzia贸w_ dla sprawiedliwoci. |
| **Sprawiedliwo algorytmiczna**  | 2018 - MIT [Gender Shades Study](http://gendershades.org/overview.html) ocenio dokadno produkt贸w AI klasyfikujcych pe, ujawniajc luki w dokadnoci dla kobiet i os贸b o ciemniejszym kolorze sk贸ry. [Apple Card z 2019 roku](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) wydawaa si oferowa mniej kredytu kobietom ni偶 m偶czyznom. Oba przypadki ilustruj problemy z uprzedzeniami algorytmicznymi prowadzcymi do szk贸d spoeczno-ekonomicznych.|
| **Wprowadzenie w bd w danych** | 2020 - [Georgia Department of Public Health opublikowao wykresy COVID-19](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening), kt贸re wydaway si wprowadza obywateli w bd co do trend贸w w potwierdzonych przypadkach poprzez niechronologiczne uporzdkowanie osi x. To ilustruje wprowadzenie w bd za pomoc trik贸w wizualizacyjnych. |
| **Iluzja wolnego wyboru** | 2020 - Aplikacja edukacyjna [ABCmouse zapacia 10M dolar贸w w ramach ugody z FTC](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/), gdzie rodzice byli zmuszani do pacenia za subskrypcje, kt贸rych nie mogli anulowa. To ilustruje ciemne wzorce w architekturach wyboru, gdzie u偶ytkownicy byli nakaniani do potencjalnie szkodliwych decyzji. |
| **Prywatno danych i prawa u偶ytkownik贸w** | 2021 - Facebook [Data Breach](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) ujawnio dane 530M u偶ytkownik贸w, co skutkowao ugod w wysokoci 5B dolar贸w z FTC. Jednak odm贸wio powiadomienia u偶ytkownik贸w o naruszeniu, naruszajc prawa u偶ytkownik贸w dotyczce przejrzystoci danych i dostpu. |

Chcesz pozna wicej studi贸w przypadk贸w? Sprawd藕 te zasoby:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - dylematy etyczne w r贸偶nych bran偶ach. 
* [Data Science Ethics course](https://www.coursera.org/learn/data-science-ethics#syllabus) - om贸wione kluczowe studia przypadk贸w.
* [Where things have gone wrong](https://deon.drivendata.org/examples/) - lista kontrolna Deon z przykadami.

>  Zastan贸w si nad studiami przypadk贸w, kt贸re widziae - czy dowiadczye lub bye dotknity podobnym wyzwaniem etycznym w swoim 偶yciu? Czy mo偶esz wymyli co najmniej jedno inne studium przypadku, kt贸re ilustruje jedno z wyzwa etycznych om贸wionych w tej sekcji?

## Zastosowanie etyki

Om贸wilimy koncepcje etyczne, wyzwania i studia przypadk贸w w kontekstach rzeczywistych. Ale jak zacz _stosowa_ zasady i praktyki etyczne w naszych projektach? I jak _operacjonalizowa_ te praktyki dla lepszego zarzdzania? Przyjrzyjmy si kilku rozwizaniom w rzeczywistym wiecie:

### 1. Kodeksy zawodowe

Kodeksy zawodowe oferuj jedn z opcji dla organizacji, aby "zachci" czonk贸w do wspierania ich zasad etycznych i misji. Kodeksy s _moralnymi wytycznymi_ dla zachowa zawodowych, pomagajc pracownikom lub czonkom podejmowa decyzje zgodne z zasadami organizacji. S skuteczne tylko w przypadku dobrowolnego przestrzegania przez czonk贸w; jednak wiele organizacji oferuje dodatkowe nagrody i kary, aby motywowa czonk贸w do przestrzegania zasad.

Przykady obejmuj:

 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Kodeks Etyki
 * [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Kodeks Postpowania (utworzony w 2013 roku)
 * [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (od 1993 roku)

>  Czy nale偶ysz do organizacji zawodowej zwizanej z in偶ynieri lub nauk o danych? Sprawd藕 ich stron, aby zobaczy, czy definiuj kodeks etyki zawodowej. Co m贸wi to o ich zasadach etycznych? Jak "zachcaj" czonk贸w do przestrzegania kodeksu?

### 2. Listy kontrolne etyki

Podczas gdy kodeksy zawodowe definiuj wymagane _zachowania etyczne_ od praktyk贸w, [maj znane ograniczenia](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) w egzekwowaniu, szczeg贸lnie w projektach na du偶 skal. Zamiast tego wielu ekspert贸w ds. nauki o danych [zaleca listy kontrolne](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), kt贸re mog **poczy zasady z praktykami** w bardziej deterministyczny i wykonalny spos贸b.

Listy kontrolne przeksztacaj pytania w zadania "tak/nie", kt贸re mo偶na operacjonalizowa, umo偶liwiajc ich ledzenie jako cz standardowych proces贸w wydania produktu.

Przykady obejmuj:
 * [Deon](https://deon.drivendata.org/) - og贸lna lista kontrolna etyki danych stworzona na podstawie [rekomendacji bran偶owych](https://deon.drivendata.org/#checklist-citations) z narzdziem wiersza polece do atwej integracji.
 * [Privacy Audit Checklist](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - zapewnia og贸lne wskaz贸wki dotyczce praktyk obsugi informacji z perspektywy prawnej i spoecznej.
 * [AI Fairness Checklist](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - stworzona przez praktyk贸w AI, aby wspiera przyjcie i integracj kontroli sprawiedliwoci w cyklach rozwoju AI.
 * [22 questions for ethics in data and AI](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - bardziej otwarta struktura, zaprojektowana do wstpnej eksploracji problem贸w etycznych w projektowaniu, wdra偶aniu i kontekstach organizacyjnych.

### 3. Regulacje etyczne

Etyka dotyczy definiowania wsp贸lnych wartoci i dobrowolnego postpowania waciwie. **Zgodno** dotyczy _przestrzegania prawa_, jeli jest ono okrelone. **Zarzdzanie** obejmuje szeroko wszystkie sposoby, w jakie organizacje dziaaj, aby egzekwowa zasady etyczne i przestrzega ustalonych przepis贸w.

Obecnie zarzdzanie przyjmuje dwie formy w organizacjach. Po pierwsze, chodzi o definiowanie zasad **etycznego AI** i ustanawianie praktyk, kt贸re operacjonalizuj ich przyjcie we wszystkich projektach zwizanych z AI w organizacji. Po drugie, chodzi o przestrzeganie wszystkich rzdowych regulacji dotyczcych **ochrony danych** w regionach, w kt贸rych dziaa.

Przykady regulacji dotyczcych ochrony danych i prywatnoci:

 * `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - reguluje _federalne_ zbieranie, u偶ycie i ujawnianie danych osobowych.
 * `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - chroni dane osobowe dotyczce zdrowia.
 * `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - chroni prywatno danych dzieci poni偶ej 13 roku 偶ycia.
 * `2018`, [General Data Protection Regulation (GDPR)](https://gdpr-info.eu/) - zapewnia prawa u偶ytkownik贸w, ochron danych i prywatno.
 * `2018`, [California Consumer Privacy Act (CCPA)](https://www.oag.ca.gov/privacy/ccpa) daje konsumentom wicej _praw_ dotyczcych ich (osobistych) danych.
 * `2021`, [Chiska ustawa o ochronie danych osobowych](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) wanie uchwalona, tworzc jedne z najsilniejszych regulacji dotyczcych prywatnoci danych online na wiecie.

>  Unia Europejska zdefiniowaa GDPR (Og贸lne Rozporzdzenie o Ochronie Danych), kt贸re pozostaje jednym z najbardziej wpywowych regulacji dotyczcych prywatnoci danych dzisiaj. Czy wiesz, 偶e definiuje r贸wnie偶 [8 praw u偶ytkownik贸w](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr), aby chroni cyfrow prywatno i dane osobowe obywateli? Dowiedz si, czym s te prawa i dlaczego s wa偶ne.

### 4. Kultura etyki

Nale偶y zauwa偶y, 偶e istnieje niematerialna luka midzy _zgodnoci_ (robieniem wystarczajco du偶o, aby speni "liter prawa") a rozwizywaniem [systemowych problem贸w](https://www.coursera.org/learn/data-science-ethics/home/week/4) (takich jak utrwalanie, asymetria informacji i niesprawiedliwo dystrybucyjna), kt贸re mog przyspieszy uzbrojenie AI.

To drugie wymaga [wsp贸pracy w definiowaniu kultur etycznych](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f), kt贸re buduj emocjonalne wizi i sp贸jne wsp贸lne wartoci _w organizacjach_ w bran偶y. To wymaga bardziej [sformalizowanych kultur etyki danych](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) w organizacjach - pozwalajc _ka偶demu_ [pocign za sznur Andon](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (aby zgosi obawy etyczne na wczesnym etapie procesu) i czynic _oceny etyczne_ (np. w zatrudnianiu) kluczowym kryterium formowania zespo贸w w projektach AI.

---
## [Quiz po wykadzie](https://ff-quizzes.netlify.app/en/ds/quiz/3) 
## Przegld i samodzielna nauka 

Kursy i ksi偶ki pomagaj w zrozumieniu podstawowych koncepcji etyki i wyzwa, podczas gdy studia przypadk贸w i narzdzia pomagaj w stosowaniu praktyk etycznych w rzeczywistych kontekstach. Oto kilka zasob贸w na pocztek:

* [Machine Learning For Beginners](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - lekcja o sprawiedliwoci, od Microsoft.
* [Zasady odpowiedzialnej sztucznej inteligencji](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - darmowy kurs edukacyjny od Microsoft Learn.
* [Etyka i nauka o danych](https://resources.oreilly.com/examples/0636920203964) - e-book O'Reilly (M. Loukides, H. Mason i in.)
* [Etyka w nauce o danych](https://www.coursera.org/learn/data-science-ethics#syllabus) - kurs online Uniwersytetu Michigan.
* [Etyka w praktyce](https://ethicsunwrapped.utexas.edu/case-studies) - studia przypadk贸w Uniwersytetu Teksasu.

# Zadanie

[Napisz studium przypadku dotyczce etyki danych](assignment.md)

---

**Zastrze偶enie**:  
Ten dokument zosta przetumaczony za pomoc usugi tumaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). Chocia偶 dokadamy wszelkich stara, aby tumaczenie byo precyzyjne, prosimy pamita, 偶e automatyczne tumaczenia mog zawiera bdy lub niecisoci. Oryginalny dokument w jego rodzimym jzyku powinien by uznawany za 藕r贸do autorytatywne. W przypadku informacji o kluczowym znaczeniu zaleca si skorzystanie z profesjonalnego tumaczenia przez czowieka. Nie ponosimy odpowiedzialnoci za jakiekolwiek nieporozumienia lub bdne interpretacje wynikajce z u偶ycia tego tumaczenia.