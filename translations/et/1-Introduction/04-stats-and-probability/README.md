<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ce95884566a74db72572cd51f0cb25ad",
  "translation_date": "2025-10-11T15:43:30+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "et"
}
-->
# L√ºhike sissejuhatus statistikasse ja t√µen√§osusteooriasse

|![ Sketchnote autorilt [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| Statistika ja t√µen√§osusteooria - _Sketchnote autorilt [@nitya](https://twitter.com/nitya)_ |

Statistika ja t√µen√§osusteooria on kaks tihedalt seotud matemaatika valdkonda, mis on v√§ga olulised andmeteaduse jaoks. Andmetega on v√µimalik t√∂√∂tada ka ilma s√ºgavate matemaatiliste teadmisteta, kuid siiski on parem omada v√§hemalt m√µningaid p√µhiteadmisi. Siin anname l√ºhikese sissejuhatuse, mis aitab teil alustada.

[![Sissejuhatav video](../../../../translated_images/et/video-prob-and-stats.e4282e5efa2f2543400843ed98b1057065c9600cebfc8a728e8931b5702b2ae4.png)](https://youtu.be/Z5Zy85g4Yjw)


## [Loengu-eelne viktoriin](https://ff-quizzes.netlify.app/en/ds/quiz/6)

## T√µen√§osus ja juhuslikud muutujad

**T√µen√§osus** on arv vahemikus 0 kuni 1, mis v√§ljendab, kui t√µen√§oline on mingi **s√ºndmus**. See m√§√§ratletakse positiivsete tulemuste arvuna (mis viivad s√ºndmuseni), jagatuna k√µigi tulemuste arvuga, eeldades, et k√µik tulemused on v√µrdselt t√µen√§olised. N√§iteks, kui viskame t√§ringut, siis t√µen√§osus saada paarisarv on 3/6 = 0.5.

S√ºndmustest r√§√§kides kasutame **juhuslikke muutujaid**. N√§iteks juhuslik muutuja, mis esindab t√§ringuviske tulemust, v√µib v√µtta v√§√§rtusi 1 kuni 6. Arvude kogumit 1-st 6-ni nimetatakse **valimruumiks**. Me saame r√§√§kida juhusliku muutuja t√µen√§osusest v√µtta teatud v√§√§rtus, n√§iteks P(X=3)=1/6.

Eelmises n√§ites olevat juhuslikku muutujat nimetatakse **diskreetseks**, kuna selle valimruum on loendatav, st seal on eraldi v√§√§rtused, mida saab loendada. On ka juhtumeid, kus valimruum on reaalarvude vahemik v√µi kogu reaalarvude hulk. Selliseid muutujaid nimetatakse **pidevateks**. Heaks n√§iteks on bussi saabumise aeg.

## T√µen√§osusjaotus

Diskreetsete juhuslike muutujate puhul on lihtne kirjeldada iga s√ºndmuse t√µen√§osust funktsiooni P(X) abil. Iga v√§√§rtuse *s* jaoks valimruumist *S* annab see funktsioon arvu vahemikus 0 kuni 1, nii et k√µigi s√ºndmuste P(X=s) v√§√§rtuste summa oleks 1.

K√µige tuntum diskreetne jaotus on **√ºhtlane jaotus**, kus valimruumis on N elementi, millest iga√ºhe t√µen√§osus on 1/N.

Pideva muutuja t√µen√§osusjaotuse kirjeldamine on keerulisem, kui v√§√§rtused on v√µetud m√µnest intervallist [a,b] v√µi kogu reaalarvude hulgast &Ropf;. Vaatleme bussi saabumise aega. Tegelikult on iga t√§pse saabumisaja *t* puhul t√µen√§osus, et buss saabub t√§pselt sel ajal, 0!

> N√º√ºd teate, et s√ºndmused, mille t√µen√§osus on 0, juhtuvad ja v√§ga sageli! V√§hemalt iga kord, kui buss saabub!

Me saame r√§√§kida ainult muutuja t√µen√§osusest langeda teatud v√§√§rtuste vahemikku, nt P(t<sub>1</sub>&le;X&lt;t<sub>2</sub>). Sel juhul kirjeldatakse t√µen√§osusjaotust **t√µen√§osustihedusfunktsiooni** p(x) abil, nii et

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../translated_images/et/probability-density.a8aad29f17a14afb519b407c7b6edeb9f3f9aa5f69c9e6d9445f604e5f8a2bf7.png)
  
Pideva √ºhtlase jaotuse analoog on **pidev √ºhtlane jaotus**, mis on m√§√§ratletud l√µplikul intervallil. T√µen√§osus, et v√§√§rtus X langeb pikkusega l intervalli, on proportsionaalne l-ga ja ulatub kuni 1-ni.

Teine oluline jaotus on **normaaljaotus**, millest r√§√§gime allpool √ºksikasjalikumalt.

## Keskmine, dispersioon ja standardh√§lve

Oletame, et v√µtame juhusliku muutuja X n n√§idist: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. Me saame m√§√§ratleda j√§rjestuse **keskmise** (v√µi **aritmeetilise keskmise**) traditsioonilisel viisil kui (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n. Kui suurendame valimi suurust (st v√µtame piiri n&rarr;&infin;), saame jaotuse keskmise (mida nimetatakse ka **ootuseks**). Ootust t√§histame **E**(x).

> On v√µimalik n√§idata, et iga diskreetse jaotuse korral, mille v√§√§rtused on {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} ja vastavad t√µen√§osused p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, on ootus v√µrdne E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>.

Et m√§√§rata, kui palju v√§√§rtused on hajutatud, saame arvutada dispersiooni &sigma;<sup>2</sup> = &sum;(x<sub>i</sub> - &mu;)<sup>2</sup>/n, kus &mu; on j√§rjestuse keskmine. V√§√§rtust &sigma; nimetatakse **standardh√§lbeks** ja &sigma;<sup>2</sup> nimetatakse **dispersiooniks**.

## Mood, mediaan ja kvartiilid

M√µnikord ei esinda keskmine piisavalt h√§sti andmete "t√º√ºpilist" v√§√§rtust. N√§iteks, kui on m√µned √§√§rmuslikud v√§√§rtused, mis on t√§iesti vahemikust v√§ljas, v√µivad need keskmist m√µjutada. Teine hea n√§itaja on **mediaan**, v√§√§rtus, mille puhul pooled andmepunktid on sellest madalamad ja teine pool k√µrgemad.

Et aidata meil andmete jaotust paremini m√µista, on kasulik r√§√§kida **kvartiilidest**:

* Esimene kvartiil ehk Q1 on v√§√§rtus, mille puhul 25% andmetest j√§√§b sellest allapoole
* Kolmas kvartiil ehk Q3 on v√§√§rtus, mille puhul 75% andmetest j√§√§b sellest allapoole

Graafiliselt saame mediaani ja kvartiilide suhet kujutada diagrammil, mida nimetatakse **kastdiagrammiks**:

<img src="../../../../translated_images/et/boxplot_explanation.4039b7de08780fd493ef798b41f7291d753f1f84de8955645f00c586e65f16a3.png" alt="Kastdiagrammi selgitus" width="50%">

Siin arvutame ka **kvartiilidevahelise ulatuse** IQR=Q3-Q1 ja nn **√§√§rmusv√§√§rtused** - v√§√§rtused, mis j√§√§vad v√§ljapoole piire [Q1-1.5*IQR,Q3+1.5*IQR].

L√µpliku jaotuse korral, mis sisaldab v√§ikest arvu v√µimalikke v√§√§rtusi, on heaks "t√º√ºpiliseks" v√§√§rtuseks see, mis esineb k√µige sagedamini, mida nimetatakse **moodiks**. Seda rakendatakse sageli kategoorilistele andmetele, n√§iteks v√§rvidele. Kujutage ette olukorda, kus meil on kaks inimgruppi - m√µned, kes eelistavad tugevalt punast, ja teised, kes eelistavad sinist. Kui kodeerime v√§rvid numbritega, oleks lemmikv√§rvi keskmine v√§√§rtus kuskil oran≈æi-rohelise spektris, mis ei n√§ita tegelikku eelistust kummagi grupi puhul. Kuid mood oleks kas √ºks v√§rvidest v√µi m√µlemad v√§rvid, kui nende poolt h√§√§letavate inimeste arv on v√µrdne (sel juhul nimetame valimit **mitmemoodiliseks**).
## P√§riselu andmed

Kui anal√º√ºsime p√§riselust p√§rit andmeid, ei ole need sageli otseselt juhuslikud muutujad, selles m√µttes, et me ei tee katseid tundmatu tulemusega. N√§iteks, kui vaatleme pesapallimeeskonna liikmeid ja nende kehalisi andmeid, nagu pikkus, kaal ja vanus. Need numbrid ei ole t√§pselt juhuslikud, kuid me saame siiski rakendada samu matemaatilisi kontseptsioone. N√§iteks v√µib inimeste kehakaalu j√§rjestust pidada v√§√§rtuste j√§rjestuseks, mis on v√µetud mingist juhuslikust muutujast. Allpool on reaalsed pesapallim√§ngijate kaalud [Major League Baseball](http://mlb.mlb.com/index.jsp) liigast, v√µetud [sellest andmestikust](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) (mugavuse huvides on n√§idatud ainult esimesed 20 v√§√§rtust):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **M√§rkus**: Selle andmestikuga t√∂√∂tamise n√§idet n√§ete [kaasnevas m√§rkmikus](notebook.ipynb). Selles √µppet√ºkis on ka mitmeid v√§ljakutseid, mida saate t√§ita, lisades m√§rkmikusse koodi. Kui te ei ole kindel, kuidas andmetega t√∂√∂tada, √§rge muretsege - p√∂√∂rdume hiljem Pythoniga t√∂√∂tamise juurde tagasi. Kui te ei tea, kuidas Jupyter Notebookis koodi k√§ivitada, vaadake [seda artiklit](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

Siin on kastdiagramm, mis n√§itab meie andmete keskmist, mediaani ja kvartiile:

![Kaalude kastdiagramm](../../../../translated_images/et/weight-boxplot.1dbab1c03af26f8a008fff4e17680082c8ab147d6df646cbac440bbf8f5b9c42.png)

Kuna meie andmed sisaldavad teavet erinevate m√§ngijate **rollide** kohta, saame teha kastdiagrammi ka rolli j√§rgi - see v√µimaldab meil saada aimu, kuidas parameetrite v√§√§rtused rollide l√µikes erinevad. Seekord vaatleme pikkust:

![Kastdiagramm rolli j√§rgi](../../../../translated_images/et/boxplot_byrole.036b27a1c3f52d42f66fba2324ec5cde0a1bca6a01a619eeb0ce7cd054b2527b.png)

See diagramm viitab sellele, et esimese baasi m√§ngijate keskmine pikkus on suurem kui teise baasi m√§ngijate keskmine pikkus. Hiljem selles √µppet√ºkis √µpime, kuidas saame seda h√ºpoteesi formaalsemalt testida ja kuidas n√§idata, et meie andmed on statistiliselt olulised selle t√µestamiseks.

> P√§riselu andmetega t√∂√∂tades eeldame, et k√µik andmepunktid on valimid, mis on v√µetud mingist t√µen√§osusjaotusest. See eeldus v√µimaldab meil rakendada masin√µppe tehnikaid ja luua toimivaid ennustusmudeleid.

Et n√§ha, milline on meie andmete jaotus, saame joonistada graafiku, mida nimetatakse **histogrammiks**. X-telg sisaldab erinevate kaalude vahemikke (nn **binne**) ja vertikaaltelg n√§itab, mitu korda meie juhusliku muutuja valim oli antud vahemikus.

![P√§riselu andmete histogramm](../../../../translated_images/et/weight-histogram.bfd00caf7fc30b145b21e862dba7def41c75635d5280de25d840dd7f0b00545e.png)

Sellest histogrammist n√§ete, et k√µik v√§√§rtused koonduvad teatud keskmise kaalu √ºmber ja mida kaugemale me sellest kaalust l√§heme, seda v√§hem esineb selle v√§√§rtusega kaale. St, on v√§ga ebat√µen√§oline, et pesapallim√§ngija kaal erineb oluliselt keskmisest kaalust. Kaalude dispersioon n√§itab, mil m√§√§ral kaalud t√µen√§oliselt keskmisest erinevad.

> Kui v√µtame teiste inimeste, mitte pesapalliliiga m√§ngijate, kaalud, on jaotus t√µen√§oliselt erinev. Kuid jaotuse kuju j√§√§b samaks, kuid keskmine ja dispersioon muutuvad. Seega, kui treenime oma mudelit pesapallim√§ngijate peal, on t√µen√§oline, et see annab valesid tulemusi, kui rakendame seda √ºlikooli tudengite peal, kuna aluseks olev jaotus on erinev.
## Normaaljaotus

Kaalude jaotus, mida me eespool n√§gime, on v√§ga t√º√ºpiline ja paljud reaalsed m√µ√µtmised j√§rgivad sama t√º√ºpi jaotust, kuid erineva keskmise ja dispersiooniga. Seda jaotust nimetatakse **normaaljaotuseks** ja see m√§ngib statistikas v√§ga olulist rolli.

Normaaljaotuse kasutamine on √µige viis potentsiaalsete pesapallim√§ngijate juhuslike kaalude genereerimiseks. Kui me teame keskmist kaalu `mean` ja standardh√§lvet `std`, saame genereerida 1000 kaaluvalimit j√§rgmiselt:
```python
samples = np.random.normal(mean,std,1000)
``` 

Kui joonistame genereeritud valimite histogrammi, n√§eme pilti, mis on v√§ga sarnane √ºlaltoodud pildiga. Ja kui suurendame valimite arvu ja binide arvu, saame genereerida normaaljaotuse graafiku, mis on ideaalile l√§hemal:

![Normaaljaotus keskmisega=0 ja standardh√§lbega=1](../../../../translated_images/et/normal-histogram.dfae0d67c202137d552d0015fb87581eca263925e512404f3c12d8885315432e.png)

*Normaaljaotus keskmisega=0 ja standardh√§lbega=1*

## Usaldusvahemikud

Kui r√§√§gime pesapallim√§ngijate kaaludest, eeldame, et on olemas teatud **juhuslik muutuja W**, mis vastab k√µigi pesapallim√§ngijate ideaalile t√µen√§osusjaotuses (nn **populatsioon**). Meie kaalude j√§rjestus vastab k√µigi pesapallim√§ngijate alamhulgale, mida me nimetame **valimiks**. Huvitav k√ºsimus on, kas me saame teada W jaotuse parameetreid, st populatsiooni keskmist ja dispersiooni?

Lihtsaim vastus oleks arvutada meie valimi keskmine ja dispersioon. Kuid v√µib juhtuda, et meie juhuslik valim ei esinda t√§pselt kogu populatsiooni. Seega on m√µistlik r√§√§kida **usaldusvahemikust**.

> **Usaldusvahemik** on hinnang populatsiooni tegelikule keskmisele, mis p√µhineb meie valimil ja on teatud t√µen√§osusega (v√µi **usaldustasemega**) t√§pne.

Oletame, et meil on valim X<sub>1</sub>, ..., X<sub>n</sub> meie jaotusest. Iga kord, kui v√µtame oma jaotusest valimi, j√µuame erineva keskmise v√§√§rtuseni &mu;. Seega v√µib &mu;d pidada juhuslikuks muutujaks. **Usaldusvahemik** usaldustasemega p on v√§√§rtuste paar (L<sub>p</sub>,R<sub>p</sub>), nii et **P**(L<sub>p</sub>&leq;&mu;&leq;R<sub>p</sub>) = p, st t√µen√§osus, et m√µ√µdetud keskmine v√§√§rtus j√§√§b vahemikku, on p.

See l√§heb kaugemale meie l√ºhikesest sissejuhatusest, et arutada √ºksikasjalikult, kuidas neid usaldusvahemikke arvutatakse. Rohkem √ºksikasju leiate [Wikipediast](https://en.wikipedia.org/wiki/Confidence_interval). L√ºhidalt √∂eldes m√§√§ratleme arvutatud valimi keskmise ja populatsiooni tegeliku keskmise jaotuse, mida nimetatakse **studenti jaotuseks**.
> **Huvitav fakt**: Student'i jaotus on nime saanud matemaatiku William Sealy Gosset'i j√§rgi, kes avaldas oma artikli pseudon√º√ºmi "Student" all. Ta t√∂√∂tas Guinnessi √µlletehases ja √ºhe versiooni kohaselt ei soovinud tema t√∂√∂andja, et √ºldsus teaks, et nad kasutasid statistilisi teste tooraine kvaliteedi m√§√§ramiseks.

Kui soovime hinnata oma populatsiooni keskmist &mu; kindlustundega p, peame v√µtma *(1-p)/2-nda protsentiili* Student'i jaotusest A, mida saab kas tabelitest v√µi arvutada statistikatarkvara (nt Python, R jne) sisseehitatud funktsioonide abil. Seej√§rel oleks &mu; intervall antud kujul X&pm;A*D/&radic;n, kus X on saadud valimi keskmine ja D on standardh√§lve.

> **M√§rkus**: J√§tame siinkohal v√§lja olulise m√µiste [vabadusastmed](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)), mis on Student'i jaotuse kontekstis t√§htis. Selle m√µiste s√ºgavamaks m√µistmiseks v√µite viidata p√µhjalikumatele statistikaraamatutele.

N√§ide kehakaalu ja pikkuse usaldusintervalli arvutamisest on toodud [kaasnevates m√§rkmikes](notebook.ipynb).

| p | Kehakaalu keskmine |
|-----|------------------|
| 0.85 | 201.73¬±0.94     |
| 0.90 | 201.73¬±1.08     |
| 0.95 | 201.73¬±1.28     |

Pange t√§hele, et mida suurem on usaldusv√§√§rsuse t√µen√§osus, seda laiem on usaldusintervall.

## H√ºpoteeside testimine

Meie pesapallurite andmestikus on erinevad m√§ngijarollid, mida saab kokku v√µtta allj√§rgnevalt (vaadake [kaasnevat m√§rkmikku](notebook.ipynb), et n√§ha, kuidas see tabel arvutatakse):

| Roll | Pikkus | Kehakaal | Arv |
|------|--------|----------|-----|
| P√º√ºdja | 72.723684 | 204.328947 | 76  |
| M√§√§ratud l√∂√∂ja | 74.222222 | 220.888889 | 18  |
| Esimene baasimees | 74.000000 | 213.109091 | 55  |
| V√§ljakum√§ngija | 73.010309 | 199.113402 | 194 |
| Vahetusviskaja | 74.374603 | 203.517460 | 315 |
| Teine baasimees | 71.362069 | 184.344828 | 58  |
| L√ºhim√§ngija | 71.903846 | 182.923077 | 52  |
| Algviskaja | 74.719457 | 205.163636 | 221 |
| Kolmas baasimees | 73.044444 | 200.955556 | 45  |

V√µime m√§rgata, et esimeste baasimeeste keskmine pikkus on suurem kui teiste baasimeeste oma. Seega v√µime kiusatuses j√§reldada, et **esimesed baasimehed on pikemad kui teised baasimehed**.

> Seda v√§idet nimetatakse **h√ºpoteesiks**, kuna me ei tea, kas see fakt tegelikult t√µene on.

Siiski ei ole alati ilmne, kas saame sellise j√§relduse teha. √úlaltoodud arutelust teame, et igal keskmisel on seotud usaldusintervall, mist√µttu v√µib see erinevus olla lihtsalt statistiline viga. Vajame formaalsemat viisi h√ºpoteesi testimiseks.

Arvutame usaldusintervallid eraldi esimeste ja teiste baasimeeste pikkuste jaoks:

| Usaldusv√§√§rsus | Esimesed baasimehed | Teised baasimehed |
|----------------|---------------------|-------------------|
| 0.85           | 73.62..74.38       | 71.04..71.69      |
| 0.90           | 73.56..74.44       | 70.99..71.73      |
| 0.95           | 73.47..74.53       | 70.92..71.81      |

N√§eme, et √ºhegi usaldusv√§√§rsuse korral intervallid ei kattu. See t√µestab meie h√ºpoteesi, et esimesed baasimehed on pikemad kui teised baasimehed.

Formaalsemalt lahendame probleemi, et n√§ha, kas **kaks t√µen√§osusjaotust on samad** v√µi v√§hemalt samade parameetritega. S√µltuvalt jaotusest peame selleks kasutama erinevaid teste. Kui teame, et meie jaotused on normaalsed, saame rakendada **[Student'i t-testi](https://en.wikipedia.org/wiki/Student%27s_t-test)**.

Student'i t-testis arvutame nn **t-v√§√§rtuse**, mis n√§itab keskmiste erinevust, v√µttes arvesse dispersiooni. On n√§idatud, et t-v√§√§rtus j√§rgib **Student'i jaotust**, mis v√µimaldab meil saada l√§vev√§√§rtuse antud usaldustaseme **p** jaoks (seda saab arvutada v√µi leida numbrilistest tabelitest). Seej√§rel v√µrdleme t-v√§√§rtust selle l√§vega, et h√ºpoteesi kinnitada v√µi √ºmber l√ºkata.

Pythonis saame kasutada **SciPy** paketti, mis sisaldab `ttest_ind` funktsiooni (lisaks paljudele teistele kasulikele statistilistele funktsioonidele!). See arvutab meie jaoks t-v√§√§rtuse ja teeb ka vastupidise usaldustaseme p-v√§√§rtuse otsingu, nii et saame lihtsalt usaldustaseme p√µhjal j√§relduse teha.

N√§iteks meie v√µrdlus esimeste ja teiste baasimeeste pikkuste vahel annab j√§rgmised tulemused: 
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
Meie puhul on p-v√§√§rtus v√§ga madal, mis t√§hendab, et on tugevad t√µendid, mis toetavad v√§idet, et esimesed baasimehed on pikemad.

On ka mitmeid teisi h√ºpoteese, mida v√µime soovida testida, n√§iteks:
* T√µestada, et antud valim j√§rgib mingit jaotust. Meie puhul oleme eeldanud, et pikkused on normaalselt jaotatud, kuid see vajab formaalset statistilist kinnitust.
* T√µestada, et valimi keskmine v√§√§rtus vastab etteantud v√§√§rtusele.
* V√µrrelda mitme valimi keskmisi (nt milline on √µnnetaseme erinevus erinevate vanuser√ºhmade vahel).

## Suurte arvude seadus ja keskv√§√§rtusteoreem

√úks p√µhjus, miks normaaljaotus on nii oluline, on nn **keskv√§√§rtusteoreem**. Oletame, et meil on suur valim s√µltumatuid N v√§√§rtusi X<sub>1</sub>, ..., X<sub>N</sub>, mis on v√µetud mis tahes jaotusest keskmise &mu; ja dispersiooniga &sigma;<sup>2</sup>. Siis, piisavalt suure N korral (teisis√µnu, kui N&rarr;&infin;), on keskmine &Sigma;<sub>i</sub>X<sub>i</sub> normaalselt jaotatud, keskmise &mu; ja dispersiooniga &sigma;<sup>2</sup>/N.

> Teine viis keskv√§√§rtusteoreemi t√µlgendamiseks on √∂elda, et s√µltumata jaotusest, kui arvutate mis tahes juhuslike v√§√§rtuste summa keskmise, j√µuate normaalse jaotuseni.

Keskv√§√§rtusteoreemist tuleneb ka see, et kui N&rarr;&infin;, siis valimi keskmise t√µen√§osus olla v√µrdne &mu; muutub 1-ks. Seda tuntakse kui **suurte arvude seadust**.

## Kovariatsioon ja korrelatsioon

√úks andmeteaduse √ºlesandeid on leida seoseid andmete vahel. √útleme, et kaks j√§rjestust **korreleeruvad**, kui nad n√§itavad sarnast k√§itumist samal ajal, st nad kas t√µusevad/langevad samaaegselt v√µi √ºks j√§rjestus t√µuseb, kui teine langeb ja vastupidi. Teisis√µnu, nende vahel n√§ib olevat mingi seos.

> Korrelatsioon ei t√§henda tingimata p√µhjuslikku seost kahe j√§rjestuse vahel; m√µnikord v√µivad m√µlemad muutujad s√µltuda mingist v√§lisest p√µhjusest v√µi v√µib see olla puhtalt juhus, et kaks j√§rjestust korreleeruvad. Kuid tugev matemaatiline korrelatsioon on hea n√§itaja, et kaks muutujat on kuidagi seotud.

Matemaatiliselt on peamine m√µiste, mis n√§itab kahe juhusliku muutuja vahelist seost, **kovariatsioon**, mida arvutatakse j√§rgmiselt: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. Arvutame m√µlema muutuja k√µrvalekalde nende keskmisest v√§√§rtusest ja seej√§rel nende k√µrvalekallete korrutise. Kui m√µlemad muutujad kalduvad koos, on korrutis alati positiivne v√§√§rtus, mis lisandub positiivsele kovariatsioonile. Kui m√µlemad muutujad kalduvad ebas√ºnkroonselt (st √ºks langeb keskmisest allapoole, kui teine t√µuseb keskmisest k√µrgemale), saame alati negatiivseid numbreid, mis lisanduvad negatiivsele kovariatsioonile. Kui k√µrvalekalded ei ole s√µltuvad, lisanduvad need ligikaudu nulliks.

Kovariatsiooni absoluutv√§√§rtus ei √ºtle meile palju korrelatsiooni suuruse kohta, kuna see s√µltub tegelike v√§√§rtuste suurusest. Selle normaliseerimiseks saame jagada kovariatsiooni m√µlema muutuja standardh√§lbega, et saada **korrelatsioon**. Hea asi on see, et korrelatsioon j√§√§b alati vahemikku [-1,1], kus 1 n√§itab tugevat positiivset korrelatsiooni v√§√§rtuste vahel, -1 tugevat negatiivset korrelatsiooni ja 0 korrelatsiooni puudumist (muutujad on s√µltumatud).

**N√§ide**: V√µime arvutada korrelatsiooni pesapallurite kehakaalu ja pikkuse vahel √ºlalmainitud andmestikust:
```python
print(np.corrcoef(weights,heights))
```
Tulemuseks saame **korrelatsioonimaatriksi**, mis n√§eb v√§lja selline:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> Korrelatsioonimaatriksit C saab arvutada mis tahes arvu sisendj√§rjestuste S<sub>1</sub>, ..., S<sub>n</sub> jaoks. C<sub>ij</sub> v√§√§rtus on korrelatsioon S<sub>i</sub> ja S<sub>j</sub> vahel ning diagonaalielemendid on alati 1 (mis on ka S<sub>i</sub> enesekorrelatsioon).

Meie puhul n√§itab v√§√§rtus 0.53, et kehakaalu ja pikkuse vahel on mingi korrelatsioon. V√µime teha ka hajuvusdiagrammi √ºhe v√§√§rtuse kohta teise vastu, et n√§ha seost visuaalselt:

![Seos kehakaalu ja pikkuse vahel](../../../../translated_images/et/weight-height-relationship.3f06bde4ca2aba9974182c4ef037ed602acd0fbbbbe2ca91cefd838a9e66bcf9.png)

> Rohkem korrelatsiooni ja kovariatsiooni n√§iteid leiate [kaasnevast m√§rkmikust](notebook.ipynb).

## Kokkuv√µte

Selles osas √µppisime:

* andmete p√µhilisi statistilisi omadusi, nagu keskmine, dispersioon, mood ja kvartiilid
* juhuslike muutujate erinevaid jaotusi, sealhulgas normaaljaotust
* kuidas leida korrelatsiooni erinevate omaduste vahel
* kuidas kasutada matemaatika ja statistika tugevat aparatuuri h√ºpoteeside t√µestamiseks
* kuidas arvutada juhusliku muutuja usaldusintervalli antud valimi p√µhjal

Kuigi see ei ole kindlasti ammendav loetelu t√µen√§osuse ja statistika teemadest, peaks see olema piisav, et anda teile hea algus selle kursuse jaoks.

## üöÄ V√§ljakutse

Kasutage m√§rkmikus olevat n√§idiskoodi, et testida j√§rgmisi h√ºpoteese:
1. Esimesed baasimehed on vanemad kui teised baasimehed.
2. Esimesed baasimehed on pikemad kui kolmandad baasimehed.
3. L√ºhim√§ngijad on pikemad kui teised baasimehed.

## [Loengu j√§rgne viktoriin](https://ff-quizzes.netlify.app/en/ds/quiz/7)

## √úlevaade ja iseseisev √µppimine

T√µen√§osus ja statistika on nii lai teema, et see v√§√§rib omaette kursust. Kui olete huvitatud teooriasse s√ºgavamalt sukeldumisest, v√µite j√§tkata lugemist m√µnest j√§rgmisest raamatust:

1. [Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/) New Yorgi √úlikoolist on koostanud suurep√§rased loengum√§rkmed [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (saadaval veebis).
1. [Peter ja Andrew Bruce. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[n√§idiskood R-is](https://github.com/andrewgbruce/statistics-for-data-scientists)].
1. [James D. Miller. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[n√§idiskood R-is](https://github.com/PacktPublishing/Statistics-for-Data-Science)].

## √úlesanne

[V√§ike diabeediuuring](assignment.md)

## Autorid

Selle √µppetunni on koostanud ‚ô•Ô∏è [Dmitry Soshnikov](http://soshnikov.com).

---

**Vastutusest loobumine**:  
See dokument on t√µlgitud AI t√µlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi p√º√ºame tagada t√§psust, palume arvestada, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimt√µlget. Me ei vastuta arusaamatuste v√µi valesti t√µlgenduste eest, mis v√µivad tuleneda selle t√µlke kasutamisest.