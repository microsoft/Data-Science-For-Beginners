<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "58860ce9a4b8a564003d2752f7c72851",
  "translation_date": "2025-10-11T15:39:35+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "et"
}
-->
# Sissejuhatus andme-eetikasse

|![ Sketchnote autorilt [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Andmeteaduse eetika - _Sketchnote autorilt [@nitya](https://twitter.com/nitya)_ |

---

Me k√µik oleme andmekodanikud, kes elavad andmestunud maailmas.

Turutrendid n√§itavad, et aastaks 2022 hakkab iga kolmas suurorganisatsioon ostma ja m√º√ºma oma andmeid veebip√µhiste [turgude ja vahetusplatvormide](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/) kaudu. **Rakenduste arendajatena** muutub andmep√µhiste teadmiste ja algoritmip√µhise automatiseerimise integreerimine igap√§evastesse kasutajakogemustesse lihtsamaks ja odavamaks. Kuid kuna tehisintellekt muutub k√µikjalolevaks, peame m√µistma ka v√µimalikke kahjusid, mida p√µhjustab selliste algoritmide [relvastamine](https://www.youtube.com/watch?v=TQHs8SA1qpk) suurel skaalal.

Trendid viitavad sellele, et aastaks 2025 loome ja tarbime √ºle [180 zettabaidi](https://www.statista.com/statistics/871513/worldwide-data-created/) andmeid. **Andmeteadlastele** pakub see andmeplahvatus enneolematut juurdep√§√§su isiku- ja k√§itumisandmetele. Sellega kaasneb v√µime luua √ºksikasjalikke kasutajaprofiile ja m√µjutada otsuste tegemist peenelt‚Äîtihti viisil, mis tekitab [vaba valiku illusiooni](https://www.datasciencecentral.com/the-pareto-set-and-the-paradox-of-choice/). Kuigi seda saab kasutada kasutajate suunamiseks eelistatud tulemusteni, t√µstatab see ka olulisi k√ºsimusi andmete privaatsuse, autonoomia ja algoritmilise m√µju eetiliste piiride kohta.

Andme-eetika on n√º√ºd _vajalikud kaitsepiirded_ andmeteaduse ja inseneeria jaoks, aidates meil minimeerida v√µimalikke kahjusid ja soovimatuid tagaj√§rgi, mis tulenevad meie andmep√µhistest tegevustest. [Gartneri tehisintellekti hype-ts√ºkkel](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) toob esile digitaalse eetika, vastutustundliku AI ja AI juhtimise kui olulised suundumused, mis juhivad suuremaid megatrende, nagu tehisintellekti _demokratiseerimine_ ja _industrialiseerimine_.

![Gartneri tehisintellekti hype-ts√ºkkel - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

Selles √µppet√ºkis uurime p√µnevat andme-eetika valdkonda‚Äîalates p√µhikontseptsioonidest ja v√§ljakutsetest kuni juhtumiuuringute ja rakendatud AI kontseptsioonideni, nagu juhtimine‚Äîmis aitavad luua eetika kultuuri meeskondades ja organisatsioonides, mis t√∂√∂tavad andmete ja tehisintellektiga.




## [Loengu-eelne viktoriin](https://ff-quizzes.netlify.app/en/ds/quiz/2) üéØ

## P√µhim√µisted

Alustame p√µhiterminoloogia m√µistmisest.

S√µna "eetika" p√§rineb [kreeka s√µnast "ethikos"](https://en.wikipedia.org/wiki/Ethics) (ja selle juurest "ethos"), mis t√§hendab _iseloomu v√µi moraalset olemust_.

**Eetika** k√§sitleb jagatud v√§√§rtusi ja moraalseid p√µhim√µtteid, mis juhivad meie k√§itumist √ºhiskonnas. Eetika ei p√µhine seadustel, vaid laialdaselt aktsepteeritud normidel selle kohta, mis on "√µige vs. vale". Siiski v√µivad eetilised kaalutlused m√µjutada ettev√µtte juhtimisalgatusi ja valitsuse regulatsioone, mis loovad rohkem stiimuleid vastavuse tagamiseks.

**Andme-eetika** on [uus eetika haru](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1), mis "uurib ja hindab moraalseid probleeme, mis on seotud _andmete, algoritmide ja vastavate praktikatega_". Siin keskendub **"andmed"** tegevustele, mis on seotud andmete loomise, salvestamise, kureerimise, t√∂√∂tlemise, levitamise, jagamise ja kasutamisega, **"algoritmid"** keskenduvad tehisintellektile, agentidele, masin√µppele ja robotitele ning **"praktikad"** keskenduvad teemadele nagu vastutustundlik innovatsioon, programmeerimine, h√§kkimine ja eetika koodid.

**Rakenduseetika** on [moraalsete kaalutluste praktiline rakendamine](https://en.wikipedia.org/wiki/Applied_ethics). See on protsess, kus aktiivselt uuritakse eetilisi k√ºsimusi _reaalse maailma tegevuste, toodete ja protsesside_ kontekstis ning v√µetakse parandusmeetmeid, et need j√§√§ksid koosk√µlla meie m√§√§ratletud eetiliste v√§√§rtustega.

**Eetika kultuur** k√§sitleb [_rakenduseetika operationaliseerimist_](https://hbr.org/2019/05/how-to-design-an-ethical-organization), et tagada, et meie eetilised p√µhim√µtted ja praktikad v√µetakse kasutusele j√§rjepidevalt ja skaleeritavalt kogu organisatsioonis. Edukad eetika kultuurid m√§√§ratlevad organisatsiooni√ºlesed eetilised p√µhim√µtted, pakuvad t√§hendusrikkaid stiimuleid vastavuse tagamiseks ning tugevdavad eetikanorme, julgustades ja v√µimendades soovitud k√§itumist igal organisatsiooni tasandil.


## Eetika kontseptsioonid

Selles jaotises arutame selliseid kontseptsioone nagu **jagatud v√§√§rtused** (p√µhim√µtted) ja **eetilised v√§ljakutsed** (probleemid) andme-eetika jaoks‚Äîning uurime **juhtumiuuringuid**, mis aitavad teil m√µista neid kontseptsioone reaalse maailma kontekstis.

### 1. Eetika p√µhim√µtted

Iga andme-eetika strateegia algab _eetiliste p√µhim√µtete_ m√§√§ratlemisest‚Äî"jagatud v√§√§rtustest", mis kirjeldavad vastuv√µetavat k√§itumist ja juhivad vastavuses olevaid tegevusi meie andme- ja AI-projektides. Neid saab m√§√§ratleda individuaalsel v√µi meeskonna tasandil. Kuid enamik suuri organisatsioone m√§√§ratleb need _eetilise AI_ missioonilause v√µi raamistikuna, mis on m√§√§ratletud korporatiivsel tasandil ja rakendatud j√§rjepidevalt k√µigis meeskondades.

**N√§ide:** Microsofti [Vastutustundliku AI](https://www.microsoft.com/en-us/ai/responsible-ai) missioonilause k√µlab: _"Me oleme p√ºhendunud AI edendamisele eetiliste p√µhim√µtete alusel, mis asetavad inimesed esikohale"_‚Äîtuvastades 6 eetilist p√µhim√µtet allolevas raamistikus:

![Vastutustundlik AI Microsoftis](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

Vaatame l√ºhidalt neid p√µhim√µtteid. _L√§bipaistvus_ ja _vastutus_ on p√µhiv√§√§rtused, millele teised p√µhim√µtted tuginevad‚Äîalustame neist:

* [**Vastutus**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) teeb praktikud _vastutavaks_ nende andme- ja AI-tegevuste eest ning vastavuse eest nendele eetilistele p√µhim√µtetele.
* [**L√§bipaistvus**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) tagab, et andme- ja AI-tegevused on _arusaadavad_ (t√µlgendatavad) kasutajatele, selgitades otsuste taga olevat "mida" ja "miks".
* [**√ïiglus**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) keskendub sellele, et AI kohtleks _k√µiki inimesi_ √µiglaselt, lahendades s√ºsteemseid v√µi varjatud sotsiaal-tehnilisi eelarvamusi andmetes ja s√ºsteemides.
* [**Usaldusv√§√§rsus ja ohutus**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) tagab, et AI k√§itub _j√§rjekindlalt_ m√§√§ratletud v√§√§rtustega, minimeerides v√µimalikke kahjusid v√µi soovimatuid tagaj√§rgi.
* [**Privaatsus ja turvalisus**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) k√§sitleb andmete p√§ritolu m√µistmist ja kasutajatele _andmeprivaatsuse ja sellega seotud kaitsete_ pakkumist.
* [**Kaasatus**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) keskendub AI lahenduste kavandamisele eesm√§rgiga kohandada neid _laiade inimvajaduste ja -v√µimaluste_ rahuldamiseks.

> üö® M√µelge, milline v√µiks olla teie andme-eetika missioonilause. Uurige teiste organisatsioonide eetilise AI raamistikke‚Äîsiin on n√§ited [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles) ja [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Millised jagatud v√§√§rtused neil on √ºhiselt? Kuidas need p√µhim√µtted seostuvad AI toodete v√µi t√∂√∂stusharuga, milles nad tegutsevad?

### 2. Eetilised v√§ljakutsed

Kui eetilised p√µhim√µtted on m√§√§ratletud, on j√§rgmine samm hinnata meie andme- ja AI-tegevusi, et n√§ha, kas need vastavad neile jagatud v√§√§rtustele. M√µelge oma tegevustele kahes kategoorias: _andmete kogumine_ ja _algoritmide kujundamine_.

Andmete kogumisega seotud tegevused h√µlmavad t√µen√§oliselt **isikuandmeid** v√µi isikut tuvastavat teavet (PII) tuvastatavate elavate isikute kohta. See h√µlmab [mitmekesiseid mitteisiklikke andmeid](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en), mis _koos_ tuvastavad isiku. Eetilised v√§ljakutsed v√µivad olla seotud _andmete privaatsuse_, _andmete omandi√µiguse_ ja seotud teemadega, nagu _teadlik n√µusolek_ ja _intellektuaalomandi √µigused_ kasutajatele.

Algoritmide kujundamisega seotud tegevused h√µlmavad **andmekogumite** kogumist ja kureerimist ning nende kasutamist **andmemudelite** treenimiseks ja juurutamiseks, mis ennustavad tulemusi v√µi automatiseerivad otsuseid reaalses maailmas. Eetilised v√§ljakutsed v√µivad tekkida _andmekogumi eelarvamustest_, _andmete kvaliteedi_ probleemidest, _eba√µiglusest_ ja _valest esitusest_ algoritmides‚Äîsealhulgas m√µned probleemid, mis on s√ºsteemsed.

M√µlemal juhul toovad eetilised v√§ljakutsed esile valdkonnad, kus meie tegevused v√µivad olla vastuolus meie jagatud v√§√§rtustega. Nende probleemide tuvastamiseks, leevendamiseks, minimeerimiseks v√µi k√µrvaldamiseks peame esitama moraalseid "jah/ei" k√ºsimusi, mis on seotud meie tegevustega, ja v√µtma vajadusel parandusmeetmeid. Vaatame m√µningaid eetilisi v√§ljakutseid ja moraalseid k√ºsimusi, mida need t√µstatavad:


#### 2.1 Andmete omandi√µigus

Andmete kogumine h√µlmab sageli isikuandmeid, mis v√µivad tuvastada andmesubjekte. [Andmete omandi√µigus](https://permission.io/blog/data-ownership) k√§sitleb _kontrolli_ ja [_kasutaja √µigusi_](https://permission.io/blog/data-ownership), mis on seotud andmete loomise, t√∂√∂tlemise ja levitamisega.

Moraalsed k√ºsimused, mida peame esitama, on:
 * Kes omab andmeid? (kasutaja v√µi organisatsioon)
 * Millised √µigused on andmesubjektidel? (nt juurdep√§√§s, kustutamine, teisaldatavus)
 * Millised √µigused on organisatsioonidel? (nt pahatahtlike kasutaja√ºlevaadete parandamine)

#### 2.2 Teadlik n√µusolek

[Teadlik n√µusolek](https://legaldictionary.net/informed-consent/) m√§√§ratleb kasutajate tegevuse (nt andmete kogumine) n√µustumise _t√§ieliku arusaamisega_ asjakohastest faktidest, sealhulgas eesm√§rgist, v√µimalikest riskidest ja alternatiividest.

K√ºsimused, mida siin uurida:
 * Kas kasutaja (andmesubjekt) andis loa andmete kogumiseks ja kasutamiseks?
 * Kas kasutaja m√µistis, mis eesm√§rgil need andmed koguti?
 * Kas kasutaja m√µistis osalemisega kaasnevaid v√µimalikke riske?

#### 2.3 Intellektuaalomand

[Intellektuaalomand](https://en.wikipedia.org/wiki/Intellectual_property) viitab immateriaalsetele loomingutele, mis tulenevad inimlikust algatusest ja v√µivad _omada majanduslikku v√§√§rtust_ √ºksikisikutele v√µi ettev√µtetele.

K√ºsimused, mida siin uurida:
 * Kas kogutud andmetel oli majanduslik v√§√§rtus kasutajale v√µi ettev√µttele?
 * Kas **kasutajal** on siin intellektuaalomand?
 * Kas **organisatsioonil** on siin intellektuaalomand?
 * Kui need √µigused eksisteerivad, kuidas me neid kaitseme?

#### 2.4 Andmete privaatsus

[Andmete privaatsus](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) v√µi teabe privaatsus viitab kasutaja privaatsuse s√§ilitamisele ja kasutaja identiteedi kaitsmisele isikut tuvastava teabe osas.

K√ºsimused, mida siin uurida:
 * Kas kasutajate (isiklikud) andmed on kaitstud h√§kkimiste ja lekkimiste eest?
 * Kas kasutajate andmed on juurdep√§√§setavad ainult volitatud kasutajatele ja kontekstidele?
 * Kas kasutajate anon√º√ºmsus s√§ilib, kui andmeid jagatakse v√µi levitatakse?
 * Kas kasutaja saab anon√º√ºmsetest andmekogumitest tuvastamatuks muuta?

#### 2.5 √ïigus olla unustatud

[√ïigus olla unustatud](https://en.wikipedia.org/wiki/Right_to_be_forgotten) v√µi [√ïigus kustutamisele](https://www.gdpreu.org/right-to-be-forgotten/) pakub kasutajatele t√§iendavat isikuandmete kaitset. Eelk√µige annab see kasutajatele √µiguse taotleda isikuandmete kustutamist v√µi eemaldamist Interneti otsingutest ja muudest kohtadest, _teatud tingimustel_‚Äîv√µimaldades neile veebis uut algust, ilma et mineviku tegevusi nende vastu kasutataks.

K√ºsimused, mida siin uurida:
 * Kas s√ºsteem v√µimaldab andmesubjektidel taotleda kustutamist?
 * Kas kasutaja n√µusoleku tagasiv√µtmine peaks k√§ivitama automaatse kustutamise?
 * Kas andmeid koguti ilma n√µusolekuta v√µi ebaseaduslikult?
 * Kas me j√§rgime valitsuse regulatsioone andmete privaatsuse osas?

#### 2.6 Andmekogumi eelarvamused

Andmekogumi v√µi [kogumise eelarvamused](http://researcharticles.com/index.php/bias-in-data-collection-in-research/) k√§sitlevad _mitteesindusliku_ andmealamkogumi valimist algoritmi arendamiseks, mis v√µib luua potentsiaalset eba√µiglust tulemuste osas erinevatele gruppidele. Eelarvamuste t√º√ºbid h√µlmavad valiku- v√µi prooviv√µtueelarvamusi, vabatahtlike eelarvamusi ja instrumentaalset eelarvamust.

K√ºsimused, mida siin uurida:
 * Kas me kaasasime esindusliku andmesubjektide kogumi?
 * Kas me testisime kogutud v√µi kureeritud andmekogumit erinevate eelarvamuste osas?
 * Kas me saame avastatud eelarvamusi leevendada v√µi eemaldada?

#### 2.7 Andmete kvaliteet

[Andmete kvaliteet](https://lakefs.io/data-quality-testing/) uurib kureeritud andmekogumi kehtivust, mida kasutatakse meie algoritmide arendamiseks, kontrollides, kas tunnused ja kirjed vastavad meie AI
* Kas teave kajastab _t√§pselt_ tegelikkust?

#### 2.8 Algoritmiline √µiglus

[Algoritmiline √µiglus](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) uurib, kas algoritmi disain diskrimineerib s√ºstemaatiliselt teatud andmesubjektide alar√ºhmi, p√µhjustades [potentsiaalseid kahjusid](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) _ressursside jaotamisel_ (kus ressursid j√§etakse grupile k√§ttesaamatuks) ja _teenuse kvaliteedis_ (kus AI ei ole teatud alar√ºhmade jaoks nii t√§pne kui teiste jaoks).

K√ºsimused, mida siin uurida:
* Kas me hindasime mudeli t√§psust erinevate alar√ºhmade ja tingimuste jaoks?
* Kas me anal√º√ºsisime s√ºsteemi v√µimalike kahjude (nt stereot√º√ºbid) osas?
* Kas me saame andmeid muuta v√µi mudeleid uuesti treenida, et tuvastatud kahjusid v√§hendada?

Tutvu ressurssidega nagu [AI √µiglus kontrollnimekirjad](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA), et rohkem teada saada.

#### 2.9 Valeandmete esitamine

[Andmete vale esitamine](https://www.sciencedirect.com/topics/computer-science/misrepresentation) t√§hendab k√ºsimust, kas me edastame ausalt esitatud andmetest saadud teadmisi eksitaval viisil, et toetada soovitud narratiivi.

K√ºsimused, mida siin uurida:
* Kas me esitame puudulikke v√µi ebat√§pseid andmeid?
* Kas me visualiseerime andmeid viisil, mis viib eksitavate j√§reldusteni?
* Kas me kasutame valikulisi statistilisi meetodeid tulemuste manipuleerimiseks?
* Kas on olemas alternatiivseid selgitusi, mis v√µivad pakkuda teistsugust j√§reldust?

#### 2.10 Vaba valiku illusioon

[Vaba valiku illusioon](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) tekib siis, kui s√ºsteemi "valikuarhitektuurid" kasutavad otsustusalgoritme, et suunata inimesi eelistatud tulemuse poole, samal ajal n√§idates, et neil on valikud ja kontroll. Need [tumedad mustrid](https://www.darkpatterns.org/) v√µivad p√µhjustada kasutajatele sotsiaalset ja majanduslikku kahju. Kuna kasutajate otsused m√µjutavad k√§itumisprofiile, v√µivad need tegevused potentsiaalselt v√µimendada v√µi pikendada nende kahjude m√µju.

K√ºsimused, mida siin uurida:
* Kas kasutaja m√µistis selle valiku tegemise tagaj√§rgi?
* Kas kasutaja oli teadlik (alternatiivsetest) valikutest ja nende plussidest ja miinustest?
* Kas kasutaja saab hiljem automatiseeritud v√µi m√µjutatud valiku tagasi p√∂√∂rata?

### 3. Juhtumiuuringud

Et panna need eetilised v√§ljakutsed reaalsesse konteksti, on kasulik vaadata juhtumiuuringuid, mis toovad esile potentsiaalsed kahjud ja tagaj√§rjed √ºksikisikutele ja √ºhiskonnale, kui selliseid eetikarikkumisi eiratakse.

Siin on m√µned n√§ited:

| Eetiline v√§ljakutse | Juhtumiuuring | 
|--- |--- |
| **Teadlik n√µusolek** | 1972 - [Tuskegee s√º√ºfilise uuring](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - Aafrika-Ameerika mehed, kes osalesid uuringus, lubati tasuta arstiabi, _kuid peteti_, kuna teadlased ei teavitanud osalejaid nende diagnoosist ega ravi k√§ttesaadavusest. Paljud osalejad surid ja nende partnerid v√µi lapsed olid m√µjutatud; uuring kestis 40 aastat. | 
| **Andmete privaatsus** | 2007 - [Netflixi andmeauhind](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) pakkus teadlastele _10M anon√º√ºmset filmihinnangut 50K kliendilt_, et parandada soovitusalgoritme. Kuid teadlased suutsid anon√º√ºmseid andmeid korreleerida isikutuvastatavate andmetega _v√§lises andmebaasis_ (nt IMDb kommentaarid), mis sisuliselt "deanon√º√ºmis" m√µned Netflixi tellijad.|
| **Kogumise kallutatus** | 2013 - Bostoni linn [arendas Street Bumpi](https://www.boston.gov/transportation/street-bump), rakenduse, mis v√µimaldas kodanikel teatada teekatteaukudest, andes linnale paremaid andmeid probleemide leidmiseks ja parandamiseks. Kuid [madalama sissetulekuga inimesed omasid v√§hem autosid ja telefone](https://hbr.org/2013/04/the-hidden-biases-in-big-data), muutes nende teekatteprobleemid rakenduses n√§htamatuks. Arendajad tegid koost√∂√∂d akadeemikutega, et lahendada _v√µrdse juurdep√§√§su ja digitaalse l√µhe_ k√ºsimusi √µiglasuse tagamiseks. |
| **Algoritmiline √µiglus** | 2018 - MIT [Gender Shades Study](http://gendershades.org/overview.html) hindas soo klassifitseerimise AI toodete t√§psust, paljastades t√§psuse puuduj√§√§ke naiste ja v√§rviliste inimeste jaoks. [2019 Apple'i krediitkaart](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) n√§is pakkuvat naistele v√§hem krediiti kui meestele. M√µlemad n√§itasid algoritmilise kallutatuse probleeme, mis p√µhjustasid sotsiaal-majanduslikku kahju.|
| **Andmete vale esitamine** | 2020 - [Georgia rahvatervise osakond avaldas COVID-19 graafikud](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening), mis n√§isid eksitavat kodanikke kinnitatud juhtumite trendide osas, kasutades mitte-kronoloogilist j√§rjestust x-teljel. See illustreerib valeandmete esitamist visualiseerimise trikkide kaudu. |
| **Vaba valiku illusioon** | 2020 - √ïppe√§pp [ABCmouse maksis $10M, et lahendada FTC kaebus](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/), kus vanemad olid sunnitud maksma tellimuste eest, mida nad ei saanud t√ºhistada. See illustreerib tumedaid mustreid valikuarhitektuurides, kus kasutajad suunati potentsiaalselt kahjulike valikute poole. |
| **Andmete privaatsus ja kasutaja√µigused** | 2021 - Facebooki [andmeleke](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) paljastas 530M kasutaja andmed, mille tulemusel m√§√§rati FTC-le $5B trahv. Kuid Facebook keeldus kasutajaid lekke kohta teavitamast, rikkudes kasutaja√µigusi andmete l√§bipaistvuse ja juurdep√§√§su osas. |

Kas soovid uurida rohkem juhtumiuuringuid? Vaata neid ressursse:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - eetilised dilemmad erinevates t√∂√∂stusharudes.
* [Andmeteaduse eetika kursus](https://www.coursera.org/learn/data-science-ethics#syllabus) - olulised juhtumiuuringud.
* [Kus asjad on valesti l√§inud](https://deon.drivendata.org/examples/) - Deoni kontrollnimekiri koos n√§idetega.

> üö® M√µtle juhtumiuuringutele, mida oled n√§inud - kas oled kogenud v√µi olnud m√µjutatud sarnasest eetilisest v√§ljakutsest oma elus? Kas suudad m√µelda v√§hemalt √ºhele teisele juhtumiuuringule, mis illustreerib √ºhte eetilist v√§ljakutset, mida oleme selles osas arutanud?

## Rakendatud eetika

Oleme r√§√§kinud eetika kontseptsioonidest, v√§ljakutsetest ja juhtumiuuringutest reaalses kontekstis. Aga kuidas alustada eetiliste p√µhim√µtete ja praktikate _rakendamist_ oma projektides? Ja kuidas _operationaliseerida_ neid praktikaid parema juhtimise jaoks? Uurime m√µningaid reaalse maailma lahendusi:

### 1. Professionaalsed eetikakoodeksid

Professionaalsed eetikakoodeksid pakuvad √ºhte v√µimalust organisatsioonidele "motiveerida" liikmeid toetama nende eetilisi p√µhim√µtteid ja missioonilauseid. Koodeksid on _moraalsed juhised_ professionaalseks k√§itumiseks, aidates t√∂√∂tajatel v√µi liikmetel teha otsuseid, mis vastavad nende organisatsiooni p√µhim√µtetele. Need on ainult nii head, kui liikmete vabatahtlik j√§rgimine; siiski pakuvad paljud organisatsioonid t√§iendavaid preemiaid ja karistusi, et motiveerida liikmeid j√§rgima koodeksit.

N√§ited:
* [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) eetikakoodeks
* [Andmeteaduse Assotsiatsioon](http://datascienceassn.org/code-of-conduct.html) k√§itumiskoodeks (loodud 2013)
* [ACM eetikakoodeks ja professionaalse k√§itumise juhend](https://www.acm.org/code-of-ethics) (alates 1993)

> üö® Kas kuulud professionaalsesse inseneri- v√µi andmeteaduse organisatsiooni? Uuri nende veebisaiti, et n√§ha, kas nad m√§√§ratlevad professionaalse eetikakoodeksi. Mida see √ºtleb nende eetiliste p√µhim√µtete kohta? Kuidas nad "motiveerivad" liikmeid koodeksit j√§rgima?

### 2. Eetika kontrollnimekirjad

Kuigi professionaalsed koodeksid m√§√§ratlevad praktikutelt n√µutava _eetilise k√§itumise_, on neil [teadaolevad piirangud](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) j√µustamisel, eriti suurtes projektides. Selle asemel soovitavad paljud andmeteaduse eksperdid [kontrollnimekirju](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), mis v√µivad **√ºhendada p√µhim√µtted praktikatega** deterministlikumal ja rakendatavamal viisil.

Kontrollnimekirjad muudavad k√ºsimused "jah/ei" √ºlesanneteks, mida saab operationaliseerida, v√µimaldades neid j√§lgida osana standardsetest toote v√§ljalaske t√∂√∂voogudest.

N√§ited:
* [Deon](https://deon.drivendata.org/) - √ºldotstarbeline andmete eetika kontrollnimekiri, loodud [t√∂√∂stuse soovituste](https://deon.drivendata.org/#checklist-citations) p√µhjal koos k√§surea t√∂√∂riistaga lihtsaks integreerimiseks.
* [Privaatsuse auditi kontrollnimekiri](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - pakub √ºldist juhendit teabe k√§sitlemise praktikate kohta juriidilisest ja sotsiaalsest vaatenurgast.
* [AI √µiglus kontrollnimekiri](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - loodud AI praktikute poolt, et toetada √µigluskontrollide kasutuselev√µttu ja integreerimist AI arendusts√ºklitesse.
* [22 k√ºsimust eetika kohta andmetes ja AI-s](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - avatum raamistik, struktureeritud eetiliste probleemide esialgseks uurimiseks disaini, rakendamise ja organisatsioonilises kontekstis.

### 3. Eetika regulatsioonid

Eetika seisneb jagatud v√§√§rtuste m√§√§ratlemises ja √µige asja tegemises _vabatahtlikult_. **Vastavus** seisneb _seaduse j√§rgimises_, kui ja kus see on m√§√§ratletud. **Juhtimine** h√µlmab laiemalt k√µiki viise, kuidas organisatsioonid rakendavad eetilisi p√µhim√µtteid ja j√§rgivad kehtestatud seadusi.

T√§nap√§eval toimub juhtimine organisatsioonides kahel viisil. Esiteks seisneb see **eetiliste AI** p√µhim√µtete m√§√§ratlemises ja praktikate kehtestamises, et operationaliseerida nende kasutuselev√µttu k√µigis organisatsiooni AI-ga seotud projektides. Teiseks seisneb see k√µigi valitsuse m√§√§ratud **andmekaitse regulatsioonide** j√§rgimises piirkondades, kus organisatsioon tegutseb.

N√§ited andmekaitse ja privaatsuse regulatsioonidest:
* `1974`, [USA privaatsusseadus](https://www.justice.gov/opcl/privacy-act-1974) - reguleerib _f√∂deraalvalitsuse_ isikuandmete kogumist, kasutamist ja avalikustamist.
* `1996`, [USA tervisekindlustuse kaasaskantavuse ja vastutuse seadus (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - kaitseb isiklikke terviseandmeid.
* `1998`, [USA laste veebip√µhise privaatsuse kaitse seadus (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - kaitseb alla 13-aastaste laste andmete privaatsust.
* `2018`, [√úldine andmekaitse m√§√§rus (GDPR)](https://gdpr-info.eu/) - pakub kasutaja√µigusi, andmekaitset ja privaatsust.
* `2018`, [California tarbijate privaatsusseadus (CCPA)](https://www.oag.ca.gov/privacy/ccpa) annab tarbijatele rohkem _√µigusi_ nende (isiku)andmete √ºle.
* `2021`, Hiina [isikuandmete kaitse seadus](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) just vastu v√µetud, luues √ºhe maailma tugevaima veebip√µhise andmete privaatsuse regulatsiooni.

> üö® Euroopa Liidu m√§√§ratletud GDPR (√úldine andmekaitse m√§√§rus) j√§√§b t√§nap√§eval √ºheks m√µjukamaks andmete privaatsuse regulatsiooniks. Kas teadsite, et see m√§√§ratleb ka [8 kasutaja√µigust](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr), et kaitsta kodanike digitaalset privaatsust ja isikuandmeid? Uurige, mis need on ja miks need on olulised.

### 4. Eetika kultuur

Pange t√§hele, et j√§√§b puudu _vastavuse_ (tehes piisavalt, et t√§ita "seaduse kirja") ja [s√ºsteemsete probleemide](https://www.coursera.org/learn/data-science-ethics/home/week/4) (nagu ossifikatsioon, teabe as√ºmmeetria ja jaotuse eba√µiglus) lahendamise vahel, mis v√µivad kiirendada AI relvastamist.

Viimane n√µuab [koost√∂√∂l p√µhinevaid l√§henemisviise eetika kultuuride m√§√§ratlemiseks](https://towardsdatascience.com/why-ai-ethics-requires-a-culture-driven-approach-26f451afa29f), mis loovad emotsionaalseid sidemeid ja j√§rjepidevaid jagatud v√§√§rtusi _organisatsioonide vahel_ t√∂√∂stuses. See n√µuab rohkem [formaliseeritud andmete eetika kultuure](https://www.codeforamerica.org/news/formalizing-an-ethical-data-culture/) organisatsioonides - v√µimaldades _k√µigil_ [t√µmmata Andoni n√∂√∂ri](https://en.wikipedia.org/wiki/Andon_(manufacturing)) (et t√µstatada eetilisi probleeme varakult protsessis) ja muutes _eetilised hinnangud_ (nt v√§rbamisel) AI projektide meeskonna moodustamise p√µhikriteeriumiks.

---
## [Loengu j√§rgne viktoriin](https://ff-quizzes.netlify.app/en/ds/quiz/3) üéØ
## √úlevaade ja iseseisev √µpe

Kursused ja raamatud aitavad m√µista eetika p√µhikontseptsioone ja v√§ljakutseid, samas kui juhtumiuuringud ja t√∂√∂riistad aitavad rakendada eetika praktikaid reaalses kontekstis. Siin on m√µned ressursid alustamiseks.
* [Masin√µpe algajatele](https://github.com/microsoft/ML-For-Beginners/blob/main/1-Introduction/3-fairness/README.md) - Microsofti √µppetund √µiglusest.
* [Vastutustundliku tehisintellekti p√µhim√µtted](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - tasuta √µppeprogramm Microsoft Learnist.
* [Eetika ja andmeteadus](https://resources.oreilly.com/examples/0636920203964) - O'Reilly e-raamat (M. Loukides, H. Mason jt.)
* [Andmeteaduse eetika](https://www.coursera.org/learn/data-science-ethics#syllabus) - veebikursus Michigani √úlikoolist.
* [Eetika lahtiseletatult](https://ethicsunwrapped.utexas.edu/case-studies) - juhtumiuuringud Texase √úlikoolist.

# √úlesanne

[Kirjuta andmeeetika juhtumiuuring](assignment.md)

---

**Lahti√ºtlus**:  
See dokument on t√µlgitud, kasutades AI t√µlketeenust [Co-op Translator](https://github.com/Azure/co-op-translator). Kuigi p√º√ºame tagada t√§psust, palume arvestada, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Algne dokument selle algkeeles tuleks lugeda autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimt√µlget. Me ei vastuta selle t√µlke kasutamisest tulenevate arusaamatuste v√µi valede t√µlgenduste eest.