{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Science nel Cloud: Il metodo \"Azure ML SDK\"\n",
    "\n",
    "## Introduzione\n",
    "\n",
    "In questo notebook, impareremo a utilizzare l'Azure ML SDK per addestrare, distribuire e consumare un modello tramite Azure ML.\n",
    "\n",
    "Prerequisiti:\n",
    "1. Hai creato un workspace di Azure ML.\n",
    "2. Hai caricato il [dataset Heart Failure](https://www.kaggle.com/andrewmvd/heart-failure-clinical-data) in Azure ML.\n",
    "3. Hai caricato questo notebook in Azure ML Studio.\n",
    "\n",
    "I prossimi passi sono:\n",
    "\n",
    "1. Creare un Esperimento in un Workspace esistente.\n",
    "2. Creare un cluster di Calcolo.\n",
    "3. Caricare il dataset.\n",
    "4. Configurare AutoML utilizzando AutoMLConfig.\n",
    "5. Eseguire l'esperimento AutoML.\n",
    "6. Esplorare i risultati e ottenere il miglior modello.\n",
    "7. Registrare il miglior modello.\n",
    "8. Distribuire il miglior modello.\n",
    "9. Consumare l'endpoint.\n",
    "\n",
    "## Importazioni specifiche per Azure Machine Learning SDK\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import AciWebservice"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inizializzare l'area di lavoro\n",
    "Inizializza un oggetto area di lavoro dalla configurazione salvata. Assicurati che il file di configurazione sia presente in .\\config.json\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creare un esperimento Azure ML\n",
    "\n",
    "Creiamo un esperimento chiamato 'aml-experiment' nello spazio di lavoro che abbiamo appena inizializzato.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "experiment_name = 'aml-experiment'\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "experiment"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creare un Cluster di Calcolo  \n",
    "Dovrai creare un [compute target](https://docs.microsoft.com/azure/machine-learning/concept-azure-machine-learning-architecture#compute-target) per la tua esecuzione AutoML.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "aml_name = \"heart-f-cluster\"\n",
    "try:\n",
    "    aml_compute = AmlCompute(ws, aml_name)\n",
    "    print('Found existing AML compute context.')\n",
    "except:\n",
    "    print('Creating new AML compute context.')\n",
    "    aml_config = AmlCompute.provisioning_configuration(vm_size = \"Standard_D2_v2\", min_nodes=1, max_nodes=3)\n",
    "    aml_compute = AmlCompute.create(ws, name = aml_name, provisioning_configuration = aml_config)\n",
    "    aml_compute.wait_for_completion(show_output = True)\n",
    "\n",
    "cts = ws.compute_targets\n",
    "compute_target = cts[aml_name]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dati\n",
    "Assicurati di aver caricato il dataset su Azure ML e che la chiave abbia lo stesso nome del dataset.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "key = 'heart-failure-records'\n",
    "dataset = ws.datasets[key]\n",
    "df = dataset.to_pandas_dataframe()\n",
    "df.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configurazione AutoML\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\": 20,\n",
    "    \"max_concurrent_iterations\": 3,\n",
    "    \"primary_metric\" : 'AUC_weighted'\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(compute_target=compute_target,\n",
    "                             task = \"classification\",\n",
    "                             training_data=dataset,\n",
    "                             label_column_name=\"DEATH_EVENT\",\n",
    "                             enable_early_stopping= True,\n",
    "                             featurization= 'auto',\n",
    "                             debug_log = \"automl_errors.log\",\n",
    "                             **automl_settings\n",
    "                            )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Esecuzione AutoML\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "remote_run = experiment.submit(automl_config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "RunDetails(remote_run).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_run, fitted_model = remote_run.get_output()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_run.get_properties()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_name = best_run.properties['model_name']\n",
    "script_file_name = 'inference/score.py'\n",
    "best_run.download_file('outputs/scoring_file_v_1_0_0.py', 'inference/score.py')\n",
    "description = \"aml heart failure project sdk\"\n",
    "model = best_run.register_model(model_name = model_name,\n",
    "                                description = description,\n",
    "                                tags = None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Distribuire il Miglior Modello\n",
    "\n",
    "Esegui il seguente codice per distribuire il miglior modello. Puoi vedere lo stato della distribuzione nel portale di Azure ML. Questo passaggio può richiedere alcuni minuti.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "inference_config = InferenceConfig(entry_script=script_file_name, environment=best_run.get_environment())\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
    "                                               memory_gb = 1,\n",
    "                                               tags = {'type': \"automl-heart-failure-prediction\"},\n",
    "                                               description = 'Sample service for AutoML Heart Failure Prediction')\n",
    "\n",
    "aci_service_name = 'automl-hf-sdk'\n",
    "aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utilizzare l'Endpoint\n",
    "Puoi aggiungere input al seguente esempio di input.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = {\n",
    "    \"data\":\n",
    "    [\n",
    "        {\n",
    "            'age': \"60\",\n",
    "            'anaemia': \"false\",\n",
    "            'creatinine_phosphokinase': \"500\",\n",
    "            'diabetes': \"false\",\n",
    "            'ejection_fraction': \"38\",\n",
    "            'high_blood_pressure': \"false\",\n",
    "            'platelets': \"260000\",\n",
    "            'serum_creatinine': \"1.40\",\n",
    "            'serum_sodium': \"137\",\n",
    "            'sex': \"false\",\n",
    "            'smoking': \"false\",\n",
    "            'time': \"130\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "test_sample = str.encode(json.dumps(data))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "response = aci_service.run(input_data=test_sample)\n",
    "response"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Disclaimer**:  \nQuesto documento è stato tradotto utilizzando il servizio di traduzione automatica [Co-op Translator](https://github.com/Azure/co-op-translator). Sebbene ci impegniamo per garantire l'accuratezza, si prega di notare che le traduzioni automatiche possono contenere errori o imprecisioni. Il documento originale nella sua lingua nativa dovrebbe essere considerato la fonte autorevole. Per informazioni critiche, si raccomanda una traduzione professionale effettuata da un traduttore umano. Non siamo responsabili per eventuali fraintendimenti o interpretazioni errate derivanti dall'uso di questa traduzione.\n"
   ]
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  },
  "coopTranslator": {
   "original_hash": "af42669556d5dc19fc4cc3866f7d2597",
   "translation_date": "2025-09-01T20:08:29+00:00",
   "source_file": "5-Data-Science-In-Cloud/19-Azure/notebook.ipynb",
   "language_code": "it"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}