<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d92f57eb110dc7f765c05cbf0f837c77",
  "translation_date": "2025-08-25T17:47:06+00:00",
  "source_file": "4-Data-Science-Lifecycle/15-analyzing/README.md",
  "language_code": "ja"
}
-->
# データサイエンスライフサイクル: 分析

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/15-Analyzing.png)|
|:---:|
| データサイエンスライフサイクル: 分析 - _スケッチノート by [@nitya](https://twitter.com/nitya)_ |

## 講義前クイズ

## [講義前クイズ](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/28)

データライフサイクルにおける分析は、データが提案された質問に答えたり、特定の問題を解決したりできることを確認するプロセスです。このステップでは、モデルがこれらの質問や問題に正しく対応しているかを確認することにも焦点を当てます。このレッスンでは、探索的データ分析（EDA）に焦点を当てます。EDAは、データ内の特徴や関係性を定義するための手法であり、モデリングの準備に役立ちます。

ここでは、[Kaggle](https://www.kaggle.com/balaka18/email-spam-classification-dataset-csv/version/1) の例のデータセットを使用して、PythonとPandasライブラリを使った適用方法を示します。このデータセットには、メール内でよく見られる単語の出現回数が含まれており、メールの送信元は匿名化されています。このディレクトリ内の [notebook](../../../../4-Data-Science-Lifecycle/15-analyzing/notebook.ipynb) を使用して一緒に進めてください。

## 探索的データ分析

ライフサイクルのキャプチャフェーズでは、データの取得と問題や質問の特定が行われますが、そのデータが最終的な結果をサポートできるかどうかはどうやって確認するのでしょうか？
データサイエンティストは、データを取得した際に以下のような質問をするかもしれません：
- この問題を解決するのに十分なデータがあるか？
- この問題に対してデータの品質は許容範囲内か？
- このデータを通じて追加の情報を発見した場合、目標を変更または再定義すべきか？

探索的データ分析は、データを理解するプロセスであり、これらの質問に答えるだけでなく、データセットを扱う上での課題を特定するのにも役立ちます。ここでは、この目的を達成するために使用されるいくつかの手法に焦点を当てます。

## データプロファイリング、記述統計、およびPandas
この問題を解決するのに十分なデータがあるかどうかをどのように評価するのでしょうか？データプロファイリングは、記述統計の手法を通じて、データセットに関する一般的な情報を要約し収集することができます。データプロファイリングは、利用可能なものを理解するのに役立ち、記述統計は、利用可能なものの量を理解するのに役立ちます。

以前のいくつかのレッスンでは、Pandasを使用して [`describe()` 関数](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) を使い、記述統計を提供しました。この関数は、数値データに対して、件数、最大値と最小値、平均、標準偏差、分位点を提供します。`describe()` 関数のような記述統計を使用することで、データの量を評価し、追加が必要かどうかを判断できます。

## サンプリングとクエリ
大規模なデータセット全体を探索するのは非常に時間がかかる作業であり、通常はコンピュータに任せる作業です。しかし、サンプリングはデータを理解するための便利なツールであり、データセットに含まれる内容やその意味をよりよく理解するのに役立ちます。サンプルを使用することで、確率や統計を適用してデータに関する一般的な結論を導き出すことができます。サンプリングするデータの量に明確なルールはありませんが、サンプリングするデータが多いほど、データに関する一般化の精度が高まることに注意してください。
Pandasには、[`sample()` 関数](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html) があり、取得したいランダムサンプルの数を引数として渡すことができます。

データの一般的なクエリは、持っているデータに関する一般的な質問や仮説に答えるのに役立ちます。サンプリングとは対照的に、クエリは特定の部分に焦点を当て、質問に答えるためのコントロールを提供します。
Pandasライブラリの [`query()` 関数](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html) を使用すると、列を選択し、取得した行を通じてデータに関する簡単な回答を得ることができます。

## 可視化を使った探索
データが完全にクリーンアップされ、分析されるのを待つ必要はありません。実際、探索中に視覚的な表現を作成することで、データ内のパターン、関係性、問題を特定するのに役立ちます。さらに、可視化はデータ管理に関与していない人々とのコミュニケーション手段を提供し、キャプチャ段階で扱われなかった追加の質問を共有し明確にする機会を提供します。[可視化に関するセクション](../../../../../../../../../3-Data-Visualization) を参照して、視覚的に探索するための一般的な方法について学んでください。

## 不整合を特定するための探索
このレッスンのすべてのトピックは、欠損値や不整合な値を特定するのに役立ちますが、Pandasはこれらをチェックするための関数を提供しています。[isna() または isnull()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.isna.html) を使用して欠損値をチェックできます。データ内のこれらの値を探索する際に重要なのは、それらがなぜそのような状態になったのかを調べることです。これにより、それらを解決するためにどのような[アクションを取るべきか](../../../../../../../../../2-Working-With-Data/08-data-preparation/notebook.ipynb) を決定するのに役立ちます。

## [講義前クイズ](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/27)

## 課題

[答えを探索する](assignment.md)

**免責事項**:  
この文書は、AI翻訳サービス [Co-op Translator](https://github.com/Azure/co-op-translator) を使用して翻訳されています。正確性を追求しておりますが、自動翻訳には誤りや不正確な部分が含まれる可能性があることをご承知ください。元の言語で記載された文書が正式な情報源とみなされるべきです。重要な情報については、専門の人間による翻訳を推奨します。この翻訳の使用に起因する誤解や誤った解釈について、当方は一切の責任を負いません。