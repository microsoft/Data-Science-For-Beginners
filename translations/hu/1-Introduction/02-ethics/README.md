<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1341f6da63d434f5ba31b08ea951b02c",
  "translation_date": "2025-09-05T17:39:53+00:00",
  "source_file": "1-Introduction/02-ethics/README.md",
  "language_code": "hu"
}
-->
# Bevezet√©s az adatetika vil√°g√°ba

|![ Sketchnote k√©sz√≠tette: [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/02-Ethics.png)|
|:---:|
| Adatelemz√©si etika - _Sketchnote k√©sz√≠tette: [@nitya](https://twitter.com/nitya)_ |

---

Mindannyian adatpolg√°rok vagyunk egy adatokkal √°tsz≈ëtt vil√°gban.

A piaci trendek azt mutatj√°k, hogy 2022-re minden harmadik nagy szervezet online [piactereken √©s adatcser√©kben](https://www.gartner.com/smarterwithgartner/gartner-top-10-trends-in-data-and-analytics-for-2020/) fog adatokat v√°s√°rolni √©s eladni. **Alkalmaz√°sfejleszt≈ëk√©nt** k√∂nnyebb√© √©s olcs√≥bb√° v√°lik az adatvez√©relt elemz√©sek √©s algoritmusvez√©relt automatiz√°ci√≥ integr√°l√°sa a mindennapi felhaszn√°l√≥i √©lm√©nyekbe. Azonban ahogy az AI egyre elterjedtebb√© v√°lik, meg kell √©rten√ºnk azokat a potenci√°lis k√°rokat is, amelyeket az ilyen algoritmusok [fegyveres alkalmaz√°sa](https://www.youtube.com/watch?v=TQHs8SA1qpk) okozhat nagy l√©pt√©kben.

A trendek azt is mutatj√°k, hogy 2025-re t√∂bb mint [180 zettab√°jtnyi](https://www.statista.com/statistics/871513/worldwide-data-created/) adatot fogunk l√©trehozni √©s fogyasztani. **Adattud√≥sk√©nt** ez p√©ld√°tlan szint≈± hozz√°f√©r√©st biztos√≠t sz√°munkra szem√©lyes adatokhoz. Ez lehet≈ëv√© teszi, hogy viselked√©si profilokat √©p√≠ts√ºnk fel a felhaszn√°l√≥kr√≥l, √©s befoly√°soljuk d√∂nt√©seiket oly m√≥don, hogy [a szabad v√°laszt√°s ill√∫zi√≥j√°t](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) kelts√ºk, mik√∂zben esetleg a sz√°munkra kedvez≈ë eredm√©nyek fel√© terelj√ºk ≈ëket. Ez sz√©lesebb k√∂r≈± k√©rd√©seket is felvet az adatv√©delemr≈ël √©s a felhaszn√°l√≥i jogok v√©delm√©r≈ël.

Az adatetika mostanra _elengedhetetlen ir√°nyelvv√©_ v√°lt az adatelemz√©s √©s m√©rn√∂ki munka ter√ºlet√©n, seg√≠tve minket abban, hogy minimaliz√°ljuk az adatvez√©relt cselekedeteinkb≈ël fakad√≥ potenci√°lis k√°rokat √©s nem sz√°nd√©kos k√∂vetkezm√©nyeket. A [Gartner AI Hype Cycle](https://www.gartner.com/smarterwithgartner/2-megatrends-dominate-the-gartner-hype-cycle-for-artificial-intelligence-2020/) az adatetika, a felel≈ës AI √©s az AI ir√°ny√≠t√°s relev√°ns trendjeit az AI _demokratiz√°l√°s√°nak_ √©s _iparos√≠t√°s√°nak_ kulcsfontoss√°g√∫ hajt√≥erejek√©nt azonos√≠tja.

![Gartner AI Hype Cycle - 2020](https://images-cdn.newscred.com/Zz1mOWJhNzlkNDA2ZTMxMWViYjRiOGFiM2IyMjQ1YmMwZQ==)

Ebben a leck√©ben az adatetika leny≈±g√∂z≈ë ter√ºlet√©t fogjuk felfedezni - az alapfogalmakt√≥l √©s kih√≠v√°sokt√≥l kezdve az esettanulm√°nyokon √©s alkalmazott AI koncepci√≥kon √°t, mint p√©ld√°ul az ir√°ny√≠t√°s -, amelyek seg√≠tenek az etikai kult√∫ra kialak√≠t√°s√°ban az adatokkal √©s AI-val foglalkoz√≥ csapatokban √©s szervezetekben.

## [El≈ëad√°s el≈ëtti kv√≠z](https://ff-quizzes.netlify.app/en/ds/quiz/2) üéØ

## Alapvet≈ë fogalmak

Kezdj√ºk az alapvet≈ë terminol√≥gia meg√©rt√©s√©vel.

Az "etika" sz√≥ a [g√∂r√∂g "ethikos"](https://en.wikipedia.org/wiki/Ethics) (√©s annak "ethos" gy√∂kere) sz√≥b√≥l sz√°rmazik, amely _jellemet vagy erk√∂lcsi term√©szetet_ jelent.

**Etika** azokr√≥l a k√∂z√∂s √©rt√©kekr≈ël √©s erk√∂lcsi elvekr≈ël sz√≥l, amelyek ir√°ny√≠tj√°k viselked√©s√ºnket a t√°rsadalomban. Az etika nem t√∂rv√©nyeken alapul, hanem sz√©les k√∂rben elfogadott norm√°kon, amelyek meghat√°rozz√°k, mi "helyes vagy helytelen". Az etikai megfontol√°sok azonban befoly√°solhatj√°k a v√°llalati ir√°ny√≠t√°si kezdem√©nyez√©seket √©s a korm√°nyzati szab√°lyoz√°sokat, amelyek t√∂bb √∂szt√∂nz≈ët teremtenek a megfelel√©sre.

**Adatetika** az etika egy [√∫j √°ga](https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0360#sec-1), amely "tanulm√°nyozza √©s √©rt√©keli az _adatokkal, algoritmusokkal √©s kapcsol√≥d√≥ gyakorlatokkal_ √∂sszef√ºgg≈ë erk√∂lcsi probl√©m√°kat". Itt az **"adatok"** az adatok l√©trehoz√°s√°val, r√∂gz√≠t√©s√©vel, gondoz√°s√°val, feldolgoz√°s√°val, terjeszt√©s√©vel, megoszt√°s√°val √©s felhaszn√°l√°s√°val kapcsolatos cselekv√©sekre √∂sszpontos√≠tanak, az **"algoritmusok"** az AI-ra, √ºgyn√∂k√∂kre, g√©pi tanul√°sra √©s robotokra, m√≠g a **"gyakorlatok"** olyan t√©m√°kra, mint a felel≈ës innov√°ci√≥, programoz√°s, hackel√©s √©s etikai k√≥dexek.

**Alkalmazott etika** az [erk√∂lcsi megfontol√°sok gyakorlati alkalmaz√°sa](https://en.wikipedia.org/wiki/Applied_ethics). Ez az etikai k√©rd√©sek akt√≠v vizsg√°lat√°nak folyamata a _val√≥s cselekv√©sek, term√©kek √©s folyamatok_ kontextus√°ban, √©s korrekci√≥s int√©zked√©sek megt√©tele annak √©rdek√©ben, hogy ezek √∂sszhangban maradjanak a meghat√°rozott etikai √©rt√©keinkkel.

**Etikai kult√∫ra** az [_alkalmazott etika m≈±k√∂dtet√©se_](https://hbr.org/2019/05/how-to-design-an-ethical-organization), amely biztos√≠tja, hogy etikai elveink √©s gyakorlataink k√∂vetkezetesen √©s sk√°l√°zhat√≥ m√≥don ker√ºljenek alkalmaz√°sra az eg√©sz szervezetben. A sikeres etikai kult√∫r√°k szervezet-szint≈± etikai elveket hat√°roznak meg, jelent≈ës √∂szt√∂nz≈ëket biztos√≠tanak a megfelel√©shez, √©s meger≈ës√≠tik az etikai norm√°kat az√°ltal, hogy √∂szt√∂nzik √©s feler≈ës√≠tik a k√≠v√°nt viselked√©seket a szervezet minden szintj√©n.

## Etikai fogalmak

Ebben a szakaszban olyan fogalmakat t√°rgyalunk, mint a **k√∂z√∂s √©rt√©kek** (elvek) √©s az **etikai kih√≠v√°sok** (probl√©m√°k) az adatetika ter√ºlet√©n - valamint **esettanulm√°nyokat** vizsg√°lunk, amelyek seg√≠tenek meg√©rteni ezeket a fogalmakat a val√≥s helyzetekben.

### 1. Etikai elvek

Minden adatetikai strat√©gia az _etikai elvek_ meghat√°roz√°s√°val kezd≈ëdik - azokkal a "k√∂z√∂s √©rt√©kekkel", amelyek le√≠rj√°k az elfogadhat√≥ viselked√©seket, √©s ir√°ny√≠tj√°k a megfelel√©si cselekv√©seket az adat- √©s AI-projektjeinkben. Ezeket egy√©ni vagy csapatszinten is meghat√°rozhatjuk. Azonban a legt√∂bb nagy szervezet ezeket egy _etikus AI_ k√ºldet√©snyilatkozatban vagy keretrendszerben hat√°rozza meg, amelyet v√°llalati szinten defini√°lnak √©s k√∂vetkezetesen √©rv√©nyes√≠tenek minden csapatn√°l.

**P√©lda:** A Microsoft [Felel≈ës AI](https://www.microsoft.com/en-us/ai/responsible-ai) k√ºldet√©snyilatkozata √≠gy sz√≥l: _"Elk√∂telezettek vagyunk az AI fejl≈ëd√©se mellett, amelyet olyan etikai elvek vez√©relnek, amelyek az embereket helyezik el≈ët√©rbe"_ - az al√°bbi keretrendszerben 6 etikai elvet azonos√≠tva:

![Felel≈ës AI a Microsoftn√°l](https://docs.microsoft.com/en-gb/azure/cognitive-services/personalizer/media/ethics-and-responsible-use/ai-values-future-computed.png)

N√©zz√ºk meg r√∂viden ezeket az elveket. A _transzparencia_ √©s az _elsz√°moltathat√≥s√°g_ alapvet≈ë √©rt√©kek, amelyekre a t√∂bbi elv √©p√ºl - kezdj√ºk ezekkel:

* [**Elsz√°moltathat√≥s√°g**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) arra √∂szt√∂nzi a szakembereket, hogy _felel≈ëss√©get v√°llaljanak_ adat- √©s AI-m≈±veleteik√©rt, valamint az etikai elvek betart√°s√°√©rt.
* [**Transzparencia**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) biztos√≠tja, hogy az adat- √©s AI-cselekv√©sek _√©rthet≈ëek_ legyenek a felhaszn√°l√≥k sz√°m√°ra, megmagyar√°zva a d√∂nt√©sek m√∂g√∂tti mit √©s mi√©rt.
* [**M√©lt√°nyoss√°g**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6) - arra √∂sszpontos√≠t, hogy az AI _minden embert_ m√©lt√°nyosan kezeljen, foglalkozva az adatokban √©s rendszerekben l√©v≈ë szisztematikus vagy implicit t√°rsadalmi-technikai torz√≠t√°sokkal.
* [**Megb√≠zhat√≥s√°g √©s biztons√°g**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - biztos√≠tja, hogy az AI _k√∂vetkezetesen_ viselkedjen a meghat√°rozott √©rt√©kekkel, minimaliz√°lva a potenci√°lis k√°rokat vagy nem sz√°nd√©kos k√∂vetkezm√©nyeket.
* [**Adatv√©delem √©s biztons√°g**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - az adatok eredet√©nek meg√©rt√©s√©r≈ël sz√≥l, √©s _adatv√©delemhez kapcsol√≥d√≥ v√©delmet_ ny√∫jt a felhaszn√°l√≥knak.
* [**Befogad√°s**](https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1:primaryr6) - az AI-megold√°sok sz√°nd√©kos tervez√©s√©r≈ël sz√≥l, amelyek _sz√©les k√∂r≈± emberi ig√©nyekhez_ √©s k√©pess√©gekhez igazodnak.

> üö® Gondolkodj el azon, hogy mi lehetne az adatetikai k√ºldet√©snyilatkozatod. Fedezd fel m√°s szervezetek etikus AI keretrendszereit - itt van n√©h√°ny p√©lda: [IBM](https://www.ibm.com/cloud/learn/ai-ethics), [Google](https://ai.google/principles), √©s [Facebook](https://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/). Milyen k√∂z√∂s √©rt√©kekkel rendelkeznek? Hogyan kapcsol√≥dnak ezek az elvek az √°ltaluk m≈±k√∂dtetett AI-term√©khez vagy ipar√°ghoz?

### 2. Etikai kih√≠v√°sok

Miut√°n meghat√°roztuk az etikai elveket, a k√∂vetkez≈ë l√©p√©s az adat- √©s AI-cselekv√©seink √©rt√©kel√©se annak √©rdek√©ben, hogy megfelelnek-e ezeknek a k√∂z√∂s √©rt√©keknek. Gondolj a cselekv√©sekre k√©t kateg√≥ri√°ban: _adatgy≈±jt√©s_ √©s _algoritmus tervez√©s_.

Az adatgy≈±jt√©s sor√°n a cselekv√©sek val√≥sz√≠n≈±leg **szem√©lyes adatokat** vagy szem√©lyesen azonos√≠that√≥ inform√°ci√≥kat (PII) √©rintenek, amelyek azonos√≠that√≥ √©l≈ë szem√©lyekre vonatkoznak. Ez mag√°ban foglalja a [k√ºl√∂nf√©le nem szem√©lyes adatokat](https://ec.europa.eu/info/law/law-topic/data-protection/reform/what-personal-data_en), amelyek _egy√ºttesen_ azonos√≠tanak egy szem√©lyt. Az etikai kih√≠v√°sok az _adatv√©delem_, _adatbirtokl√°s_ √©s kapcsol√≥d√≥ t√©m√°k, mint p√©ld√°ul _t√°j√©kozott beleegyez√©s_ √©s _szellemi tulajdonjogok_ k√∂r√© csoportosulhatnak.

Az algoritmus tervez√©s sor√°n a cselekv√©sek magukban foglalj√°k **adatk√©szletek** gy≈±jt√©s√©t √©s gondoz√°s√°t, majd ezek felhaszn√°l√°s√°t **adatmodellek** tan√≠t√°s√°ra √©s telep√≠t√©s√©re, amelyek val√≥s helyzetekben el≈ërejelz√©seket k√©sz√≠tenek vagy automatiz√°lt d√∂nt√©seket hoznak. Az etikai kih√≠v√°sok a _adatk√©szlet torz√≠t√°s√°b√≥l_, _adatmin≈ës√©gi_ probl√©m√°kb√≥l, _m√©lt√°nytalans√°gb√≥l_ √©s _f√©lrevezet√©sb≈ël_ fakadhatnak az algoritmusokban - bele√©rtve n√©h√°ny szisztematikus jelleg≈± probl√©m√°t.

Mindk√©t esetben az etikai kih√≠v√°sok olyan ter√ºleteket emelnek ki, ahol cselekv√©seink konfliktusba ker√ºlhetnek a k√∂z√∂s √©rt√©keinkkel. Az ilyen agg√°lyok √©szlel√©s√©hez, enyh√≠t√©s√©hez, minimaliz√°l√°s√°hoz vagy megsz√ºntet√©s√©hez erk√∂lcsi "igen/nem" k√©rd√©seket kell feltenn√ºnk a cselekv√©seinkkel kapcsolatban, majd sz√ºks√©g eset√©n korrekci√≥s int√©zked√©seket kell tenn√ºnk. N√©zz√ºnk meg n√©h√°ny etikai kih√≠v√°st √©s az √°ltaluk felvetett erk√∂lcsi k√©rd√©seket:

#### 2.1 Adatbirtokl√°s

Az adatgy≈±jt√©s gyakran szem√©lyes adatokat √©rint, amelyek az adat alanyait azonos√≠thatj√°k. Az [adatbirtokl√°s](https://permission.io/blog/data-ownership) az adatok l√©trehoz√°s√°val, feldolgoz√°s√°val √©s terjeszt√©s√©vel kapcsolatos _ellen≈ërz√©sr≈ël_ √©s [_felhaszn√°l√≥i jogokr√≥l_](https://permission.io/blog/data-ownership) sz√≥l.

Az erk√∂lcsi k√©rd√©sek, amelyeket fel kell tenn√ºnk:
 * Ki birtokolja az adatokat? (felhaszn√°l√≥ vagy szervezet)
 * Milyen jogai vannak az adat alanyainak? (pl. hozz√°f√©r√©s, t√∂rl√©s, hordozhat√≥s√°g)
 * Milyen jogai vannak a szervezeteknek? (pl. rosszindulat√∫ felhaszn√°l√≥i v√©lem√©nyek helyesb√≠t√©se)

#### 2.2 T√°j√©kozott beleegyez√©s

A [t√°j√©kozott beleegyez√©s](https://legaldictionary.net/informed-consent/) azt jelenti, hogy a felhaszn√°l√≥k egy cselekv√©shez (p√©ld√°ul adatgy≈±jt√©shez) _teljes k√∂r≈± t√°j√©koztat√°s_ birtok√°ban j√°rulnak hozz√°, bele√©rtve a c√©lt, a potenci√°lis kock√°zatokat √©s az alternat√≠v√°kat.

Itt felmer√ºl≈ë k√©rd√©sek:
 * A felhaszn√°l√≥ (adat alanya) enged√©lyt adott az adatok r√∂gz√≠t√©s√©re √©s felhaszn√°l√°s√°ra?
 * A felhaszn√°l√≥ meg√©rtette, hogy mi√©rt gy≈±jt√∂tt√©k az adatokat?
 * A felhaszn√°l√≥ meg√©rtette a r√©szv√©tel√©b≈ël fakad√≥ potenci√°lis kock√°zatokat?

#### 2.3 Szellemi tulajdon

A [szellemi tulajdon](https://en.wikipedia.org/wiki/Intellectual_property) az emberi kezdem√©nyez√©sb≈ël sz√°rmaz√≥ immateri√°lis alkot√°sokra utal, amelyek _gazdas√°gi √©rt√©kkel_ b√≠rhatnak egy√©nek vagy v√°llalkoz√°sok sz√°m√°ra.

Itt felmer√ºl≈ë k√©rd√©sek:
 * A gy≈±jt√∂tt adatok gazdas√°gi √©rt√©kkel b√≠rnak-e egy felhaszn√°l√≥ vagy v√°llalkoz√°s sz√°m√°ra?
 * Van-e **felhaszn√°l√≥i** szellemi tulajdonjog itt?
 * Van-e **szervezeti** szellemi tulajdonjog itt?
 * Ha ezek a jogok l√©teznek, hogyan v√©dj√ºk ≈ëket?

#### 2.4 Adatv√©delem

Az [adatv√©delem](https://www.northeastern.edu/graduate/blog/what-is-data-privacy/) vagy inform√°ci√≥s mag√°n√©let a felhaszn√°l√≥i mag√°n√©let meg≈ërz√©s√©re √©s a felhaszn√°l√≥i identit√°s v√©delm√©re vonatkozik a szem√©lyesen azonos√≠that√≥ inform√°ci√≥k tekintet√©ben.

Itt felmer√ºl≈ë k√©rd√©sek:
 * A felhaszn√°l√≥k (szem√©lyes) adatai v√©dettek-e a hackel√©s √©s sziv√°rg√°s ellen?
 * A felhaszn√°l√≥k adatai csak jogosult felhaszn√°l√≥k √©s kontextusok sz√°m√°ra hozz√°f√©rhet≈ëk-e?
 * A felhaszn√°l√≥k anonimit√°sa meg≈ërz√∂tt-e, amikor az adatokat megosztj√°k vagy terjesztik?
 * Lehet-e egy felhaszn√°l√≥t azonos√≠tani anonimiz√°lt adat√°ll
[Algorithmusok m√©lt√°nyoss√°ga](https://towardsdatascience.com/what-is-algorithm-fairness-3182e161cf9f) azt vizsg√°lja, hogy az algoritmus tervez√©se szisztematikusan diszkrimin√°l-e bizonyos adatcsoportok ellen, ami [potenci√°lis k√°rokat](https://docs.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml) okozhat az _eloszt√°sban_ (ahol er≈ëforr√°sokat tagadnak meg vagy vonnak vissza az adott csoportt√≥l) √©s a _szolg√°ltat√°s min≈ës√©g√©ben_ (ahol az AI nem olyan pontos bizonyos csoportok eset√©ben, mint m√°sokn√°l).

K√©rd√©sek, amelyeket √©rdemes megvizsg√°lni:
 * √ârt√©kelt√ºk-e a modell pontoss√°g√°t k√ºl√∂nb√∂z≈ë csoportok √©s felt√©telek eset√©ben?
 * Vizsg√°ltuk-e a rendszert potenci√°lis k√°rok (pl. sztereotipiz√°l√°s) szempontj√°b√≥l?
 * Tudjuk-e m√≥dos√≠tani az adatokat vagy √∫jratan√≠tani a modelleket az azonos√≠tott k√°rok enyh√≠t√©se √©rdek√©ben?

Fedezze fel az olyan forr√°sokat, mint az [AI m√©lt√°nyoss√°gi ellen≈ërz≈ëlist√°k](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA), hogy t√∂bbet megtudjon.

#### 2.9 F√©lrevezet√©s

[Adataz f√©lrevezet√©se](https://www.sciencedirect.com/topics/computer-science/misrepresentation) arra vonatkozik, hogy vajon ≈ëszint√©n jelentett adatokb√≥l sz√°rmaz√≥ betekint√©seket megt√©veszt≈ë m√≥don kommunik√°lunk-e egy k√≠v√°nt narrat√≠va t√°mogat√°sa √©rdek√©ben.

K√©rd√©sek, amelyeket √©rdemes megvizsg√°lni:
 * Jelent√ºnk-e hi√°nyos vagy pontatlan adatokat?
 * √ögy vizualiz√°ljuk-e az adatokat, hogy f√©lrevezet≈ë k√∂vetkeztet√©seket vonjanak le bel≈ël√ºk?
 * Haszn√°lunk-e szelekt√≠v statisztikai technik√°kat az eredm√©nyek manipul√°l√°s√°ra?
 * Vannak-e alternat√≠v magyar√°zatok, amelyek m√°s k√∂vetkeztet√©st k√≠n√°lhatnak?

#### 2.10 Szabad v√°laszt√°s
A [szabad v√°laszt√°s ill√∫zi√≥ja](https://www.datasciencecentral.com/profiles/blogs/the-illusion-of-choice) akkor fordul el≈ë, amikor a rendszer "v√°laszt√°si architekt√∫r√°i" d√∂nt√©shoz√≥ algoritmusokat haszn√°lnak arra, hogy az embereket egy prefer√°lt eredm√©ny fel√© terelj√©k, mik√∂zben l√°tsz√≥lag lehet≈ës√©geket √©s kontrollt k√≠n√°lnak nekik. Ezek a [s√∂t√©t mint√°k](https://www.darkpatterns.org/) t√°rsadalmi √©s gazdas√°gi k√°rokat okozhatnak a felhaszn√°l√≥knak. Mivel a felhaszn√°l√≥i d√∂nt√©sek hat√°ssal vannak a viselked√©si profilokra, ezek a cselekv√©sek potenci√°lisan befoly√°solj√°k a j√∂v≈ëbeli v√°laszt√°sokat, amelyek feler≈ës√≠thetik vagy kiterjeszthetik ezen k√°rok hat√°s√°t.

K√©rd√©sek, amelyeket √©rdemes megvizsg√°lni:
 * √ârtette-e a felhaszn√°l√≥ annak a v√°laszt√°snak a k√∂vetkezm√©nyeit?
 * Tudott-e a felhaszn√°l√≥ (alternat√≠v) v√°laszt√°si lehet≈ës√©gekr≈ël √©s azok el≈ënyeir≈ël √©s h√°tr√°nyair√≥l?
 * Visszaford√≠thatja-e a felhaszn√°l√≥ egy automatiz√°lt vagy befoly√°solt d√∂nt√©st k√©s≈ëbb?

### 3. Esettanulm√°nyok

Ahhoz, hogy ezeket az etikai kih√≠v√°sokat val√≥s kontextusba helyezz√ºk, √©rdemes olyan esettanulm√°nyokat megvizsg√°lni, amelyek kiemelik az egy√©nekre √©s a t√°rsadalomra gyakorolt potenci√°lis k√°rokat √©s k√∂vetkezm√©nyeket, amikor az ilyen etikai v√©ts√©geket figyelmen k√≠v√ºl hagyj√°k.

√çme n√©h√°ny p√©lda:

| Etikai kih√≠v√°s | Esettanulm√°ny  | 
|--- |--- |
| **T√°j√©kozott beleegyez√©s** | 1972 - [Tuskegee szifilisz tanulm√°ny](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) - Az afrikai-amerikai f√©rfiak, akik r√©szt vettek a tanulm√°nyban, ingyenes orvosi ell√°t√°st √≠g√©rtek, _de megt√©vesztett√©k ≈ëket_ a kutat√≥k, akik nem t√°j√©koztatt√°k ≈ëket a diagn√≥zisukr√≥l vagy a kezel√©s el√©rhet≈ës√©g√©r≈ël. Sok alany meghalt, √©s partnerek vagy gyermekek is √©rintettek voltak; a tanulm√°ny 40 √©vig tartott. | 
| **Adatv√©delem** |  2007 - A [Netflix adatd√≠j](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/) kutat√≥knak _10M anonimiz√°lt film√©rt√©kel√©st 50K √ºgyf√©lt≈ël_ biztos√≠tott, hogy jav√≠ts√°k az aj√°nl√°si algoritmusokat. Azonban a kutat√≥k k√©pesek voltak az anonimiz√°lt adatokat szem√©lyazonos√≠t√≥ adatokkal korrel√°lni _k√ºls≈ë adatb√°zisokban_ (pl. IMDb hozz√°sz√≥l√°sok) - hat√©konyan "deanonimiz√°lva" n√©h√°ny Netflix el≈ëfizet≈ët.|
| **Gy≈±jt√©si torz√≠t√°s**  | 2013 - Boston v√°rosa [kifejlesztette a Street Bump](https://www.boston.gov/transportation/street-bump) nev≈± alkalmaz√°st, amely lehet≈ëv√© tette a polg√°rok sz√°m√°ra, hogy k√°ty√∫kat jelentsenek, jobb √∫th√°l√≥zati adatokat biztos√≠tva a v√°rosnak a probl√©m√°k megtal√°l√°s√°hoz √©s jav√≠t√°s√°hoz. Azonban [az alacsonyabb j√∂vedelm≈± csoportoknak kevesebb hozz√°f√©r√©s√ºk volt aut√≥khoz √©s telefonokhoz](https://hbr.org/2013/04/the-hidden-biases-in-big-data), √≠gy az ≈ë √∫th√°l√≥zati probl√©m√°ik l√°thatatlanok maradtak az alkalmaz√°sban. A fejleszt≈ëk akad√©mikusokkal dolgoztak egy√ºtt az _egyenl≈ë hozz√°f√©r√©s √©s digit√°lis szakad√©k_ k√©rd√©seinek megold√°sa √©rdek√©ben. |
| **Algoritmusok m√©lt√°nyoss√°ga**  | 2018 - A MIT [Gender Shades Study](http://gendershades.org/overview.html) √©rt√©kelte a nemek oszt√°lyoz√°s√°ra szolg√°l√≥ AI term√©kek pontoss√°g√°t, felt√°rva a pontoss√°gi hi√°nyoss√°gokat n≈ëk √©s sz√≠nes b≈ër≈±ek eset√©ben. Egy [2019-es Apple Card](https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/) l√°tsz√≥lag kevesebb hitelt k√≠n√°lt n≈ëknek, mint f√©rfiaknak. Mindkett≈ë az algoritmikus torz√≠t√°s probl√©m√°it illusztr√°lta, amelyek t√°rsadalmi-gazdas√°gi k√°rokat okoztak.|
| **Adatok f√©lrevezet√©se** | 2020 - A [Georgia Eg√©szs√©g√ºgyi Miniszt√©rium COVID-19 grafikonokat](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) tett k√∂zz√©, amelyek l√°tsz√≥lag f√©lrevezett√©k a polg√°rokat az igazolt esetek trendjeir≈ël a nem kronol√≥giai sorrendben elhelyezett x-tengely miatt. Ez a vizualiz√°ci√≥s tr√ºkk√∂k √°ltali f√©lrevezet√©st illusztr√°lja. |
| **Szabad v√°laszt√°s ill√∫zi√≥ja** | 2020 - A tanul√°si alkalmaz√°s [ABCmouse 10M doll√°rt fizetett az FTC panasz rendez√©s√©re](https://www.washingtonpost.com/business/2020/09/04/abcmouse-10-million-ftc-settlement/), ahol a sz√ºl≈ëk nem tudt√°k lemondani az el≈ëfizet√©seket, amelyekbe belecs√∫sztak. Ez a v√°laszt√°si architekt√∫r√°k s√∂t√©t mint√°it illusztr√°lja, ahol a felhaszn√°l√≥kat potenci√°lisan k√°ros d√∂nt√©sek fel√© terelt√©k. |
| **Adatv√©delem √©s felhaszn√°l√≥i jogok** | 2021 - A Facebook [adatv√©delmi incidens](https://www.npr.org/2021/04/09/986005820/after-data-breach-exposes-530-million-facebook-says-it-will-not-notify-users) 530M felhaszn√°l√≥ adatait tette ki, ami 5B doll√°ros egyezs√©get eredm√©nyezett az FTC-vel. Azonban megtagadta a felhaszn√°l√≥k √©rtes√≠t√©s√©t az incidensr≈ël, megs√©rtve a felhaszn√°l√≥i jogokat az adat√°tl√°that√≥s√°g √©s hozz√°f√©r√©s ter√©n. |

Szeretne tov√°bbi esettanulm√°nyokat felfedezni? N√©zze meg ezeket a forr√°sokat:
* [Ethics Unwrapped](https://ethicsunwrapped.utexas.edu/case-studies) - etikai dilemm√°k k√ºl√∂nb√∂z≈ë ipar√°gakban. 
* [Data Science Ethics course](https://www.coursera.org/learn/data-science-ethics#syllabus) - m√©rf√∂ldk≈ënek sz√°m√≠t√≥ esettanulm√°nyok.
* [Where things have gone wrong](https://deon.drivendata.org/examples/) - deon ellen≈ërz≈ëlista p√©ld√°kkal.


> üö® Gondoljon azokra az esettanulm√°nyokra, amelyeket l√°tott - tapasztalt-e, vagy √©rintett√©k-e hasonl√≥ etikai kih√≠v√°sok az √©let√©ben? Tud-e legal√°bb egy m√°sik esettanulm√°nyt, amely illusztr√°lja az ebben a szakaszban t√°rgyalt etikai kih√≠v√°sok egyik√©t?

## Alkalmazott etika

Besz√©lt√ºnk az etikai fogalmakr√≥l, kih√≠v√°sokr√≥l √©s esettanulm√°nyokr√≥l val√≥s kontextusban. De hogyan kezdj√ºk el _alkalmazni_ az etikai elveket √©s gyakorlatokat a projektjeinkben? √âs hogyan _operacionaliz√°ljuk_ ezeket a gyakorlatokat a jobb ir√°ny√≠t√°s √©rdek√©ben? N√©zz√ºnk meg n√©h√°ny val√≥s megold√°st:

### 1. Szakmai k√≥dexek

A szakmai k√≥dexek egy lehet≈ës√©get k√≠n√°lnak a szervezetek sz√°m√°ra, hogy "√∂szt√∂n√∂zz√©k" tagjaikat az etikai elvek √©s k√ºldet√©snyilatkozat t√°mogat√°s√°ra. A k√≥dexek _erk√∂lcsi ir√°nymutat√°sok_ a szakmai viselked√©shez, seg√≠tve az alkalmazottakat vagy tagokat olyan d√∂nt√©sek meghozatal√°ban, amelyek √∂sszhangban vannak a szervezet elveivel. Csak annyira hat√©konyak, amennyire a tagok √∂nk√©ntes megfelel√©se; azonban sok szervezet tov√°bbi jutalmakat √©s b√ºntet√©seket k√≠n√°l a megfelel√©s √∂szt√∂nz√©s√©re.

P√©ld√°k:
 * [Oxford Munich](http://www.code-of-ethics.org/code-of-conduct/) Etikai K√≥dex
 * [Data Science Association](http://datascienceassn.org/code-of-conduct.html) Magatart√°si K√≥dex (2013-ban l√©trehozva)
 * [ACM Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) (1993 √≥ta)

> üö® Tagja-e valamilyen szakmai m√©rn√∂ki vagy adatkutat√°si szervezetnek? N√©zze meg a weboldalukat, hogy meghat√°roznak-e szakmai etikai k√≥dexet. Mit mond ez az etikai elveikr≈ël? Hogyan "√∂szt√∂nzik" a tagokat a k√≥dex k√∂vet√©s√©re?

### 2. Etikai ellen≈ërz≈ëlist√°k

M√≠g a szakmai k√≥dexek meghat√°rozz√°k a szakemberek _etikai viselked√©s√©t_, [ismert korl√°tokkal](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md) rendelkeznek a v√©grehajt√°sban, k√ºl√∂n√∂sen nagyszab√°s√∫ projektek eset√©ben. Ehelyett sok adatkutat√°si szak√©rt≈ë [ellen≈ërz≈ëlist√°kat javasol](https://resources.oreilly.com/examples/0636920203964/blob/master/of_oaths_and_checklists.md), amelyek **√∂sszekapcsolj√°k az elveket a gyakorlatokkal** determinisztikusabb √©s cselekv≈ëk√©pesebb m√≥don.

Az ellen≈ërz≈ëlist√°k a k√©rd√©seket "igen/nem" feladatokk√° alak√≠tj√°k, amelyek operacionaliz√°lhat√≥k, lehet≈ëv√© t√©ve, hogy nyomon k√∂vess√©k ≈ëket a szok√°sos term√©kkiad√°si munkafolyamatok r√©szek√©nt.

P√©ld√°k:
 * [Deon](https://deon.drivendata.org/) - √°ltal√°nos c√©l√∫ adatetikai ellen≈ërz≈ëlista, amelyet [ipar√°gi aj√°nl√°sok](https://deon.drivendata.org/#checklist-citations) alapj√°n hoztak l√©tre, parancssori eszk√∂zzel a k√∂nny≈± integr√°ci√≥ √©rdek√©ben.
 * [Adatv√©delmi audit ellen≈ërz≈ëlista](https://cyber.harvard.edu/ecommerce/privacyaudit.html) - √°ltal√°nos ir√°nymutat√°st ny√∫jt az inform√°ci√≥kezel√©si gyakorlatokhoz jogi √©s t√°rsadalmi kitetts√©g szempontj√°b√≥l.
 * [AI m√©lt√°nyoss√°gi ellen≈ërz≈ëlista](https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/) - AI szakemberek √°ltal l√©trehozva, hogy t√°mogass√°k a m√©lt√°nyoss√°gi ellen≈ërz√©sek bevezet√©s√©t √©s integr√°ci√≥j√°t az AI fejleszt√©si ciklusokba.
 * [22 k√©rd√©s az adatok √©s AI etik√°j√°r√≥l](https://medium.com/the-organization/22-questions-for-ethics-in-data-and-ai-efb68fd19429) - nyitottabb keretrendszer, amely az etikai k√©rd√©sek kezdeti felt√°r√°s√°ra van struktur√°lva a tervez√©s, megval√≥s√≠t√°s √©s szervezeti kontextusokban.

### 3. Etikai szab√°lyoz√°sok

Az etika k√∂z√∂s √©rt√©kek meghat√°roz√°s√°r√≥l √©s a helyes cselekv√©sr≈ël sz√≥l _√∂nk√©ntesen_. **Megfelel√©s** a _t√∂rv√©nyek betart√°s√°r√≥l_ sz√≥l, ha √©s ahol meghat√°rozt√°k. **Ir√°ny√≠t√°s** sz√©les k√∂rben lefedi az √∂sszes m√≥dot, ahogyan a szervezetek m≈±k√∂dnek az etikai elvek √©rv√©nyes√≠t√©se √©s a meghat√°rozott t√∂rv√©nyek betart√°sa √©rdek√©ben.

Ma az ir√°ny√≠t√°s k√©t form√°t √∂lt a szervezeteken bel√ºl. El≈ësz√∂r is, az **etikus AI** elvek meghat√°roz√°s√°r√≥l √©s a gyakorlatok l√©trehoz√°s√°r√≥l sz√≥l, amelyek t√°mogatj√°k az elfogad√°st az √∂sszes AI-val kapcsolatos projektben a szervezeten bel√ºl. M√°sodszor, az √∂sszes korm√°ny √°ltal el≈ë√≠rt **adatv√©delmi szab√°lyoz√°snak** val√≥ megfelel√©sr≈ël sz√≥l azokban a r√©gi√≥kban, ahol m≈±k√∂dik.

Adatv√©delmi √©s adatv√©delmi szab√°lyoz√°sok p√©ld√°i:

 * `1974`, [US Privacy Act](https://www.justice.gov/opcl/privacy-act-1974) - szab√°lyozza a _sz√∂vets√©gi korm√°ny_ szem√©lyes inform√°ci√≥k gy≈±jt√©s√©t, haszn√°lat√°t √©s k√∂zz√©t√©tel√©t.
 * `1996`, [US Health Insurance Portability & Accountability Act (HIPAA)](https://www.cdc.gov/phlp/publications/topic/hipaa.html) - v√©di a szem√©lyes eg√©szs√©g√ºgyi adatokat.
 * `1998`, [US Children's Online Privacy Protection Act (COPPA)](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule) - v√©di a 13 √©v alatti gyermekek adatv√©delm√©t.
 * `2018`, [General Data Protection Regulation (GDPR)](https://gdpr-info.eu/) - felhaszn√°l√≥i jogokat, adatv√©delmet √©s adatbiztons√°got biztos√≠t.
 * `2018`, [California Consumer Privacy Act (CCPA)](https://www.oag.ca.gov/privacy/ccpa) t√∂bb _jogot_ biztos√≠t a fogyaszt√≥knak a szem√©lyes adataik felett.
 * `2021`, K√≠na [Szem√©lyes Adatv√©delmi T√∂rv√©nye](https://www.reuters.com/world/china/china-passes-new-personal-data-privacy-law-take-effect-nov-1-2021-08-20/) √©ppen elfogadva, l√©trehozva az egyik leger≈ësebb online adatv√©delmi szab√°lyoz√°st vil√°gszerte.

> üö® Az Eur√≥pai Uni√≥ √°ltal meghat√°rozott GDPR (General Data Protection Regulation) ma az egyik legbefoly√°sosabb adatv√©delmi szab√°lyoz√°s. Tudta, hogy ez [8 felhaszn√°l√≥i jogot](https://www.freeprivacypolicy.com/blog/8-user-rights-gdpr) is meghat√°roz a digit√°lis adatv√©delem √©s szem√©lyes adatok v√©delme √©rdek√©ben? Tudjon meg t√∂bbet arr√≥l, hogy mik ezek, √©s mi√©rt fontosak.

### 4. Etikai kult√∫ra

Vegye figyelembe, hogy tov√°bbra is fenn√°ll egy
* [A felel≈ës mesters√©ges intelligencia alapelvei](https://docs.microsoft.com/en-us/learn/modules/responsible-ai-principles/) - ingyenes tanul√°si √∫tvonal a Microsoft Learn-t≈ël.
* [Etika √©s adattudom√°ny](https://resources.oreilly.com/examples/0636920203964) - O'Reilly EBook (M. Loukides, H. Mason √©s m√°sok)
* [Adattudom√°nyi etika](https://www.coursera.org/learn/data-science-ethics#syllabus) - online kurzus a Michigani Egyetemt≈ël.
* [Etika kibontva](https://ethicsunwrapped.utexas.edu/case-studies) - esettanulm√°nyok a Texasi Egyetemt≈ël.

# Feladat 

[√çrj egy esettanulm√°nyt az adatetik√°r√≥l](assignment.md)

---

**Felel≈ëss√©g kiz√°r√°sa**:  
Ez a dokumentum az AI ford√≠t√°si szolg√°ltat√°s, a [Co-op Translator](https://github.com/Azure/co-op-translator) seg√≠ts√©g√©vel lett leford√≠tva. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Fontos inform√°ci√≥k eset√©n javasolt professzion√°lis, emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get semmilyen f√©lre√©rt√©s√©rt vagy t√©ves √©rtelmez√©s√©rt, amely a ford√≠t√°s haszn√°lat√°b√≥l eredhet.