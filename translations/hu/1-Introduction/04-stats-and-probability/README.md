<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8bbb3fa0d4ad61384a3b4b5f7560226f",
  "translation_date": "2025-09-04T22:18:05+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "hu"
}
-->
# R√∂vid bevezet√©s a statisztik√°ba √©s val√≥sz√≠n≈±s√©gsz√°m√≠t√°sba

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| Statisztika √©s val√≥sz√≠n≈±s√©gsz√°m√≠t√°s - _Sketchnote by [@nitya](https://twitter.com/nitya)_ |

A statisztika √©s a val√≥sz√≠n≈±s√©gsz√°m√≠t√°s k√©t szorosan √∂sszef√ºgg≈ë matematikai ter√ºlet, amelyek rendk√≠v√ºl fontosak az adatelemz√©s szempontj√°b√≥l. B√°r lehets√©ges adatokkal dolgozni m√©ly matematikai ismeretek n√©lk√ºl, m√©gis hasznos, ha legal√°bb az alapfogalmakkal tiszt√°ban vagyunk. Itt egy r√∂vid bevezet≈ët ny√∫jtunk, amely seg√≠t az indul√°sban.

[![Bevezet≈ë vide√≥](../../../../1-Introduction/04-stats-and-probability/images/video-prob-and-stats.png)](https://youtu.be/Z5Zy85g4Yjw)

## [El≈ëad√°s el≈ëtti kv√≠z](https://purple-hill-04aebfb03.1.azurestaticapps.net/quiz/6)

## Val√≥sz√≠n≈±s√©g √©s v√©letlen v√°ltoz√≥k

A **val√≥sz√≠n≈±s√©g** egy 0 √©s 1 k√∂z√∂tti sz√°m, amely kifejezi, hogy egy **esem√©ny** mennyire val√≥sz√≠n≈±. √ögy defini√°ljuk, mint a pozit√≠v kimenetelek sz√°m√°nak (amelyek az esem√©nyhez vezetnek) √©s az √∂sszes lehets√©ges kimenetel sz√°m√°nak h√°nyados√°t, felt√©telezve, hogy minden kimenetel egyform√°n val√≥sz√≠n≈±. P√©ld√°ul, ha dobunk egy kock√°val, annak a val√≥sz√≠n≈±s√©ge, hogy p√°ros sz√°mot kapunk, 3/6 = 0,5.

Amikor esem√©nyekr≈ël besz√©l√ºnk, **v√©letlen v√°ltoz√≥kat** haszn√°lunk. P√©ld√°ul a v√©letlen v√°ltoz√≥, amely a kockadob√°s eredm√©ny√©t reprezent√°lja, az 1-t≈ël 6-ig terjed≈ë √©rt√©keket veheti fel. Az 1-t≈ël 6-ig terjed≈ë sz√°mok halmaz√°t **minta-t√©rnek** nevezz√ºk. Besz√©lhet√ºnk egy v√©letlen v√°ltoz√≥ adott √©rt√©ket felvev≈ë val√≥sz√≠n≈±s√©g√©r≈ël, p√©ld√°ul P(X=3)=1/6.

Az el≈ëz≈ë p√©ld√°ban szerepl≈ë v√©letlen v√°ltoz√≥t **diszkr√©tnek** nevezz√ºk, mert a minta-t√©r megsz√°ml√°lhat√≥, azaz k√ºl√∂n√°ll√≥ √©rt√©kek sorolhat√≥k fel. Vannak azonban olyan esetek, amikor a minta-t√©r egy val√≥s sz√°mokb√≥l √°ll√≥ intervallum, vagy az eg√©sz val√≥s sz√°mhalmaz. Az ilyen v√°ltoz√≥kat **folytonosnak** nevezz√ºk. J√≥ p√©lda erre a busz √©rkez√©si ideje.

## Val√≥sz√≠n≈±s√©gi eloszl√°s

Diszkr√©t v√©letlen v√°ltoz√≥k eset√©n k√∂nny≈± le√≠rni az egyes esem√©nyek val√≥sz√≠n≈±s√©g√©t egy P(X) f√ºggv√©nnyel. A minta-t√©r *S* minden egyes *s* √©rt√©k√©hez egy 0 √©s 1 k√∂z√∂tti sz√°mot rendel√ºnk, √∫gy, hogy az √∂sszes esem√©nyre vonatkoz√≥ P(X=s) √©rt√©kek √∂sszege 1 legyen.

A legismertebb diszkr√©t eloszl√°s az **egyenletes eloszl√°s**, amelyben a minta-t√©r N elemb≈ël √°ll, √©s mindegyik√ºk val√≥sz√≠n≈±s√©ge 1/N.

Folytonos v√°ltoz√≥k eset√©n nehezebb le√≠rni a val√≥sz√≠n≈±s√©gi eloszl√°st, ha az √©rt√©kek egy [a,b] intervallumb√≥l, vagy az eg√©sz val√≥s sz√°mhalmazb√≥l ‚Ñù sz√°rmaznak. Vegy√ºk p√©ld√°ul a busz √©rkez√©si idej√©t. Val√≥j√°ban egy adott √©rkez√©si id≈ëpont *t* eset√©n annak a val√≥sz√≠n≈±s√©ge, hogy a busz pontosan akkor √©rkezik, 0!

> Most m√°r tudod, hogy 0 val√≥sz√≠n≈±s√©g≈± esem√©nyek is el≈ëfordulnak, √©s nagyon gyakran! Legal√°bbis minden alkalommal, amikor a busz meg√©rkezik!

Csak arr√≥l besz√©lhet√ºnk, hogy egy v√°ltoz√≥ egy adott √©rt√©ktartom√°nyba esik, p√©ld√°ul P(t<sub>1</sub>‚â§X<t<sub>2</sub>). Ebben az esetben a val√≥sz√≠n≈±s√©gi eloszl√°st egy **s≈±r≈±s√©gf√ºggv√©ny** p(x) √≠rja le, amelyre igaz, hogy

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../1-Introduction/04-stats-and-probability/images/probability-density.png)

Az egyenletes eloszl√°s folytonos megfelel≈ëj√©t **folytonos egyenletes eloszl√°snak** nevezz√ºk, amely egy v√©ges intervallumon van defini√°lva. Annak a val√≥sz√≠n≈±s√©ge, hogy az X √©rt√©k egy l hossz√∫s√°g√∫ intervallumba esik, ar√°nyos l-lel, √©s legfeljebb 1 lehet.

Egy m√°sik fontos eloszl√°s a **norm√°lis eloszl√°s**, amelyr≈ël r√©szletesebben az al√°bbiakban lesz sz√≥.

## √Åtlag, sz√≥r√°s √©s variancia

Tegy√ºk fel, hogy egy v√©letlen v√°ltoz√≥ X n mint√°j√°t vessz√ºk: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. Az **√°tlagot** (vagy **sz√°mtani k√∂zepet**) a hagyom√°nyos m√≥don defini√°lhatjuk: (x<sub>1</sub>+x<sub>2</sub>+...+x<sub>n</sub>)/n. Ha n√∂velj√ºk a minta m√©ret√©t (azaz n‚Üí‚àû), megkapjuk az eloszl√°s √°tlag√°t (m√°s n√©ven **v√°rhat√≥ √©rt√©k√©t**). A v√°rhat√≥ √©rt√©ket **E**(x)-szel jel√∂lj√ºk.

> Kimutathat√≥, hogy b√°rmely diszkr√©t eloszl√°s eset√©n, amelynek √©rt√©kei {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} √©s megfelel≈ë val√≥sz√≠n≈±s√©gei p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, a v√°rhat√≥ √©rt√©k E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub>.

Az √©rt√©kek sz√≥r√≥d√°s√°nak meghat√°roz√°s√°hoz kisz√°m√≠thatjuk a varianci√°t: œÉ<sup>2</sup> = ‚àë(x<sub>i</sub> - Œº)<sup>2</sup>/n, ahol Œº a minta √°tlaga. A œÉ √©rt√©ket **sz√≥r√°snak**, a œÉ<sup>2</sup>-et pedig **varianci√°nak** nevezz√ºk.

## M√≥dusz, medi√°n √©s kvartilisek

Az √°tlag nem mindig ad megfelel≈ë k√©pet az "√°tlagos" √©rt√©kr≈ël. P√©ld√°ul, ha n√©h√°ny sz√©ls≈ës√©ges √©rt√©k jelent≈ësen elt√©r a t√∂bbit≈ël, ezek befoly√°solhatj√°k az √°tlagot. Egy m√°sik j√≥ mutat√≥ a **medi√°n**, amely olyan √©rt√©k, amelyn√©l az adatok fele kisebb, a m√°sik fele pedig nagyobb.

Az adatok eloszl√°s√°nak meg√©rt√©s√©hez hasznos a **kvartilisekr≈ël** besz√©lni:

* Az els≈ë kvartilis (Q1) az az √©rt√©k, amely alatt az adatok 25%-a tal√°lhat√≥.
* A harmadik kvartilis (Q3) az az √©rt√©k, amely alatt az adatok 75%-a tal√°lhat√≥.

Grafikusan a medi√°n √©s a kvartilisek kapcsolat√°t egy **dobozdiagramon** (box plot) √°br√°zolhatjuk:

<img src="images/boxplot_explanation.png" width="50%"/>

Itt kisz√°m√≠tjuk az **interkvartilis tartom√°nyt** (IQR=Q3-Q1), valamint az √∫gynevezett **kiugr√≥ √©rt√©keket** - azokat az √©rt√©keket, amelyek a [Q1-1.5*IQR, Q3+1.5*IQR] hat√°rokon k√≠v√ºl esnek.

Ha az eloszl√°s v√©ges √©s kev√©s lehets√©ges √©rt√©ket tartalmaz, egy j√≥ "tipikus" √©rt√©k az, amely a leggyakrabban fordul el≈ë, ezt nevezz√ºk **m√≥dusznak**. Ez gyakran alkalmazhat√≥ kateg√≥ri√°kra, p√©ld√°ul sz√≠nekre. Vegy√ºnk egy p√©ld√°t, ahol k√©t csoport van: az egyik a pirosat, a m√°sik a k√©ket r√©szes√≠ti el≈ënyben. Ha a sz√≠neket sz√°mokkal k√≥doljuk, az √°tlagos kedvenc sz√≠n valahol a narancs-z√∂ld spektrumban lenne, ami egyik csoport preferenci√°j√°t sem t√ºkr√∂zi. A m√≥dusz viszont vagy az egyik sz√≠n, vagy mindkett≈ë lehet, ha azonos sz√°m√∫ ember szavaz r√°juk (ebben az esetben az eloszl√°st **multimod√°lisnak** nevezz√ºk).

## Val√≥s adatok

Amikor val√≥s √©letb≈ël sz√°rmaz√≥ adatokat elemz√ºnk, azok gyakran nem tekinthet≈ëk v√©letlen v√°ltoz√≥knak abban az √©rtelemben, hogy nem ismeretlen eredm√©ny≈± k√≠s√©rletek eredm√©nyei. P√©ld√°ul vegy√ºnk egy baseballcsapatot, √©s az ≈ë testadataikat, mint p√©ld√°ul magass√°g, s√∫ly √©s √©letkor. Ezek a sz√°mok nem teljesen v√©letlenek, de ugyanazokat a matematikai fogalmakat alkalmazhatjuk r√°juk. P√©ld√°ul az emberek s√∫ly√°nak sorozata tekinthet≈ë egy v√©letlen v√°ltoz√≥b√≥l sz√°rmaz√≥ √©rt√©kek sorozat√°nak. Az al√°bbiakban a [Major League Baseball](http://mlb.mlb.com/index.jsp) j√°t√©kosainak s√∫lyadatai l√°that√≥k, amelyeket [ebb≈ël az adatb√°zisb√≥l](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) vett√ºnk (a k√∂nnyebb √©rthet≈ës√©g kedv√©√©rt csak az els≈ë 20 √©rt√©ket mutatjuk):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Megjegyz√©s**: Ha szeretn√©d l√°tni, hogyan dolgozhatsz ezzel az adathalmazzal, n√©zd meg a [kapcsol√≥d√≥ notebookot](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb). Az √≥ra sor√°n sz√°mos kih√≠v√°s is tal√°lhat√≥, amelyeket a notebookhoz k√≥d hozz√°ad√°s√°val oldhatsz meg. Ha nem vagy biztos abban, hogyan kell adatokat kezelni, ne agg√≥dj - k√©s≈ëbb visszat√©r√ºnk az adatok Pythonban t√∂rt√©n≈ë feldolgoz√°s√°ra. Ha nem tudod, hogyan futtass k√≥dot Jupyter Notebookban, olvasd el [ezt a cikket](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

Itt l√°that√≥ egy dobozdiagram, amely bemutatja az adatok √°tlag√°t, medi√°nj√°t √©s kvartilis√©t:

![S√∫ly dobozdiagram](../../../../1-Introduction/04-stats-and-probability/images/weight-boxplot.png)

Mivel adataink k√ºl√∂nb√∂z≈ë j√°t√©kos **szerepekr≈ël** tartalmaznak inform√°ci√≥t, k√©sz√≠thet√ºnk szerepek szerinti dobozdiagramot is - ez lehet≈ëv√© teszi, hogy k√©pet kapjunk arr√≥l, hogyan k√ºl√∂nb√∂znek az √©rt√©kek a szerepek k√∂z√∂tt. Ez√∫ttal a magass√°got vizsg√°ljuk:

![Dobozdiagram szerepek szerint](../../../../1-Introduction/04-stats-and-probability/images/boxplot_byrole.png)

Ez a diagram azt sugallja, hogy az els≈ë b√°zisj√°t√©kosok √°tlagos magass√°ga nagyobb, mint a m√°sodik b√°zisj√°t√©kosok√©. K√©s≈ëbb az √≥r√°n megtanuljuk, hogyan tesztelhetj√ºk ezt a hipot√©zist form√°lisabban, √©s hogyan bizony√≠thatjuk, hogy adataink statisztikailag szignifik√°nsak.

> Amikor val√≥s adatokkal dolgozunk, felt√©telezz√ºk, hogy minden adatpont egy val√≥sz√≠n≈±s√©gi eloszl√°sb√≥l sz√°rmaz√≥ minta. Ez a felt√©telez√©s lehet≈ëv√© teszi sz√°munkra, hogy g√©pi tanul√°si technik√°kat alkalmazzunk √©s m≈±k√∂d≈ë predikt√≠v modelleket √©p√≠ts√ºnk.

Adataink eloszl√°s√°nak megismer√©s√©hez k√©sz√≠thet√ºnk egy **hisztogramot**. Az X-tengely k√ºl√∂nb√∂z≈ë s√∫lyintervallumokat (√∫gynevezett **bin-eket**) tartalmaz, m√≠g a f√ºgg≈ëleges tengely azt mutatja, hogy a v√©letlen v√°ltoz√≥ mint√°ja h√°nyszor esett egy adott intervallumba.

![Val√≥s adatok hisztogramja](../../../../1-Introduction/04-stats-and-probability/images/weight-histogram.png)

Ebb≈ël a hisztogramb√≥l l√°that√≥, hogy az √∂sszes √©rt√©k egy bizonyos √°tlagos s√∫ly k√∂r√ºl koncentr√°l√≥dik, √©s min√©l t√°volabb megy√ºnk ett≈ël a s√∫lyt√≥l, ann√°l kevesebb ilyen √©rt√©k fordul el≈ë. Azaz nagyon val√≥sz√≠n≈±tlen, hogy egy baseballj√°t√©kos s√∫lya jelent≈ësen elt√©r az √°tlagt√≥l. A s√∫lyok sz√≥r√°sa azt mutatja, hogy a s√∫lyok mennyire t√©rhetnek el az √°tlagt√≥l.

> Ha m√°s emberek, p√©ld√°ul egyetemi hallgat√≥k s√∫ly√°t vizsg√°ln√°nk, az eloszl√°s val√≥sz√≠n≈±leg elt√©r≈ë lenne. Azonban az eloszl√°s alakja ugyanaz maradna, csak az √°tlag √©s a sz√≥r√°s v√°ltozna. Teh√°t, ha modell√ºnket baseballj√°t√©kosokon k√©pezz√ºk, val√≥sz√≠n≈±leg rossz eredm√©nyeket adna, ha egyetemist√°kra alkalmazn√°nk, mert az alapul szolg√°l√≥ eloszl√°s elt√©r≈ë.

## Norm√°lis eloszl√°s

A fent l√°tott s√∫lyeloszl√°s nagyon tipikus, √©s sok val√≥s m√©r√©st ugyanilyen t√≠pus√∫ eloszl√°s k√∂vet, de elt√©r≈ë √°tlaggal √©s sz√≥r√°ssal. Ezt az eloszl√°st **norm√°lis eloszl√°snak** nevezz√ºk, √©s nagyon fontos szerepet j√°tszik a statisztik√°ban.

A norm√°lis eloszl√°s helyes m√≥dja a potenci√°lis baseballj√°t√©kosok v√©letlenszer≈± s√∫lyainak gener√°l√°s√°ra. Ha ismerj√ºk az √°tlagos s√∫lyt `mean` √©s a sz√≥r√°st `std`, akkor 1000 s√∫lymint√°t gener√°lhatunk az al√°bbi m√≥don:
```python
samples = np.random.normal(mean,std,1000)
``` 

Ha a gener√°lt mint√°k hisztogramj√°t √°br√°zoljuk, nagyon hasonl√≥ k√©pet kapunk a fentiekhez. Ha n√∂velj√ºk a mint√°k √©s a bin-ek sz√°m√°t, egyre ink√°bb megk√∂zel√≠tj√ºk az ide√°lis norm√°lis eloszl√°s k√©p√©t:

![Norm√°lis eloszl√°s √°tlag=0 √©s sz√≥r√°s=1](../../../../1-Introduction/04-stats-and-probability/images/normal-histogram.png)

*Norm√°lis eloszl√°s √°tlag=0 √©s sz√≥r√°s=1*

## Konfidencia intervallumok

Amikor a baseballj√°t√©kosok s√∫ly√°r√≥l besz√©l√ºnk, felt√©telezz√ºk, hogy l√©tezik egy bizonyos **W v√©letlen v√°ltoz√≥**, amely az √∂sszes baseballj√°t√©kos s√∫ly√°nak ide√°lis val√≥sz√≠n≈±s√©gi eloszl√°s√°nak felel meg (az √∫gynevezett **popul√°ci√≥**). A s√∫lyaink sorozata az √∂sszes baseballj√°t√©kos egy r√©szhalmaz√°nak felel meg, amelyet **mint√°nak** nevez√ºnk. Egy √©rdekes k√©rd√©s az, hogy megismerhetj√ºk-e a W eloszl√°s√°nak param√©tereit, azaz a popul√°ci√≥ √°tlag√°t √©s sz√≥r√°s√°t?

A legegyszer≈±bb v√°lasz az lenne, hogy kisz√°m√≠tjuk a minta √°tlag√°t √©s sz√≥r√°s√°t. Azonban el≈ëfordulhat, hogy a v√©letlen mint√°nk nem pontosan reprezent√°lja a teljes popul√°ci√≥t. Ez√©rt van √©rtelme **konfidencia intervallumokr√≥l** besz√©lni.
> **Konfidencia intervallum** a popul√°ci√≥ val√≥di √°tlag√°nak becsl√©se a mint√°nk alapj√°n, amely egy bizonyos val√≥sz√≠n≈±s√©ggel (vagyis egy **bizonyoss√°gi szinttel**) pontos.
Tegy√ºk fel, hogy van egy mint√°nk X<sub>1</sub>, ..., X<sub>n</sub> az eloszl√°sunkb√≥l. Minden alkalommal, amikor mint√°t vesz√ºnk az eloszl√°sunkb√≥l, m√°s √°tlag√©rt√©ket, Œº-t kapunk. √çgy Œº tekinthet≈ë v√©letlen v√°ltoz√≥nak. Egy **konfidencia intervallum** p konfidenciaszinttel egy (L<sub>p</sub>,R<sub>p</sub>) √©rt√©kp√°r, amelyre **P**(L<sub>p</sub>‚â§Œº‚â§R<sub>p</sub>) = p, azaz annak val√≥sz√≠n≈±s√©ge, hogy a m√©rt √°tlag√©rt√©k az intervallumba esik, p-vel egyenl≈ë.

R√∂vid bevezet≈ënk keretein t√∫lmutat, hogy r√©szletesen t√°rgyaljuk, hogyan sz√°m√≠tj√°k ki ezeket a konfidencia intervallumokat. Tov√°bbi r√©szletek tal√°lhat√≥k [a Wikip√©di√°n](https://en.wikipedia.org/wiki/Confidence_interval). R√∂viden, meghat√°rozzuk a sz√°m√≠tott minta√°tlag eloszl√°s√°t a popul√°ci√≥ val√≥di √°tlag√°hoz viszony√≠tva, amit **Student-eloszl√°snak** neveznek.

> **√ârdekes t√©ny**: A Student-eloszl√°st William Sealy Gosset matematikusr√≥l nevezt√©k el, aki "Student" √°ln√©ven publik√°lta tanulm√°ny√°t. Gosset a Guinness s√∂rgy√°rban dolgozott, √©s az egyik verzi√≥ szerint munk√°ltat√≥ja nem akarta, hogy a nagyk√∂z√∂ns√©g tudom√°st szerezzen arr√≥l, hogy statisztikai teszteket haszn√°lnak a nyersanyagok min≈ës√©g√©nek meghat√°roz√°s√°ra.

Ha a popul√°ci√≥nk √°tlag√°t, Œº-t szeretn√©nk p konfidenciaszinttel becs√ºlni, akkor a Student-eloszl√°s *(1-p)/2-edik percentilis√©t* kell venn√ºnk, amelyet t√°bl√°zatokb√≥l vagy statisztikai szoftverek (pl. Python, R stb.) be√©p√≠tett f√ºggv√©nyeivel lehet kisz√°m√≠tani. Ekkor az Œº intervalluma X¬±A*D/‚àön lesz, ahol X a minta kapott √°tlaga, D a sz√≥r√°s.

> **Megjegyz√©s**: Nem t√°rgyaljuk r√©szletesen a [szabads√°gfokok](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)) fontos fogalm√°t, amely a Student-eloszl√°ssal kapcsolatban l√©nyeges. A statisztika √°tfog√≥bb k√∂nyveiben m√©lyebben meg√©rtheted ezt a fogalmat.

Egy p√©ld√°t a s√∫lyok √©s magass√°gok konfidencia intervallum√°nak kisz√°m√≠t√°s√°ra az [mell√©kelt jegyzetf√ºzetben](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) tal√°lhatsz.

| p    | S√∫ly √°tlaga |
|------|-------------|
| 0.85 | 201.73¬±0.94 |
| 0.90 | 201.73¬±1.08 |
| 0.95 | 201.73¬±1.28 |

Figyeld meg, hogy min√©l magasabb a konfidencia val√≥sz√≠n≈±s√©ge, ann√°l sz√©lesebb a konfidencia intervallum.

## Hipot√©zisvizsg√°lat

A baseball j√°t√©kosok adatb√°zis√°ban k√ºl√∂nb√∂z≈ë j√°t√©kos szerepek tal√°lhat√≥k, amelyeket az al√°bbi t√°bl√°zatban foglalhatunk √∂ssze (n√©zd meg az [mell√©kelt jegyzetf√ºzetet](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb), hogy l√°thatod, hogyan sz√°m√≠that√≥ ki ez a t√°bl√°zat):

| Szerep             | Magass√°g | S√∫ly   | Darabsz√°m |
|--------------------|----------|--------|-----------|
| Catcher           | 72.723684 | 204.328947 | 76        |
| Designated_Hitter | 74.222222 | 220.888889 | 18        |
| First_Baseman     | 74.000000 | 213.109091 | 55        |
| Outfielder        | 73.010309 | 199.113402 | 194       |
| Relief_Pitcher    | 74.374603 | 203.517460 | 315       |
| Second_Baseman    | 71.362069 | 184.344828 | 58        |
| Shortstop         | 71.903846 | 182.923077 | 52        |
| Starting_Pitcher  | 74.719457 | 205.163636 | 221       |
| Third_Baseman     | 73.044444 | 200.955556 | 45        |

L√°thatjuk, hogy az els≈ë b√°zisj√°t√©kosok √°tlagos magass√°ga nagyobb, mint a m√°sodik b√°zisj√°t√©kosok√©. Ez√©rt k√≠s√©rt√©sbe eshet√ºnk, hogy azt a k√∂vetkeztet√©st vonjuk le, hogy **az els≈ë b√°zisj√°t√©kosok magasabbak, mint a m√°sodik b√°zisj√°t√©kosok**.

> Ezt az √°ll√≠t√°st **hipot√©zisnek** nevezz√ºk, mert nem tudjuk, hogy a t√©ny val√≥ban igaz-e vagy sem.

Azonban nem mindig egy√©rtelm≈±, hogy levonhatjuk-e ezt a k√∂vetkeztet√©st. Az el≈ëz≈ëekben t√°rgyaltakb√≥l tudjuk, hogy minden √°tlagnak van egy hozz√° tartoz√≥ konfidencia intervalluma, √≠gy ez a k√ºl√∂nbs√©g lehet puszt√°n statisztikai hiba is. Sz√ºks√©g√ºnk van egy form√°lisabb m√≥dszerre a hipot√©zis tesztel√©s√©hez.

Sz√°m√≠tsuk ki k√ºl√∂n az els≈ë √©s m√°sodik b√°zisj√°t√©kosok magass√°g√°nak konfidencia intervallumait:

| Konfidencia | Els≈ë b√°zisj√°t√©kosok | M√°sodik b√°zisj√°t√©kosok |
|-------------|---------------------|------------------------|
| 0.85        | 73.62..74.38       | 71.04..71.69          |
| 0.90        | 73.56..74.44       | 70.99..71.73          |
| 0.95        | 73.47..74.53       | 70.92..71.81          |

L√°thatjuk, hogy egyik konfidenciaszintn√©l sem fedik √°t egym√°st az intervallumok. Ez bizony√≠tja a hipot√©zis√ºnket, hogy az els≈ë b√°zisj√°t√©kosok magasabbak, mint a m√°sodik b√°zisj√°t√©kosok.

Form√°lisabban, a probl√©ma, amit megoldunk, az annak vizsg√°lata, hogy **k√©t val√≥sz√≠n≈±s√©gi eloszl√°s azonos-e**, vagy legal√°bbis azonos param√©terekkel rendelkezik-e. Az eloszl√°st√≥l f√ºgg≈ëen k√ºl√∂nb√∂z≈ë teszteket kell alkalmaznunk. Ha tudjuk, hogy az eloszl√°saink norm√°lisak, alkalmazhatjuk a **[Student t-tesztet](https://en.wikipedia.org/wiki/Student%27s_t-test)**.

A Student t-tesztben kisz√°m√≠tjuk az √∫gynevezett **t-√©rt√©ket**, amely az √°tlagok k√∂z√∂tti k√ºl√∂nbs√©get jelzi, figyelembe v√©ve a sz√≥r√°st. Kimutatt√°k, hogy a t-√©rt√©k k√∂veti a **Student-eloszl√°st**, amely lehet≈ëv√© teszi, hogy egy adott konfidenciaszinthez **p** k√ºsz√∂b√©rt√©ket kapjunk (ez kisz√°m√≠that√≥ vagy numerikus t√°bl√°zatokb√≥l kikereshet≈ë). Ezut√°n √∂sszehasonl√≠tjuk a t-√©rt√©ket ezzel a k√ºsz√∂b√©rt√©kkel, hogy elfogadjuk vagy elutas√≠tsuk a hipot√©zist.

Pythonban haszn√°lhatjuk a **SciPy** csomagot, amely tartalmazza a `ttest_ind` f√ºggv√©nyt (sok m√°s hasznos statisztikai f√ºggv√©ny mellett!). Ez kisz√°m√≠tja nek√ºnk a t-√©rt√©ket, √©s ford√≠tottan megkeresi a konfidencia p-√©rt√©k√©t is, √≠gy egyszer≈±en a konfidenci√°t n√©zve levonhatjuk a k√∂vetkeztet√©st.

P√©ld√°ul az els≈ë √©s m√°sodik b√°zisj√°t√©kosok magass√°g√°nak √∂sszehasonl√≠t√°sa a k√∂vetkez≈ë eredm√©nyeket adja:  
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```  
```
T-value = 7.65
P-value: 9.137321189738925e-12
```  
Eset√ºnkben a p-√©rt√©k nagyon alacsony, ami azt jelenti, hogy er≈ës bizony√≠t√©k van arra, hogy az els≈ë b√°zisj√°t√©kosok magasabbak.

Tov√°bbi hipot√©zisek, amelyeket tesztelhet√ºnk:
* Annak bizony√≠t√°sa, hogy egy adott minta k√∂vet egy eloszl√°st. Eset√ºnkben felt√©telezt√ºk, hogy a magass√°gok norm√°lis eloszl√°s√∫ak, de ezt form√°lisan is igazolni kell.
* Annak bizony√≠t√°sa, hogy egy minta √°tlag√©rt√©ke megfelel egy el≈ëre meghat√°rozott √©rt√©knek.
* T√∂bb minta √°tlag√°nak √∂sszehasonl√≠t√°sa (pl. milyen k√ºl√∂nbs√©gek vannak a boldogs√°gi szintek k√∂z√∂tt k√ºl√∂nb√∂z≈ë korcsoportokban).

## Nagy sz√°mok t√∂rv√©nye √©s k√∂zponti hat√°reloszl√°s t√©tel

Az egyik ok, ami√©rt a norm√°lis eloszl√°s olyan fontos, az az √∫gynevezett **k√∂zponti hat√°reloszl√°s t√©tel**. Tegy√ºk fel, hogy van egy nagy, f√ºggetlen N √©rt√©kb≈ël √°ll√≥ mint√°nk X<sub>1</sub>, ..., X<sub>N</sub>, amely b√°rmilyen eloszl√°sb√≥l sz√°rmazik, √°tlag Œº-val √©s sz√≥r√°s œÉ<sup>2</sup>-vel. Ekkor, ha N el√©g nagy (m√°s szavakkal, amikor N‚Üí‚àû), az √°tlag Œ£<sub>i</sub>X<sub>i</sub> norm√°lis eloszl√°s√∫ lesz, √°tlag Œº-val √©s sz√≥r√°s œÉ<sup>2</sup>/N-nel.

> A k√∂zponti hat√°reloszl√°s t√©tel m√°sik √©rtelmez√©se az, hogy f√ºggetlen√ºl az eloszl√°st√≥l, ha b√°rmilyen v√©letlen v√°ltoz√≥k √∂sszeg√©nek √°tlag√°t sz√°m√≠tjuk, norm√°lis eloszl√°st kapunk.

A k√∂zponti hat√°reloszl√°s t√©telb≈ël az is k√∂vetkezik, hogy amikor N‚Üí‚àû, a minta√°tlag Œº-hoz val√≥ val√≥sz√≠n≈±s√©ge 1 lesz. Ezt nevezz√ºk **nagy sz√°mok t√∂rv√©ny√©nek**.

## Kovariancia √©s korrel√°ci√≥

Az egyik dolog, amit az adatelemz√©s sor√°n keres√ºnk, az adatok k√∂z√∂tti kapcsolatok megtal√°l√°sa. Azt mondjuk, hogy k√©t sorozat **korrel√°l**, ha hasonl√≥ viselked√©st mutatnak egyidej≈±leg, azaz egyszerre emelkednek/cs√∂kkennek, vagy az egyik emelkedik, amikor a m√°sik cs√∂kken, √©s ford√≠tva. M√°s szavakkal, √∫gy t≈±nik, hogy van valamilyen kapcsolat a k√©t sorozat k√∂z√∂tt.

> A korrel√°ci√≥ nem felt√©tlen√ºl jelenti azt, hogy a k√©t sorozat k√∂z√∂tt ok-okozati kapcsolat van; n√©ha mindk√©t v√°ltoz√≥ valamilyen k√ºls≈ë oknak van al√°vetve, vagy puszt√°n v√©letlen, hogy a k√©t sorozat korrel√°l. Azonban az er≈ës matematikai korrel√°ci√≥ j√≥ jelz√©s arra, hogy a k√©t v√°ltoz√≥ valamilyen m√≥don √∂sszef√ºgg.

Matematikailag a k√©t v√©letlen v√°ltoz√≥ k√∂z√∂tti kapcsolatot mutat√≥ f≈ë fogalom a **kovariancia**, amelyet √≠gy sz√°m√≠tunk ki: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. Kisz√°m√≠tjuk mindk√©t v√°ltoz√≥ elt√©r√©s√©t az √°tlag√©rt√©k√ºkt≈ël, majd ezeknek az elt√©r√©seknek a szorzat√°t. Ha mindk√©t v√°ltoz√≥ egy√ºtt t√©r el, a szorzat mindig pozit√≠v √©rt√©k lesz, ami pozit√≠v kovarianci√°t eredm√©nyez. Ha mindk√©t v√°ltoz√≥ elt√©r√©se nincs szinkronban (azaz az egyik az √°tlag al√° esik, amikor a m√°sik az √°tlag f√∂l√© emelkedik), mindig negat√≠v sz√°mokat kapunk, amelyek negat√≠v kovarianci√°t eredm√©nyeznek. Ha az elt√©r√©sek nem f√ºggenek √∂ssze, akkor nagyj√°b√≥l null√°t kapunk.

A kovariancia abszol√∫t √©rt√©ke nem sokat mond arr√≥l, hogy mekkora a korrel√°ci√≥, mert az az aktu√°lis √©rt√©kek nagys√°g√°t√≥l f√ºgg. Ennek normaliz√°l√°s√°hoz eloszthatjuk a kovarianci√°t mindk√©t v√°ltoz√≥ sz√≥r√°s√°val, hogy megkapjuk a **korrel√°ci√≥t**. A j√≥ h√≠r az, hogy a korrel√°ci√≥ mindig [-1,1] tartom√°nyban van, ahol 1 er≈ës pozit√≠v korrel√°ci√≥t, -1 er≈ës negat√≠v korrel√°ci√≥t, √©s 0 semmilyen korrel√°ci√≥t (f√ºggetlens√©get) jelez.

**P√©lda**: Sz√°m√≠tsuk ki a baseball j√°t√©kosok s√∫lya √©s magass√°ga k√∂z√∂tti korrel√°ci√≥t az eml√≠tett adatb√°zisb√≥l:
```python
print(np.corrcoef(weights,heights))
```  
Ennek eredm√©nyek√©nt egy **korrel√°ci√≥s m√°trixot** kapunk, p√©ld√°ul ilyet:  
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```  

> A korrel√°ci√≥s m√°trix C b√°rmilyen sz√°m√∫ bemeneti sorozatra S<sub>1</sub>, ..., S<sub>n</sub> kisz√°m√≠that√≥. A C<sub>ij</sub> √©rt√©ke az S<sub>i</sub> √©s S<sub>j</sub> k√∂z√∂tti korrel√°ci√≥, √©s a diagon√°lis elemek mindig 1-ek (ami az S<sub>i</sub> √∂nkorrel√°ci√≥ja).

Eset√ºnkben a 0.53 √©rt√©k azt jelzi, hogy van n√©mi korrel√°ci√≥ egy szem√©ly s√∫lya √©s magass√°ga k√∂z√∂tt. K√©sz√≠thet√ºnk egy sz√≥r√°sdiagramot is, amely az egyik √©rt√©ket a m√°sik ellen √°br√°zolja, hogy vizu√°lisan l√°ssuk a kapcsolatot:

![Kapcsolat a s√∫ly √©s magass√°g k√∂z√∂tt](../../../../1-Introduction/04-stats-and-probability/images/weight-height-relationship.png)

> Tov√°bbi p√©ld√°k a korrel√°ci√≥ra √©s kovarianci√°ra az [mell√©kelt jegyzetf√ºzetben](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) tal√°lhat√≥k.

## K√∂vetkeztet√©s

Ebben a szakaszban megtanultuk:

* az adatok alapvet≈ë statisztikai tulajdons√°gait, mint az √°tlag, sz√≥r√°s, m√≥dusz √©s kvartilisek
* a v√©letlen v√°ltoz√≥k k√ºl√∂nb√∂z≈ë eloszl√°sait, bele√©rtve a norm√°lis eloszl√°st
* hogyan tal√°ljuk meg a k√ºl√∂nb√∂z≈ë tulajdons√°gok k√∂z√∂tti korrel√°ci√≥t
* hogyan haszn√°ljuk a matematika √©s statisztika megalapozott eszk√∂zeit hipot√©zisek bizony√≠t√°s√°ra
* hogyan sz√°m√≠tsunk konfidencia intervallumokat v√©letlen v√°ltoz√≥khoz adott minta alapj√°n

B√°r ez nem kimer√≠t≈ë lista a val√≥sz√≠n≈±s√©g √©s statisztika t√©mak√∂r√©ben, elegend≈ë alapot ny√∫jt a kurzus folytat√°s√°hoz.

## üöÄ Kih√≠v√°s

Haszn√°ld a jegyzetf√ºzetben tal√°lhat√≥ mintak√≥dot az al√°bbi hipot√©zisek tesztel√©s√©re:
1. Az els≈ë b√°zisj√°t√©kosok id≈ësebbek, mint a m√°sodik b√°zisj√°t√©kosok.
2. Az els≈ë b√°zisj√°t√©kosok magasabbak, mint a harmadik b√°zisj√°t√©kosok.
3. A shortstopok magasabbak, mint a m√°sodik b√°zisj√°t√©kosok.

## [El≈ëad√°s ut√°ni kv√≠z](https://ff-quizzes.netlify.app/en/ds/)

## √Åttekint√©s √©s √∂n√°ll√≥ tanul√°s

A val√≥sz√≠n≈±s√©g √©s statisztika olyan sz√©lesk√∂r≈± t√©ma, hogy meg√©rdemel egy k√ºl√∂n kurzust. Ha m√©lyebben szeretn√©l elmer√ºlni az elm√©letben, √©rdemes lehet folytatni az al√°bbi k√∂nyvek olvas√°s√°t:

1. [Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/) a New York-i Egyetemr≈ël nagyszer≈± el≈ëad√°sjegyzeteket k√©sz√≠tett [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) c√≠mmel (el√©rhet≈ë online).
2. [Peter √©s Andrew Bruce. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[mintak√≥d R-ben](https://github.com/andrewgbruce/statistics-for-data-scientists)].
3. [James D. Miller. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[mintak√≥d R-ben](https://github.com/PacktPublishing/Statistics-for-Data-Science)].

## Feladat

[Kis diab√©tesz tanulm√°ny](assignment.md)

## K√∂sz√∂netnyilv√°n√≠t√°s

Ezt a leck√©t ‚ô•Ô∏è-vel k√©sz√≠tette [Dmitry Soshnikov](http://soshnikov.com).

---

**Felel≈ëss√©gkiz√°r√°s**:  
Ez a dokumentum az [Co-op Translator](https://github.com/Azure/co-op-translator) AI ford√≠t√°si szolg√°ltat√°s seg√≠ts√©g√©vel k√©sz√ºlt. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n javasolt professzion√°lis, emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get a ford√≠t√°s haszn√°lat√°b√≥l ered≈ë f√©lre√©rt√©sek√©rt vagy t√©ves √©rtelmez√©sek√©rt.