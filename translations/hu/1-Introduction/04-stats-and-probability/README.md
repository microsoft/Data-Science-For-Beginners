<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1cf49f029ba1f25a54f0d5bc2fa575fc",
  "translation_date": "2025-09-05T17:35:34+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "hu"
}
-->
# A statisztika √©s a val√≥sz√≠n≈±s√©g r√∂vid bemutat√°sa

|![ Sketchnote k√©sz√≠tette: [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| Statisztika √©s Val√≥sz√≠n≈±s√©g - _Sketchnote k√©sz√≠tette: [@nitya](https://twitter.com/nitya)_ |

A statisztika √©s a val√≥sz√≠n≈±s√©gelm√©let a matematika k√©t szorosan √∂sszef√ºgg≈ë ter√ºlete, amelyek rendk√≠v√ºl fontosak az adatelemz√©s szempontj√°b√≥l. B√°r lehets√©ges adatokkal dolgozni m√©ly matematikai ismeretek n√©lk√ºl, m√©gis hasznos, ha legal√°bb az alapfogalmakat ismerj√ºk. Ebben a r√∂vid bevezet≈ëben bemutatjuk az indul√°shoz sz√ºks√©ges alapokat.

[![Bevezet≈ë vide√≥](../../../../1-Introduction/04-stats-and-probability/images/video-prob-and-stats.png)](https://youtu.be/Z5Zy85g4Yjw)

## [El≈ëad√°s el≈ëtti kv√≠z](https://ff-quizzes.netlify.app/en/ds/quiz/6)

## Val√≥sz√≠n≈±s√©g √©s v√©letlen v√°ltoz√≥k

**Val√≥sz√≠n≈±s√©g** egy 0 √©s 1 k√∂z√∂tti sz√°m, amely kifejezi, hogy egy **esem√©ny** mennyire val√≥sz√≠n≈±. √ögy defini√°ljuk, mint a pozit√≠v kimenetelek sz√°m√°t (amelyek az esem√©nyhez vezetnek), osztva az √∂sszes kimenetel sz√°m√°val, felt√©telezve, hogy minden kimenetel egyform√°n val√≥sz√≠n≈±. P√©ld√°ul, ha dobunk egy kock√°val, annak a val√≥sz√≠n≈±s√©ge, hogy p√°ros sz√°mot kapunk, 3/6 = 0,5.

Amikor esem√©nyekr≈ël besz√©l√ºnk, **v√©letlen v√°ltoz√≥kat** haszn√°lunk. P√©ld√°ul a v√©letlen v√°ltoz√≥, amely a kockadob√°s eredm√©ny√©t k√©pviseli, 1-t≈ël 6-ig terjed≈ë √©rt√©keket vehet fel. Az 1-t≈ël 6-ig terjed≈ë sz√°mok halmaz√°t **mintat√©rnek** nevezz√ºk. Besz√©lhet√ºnk arr√≥l, hogy egy v√©letlen v√°ltoz√≥ egy bizonyos √©rt√©ket vesz fel, p√©ld√°ul P(X=3)=1/6.

Az el≈ëz≈ë p√©ld√°ban szerepl≈ë v√©letlen v√°ltoz√≥t **diszkr√©tnek** nevezz√ºk, mert a mintat√©r megsz√°ml√°lhat√≥, azaz k√ºl√∂n√°ll√≥ √©rt√©kek vannak, amelyeket felsorolhatunk. Vannak olyan esetek, amikor a mintat√©r val√≥s sz√°mok egy tartom√°nya, vagy az eg√©sz val√≥s sz√°mhalmaz. Az ilyen v√°ltoz√≥kat **folytonosnak** nevezz√ºk. J√≥ p√©lda erre a busz √©rkez√©si ideje.

## Val√≥sz√≠n≈±s√©gi eloszl√°s

Diszkr√©t v√©letlen v√°ltoz√≥k eset√©n k√∂nny≈± le√≠rni az egyes esem√©nyek val√≥sz√≠n≈±s√©g√©t egy P(X) f√ºggv√©nnyel. A mintat√©r *S* minden *s* √©rt√©k√©re egy 0 √©s 1 k√∂z√∂tti sz√°mot ad, √∫gy, hogy az √∂sszes esem√©nyre vonatkoz√≥ P(X=s) √©rt√©kek √∂sszege 1 legyen.

A legismertebb diszkr√©t eloszl√°s az **egyenletes eloszl√°s**, amelyben N elem≈± mintat√©r van, √©s mindegyik elem val√≥sz√≠n≈±s√©ge 1/N.

Folytonos v√°ltoz√≥k eset√©n nehezebb le√≠rni az eloszl√°st, ha az √©rt√©kek egy [a,b] intervallumb√≥l, vagy az eg√©sz val√≥s sz√°mhalmazb√≥l ‚Ñù sz√°rmaznak. Vegy√ºk p√©ld√°ul a busz √©rkez√©si idej√©t. Val√≥j√°ban minden pontos √©rkez√©si id≈ë *t* eset√©n a busz pontosan abban az id≈ëpontban val√≥ √©rkez√©s√©nek val√≥sz√≠n≈±s√©ge 0!

> Most m√°r tudod, hogy 0 val√≥sz√≠n≈±s√©g≈± esem√©nyek is megt√∂rt√©nnek, √©s nagyon gyakran! Legal√°bbis minden alkalommal, amikor a busz meg√©rkezik!

Csak arr√≥l besz√©lhet√ºnk, hogy egy v√°ltoz√≥ egy adott √©rt√©ktartom√°nyba esik, p√©ld√°ul P(t<sub>1</sub>‚â§X<t<sub>2</sub>). Ebben az esetben az eloszl√°st egy **val√≥sz√≠n≈±s√©gi s≈±r≈±s√©gf√ºggv√©ny** p(x) √≠rja le, amelyre igaz, hogy

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../1-Introduction/04-stats-and-probability/images/probability-density.png)

Az egyenletes eloszl√°s folytonos anal√≥gj√°t **folytonos egyenletes eloszl√°snak** nevezz√ºk, amely egy v√©ges intervallumon van defini√°lva. Annak a val√≥sz√≠n≈±s√©ge, hogy az X √©rt√©k egy l hossz√∫s√°g√∫ intervallumba esik, ar√°nyos l-lel, √©s legfeljebb 1 lehet.

Egy m√°sik fontos eloszl√°s a **norm√°lis eloszl√°s**, amelyr≈ël k√©s≈ëbb r√©szletesebben besz√©l√ºnk.

## √Åtlag, sz√≥r√°s √©s variancia

Tegy√ºk fel, hogy egy v√©letlen v√°ltoz√≥ X n mint√°j√°t vessz√ºk: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>. Az **√°tlagos** (vagy **sz√°mtani k√∂z√©p**) √©rt√©ket a hagyom√°nyos m√≥don defini√°lhatjuk: (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n. Ahogy n√∂velj√ºk a minta m√©ret√©t (azaz n‚Üí‚àû hat√°r√©rt√©ket vesz√ºnk), megkapjuk az eloszl√°s √°tlag√°t (m√°s n√©ven **v√°rhat√≥ √©rt√©k**). A v√°rhat√≥ √©rt√©ket **E**(x)-szel jel√∂lj√ºk.

> Kimutathat√≥, hogy b√°rmely diszkr√©t eloszl√°s eset√©n, amelynek √©rt√©kei {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} √©s megfelel≈ë val√≥sz√≠n≈±s√©gei p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub>, a v√°rhat√≥ √©rt√©k E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub> lesz.

Annak meghat√°roz√°s√°ra, hogy az √©rt√©kek mennyire sz√≥r√≥dnak, kisz√°m√≠thatjuk a varianci√°t: œÉ<sup>2</sup> = ‚àë(x<sub>i</sub> - Œº)<sup>2</sup>/n, ahol Œº a minta √°tlaga. Az √©rt√©ket **sz√≥r√°snak** nevezz√ºk, m√≠g œÉ<sup>2</sup>-t **varianci√°nak**.

## M√≥dusz, medi√°n √©s kvartilisek

N√©ha az √°tlag nem megfelel≈ëen reprezent√°lja az "tipikus" √©rt√©ket az adatokban. P√©ld√°ul, ha van n√©h√°ny sz√©ls≈ës√©ges √©rt√©k, amelyek teljesen kil√≥gnak a tartom√°nyb√≥l, ezek befoly√°solhatj√°k az √°tlagot. Egy m√°sik j√≥ mutat√≥ a **medi√°n**, egy olyan √©rt√©k, amelyn√©l az adatok fele alacsonyabb, a m√°sik fele pedig magasabb.

Az adatok eloszl√°s√°nak meg√©rt√©s√©hez hasznos a **kvartilisekr≈ël** besz√©lni:

* Az els≈ë kvartilis, vagy Q1, egy olyan √©rt√©k, amelyn√©l az adatok 25%-a alatta van
* A harmadik kvartilis, vagy Q3, egy olyan √©rt√©k, amelyn√©l az adatok 75%-a alatta van

Grafikusan a medi√°n √©s a kvartilisek kapcsolat√°t egy **dobozdiagramon** √°br√°zolhatjuk:

<img src="images/boxplot_explanation.png" width="50%"/>

Itt kisz√°m√≠tjuk az **interkvartilis tartom√°nyt** IQR=Q3-Q1, valamint az √∫gynevezett **kiugr√≥ √©rt√©keket** - azokat az √©rt√©keket, amelyek k√≠v√ºl esnek a [Q1-1.5*IQR,Q3+1.5*IQR] hat√°rokon.

Egy v√©ges eloszl√°s eset√©n, amely kev√©s lehets√©ges √©rt√©ket tartalmaz, egy j√≥ "tipikus" √©rt√©k az, amely a leggyakrabban fordul el≈ë, ezt **m√≥dusznak** nevezz√ºk. Gyakran alkalmazz√°k kateg√≥ri√°s adatokra, p√©ld√°ul sz√≠nekre. Vegy√ºnk egy helyzetet, amikor k√©t embercsoport van - az egyik er≈ësen kedveli a pirosat, a m√°sik pedig a k√©ket. Ha a sz√≠neket sz√°mokkal k√≥doljuk, a kedvenc sz√≠n √°tlag√©rt√©ke valahol a narancs-z√∂ld spektrumban lenne, ami nem t√ºkr√∂zi egyik csoport t√©nyleges preferenci√°j√°t sem. A m√≥dusz azonban vagy az egyik sz√≠n, vagy mindk√©t sz√≠n lenne, ha az emberek sz√°ma, akik r√°juk szavaznak, egyenl≈ë (ebben az esetben a mint√°t **multimod√°lisnak** nevezz√ºk).

## Val√≥s adatok

Amikor val√≥s √©letb≈ël sz√°rmaz√≥ adatokat elemz√ºnk, gyakran nem v√©letlen v√°ltoz√≥k√©nt kezelj√ºk ≈ëket, abban az √©rtelemben, hogy nem v√©gez√ºnk k√≠s√©rleteket ismeretlen eredm√©nnyel. P√©ld√°ul vegy√ºnk egy baseballcsapatot, √©s az ≈ë testadataikat, p√©ld√°ul magass√°got, s√∫lyt √©s √©letkort. Ezek a sz√°mok nem pontosan v√©letlenek, de m√©gis alkalmazhatjuk r√°juk ugyanazokat a matematikai fogalmakat. P√©ld√°ul az emberek s√∫ly√°nak sorozata tekinthet≈ë egy v√©letlen v√°ltoz√≥b√≥l sz√°rmaz√≥ √©rt√©kek sorozat√°nak. Az al√°bbiakban a [Major League Baseball](http://mlb.mlb.com/index.jsp) val√≥di baseballj√°t√©kosainak s√∫lyadatai l√°that√≥k, amelyeket [ebb≈ël az adatb√°zisb√≥l](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) vett√ºnk (a k√©nyelmed √©rdek√©ben csak az els≈ë 20 √©rt√©ket mutatjuk):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Note**: Ha szeretn√©d l√°tni, hogyan dolgozhatsz ezzel az adatb√°zissal, n√©zd meg a [kapcsol√≥d√≥ jegyzetf√ºzetet](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb). Az √≥ra sor√°n sz√°mos kih√≠v√°s is tal√°lhat√≥, amelyeket √∫gy oldhatsz meg, hogy k√≥dot adsz hozz√° a jegyzetf√ºzethez. Ha nem vagy biztos abban, hogyan kell adatokat kezelni, ne agg√≥dj - k√©s≈ëbb visszat√©r√ºnk az adatok Python seg√≠ts√©g√©vel t√∂rt√©n≈ë feldolgoz√°s√°hoz. Ha nem tudod, hogyan kell k√≥dot futtatni Jupyter Notebookban, n√©zd meg [ezt a cikket](https://soshnikov.com/education/how-to-execute-notebooks-from-github/).

√çme a dobozdiagram, amely bemutatja az √°tlagot, medi√°nt √©s kvartiliseket az adatainkhoz:

![S√∫ly dobozdiagram](../../../../1-Introduction/04-stats-and-probability/images/weight-boxplot.png)

Mivel adataink k√ºl√∂nb√∂z≈ë j√°t√©kos **szerepekr≈ël** tartalmaznak inform√°ci√≥t, k√©sz√≠thet√ºnk dobozdiagramot szerepek szerint is - ez lehet≈ëv√© teszi, hogy k√©pet kapjunk arr√≥l, hogyan k√ºl√∂nb√∂znek az √©rt√©kek szerepek szerint. Ez√∫ttal a magass√°got vessz√ºk figyelembe:

![Dobozdiagram szerepek szerint](../../../../1-Introduction/04-stats-and-probability/images/boxplot_byrole.png)

Ez a diagram azt sugallja, hogy az els≈ë b√°zisj√°t√©kosok magass√°ga √°tlagosan nagyobb, mint a m√°sodik b√°zisj√°t√©kosok√©. K√©s≈ëbb az √≥r√°n megtanuljuk, hogyan tesztelhetj√ºk ezt a hipot√©zist form√°lisabban, √©s hogyan mutathatjuk ki, hogy adataink statisztikailag jelent≈ësek ennek bizony√≠t√°s√°ra.

> Val√≥s adatokkal dolgozva felt√©telezz√ºk, hogy minden adatpont egy val√≥sz√≠n≈±s√©gi eloszl√°sb√≥l sz√°rmaz√≥ minta. Ez a felt√©telez√©s lehet≈ëv√© teszi sz√°munkra, hogy g√©pi tanul√°si technik√°kat alkalmazzunk √©s m≈±k√∂d≈ë predikt√≠v modelleket √©p√≠ts√ºnk.

Az adatok eloszl√°s√°nak meg√©rt√©s√©hez k√©sz√≠thet√ºnk egy **hisztogramot**. Az X-tengely k√ºl√∂nb√∂z≈ë s√∫lytartom√°nyokat (√∫gynevezett **bin-eket**) tartalmaz, m√≠g a f√ºgg≈ëleges tengely azt mutatja, hogy v√©letlen v√°ltoz√≥nk mint√°ja h√°nyszor esett egy adott tartom√°nyba.

![Val√≥s adatok hisztogramja](../../../../1-Introduction/04-stats-and-probability/images/weight-histogram.png)

Ebb≈ël a hisztogramb√≥l l√°that√≥, hogy az √∂sszes √©rt√©k egy bizonyos √°tlagos s√∫ly k√∂r√© csoportosul, √©s min√©l t√°volabb megy√ºnk ett≈ël a s√∫lyt√≥l, ann√°l kevesebb ilyen √©rt√©k fordul el≈ë. Azaz nagyon val√≥sz√≠n≈±tlen, hogy egy baseballj√°t√©kos s√∫lya jelent≈ësen elt√©r az √°tlagos s√∫lyt√≥l. A s√∫lyok varianci√°ja azt mutatja, hogy a s√∫lyok mennyire t√©rhetnek el az √°tlagt√≥l.

> Ha m√°s emberek s√∫lyait vessz√ºk, akik nem a baseball lig√°b√≥l sz√°rmaznak, az eloszl√°s val√≥sz√≠n≈±leg elt√©r≈ë lesz. Azonban az eloszl√°s alakja ugyanaz marad, csak az √°tlag √©s a variancia v√°ltozik. Teh√°t, ha modell√ºnket baseballj√°t√©kosokon tan√≠tjuk, val√≥sz√≠n≈±leg rossz eredm√©nyeket ad, ha egyetemi hallgat√≥kra alkalmazzuk, mert az alapul szolg√°l√≥ eloszl√°s elt√©r≈ë.

## Norm√°lis eloszl√°s

A s√∫lyok eloszl√°sa, amelyet fentebb l√°ttunk, nagyon tipikus, √©s sok val√≥s m√©r√©sek ugyanilyen t√≠pus√∫ eloszl√°st k√∂vetnek, de elt√©r≈ë √°tlaggal √©s varianci√°val. Ezt az eloszl√°st **norm√°lis eloszl√°snak** nevezz√ºk, √©s nagyon fontos szerepet j√°tszik a statisztik√°ban.

A norm√°lis eloszl√°s haszn√°lata helyes m√≥dja annak, hogy v√©letlenszer≈± s√∫lyokat gener√°ljunk potenci√°lis baseballj√°t√©kosok sz√°m√°ra. Ha ismerj√ºk az √°tlagos s√∫lyt `mean` √©s a sz√≥r√°st `std`, 1000 s√∫lymint√°t gener√°lhatunk a k√∂vetkez≈ë m√≥don:
```python
samples = np.random.normal(mean,std,1000)
``` 

Ha a gener√°lt mint√°k hisztogramj√°t √°br√°zoljuk, nagyon hasonl√≥ k√©pet kapunk a fentebb bemutatotthoz. √âs ha n√∂velj√ºk a mint√°k sz√°m√°t √©s a bin-ek sz√°m√°t, egy norm√°lis eloszl√°s ide√°lisabb k√©p√©t gener√°lhatjuk:

![Norm√°lis eloszl√°s √°tlag=0 √©s sz√≥r√°s=1](../../../../1-Introduction/04-stats-and-probability/images/normal-histogram.png)

*Norm√°lis eloszl√°s √°tlag=0 √©s sz√≥r√°s=1*

## Konfidencia intervallumok

Amikor baseballj√°t√©kosok s√∫lyair√≥l besz√©l√ºnk, felt√©telezz√ºk, hogy l√©tezik egy **W v√©letlen v√°ltoz√≥**, amely az √∂sszes baseballj√°t√©kos s√∫ly√°nak ide√°lis val√≥sz√≠n≈±s√©gi eloszl√°s√°t k√©pviseli (√∫gynevezett **popul√°ci√≥**). A s√∫lyaink sorozata az √∂sszes baseballj√°t√©kos egy r√©szhalmaz√°nak felel meg, amelyet **mint√°nak** nevez√ºnk. √ârdekes k√©rd√©s, hogy meg tudjuk-e hat√°rozni a W eloszl√°s√°nak param√©tereit, azaz a popul√°ci√≥ √°tlag√°t √©s varianci√°j√°t?

A legegyszer≈±bb v√°lasz az lenne, hogy kisz√°m√≠tjuk a minta √°tlag√°t √©s varianci√°j√°t. Azonban el≈ëfordulhat, hogy v√©letlen mint√°nk nem pontosan reprezent√°lja a teljes popul√°ci√≥t. Ez√©rt van √©rtelme **konfidencia intervallumr√≥l** besz√©lni.

> **Konfidencia intervallum** a popul√°ci√≥ val√≥di √°tlag√°nak becsl√©se a mint√°nk alapj√°n, amely bizonyos val√≥sz√≠n≈±s√©ggel (vagy **bizalmi szinttel**) pontos.

1</sub>, ..., X<sub>n</sub> a mi eloszl√°sunkb√≥l. Minden alkalommal, amikor mint√°t vesz√ºnk az eloszl√°sunkb√≥l, elt√©r≈ë √°tlag√©rt√©ket kapunk, Œº-t. √çgy Œº tekinthet≈ë v√©letlen v√°ltoz√≥nak. Egy **konfidencia intervallum** konfidencia p-vel egy √©rt√©kp√°r (L<sub>p</sub>,R<sub>p</sub>), amelyre **P**(L<sub>p</sub>‚â§Œº‚â§R<sub>p</sub>) = p, azaz a m√©rt √°tlag√©rt√©k intervallumba es√©s√©nek val√≥sz√≠n≈±s√©ge p.

R√∂vid bevezet≈ënk√∂n t√∫lmutat, hogy r√©szletesen t√°rgyaljuk, hogyan sz√°m√≠tj√°k ki ezeket a konfidencia intervallumokat. Tov√°bbi r√©szletek tal√°lhat√≥k [a Wikip√©di√°n](https://en.wikipedia.org/wiki/Confidence_interval). R√∂viden, meghat√°rozzuk a sz√°m√≠tott minta√°tlag eloszl√°s√°t a popul√°ci√≥ val√≥di √°tlag√°hoz viszony√≠tva, amit **student eloszl√°snak** neveznek.

> **√ârdekes t√©ny**: A student eloszl√°st William Sealy Gosset matematikusr√≥l nevezt√©k el, aki "Student" √°ln√©ven publik√°lta tanulm√°ny√°t. Gosset a Guinness s√∂rf≈ëzd√©ben dolgozott, √©s az egyik verzi√≥ szerint munk√°ltat√≥ja nem akarta, hogy a nagyk√∂z√∂ns√©g tudom√°st szerezzen arr√≥l, hogy statisztikai teszteket haszn√°lnak a nyersanyagok min≈ës√©g√©nek meghat√°roz√°s√°ra.

Ha a popul√°ci√≥nk √°tlag√°t, Œº-t szeretn√©nk p konfidenci√°val becs√ºlni, akkor a Student eloszl√°s *(1-p)/2-edik percentilis√©t* kell venn√ºnk, amelyet t√°bl√°zatokb√≥l vagy statisztikai szoftverek (pl. Python, R stb.) be√©p√≠tett f√ºggv√©nyeivel lehet kisz√°m√≠tani. Ezut√°n az Œº intervalluma X¬±A*D/‚àön lesz, ahol X a minta kapott √°tlaga, D a sz√≥r√°s.

> **Megjegyz√©s**: Az [szabads√°gfokok](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)) fontos fogalm√°nak t√°rgyal√°s√°t is kihagyjuk, amely a Student eloszl√°ssal kapcsolatban jelent≈ës. Tov√°bbi statisztikai k√∂nyvekben m√©lyebben meg√©rtheti ezt a fogalmat.

A s√∫lyok √©s magass√°gok konfidencia intervallum√°nak kisz√°m√≠t√°s√°ra p√©lda tal√°lhat√≥ az [k√≠s√©r≈ë jegyzetf√ºzetekben](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb).

| p | S√∫ly √°tlaga |
|-----|-----------|
| 0.85 | 201.73¬±0.94 |
| 0.90 | 201.73¬±1.08 |
| 0.95 | 201.73¬±1.28 |

Figyelj√ºk meg, hogy min√©l nagyobb a konfidencia val√≥sz√≠n≈±s√©ge, ann√°l sz√©lesebb a konfidencia intervallum.

## Hipot√©zisvizsg√°lat

A baseball j√°t√©kosok adat√°llom√°ny√°ban k√ºl√∂nb√∂z≈ë j√°t√©kos szerepek vannak, amelyeket az al√°bbiakban √∂sszefoglalhatunk (n√©zze meg az [k√≠s√©r≈ë jegyzetf√ºzetet](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb), hogy l√°ssa, hogyan sz√°m√≠that√≥ ki ez a t√°bl√°zat):

| Szerep | Magass√°g | S√∫ly | Darabsz√°m |
|------|--------|--------|-------|
| Catcher | 72.723684 | 204.328947 | 76 |
| Designated_Hitter | 74.222222 | 220.888889 | 18 |
| First_Baseman | 74.000000 | 213.109091 | 55 |
| Outfielder | 73.010309 | 199.113402 | 194 |
| Relief_Pitcher | 74.374603 | 203.517460 | 315 |
| Second_Baseman | 71.362069 | 184.344828 | 58 |
| Shortstop | 71.903846 | 182.923077 | 52 |
| Starting_Pitcher | 74.719457 | 205.163636 | 221 |
| Third_Baseman | 73.044444 | 200.955556 | 45 |

L√°thatjuk, hogy az els≈ë b√°zisj√°t√©kosok √°tlagos magass√°ga nagyobb, mint a m√°sodik b√°zisj√°t√©kosok√©. √çgy k√≠s√©rt√©sbe eshet√ºnk, hogy azt a k√∂vetkeztet√©st vonjuk le, hogy **az els≈ë b√°zisj√°t√©kosok magasabbak, mint a m√°sodik b√°zisj√°t√©kosok**.

> Ezt az √°ll√≠t√°st **hipot√©zisnek** nevezz√ºk, mert nem tudjuk, hogy a t√©ny val√≥ban igaz-e vagy sem.

Azonban nem mindig egy√©rtelm≈±, hogy levonhatjuk-e ezt a k√∂vetkeztet√©st. Az el≈ëz≈ëekben t√°rgyaltakb√≥l tudjuk, hogy minden √°tlaghoz tartozik egy konfidencia intervallum, √©s √≠gy ez a k√ºl√∂nbs√©g lehet puszt√°n statisztikai hiba. Sz√ºks√©g√ºnk van valamilyen form√°lis m√≥dszerre a hipot√©zis√ºnk tesztel√©s√©hez.

Sz√°m√≠tsuk ki k√ºl√∂n-k√ºl√∂n az els≈ë √©s m√°sodik b√°zisj√°t√©kosok magass√°g√°nak konfidencia intervallumait:

| Konfidencia | Els≈ë b√°zisj√°t√©kosok | M√°sodik b√°zisj√°t√©kosok |
|------------|---------------|----------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

L√°thatjuk, hogy egyetlen konfidencia szinten sem fedik √°t egym√°st az intervallumok. Ez bizony√≠tja a hipot√©zis√ºnket, miszerint az els≈ë b√°zisj√°t√©kosok magasabbak, mint a m√°sodik b√°zisj√°t√©kosok.

Form√°lisabban, az √°ltalunk megoldott probl√©ma az, hogy meg√°llap√≠tsuk, vajon **k√©t val√≥sz√≠n≈±s√©gi eloszl√°s azonos-e**, vagy legal√°bbis ugyanazokkal a param√©terekkel rendelkezik. Az eloszl√°st√≥l f√ºgg≈ëen k√ºl√∂nb√∂z≈ë teszteket kell alkalmaznunk erre. Ha tudjuk, hogy eloszl√°saink norm√°lisak, alkalmazhatjuk a **[Student t-tesztet](https://en.wikipedia.org/wiki/Student%27s_t-test)**.

A Student t-tesztben kisz√°m√≠tjuk az √∫gynevezett **t-√©rt√©ket**, amely az √°tlagok k√∂z√∂tti k√ºl√∂nbs√©get jelzi, figyelembe v√©ve a sz√≥r√°st. Kimutatt√°k, hogy a t-√©rt√©k k√∂veti a **student eloszl√°st**, amely lehet≈ëv√© teszi sz√°munkra, hogy megkapjuk a k√ºsz√∂b√©rt√©ket egy adott konfidencia szinthez **p** (ez kisz√°m√≠that√≥ vagy numerikus t√°bl√°zatokb√≥l kikereshet≈ë). Ezut√°n √∂sszehasonl√≠tjuk a t-√©rt√©ket ezzel a k√ºsz√∂b√©rt√©kkel, hogy elfogadjuk vagy elutas√≠tsuk a hipot√©zist.

Pythonban haszn√°lhatjuk a **SciPy** csomagot, amely tartalmazza a `ttest_ind` f√ºggv√©nyt (sok m√°s hasznos statisztikai f√ºggv√©ny mellett!). Ez kisz√°m√≠tja nek√ºnk a t-√©rt√©ket, √©s ford√≠tott keres√©st v√©gez a konfidencia p-√©rt√©k√©re, √≠gy csak a konfidenci√°t kell megn√©zn√ºnk, hogy k√∂vetkeztet√©st vonjunk le.

P√©ld√°ul az els≈ë √©s m√°sodik b√°zisj√°t√©kosok magass√°g√°nak √∂sszehasonl√≠t√°sa a k√∂vetkez≈ë eredm√©nyeket adja:
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
Eset√ºnkben a p-√©rt√©k nagyon alacsony, ami azt jelenti, hogy er≈ës bizony√≠t√©k van arra, hogy az els≈ë b√°zisj√°t√©kosok magasabbak.

M√°s t√≠pus√∫ hipot√©ziseket is tesztelhet√ºnk, p√©ld√°ul:
* Annak bizony√≠t√°sa, hogy egy adott minta k√∂vet egy eloszl√°st. Eset√ºnkben felt√©telezt√ºk, hogy a magass√°gok norm√°lisan oszlanak el, de ezt form√°lis statisztikai ellen≈ërz√©snek kell al√°vetni.
* Annak bizony√≠t√°sa, hogy egy minta √°tlag√©rt√©ke megfelel egy el≈ëre meghat√°rozott √©rt√©knek
* T√∂bb minta √°tlag√°nak √∂sszehasonl√≠t√°sa (pl. mi a k√ºl√∂nbs√©g a boldogs√°g szintek k√∂z√∂tt k√ºl√∂nb√∂z≈ë korcsoportokban)

## Nagysz√°mok t√∂rv√©nye √©s k√∂zponti hat√°reloszl√°s-t√©tel

Az egyik ok, ami√©rt a norm√°l eloszl√°s olyan fontos, az √∫gynevezett **k√∂zponti hat√°reloszl√°s-t√©tel**. Tegy√ºk fel, hogy van egy nagy mint√°nk f√ºggetlen N √©rt√©kekkel X<sub>1</sub>, ..., X<sub>N</sub>, amelyeket b√°rmilyen eloszl√°sb√≥l mint√°ztunk, √°tlag Œº-val √©s sz√≥r√°s œÉ<sup>2</sup>-vel. Ezut√°n, ha N el√©g nagy (m√°s sz√≥val, amikor N‚Üí‚àû), az √°tlag Œ£<sub>i</sub>X<sub>i</sub> norm√°lisan oszlik el, √°tlag Œº-val √©s sz√≥r√°s œÉ<sup>2</sup>/N-nel.

> A k√∂zponti hat√°reloszl√°s-t√©telt m√°sk√©pp is √©rtelmezhetj√ºk: f√ºggetlen√ºl az eloszl√°st√≥l, amikor b√°rmely v√©letlen v√°ltoz√≥ √©rt√©keinek √∂sszeg√©nek √°tlag√°t sz√°m√≠tjuk, norm√°l eloszl√°st kapunk.

A k√∂zponti hat√°reloszl√°s-t√©telb≈ël az is k√∂vetkezik, hogy amikor N‚Üí‚àû, a minta√°tlag Œº-hoz val√≥ val√≥sz√≠n≈±s√©ge 1 lesz. Ezt **nagysz√°mok t√∂rv√©ny√©nek** nevezik.

## Kovariancia √©s korrel√°ci√≥

Az egyik dolog, amit az adatelemz√©s v√©gez, az adatok k√∂z√∂tti kapcsolatok keres√©se. Azt mondjuk, hogy k√©t sorozat **korrel√°l**, amikor hasonl√≥ viselked√©st mutatnak ugyanabban az id≈ëben, azaz egyszerre emelkednek/cs√∂kkennek, vagy az egyik sorozat emelkedik, amikor a m√°sik cs√∂kken, √©s ford√≠tva. M√°s sz√≥val, √∫gy t≈±nik, hogy van valamilyen kapcsolat a k√©t sorozat k√∂z√∂tt.

> A korrel√°ci√≥ nem felt√©tlen√ºl jelzi a k√©t sorozat k√∂z√∂tti ok-okozati kapcsolatot; n√©ha mindk√©t v√°ltoz√≥ f√ºgghet valamilyen k√ºls≈ë okt√≥l, vagy puszt√°n v√©letlen√ºl korrel√°lhatnak. Azonban az er≈ës matematikai korrel√°ci√≥ j√≥ jelz√©s arra, hogy k√©t v√°ltoz√≥ valamilyen m√≥don √∂sszekapcsol√≥dik.

Matematikailag a f≈ë fogalom, amely megmutatja a k√©t v√©letlen v√°ltoz√≥ k√∂z√∂tti kapcsolatot, a **kovariancia**, amelyet √≠gy sz√°m√≠tunk: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]. Sz√°m√≠tjuk mindk√©t v√°ltoz√≥ elt√©r√©s√©t az √°tlag√©rt√©k√ºkt≈ël, majd ezeknek az elt√©r√©seknek a szorzat√°t. Ha mindk√©t v√°ltoz√≥ egy√ºtt t√©r el, a szorzat mindig pozit√≠v √©rt√©k lesz, amely pozit√≠v kovarianci√°t eredm√©nyez. Ha mindk√©t v√°ltoz√≥ nem szinkronban t√©r el (azaz az egyik az √°tlag al√° esik, amikor a m√°sik az √°tlag f√∂l√© emelkedik), mindig negat√≠v sz√°mokat kapunk, amelyek negat√≠v kovarianci√°t eredm√©nyeznek. Ha az elt√©r√©sek nem f√ºggnek egym√°st√≥l, akkor nagyj√°b√≥l null√°t kapunk.

A kovariancia abszol√∫t √©rt√©ke nem mond sokat arr√≥l, hogy mekkora a korrel√°ci√≥, mert az az aktu√°lis √©rt√©kek nagys√°g√°t√≥l f√ºgg. Normaliz√°l√°s√°hoz oszthatjuk a kovarianci√°t mindk√©t v√°ltoz√≥ sz√≥r√°s√°val, hogy megkapjuk a **korrel√°ci√≥t**. Az a j√≥, hogy a korrel√°ci√≥ mindig [-1,1] tartom√°nyban van, ahol 1 er≈ës pozit√≠v korrel√°ci√≥t jelez az √©rt√©kek k√∂z√∂tt, -1 er≈ës negat√≠v korrel√°ci√≥t, √©s 0 azt jelzi, hogy nincs korrel√°ci√≥ (a v√°ltoz√≥k f√ºggetlenek).

**P√©lda**: Sz√°m√≠thatunk korrel√°ci√≥t a baseball j√°t√©kosok s√∫lya √©s magass√°ga k√∂z√∂tt az eml√≠tett adat√°llom√°nyb√≥l:
```python
print(np.corrcoef(weights,heights))
```
Ennek eredm√©nyek√©nt kapunk egy **korrel√°ci√≥s m√°trixot**, amely √≠gy n√©z ki:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> A korrel√°ci√≥s m√°trix C b√°rmely sz√°m√∫ bemeneti sorozatra S<sub>1</sub>, ..., S<sub>n</sub> kisz√°m√≠that√≥. A C<sub>ij</sub> √©rt√©ke az S<sub>i</sub> √©s S<sub>j</sub> k√∂z√∂tti korrel√°ci√≥, √©s a diagon√°lis elemek mindig 1-ek (ami az S<sub>i</sub> √∂nkorrel√°ci√≥ja).

Eset√ºnkben a 0.53 √©rt√©k azt jelzi, hogy van n√©mi korrel√°ci√≥ egy szem√©ly s√∫lya √©s magass√°ga k√∂z√∂tt. K√©sz√≠thet√ºnk egy sz√≥r√°si diagramot az egyik √©rt√©kr≈ël a m√°sik ellen, hogy vizu√°lisan l√°ssuk a kapcsolatot:

![Kapcsolat a s√∫ly √©s magass√°g k√∂z√∂tt](../../../../1-Introduction/04-stats-and-probability/images/weight-height-relationship.png)

> Tov√°bbi p√©ld√°k a korrel√°ci√≥ra √©s kovarianci√°ra az [k√≠s√©r≈ë jegyzetf√ºzetben](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) tal√°lhat√≥k.

## K√∂vetkeztet√©s

Ebben a szakaszban megtanultuk:

* az adatok alapvet≈ë statisztikai tulajdons√°gait, mint az √°tlag, sz√≥r√°s, m√≥dusz √©s kvartilisek
* k√ºl√∂nb√∂z≈ë v√©letlen v√°ltoz√≥k eloszl√°sait, bele√©rtve a norm√°l eloszl√°st
* hogyan tal√°ljuk meg a korrel√°ci√≥t k√ºl√∂nb√∂z≈ë tulajdons√°gok k√∂z√∂tt
* hogyan haszn√°ljuk a matematika √©s statisztika megalapozott eszk√∂zeit hipot√©zisek bizony√≠t√°s√°ra
* hogyan sz√°m√≠tsunk konfidencia intervallumokat v√©letlen v√°ltoz√≥khoz adott adatmint√°k alapj√°n

B√°r ez nem kimer√≠t≈ë lista a val√≥sz√≠n≈±s√©g √©s statisztika t√©mak√∂reiben, elegend≈ënek kell lennie ahhoz, hogy j√≥ kezd√©st ny√∫jtson ebben a kurzusban.

## üöÄ Kih√≠v√°s

Haszn√°lja a jegyzetf√ºzetben tal√°lhat√≥ mintak√≥dot m√°s hipot√©zisek tesztel√©s√©re:
1. Az els≈ë b√°zisj√°t√©kosok id≈ësebbek, mint a m√°sodik b√°zisj√°t√©kosok
2. Az els≈ë b√°zisj√°t√©kosok magasabbak, mint a harmadik b√°zisj√°t√©kosok
3. A shortstopok magasabbak, mint a m√°sodik b√°zisj√°t√©kosok

## [Ut√≥-el≈ëad√°s kv√≠z](https://ff-quizzes.netlify.app/en/ds/quiz/7)

## √Åttekint√©s √©s √∂n√°ll√≥ tanul√°s

A val√≥sz√≠n≈±s√©g √©s statisztika olyan sz√©les t√©ma, hogy meg√©rdemel egy saj√°t kurzust. Ha m√©lyebben szeretne elmer√ºlni az elm√©letben, √©rdemes lehet folytatni az olvas√°st az al√°bbi k√∂nyvek k√∂z√ºl n√©h√°nyban:

1. [Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/) a New York-i Egyetemr≈ël nagyszer≈± el≈ëad√°sjegyzeteket k√©sz√≠tett [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (el√©rhet≈ë online)
1. [Peter √©s Andrew Bruce. Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[mintak√≥d R-ben](https://github.com/andrewgbruce/statistics-for-data-scientists)]. 
1. [James D. Miller. Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[mintak√≥d R-ben](https://github.com/PacktPublishing/Statistics-for-Data-Science)]

## Feladat

[Kis diab√©tesz tanulm√°ny](assignment.md)

## K√∂sz√∂netnyilv√°n√≠t√°s

Ezt a leck√©t ‚ô•Ô∏è-vel k√©sz√≠tette [Dmitry Soshnikov](http://soshnikov.com).

---

**Felel≈ëss√©g kiz√°r√°sa**:  
Ez a dokumentum az AI ford√≠t√°si szolg√°ltat√°s, a [Co-op Translator](https://github.com/Azure/co-op-translator) seg√≠ts√©g√©vel lett leford√≠tva. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Fontos inform√°ci√≥k eset√©n javasolt professzion√°lis emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get semmilyen f√©lre√©rt√©s√©rt vagy t√©ves √©rtelmez√©s√©rt, amely a ford√≠t√°s haszn√°lat√°b√≥l eredhet.