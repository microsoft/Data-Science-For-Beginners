{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# संभावना र तथ्यांकमा परिचय\n",
    "यस नोटबुकमा, हामी पहिले छलफल गरेका केही अवधारणाहरूलाई खेल्नेछौं। सम्भाव्यता र तथ्यांकका धेरै अवधारणाहरू पायथनमा डाटा प्रशोधनका लागि प्रमुख पुस्तकालयहरू जस्तै `numpy` र `pandas` मा राम्रोसँग प्रतिनिधित्व गरिन्छ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## र्याण्डम भेरीएबलहरू र वितरणहरू\n",
    "हामी 0 देखि 9 सम्मको युनिफर्म वितरणबाट 30 मानहरूको नमूना खिच्नेछौं। हामी माध्य र विचलन पनि गणना गर्नेछौं।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [ random.randint(0,10) for _ in range(30) ]\n",
    "print(f\"Sample: {sample}\")\n",
    "print(f\"Mean = {np.mean(sample)}\")\n",
    "print(f\"Variance = {np.var(sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "नमूनामा कति फरक मानहरू छन् भनी दृश्य रूपमा अनुमान लगाउनका लागि, हामी **हिस्टोग्राम** प्लट गर्न सक्छौं:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## वास्तविक डाटा विश्लेषण\n",
    "\n",
    "औसत र परिवर्तनशीलता वास्तविक-विश्व डाटा विश्लेषण गर्दा धेरै महत्वपूर्ण हुन्छन्। आउनुहोस् [SOCR MLB Height/Weight Data](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) बाट बेसबल खेलाडीहरूको डाटा लोड गरौं।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/SOCR_MLB.tsv\",sep='\\t', header=None, names=['Name','Team','Role','Weight','Height','Age'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> हामी यहाँ डाटा विश्लेषणको लागि [**Pandas**](https://pandas.pydata.org/) नामक प्याकेज प्रयोग गर्दैछौं। हामी यो कोर्समा पछि Pandas र Python मा डाटासँग कसरी काम गर्ने बारे थप कुरा गर्नेछौं।\n",
    "\n",
    "आयु, उचाइ र तौलको औसत मानहरू गणना गरौं:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Age','Height','Weight']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "अब हाम्रा ध्यान उचाइमा केन्द्रित गरौं, र मानक विचलन र विचरण गणना गरौं:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df['Height'])[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df['Height'].mean()\n",
    "var = df['Height'].var()\n",
    "std = df['Height'].std()\n",
    "print(f\"Mean = {mean}\\nVariance = {var}\\nStandard Deviation = {std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "औसतसँगै, मध्य मान र क्वारटाइलहरूमा पनि ध्यान दिन उचित हुन्छ। तिनीहरूलाई **बक्स प्लट** प्रयोग गरी दृश्यात्मक रूप दिन सकिन्छ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2))\n",
    "plt.boxplot(df['Height'].ffill(), vert=False, showmeans=True)\n",
    "plt.grid(color='gray', linestyle='dotted')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "हामी हाम्रो डेटासेटका उपसमूहहरूको बक्स प्लटहरू पनि बनाउन सक्छौं, उदाहरणका लागि, खेलाडीको भूमिकाले समूहबद्ध गरेर।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='Height', by='Role', figsize=(10,8))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **नोट**: यो चित्रले सुझाव दिन्छ कि औसतमा, प्रथम बेसम्यानको उचाइ दोस्रो बेसम्यानको ऊचाइभन्दा बढी हुन्छ। पछि हामी सिक्नेछौं कि कसरी हामी यो परिकल्पनालाई औपचारिक रूपमा परीक्षण गर्न सकिन्छ, र कसरी देखाउन सकिन्छ कि हाम्रो डेटा सांख्यिकीय रूपमा महत्वपूर्ण छ।  \n",
    "\n",
    "उमेर, उचाइ र वजन सबै निरन्तर यादृच्छिक चरहरू हुन्। तपाईंले के सोच्नुहुन्छ तिनीहरूको वितरण के हो? यसको पत्ता लगाउनको लागि राम्रो तरिका भनेको मानहरूको हिस्टोग्राम प्लट गर्नु हो: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weight'].hist(bins=15, figsize=(10,6))\n",
    "plt.suptitle('Weight distribution of MLB Players')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Distribution\n",
    "\n",
    "हामीसँगको वास्तविक डेटा जस्तै उस्तै औसत र विचलन हुने सामान्य वितरणको पालना गर्ने तौलहरूको कृत्रिम नमूना बनाउँछौं:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = np.random.normal(mean, std, 1000)\n",
    "generated[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(generated, bins=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(np.random.normal(0,1,50000), bins=300)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "किनभने वास्तविक जीवनका अधिकांश मानहरू सामान्य रूपमा वितरण हुन्छन्, हामीले नमूना डाटा सिर्जना गर्न एकरूप यादृच्छिक संख्या उत्पन्नकर्ता प्रयोग गर्नु हुँदैन। यदि हामी एकरूप वितरण (जसलाई `np.random.rand` द्वारा सिर्जना गरिएको छ) सँग तौलहरू सिर्जना गर्न प्रयास गर्छौं भने के हुन्छ यहाँ छ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_sample = np.random.rand(1000)*2*std+mean-std\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(wrong_sample)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## विश्वास अन्तरालहरू\n",
    "\n",
    "अब हामी बेसबल खेलाडीहरूको तौल र उचाइको लागि विश्वास अन्तराल गणना गर्ने छौं। हामी यो कोड प्रयोग गर्नेछौं [यस stackoverflow छलफलबाट](https://stackoverflow.com/questions/15033511/compute-a-confidence-interval-from-sample-data):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, h\n",
    "\n",
    "for p in [0.85, 0.9, 0.95]:\n",
    "    m, h = mean_confidence_interval(df['Weight'].fillna(method='pad'),p)\n",
    "    print(f\"p={p:.2f}, mean = {m:.2f} ± {h:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## परिकल्पना परीक्षण\n",
    "\n",
    "आउनुहोस् हाम्रा बेसबल खेलाडीहरूको डेटासेटमा विभिन्न भूमिकाहरू अन्वेषण गरौं:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Role').agg({ 'Weight' : 'mean', 'Height' : 'mean', 'Age' : 'count'}).rename(columns={ 'Age' : 'Count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "चलिए यो परिकल्पनाको परीक्षण गरौं कि पहिलो बेसम्यानहरू दोस्रो बेसम्यानहरू भन्दा अग्ला हुन्छन्। यो गर्नको सबैभन्दा सरल तरिका हो विश्वस्तता अन्तरालहरूको परीक्षण गर्नु:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [0.85,0.9,0.95]:\n",
    "    m1, h1 = mean_confidence_interval(df.loc[df['Role']=='First_Baseman',['Height']],p)\n",
    "    m2, h2 = mean_confidence_interval(df.loc[df['Role']=='Second_Baseman',['Height']],p)\n",
    "    print(f'Conf={p:.2f}, 1st basemen height: {m1-h1[0]:.2f}..{m1+h1[0]:.2f}, 2nd basemen height: {m2-h2[0]:.2f}..{m2+h2[0]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "हामीले देख्न सक्छौं कि इन्टरवलहरूले ओभरल्याप गर्दैनन्।\n",
    "\n",
    "एक तथ्याङ्कीय रूपमा अझ सही तरिका हाइपोथेसिस प्रमाणित गर्नको लागि **स्टुडेन्ट t-परीक्षण** प्रयोग गर्नु हो:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Second_Baseman',['Height']],equal_var=False)\n",
    "print(f\"T-value = {tval[0]:.2f}\\nP-value: {pval[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ttest_ind` फंक्शनले फर्काउने दुई मानहरू हुन्:\n",
    "* p-value लाई दुई वितरणहरूको एउटै मध्यमान हुने सम्भावना रूपमा मान्न सकिन्छ। हाम्रो अवस्थामा, यो धेरै कम छ, जसको अर्थ पहिलो बेसम्यानहरू उच्च हुने बलियो प्रमाण छ।\n",
    "* t-value भनेको सामान्यीकृत मध्यमान भिन्नताको मध्यवर्ती मान हो जुन t-test मा प्रयोग हुन्छ, र यो दिइएको आत्मविश्वास मानको लागि एउटा थ्रेसहोल्ड मानसँग तुलना गरिन्छ।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## केन्द्रीय सीमा प्रमेयको साथ सामान्य वितरणको अनुकरण\n",
    "\n",
    "Python मा छोली-र्यान्डम जेनरेटरलाई सिधा समान वितरण दिनको लागि डिजाइन गरिएको छ। यदि हामी सामान्य वितरणको लागि जेनरेटर बनाउन चाहन्छौं भने हामी केन्द्रीय सीमा प्रमेय प्रयोग गर्न सक्छौं। सामान्य वितरण गरिएको मान प्राप्त गर्न हामी केवल समान-जनरेट गरिएको नमुना को औसत गणना गर्नेछौं।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_random(sample_size=100):\n",
    "    sample = [random.uniform(0,1) for _ in range(sample_size) ]\n",
    "    return sum(sample)/sample_size\n",
    "\n",
    "sample = [normal_random() for _ in range(100)]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(sample)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## सहसम्बन्ध र दुष्ट बेसबल कर्पोरेशन\n",
    "\n",
    "सहसम्बन्धले हामीलाई डेटा अनुक्रमहरू बीच सम्बन्ध पत्ता लगाउन अनुमति दिन्छ। हाम्रो खेलौना उदाहरणमा, मानौं त्यहाँ एक दुष्ट बेसबल कर्पोरेशन छ जसले आफ्ना खेलाडीहरूलाई उचाइ अनुसार तलब दिन्छ - खेलाडी जतिसुकै लामा हुन्छ, उसलाई त्यति नै धेरै पैसा मिल्छ। मानौं आधारभूत तलब $1000 छ, र उचाइको आधारमा $0 देखि $100 सम्म अतिरिक्त बोनस दिइन्छ। हामी MLB का वास्तविक खेलाडीहरू लिनेछौं, र उनीहरूको काल्पनिक तलबहरू गणना गर्नेछौं:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = df['Height'].fillna(method='pad')\n",
    "salaries = 1000+(heights-heights.min())/(heights.max()-heights.mean())*100\n",
    "print(list(zip(heights, salaries))[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "अब ती श्रृंखलाहरूको सहसंबंध र सहसंबंध गणना गरौं। `np.cov` ले हामीलाई तथाकथित **सहसंबंध म्याट्रिक्स** दिनेछ, जुन बहु चरहरूमा सहसंबंधको विस्तार हो। सहसंबंध म्याट्रिक्स $M$ को तत्त्व $M_{ij}$ इनपुट चरहरू $X_i$ र $X_j$ बीचको सहसंबंध हो, र विकर्ण मानहरू $M_{ii}$ $X_i$ को वैरिएन्स हो। त्यसैगरी, `np.corrcoef` ले हामीलाई **सहसंबंध म्याट्रिक्स** दिनेछ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Covariance matrix:\\n{np.cov(heights, salaries)}\")\n",
    "print(f\"Covariance = {np.cov(heights, salaries)[0,1]}\")\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "एक सहसंबन्ध १ बराबर हुनुको अर्थ दुई चलहरूमाबीच **रेखीय सम्बन्ध** बलियो छ। हामी एक मानलाई अर्कोको विरुद्ध चित्रण गरेर रेखीय सम्बन्ध देख्न सक्छौं:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(heights,salaries)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "हेरौं के हुन्छ यदि सम्बन्ध रैखिक नहोस्। मानौं हाम्रो कम्पनीले उचाइ र तलबबीचको स्पष्ट रैखिक निर्भरतालाई लुकाउने निर्णय गर्‍यो, र सूत्रमा केहि गैर-रैखिकता परिचय गरायो, जस्तै `sin`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = 1000+np.sin((heights-heights.min())/(heights.max()-heights.mean()))*100\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "यस अवस्थामा, सहसंबन्ध केही कम छ, तर यो अझै पनि धेरै उच्च छ। अब, सम्बन्धलाई अझ कम स्पष्ट बनाउनका लागि, हामीले तलबमा केही अनियमित चर थपेर थप अनिश्चितता जोड्न सक्छौं। हेर्नुहोस् के हुन्छ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = 1000+np.sin((heights-heights.min())/(heights.max()-heights.mean()))*100+np.random.random(size=len(heights))*20-10\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(heights, salaries)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> के तपाईं अनुमान लगाउन सक्नुहुन्छ किन डटहरू यसरी ठाडो रेखामा सँगै मिल्छन्?\n",
    "\n",
    "हामीले तलब जस्ता कृत्रिम रूपमा बनाइएका अवधारणा र अवलोकन गरिएको चर *उचाइ* बीचको सम्बन्ध देख्यौं। अब हेरौं यदि दुई अवलोकन गरिएका चरहरू, जस्तै उचाइ र वजन, पनि सम्बन्धित छन् कि छैनन्:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df['Height'].ffill(),df['Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "दुर्भाग्यवश, हामीले कुनै परिणाम पाउन सकेनौं - केवल केही अनौठो `nan` मानहरू मात्र पाइयो। यसको कारण हाम्रो सिरिजमा भएका केही मानहरू अनिर्धारित छन्, जसलाई `nan` को रूपमा प्रतिनिधित्व गरिएको छ, जसले गर्दा अपरेसनको परिणाम पनि अनिर्धारित हुन्छ। म्याट्रिक्स हेर्दा हामी देख्न सक्छौं कि `Weight` समस्या भएको स्तम्भ हो, किनभने `Height` मानहरू बीचको आत्म-सहसंबन्ध गणना गरिएको छ।\n",
    "\n",
    "> यस उदाहरणले **डाटा तयार पार्ने** र **सफा गर्ने** महत्त्व देखाउँछ। उचित डाटा बिना हामी केही पनि गणना गर्न सक्दैनौं।\n",
    "\n",
    "आउनुहोस् `fillna` विधि प्रयोग गरी अभाव भएका मानहरू भर्न र सहसंबन्ध गणना गरौं: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df['Height'].fillna(method='pad'), df['Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "त्यसमा साँच्चिकै एक सम्बन्ध छ, तर हाम्रो कृत्रिम उदाहरणमा जस्तो बलियो छैन। साँच्चै, यदि हामी एउटालाई अर्कोसँग तुलना गर्ने स्क्याटर प्लटमा हेर्छौं भने, सम्बन्ध धेरै कम स्पष्ट हुनेछ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(df['Weight'],df['Height'])\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Height')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "यस नोटबुकमा हामीले तथ्याङ्कीय कार्यहरू गणना गर्न डेटा माथि आधारभूत अपरेसनहरू कसरी गर्न सकिन्छ भन्ने सिक्यौं। अब हामीले केही परिकल्पनाहरू प्रमाणित गर्नका लागि गणित र तथ्यांकको एक बलियो उपकरण कसरी प्रयोग गर्ने, र डेटा नमूना दिईएका मनमाना चरहरूको लागि विश्वास अन्तर्वाल कसरी गणना गर्ने थाहा पाइसकेका छौं।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**अस्वीकरण**:  \nयो दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) प्रयोग गरेर अनुवाद गरिएको हो। हामी शुद्धताका लागि प्रयासरत छौं भने पनि, कृपया ज्ञात गर्नुहोस् कि स्वचालित अनुवादमा त्रुटि वा अशुद्धता हुनसक्छ। मूल दस्तावेज जस भाषामा छ, त्यो आधिकारिक स्रोत मान्नुपर्दछ। महत्वपूर्ण जानकारीका लागि, पेशेवर मानव अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न हुने कुनै पनि गलतफहमी वा गलत व्याख्याका लागि हामी जिम्मेवार छैनौं।\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86193a1ab0ba47eac1c69c1756090baa3b420b3eea7d4aafab8b85f8b312f0c5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "coopTranslator": {
   "original_hash": "0f899e3c5019f948e7c787b22f3b2304",
   "translation_date": "2026-01-16T11:54:01+00:00",
   "source_file": "1-Introduction/04-stats-and-probability/notebook.ipynb",
   "language_code": "ne"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}