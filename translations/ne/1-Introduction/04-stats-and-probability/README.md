<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1cf49f029ba1f25a54f0d5bc2fa575fc",
  "translation_date": "2025-09-06T07:51:51+00:00",
  "source_file": "1-Introduction/04-stats-and-probability/README.md",
  "language_code": "ne"
}
-->
# तथ्यांक र सम्भाव्यता: एक संक्षिप्त परिचय

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/04-Statistics-Probability.png)|
|:---:|
| तथ्यांक र सम्भाव्यता - _Sketchnote by [@nitya](https://twitter.com/nitya)_ |

तथ्यांक र सम्भाव्यता सिद्धान्त गणितका दुई आपसमा गहिरो सम्बन्ध भएका क्षेत्रहरू हुन्, जसको डेटा विज्ञानमा ठूलो महत्त्व छ। गहिरो गणितीय ज्ञान बिना पनि डेटा प्रयोग गर्न सकिन्छ, तर केही आधारभूत अवधारणाहरू थाहा हुनु राम्रो हुन्छ। यहाँ हामी तपाईंलाई सुरु गर्न मद्दत गर्ने छोटो परिचय प्रस्तुत गर्नेछौं।

[![Intro Video](../../../../1-Introduction/04-stats-and-probability/images/video-prob-and-stats.png)](https://youtu.be/Z5Zy85g4Yjw)

## [पाठपूर्व प्रश्नोत्तरी](https://ff-quizzes.netlify.app/en/ds/quiz/6)

## सम्भाव्यता र र्‍यान्डम भेरिएबलहरू

**सम्भाव्यता** ० देखि १ को बीचको संख्या हो, जसले कुनै **घटना** कति सम्भावित छ भन्ने जनाउँछ। यो सकारात्मक परिणामहरूको संख्या (जसले घटनालाई निम्त्याउँछ) लाई कुल परिणामहरूको संख्याले भाग गरेर परिभाषित गरिन्छ, यदि सबै परिणामहरू समान सम्भावित छन् भने। उदाहरणका लागि, जब हामी पासा फाल्छौं, सम संख्या आउने सम्भाव्यता 3/6 = 0.5 हुन्छ।

जब हामी घटनाहरूको कुरा गर्छौं, हामी **र्‍यान्डम भेरिएबलहरू** प्रयोग गर्छौं। उदाहरणका लागि, पासा फाल्दा आउने संख्यालाई प्रतिनिधित्व गर्ने र्‍यान्डम भेरिएबलले १ देखि ६ सम्मका मानहरू लिन्छ। १ देखि ६ सम्मको संख्याको समूहलाई **नमूना स्थान (sample space)** भनिन्छ। हामी कुनै निश्चित मान लिन र्‍यान्डम भेरिएबलको सम्भाव्यताको बारेमा कुरा गर्न सक्छौं, जस्तै P(X=3)=1/6।

माथिको उदाहरणमा रहेको र्‍यान्डम भेरिएबललाई **डिस्क्रिट (discrete)** भनिन्छ, किनभने यसको नमूना स्थान गणनायोग्य छ, अर्थात् छुट्टाछुट्टै मानहरू छन् जसलाई गन्न सकिन्छ। केही अवस्थामा नमूना स्थान वास्तविक संख्याहरूको दायरा वा सम्पूर्ण वास्तविक संख्याहरूको समूह हुन सक्छ। यस्ता भेरिएबलहरूलाई **कन्टिनुअस (continuous)** भनिन्छ। बस आउने समय यसको राम्रो उदाहरण हो।

## सम्भाव्यता वितरण

डिस्क्रिट र्‍यान्डम भेरिएबलहरूको सन्दर्भमा, प्रत्येक घटनाको सम्भाव्यता P(X) नामक एक प्रकार्यद्वारा वर्णन गर्न सजिलो हुन्छ। नमूना स्थान *S* बाट प्रत्येक मान *s* का लागि यसले ० देखि १ सम्मको संख्या दिन्छ, जसले गर्दा सबै घटनाहरूको लागि P(X=s) को मानहरूको योग १ हुन्छ।

सबैभन्दा प्रख्यात डिस्क्रिट वितरण **यूनिफर्म वितरण** हो, जसमा N तत्त्वहरूको नमूना स्थान हुन्छ, र प्रत्येकको सम्भाव्यता 1/N हुन्छ।

कन्टिनुअस भेरिएबलको सम्भाव्यता वितरण वर्णन गर्न भने अलि गाह्रो हुन्छ, जसका मानहरू [a,b] को अन्तराल वा सम्पूर्ण वास्तविक संख्याहरू ℝ बाट लिइन्छ। बस आउने समयको उदाहरणलाई विचार गर्नुहोस्। वास्तवमा, कुनै निश्चित समय *t* मा बस आउने सम्भाव्यता ० हुन्छ!

> अब तपाईंलाई थाहा भयो कि ० सम्भाव्यता भएका घटनाहरू पनि हुन्छन्, र धेरै पटक हुन्छन्! कम्तीमा बस आउने प्रत्येक पटक!

हामी केवल कुनै भेरिएबलले निश्चित मानहरूको अन्तरालमा पर्ने सम्भाव्यताको कुरा गर्न सक्छौं, जस्तै P(t<sub>1</sub>≤X<t<sub>2</sub>)। यस अवस्थामा, सम्भाव्यता वितरणलाई **सम्भाव्यता घनत्व प्रकार्य (probability density function)** p(x) द्वारा वर्णन गरिन्छ, जसले

![P(t_1\le X<t_2)=\int_{t_1}^{t_2}p(x)dx](../../../../1-Introduction/04-stats-and-probability/images/probability-density.png)

कन्टिनुअस यूनिफर्म वितरणको निरन्तर संस्करणलाई **कन्टिनुअस यूनिफर्म** भनिन्छ, जुन सीमित अन्तरालमा परिभाषित हुन्छ। मान X ले लम्बाइ l को अन्तरालमा पर्ने सम्भाव्यता l को समानुपातिक हुन्छ, र १ सम्म पुग्छ।

अर्को महत्त्वपूर्ण वितरण **नर्मल वितरण** हो, जसको बारेमा हामी तल विस्तृत रूपमा कुरा गर्नेछौं।

## माध्य, विचलन र मानक विचलन

मानौं हामीले र्‍यान्डम भेरिएबल X का n नमूनाहरूको शृंखला लियौं: x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>n</sub>। हामी शृंखलाको **माध्य (mean)** (वा **गणितीय औसत**) परम्परागत तरिकाले परिभाषित गर्न सक्छौं: (x<sub>1</sub>+x<sub>2</sub>+x<sub>n</sub>)/n। जब हामी नमूनाको आकार बढाउँछौं (अर्थात् n→∞ को सिमामा जान्छौं), हामी वितरणको माध्य (जसलाई **अपेक्षा (expectation)** पनि भनिन्छ) प्राप्त गर्नेछौं। हामी अपेक्षालाई **E**(x) द्वारा जनाउँछौं।

> यो देखाउन सकिन्छ कि कुनै पनि डिस्क्रिट वितरणका लागि, जसका मानहरू {x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>N</sub>} र तिनीहरूका सम्भाव्यताहरू p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N</sub> छन्, अपेक्षा E(X)=x<sub>1</sub>p<sub>1</sub>+x<sub>2</sub>p<sub>2</sub>+...+x<sub>N</sub>p<sub>N</sub> बराबर हुन्छ।

मानहरू कति फैलिएका छन् भनेर थाहा पाउन, हामी विचलन σ<sup>2</sup> = ∑(x<sub>i</sub> - μ)<sup>2</sup>/n गणना गर्न सक्छौं, जहाँ μ शृंखलाको माध्य हो। मान σ लाई **मानक विचलन (standard deviation)** भनिन्छ, र σ<sup>2</sup> लाई **विचलन (variance)** भनिन्छ।

## मोड, माध्यिका र क्वार्टाइलहरू

कहिलेकाहीँ, माध्यले डेटा प्रतिनिधित्व गर्न पर्याप्त हुँदैन। उदाहरणका लागि, जब केही अत्यधिक मानहरू हुन्छन्, जसले माध्यलाई प्रभाव पार्न सक्छ। अर्को राम्रो सूचक **माध्यिका (median)** हो, जुन यस्तो मान हो कि आधा डेटा बिन्दुहरू यसभन्दा कम हुन्छन्, र आधा बढी।

डेटाको वितरण बुझ्न, **क्वार्टाइलहरू** को कुरा गर्नु उपयोगी हुन्छ:

* पहिलो क्वार्टाइल, वा Q1, यस्तो मान हो, जसभन्दा तल २५% डेटा पर्छ
* तेस्रो क्वार्टाइल, वा Q3, यस्तो मान हो, जसभन्दा तल ७५% डेटा पर्छ

ग्राफिकल रूपमा, हामी माध्यिका र क्वार्टाइलहरूको सम्बन्धलाई **बक्स प्लट (box plot)** मा देखाउन सक्छौं:

<img src="images/boxplot_explanation.png" width="50%"/>

यहाँ हामी **इन्टर-क्वार्टाइल रेन्ज (IQR)** = Q3-Q1 पनि गणना गर्छौं, र तथाकथित **आउटलायर्स (outliers)** - यस्ता मानहरू, जुन [Q1-1.5*IQR, Q3+1.5*IQR] को सीमाभन्दा बाहिर पर्छन्।

यदि वितरणमा सम्भावित मानहरूको संख्या सानो छ भने, "सामान्य" मान त्यो हुन्छ, जुन सबैभन्दा धेरै पटक देखा पर्छ, जसलाई **मोड (mode)** भनिन्छ। यो प्रायः श्रेणीगत डेटा, जस्तै रङहरूमा लागू हुन्छ। उदाहरणका लागि, मानौं दुई समूहका मानिसहरू छन् - केहीले रातोलाई प्राथमिकता दिन्छन्, र केहीले नीलोलाई। यदि हामी रङहरूलाई संख्याले कोड गर्छौं भने, मनपर्ने रङको माध्य मान सुन्तला-हरियो स्पेक्ट्रममा कतै पर्छ, जसले कुनै पनि समूहको वास्तविक प्राथमिकता जनाउँदैन। तर, मोड भने या त कुनै एक रङ, वा दुवै रङ हुन सक्छ, यदि तिनीहरूको लागि मत दिने मानिसहरूको संख्या बराबर छ (यस अवस्थामा नमूनालाई **मल्टिमोडल** भनिन्छ)।

## वास्तविक जीवन डेटा

जब हामी वास्तविक जीवनको डेटा विश्लेषण गर्छौं, तिनीहरू प्रायः र्‍यान्डम भेरिएबलहरू जस्ता हुँदैनन्, किनभने हामी अज्ञात परिणामसहितको प्रयोग गर्दैनौं। उदाहरणका लागि, बेसबल खेलाडीहरूको टोलीलाई विचार गर्नुहोस्, र तिनीहरूको उचाइ, तौल र उमेर जस्ता शारीरिक डेटा। यी संख्याहरू ठ्याक्कै र्‍यान्डम हुँदैनन्, तर हामी अझै पनि उही गणितीय अवधारणाहरू लागू गर्न सक्छौं। उदाहरणका लागि, मानिसहरूको तौलको शृंखलालाई केही र्‍यान्डम भेरिएबलबाट लिइएको मानहरूको शृंखला मान्न सकिन्छ। तल [मेजर लिग बेसबल](http://mlb.mlb.com/index.jsp) का वास्तविक खेलाडीहरूको तौलको शृंखला छ, जुन [यस डेटासेट](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) बाट लिइएको हो (तपाईंको सुविधाका लागि, केवल पहिलो २० मानहरू देखाइएको छ):

```
[180.0, 215.0, 210.0, 210.0, 188.0, 176.0, 209.0, 200.0, 231.0, 180.0, 188.0, 180.0, 185.0, 160.0, 180.0, 185.0, 197.0, 189.0, 185.0, 219.0]
```

> **Note**: यस डेटासेटसँग काम गर्ने उदाहरण हेर्न, [संगत नोटबुक](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) हेर्नुहोस्। यस पाठभरि धेरै चुनौतीहरू छन्, र तपाईं केही कोड थपेर तिनीहरू पूरा गर्न सक्नुहुन्छ। यदि तपाईंलाई डेटा सञ्चालन गर्न थाहा छैन भने, चिन्ता नगर्नुहोस् - हामी पछि पाइथन प्रयोग गरेर डेटा सञ्चालनमा फर्कनेछौं। यदि तपाईंलाई Jupyter Notebook मा कोड कसरी चलाउने थाहा छैन भने, [यो लेख](https://soshnikov.com/education/how-to-execute-notebooks-from-github/) हेर्नुहोस्।

यहाँ हाम्रो डेटाको लागि माध्य, माध्यिका र क्वार्टाइलहरू देखाउने बक्स प्लट छ:

![Weight Box Plot](../../../../1-Introduction/04-stats-and-probability/images/weight-boxplot.png)

हाम्रो डेटामा विभिन्न खेलाडीका **भूमिकाहरू** को जानकारी समावेश भएकाले, हामी भूमिकाअनुसार बक्स प्लट पनि बनाउन सक्छौं - यसले हामीलाई बुझ्न मद्दत गर्छ कि कसरी मापदण्डहरू भूमिकाहरूमा फरक छन्। यस पटक हामी उचाइलाई विचार गर्नेछौं:

![Box plot by role](../../../../1-Introduction/04-stats-and-probability/images/boxplot_byrole.png)

यो चित्रले सुझाव दिन्छ कि, औसतमा, पहिलो बेसम्यानहरूको उचाइ दोस्रो बेसम्यानहरूको भन्दा बढी छ। यस पाठको पछि हामी सिक्नेछौं कि कसरी यो परिकल्पनालाई औपचारिक रूपमा परीक्षण गर्ने, र कसरी हाम्रो डेटा सांख्यिकीय रूपमा महत्त्वपूर्ण छ भनेर देखाउने।

> जब हामी वास्तविक जीवनको डेटामा काम गर्छौं, हामी मान्छौं कि सबै डेटा बिन्दुहरू केही सम्भाव्यता वितरणबाट लिइएका नमूनाहरू हुन्। यो मान्यताले हामीलाई मेसिन लर्निङ प्रविधिहरू लागू गर्न र काम गर्ने भविष्यवाणी मोडेलहरू निर्माण गर्न अनुमति दिन्छ।

हाम्रो डेटाको वितरण कस्तो छ भनेर हेर्न, हामी **हिस्टोग्राम** नामक ग्राफ बनाउन सक्छौं। X-अक्षमा विभिन्न तौल अन्तरालहरूको संख्या (जसलाई **बिनहरू** भनिन्छ) हुनेछ, र ठाडो अक्षमा हाम्रो र्‍यान्डम भेरिएबल नमूना दिइएको अन्तरालभित्र कति पटक थियो भन्ने देखाउनेछ।

![Histogram of real world data](../../../../1-Introduction/04-stats-and-probability/images/weight-histogram.png)

यस हिस्टोग्रामबाट तपाईं देख्न सक्नुहुन्छ कि सबै मानहरू निश्चित माध्य तौल वरिपरि केन्द्रित छन्, र हामी त्यो तौलबाट जति टाढा जान्छौं - त्यति नै कम तौलका मानहरू भेटिन्छन्। अर्थात्, बेसबल खेलाडीको तौल माध्य तौलभन्दा धेरै फरक हुने सम्भाव्यता धेरै कम छ। तौलहरूको विचलनले तौलहरू माध्यबाट कति फरक हुन सक्छन् भन्ने देखाउँछ।

> यदि हामी बेसबल लिग बाहेकका अन्य मानिसहरूको तौल लिन्छौं भने, वितरण फरक हुने सम्भावना छ। तर, वितरणको स्वरूप उस्तै हुनेछ, तर माध्य र विचलन परिवर्तन हुनेछ। त्यसैले, यदि हामीले हाम्रो मोडेल बेसबल खेलाडीहरूमा प्रशिक्षण गर्‍यौं भने, यो विश्वविद्यालयका विद्यार्थीहरूमा लागू गर्दा गलत परिणाम दिन सक्छ, किनभने आधारभूत वितरण फरक छ।

## नर्मल वितरण

हामीले माथि देखेको तौलहरूको वितरण धेरै सामान्य हो, र वास्तविक जीवनका धेरै मापनहरू उस्तै प्रकारको वितरण अनुसरण गर्छन्, तर फरक माध्य र विचलनका साथ। यस वितरणलाई **नर्मल वितरण** भनिन्छ, र यसले तथ्यांकमा धेरै महत्त्वपूर्ण भूमिका खेल्छ।

नर्मल वितरण प्रयोग गरेर सम्भावित बेसबल खेलाडीहरूको तौलहरू उत्पन्न गर्नु सही तरिका हो। एक पटक हामीलाई माध्य तौल `mean` र मानक विचलन `std` थाहा भयो भने, हामी १००० तौल नमूनाहरू निम्न तरिकाले उत्पन्न गर्न सक्छौं:
```python
samples = np.random.normal(mean,std,1000)
``` 

यदि हामी उत्पन्न नमूनाहरूको हिस्टोग्राम बनाउँछौं भने, हामी माथि देखाइएको चित्रसँग धेरै मिल्दोजुल्दो देख्नेछौं। र यदि हामी नमूनाहरूको संख्या र बिनहरूको संख्या बढाउँछौं भने, हामी नर्मल वितरणको झन् नजिकको आदर्श चित्र बनाउन सक्छौं:

![Normal Distribution with mean=0 and std.dev=1](../../../../1-Introduction/04-stats-and-probability/images/normal-histogram.png)

*माध्य=0 र मानक विचलन=1 भएको नर्मल वितरण*

## विश्वास अन्तराल (Confidence Intervals)

जब हामी बेसबल खेलाडीहरूको तौलको कुरा गर्छौं, हामी मान्छौं कि त्यहाँ निश्चित **र्‍यान्डम भेरिएबल W** छ, जसले सबै बेसबल खेलाडीहरूको तौलको आदर्श सम्भाव्यता वितरणलाई प्रतिनिधित्व गर्छ (जसलाई **आबादी (population)** भनिन्छ)। हाम्रो तौलहरूको शृंखला सबै बेसबल खेलाडीहरूको उपसमूह हो, जसलाई हामी **नमूना (sample)** भन्छौं। एउटा रोचक प्रश्न यो हो कि, के हामी W को वितरणका मापदण्डहरू, अर्थात् आबादीको माध्य र विचलन थाहा पाउन सक्छौं?

सबैभन्दा सजिलो उत्तर भनेको हाम्रो नमूनाको माध्य र विचलन गणना गर्नु हो। तर, यस्तो हुन सक्छ कि हाम्रो र्‍यान्डम नमूनाले सम्पूर्ण आबादीलाई सही रूपमा प्रतिनिधित्व गर्दैन। त्यसैले **विश्वास अन्तराल** को कुरा गर्नु उचित हुन्छ।

> **विश्वास अन्तराल** भनेको हाम्रो नमूनालाई दिइएको आबादीको वास्तविक माध्यको अनुमान हो, जुन निश्चित सम्भाव्यता (वा **विश्वासको स्तर**) मा सही हुन्छ।

1</sub>, ..., X<sub>n</sub> हाम्रो वितरणबाट। प्रत्येक पटक हामी हाम्रो वितरणबाट नमूना लिन्छौं, हामी फरक औसत मान μ पाउँछौं। त्यसैले μ लाई एक यादृच्छिक चर मान्न सकिन्छ। **विश्वास अन्तराल** विश्वास p संग दुई मानहरूको जोडी हो (L<sub>p</sub>,R<sub>p</sub>), जसमा **P**(L<sub>p</sub>≤μ≤R<sub>p</sub>) = p, अर्थात् मापन गरिएको औसत मान अन्तराल भित्र पर्ने सम्भावना p बराबर हुन्छ।

विश्वास अन्तराल कसरी गणना गरिन्छ भन्ने विस्तृत चर्चा हाम्रो छोटो परिचय भन्दा बाहिर जान्छ। थप विवरण [विकिपिडिया](https://en.wikipedia.org/wiki/Confidence_interval) मा भेट्न सकिन्छ। संक्षेपमा, हामी जनसंख्याको वास्तविक औसतको सापेक्ष गणना गरिएको नमूना औसतको वितरणलाई परिभाषित गर्छौं, जसलाई **स्टुडेन्ट वितरण** भनिन्छ।

> **रोचक तथ्य**: स्टुडेन्ट वितरणको नाम गणितज्ञ विलियम सीली गोसेटको नाममा राखिएको हो, जसले आफ्नो कागज "स्टुडेन्ट" उपनाम अन्तर्गत प्रकाशित गरेका थिए। उनी गिनीज ब्रुअरीमा काम गर्थे, र, एउटा संस्करण अनुसार, उनको नियोक्ताले कच्चा सामग्रीको गुणस्तर निर्धारण गर्न सांख्यिकीय परीक्षण प्रयोग गरिरहेको कुरा सार्वजनिकलाई थाहा होस् भन्ने चाहँदैनथे।

यदि हामी हाम्रो जनसंख्याको औसत μ विश्वास p संग अनुमान गर्न चाहन्छौं भने, हामीलाई स्टुडेन्ट वितरण A को *(1-p)/2-थ प्रतिशतक* लिनु पर्छ, जुन तालिकाबाट लिइन सक्छ, वा सांख्यिकीय सफ्टवेयर (जस्तै Python, R, आदि) को केही बिल्ट-इन फङ्सन प्रयोग गरेर गणना गर्न सकिन्छ। त्यसपछि μ को लागि अन्तराल X±A*D/√n हुनेछ, जहाँ X नमूनाको प्राप्त औसत हो, D मानक विचलन हो।

> **नोट**: हामी [डिग्री अफ फ्रिडम](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)) को महत्त्वपूर्ण अवधारणाको चर्चा पनि छोड्छौं, जुन स्टुडेन्ट वितरणसँग सम्बन्धित छ। यो अवधारणालाई गहिरो रूपमा बुझ्नको लागि सांख्यिकीमा पूर्ण पुस्तकहरू हेर्न सकिन्छ।

वजन र उचाइको लागि विश्वास अन्तराल गणना गर्ने उदाहरण [संग्लग्न नोटबुकहरू](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) मा दिइएको छ।

| p | वजन औसत |
|-----|-----------|
| 0.85 | 201.73±0.94 |
| 0.90 | 201.73±1.08 |
| 0.95 | 201.73±1.28 |

ध्यान दिनुहोस् कि विश्वास सम्भावना उच्च भएमा, विश्वास अन्तराल चौडा हुन्छ।

## परिकल्पना परीक्षण

हाम्रो बेसबल खेलाडीहरूको डेटासेटमा विभिन्न खेलाडी भूमिकाहरू छन्, जसलाई तल संक्षेपमा प्रस्तुत गर्न सकिन्छ (यो तालिका कसरी गणना गर्न सकिन्छ हेर्न [संग्लग्न नोटबुक](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) हेर्नुहोस्):

| भूमिका | उचाइ | वजन | संख्या |
|------|--------|--------|-------|
| क्याचर | 72.723684 | 204.328947 | 76 |
| डिजिनेटेड_हिटर | 74.222222 | 220.888889 | 18 |
| फर्स्ट_बेसम्यान | 74.000000 | 213.109091 | 55 |
| आउटफिल्डर | 73.010309 | 199.113402 | 194 |
| रिलिफ_पिचर | 74.374603 | 203.517460 | 315 |
| सेकेन्ड_बेसम्यान | 71.362069 | 184.344828 | 58 |
| सर्टस्टप | 71.903846 | 182.923077 | 52 |
| स्टार्टिंग_पिचर | 74.719457 | 205.163636 | 221 |
| थर्ड_बेसम्यान | 73.044444 | 200.955556 | 45 |

हामी देख्न सक्छौं कि फर्स्ट बेसम्यानको औसत उचाइ सेकेन्ड बेसम्यानको भन्दा बढी छ। त्यसैले, हामी **फर्स्ट बेसम्यान सेकेन्ड बेसम्यानभन्दा अग्लो हुन्छन्** भन्ने निष्कर्ष निकाल्न इच्छुक हुन सक्छौं।

> यो कथनलाई **परिकल्पना** भनिन्छ, किनभने हामीलाई थाहा छैन कि यो तथ्य वास्तवमा सत्य हो वा होइन।

तर, यो निष्कर्ष निकाल्न सकिन्छ कि छैन भन्ने कुरा सधैं स्पष्ट हुँदैन। माथिको छलफलबाट हामी जान्दछौं कि प्रत्येक औसतसँग सम्बन्धित विश्वास अन्तराल हुन्छ, र यो भिन्नता केवल सांख्यिकीय त्रुटि हुन सक्छ। हामीलाई हाम्रो परिकल्पनाको परीक्षण गर्न थप औपचारिक तरिका चाहिन्छ।

हामी फर्स्ट र सेकेन्ड बेसम्यानको उचाइको लागि विश्वास अन्तराल अलग-अलग गणना गरौं:

| विश्वास | फर्स्ट बेसम्यान | सेकेन्ड बेसम्यान |
|------------|---------------|----------------|
| 0.85 | 73.62..74.38 | 71.04..71.69 |
| 0.90 | 73.56..74.44 | 70.99..71.73 |
| 0.95 | 73.47..74.53 | 70.92..71.81 |

हामी देख्न सक्छौं कि कुनै पनि विश्वासमा अन्तरालहरू ओभरल्याप गर्दैनन्। यसले हाम्रो परिकल्पनालाई प्रमाणित गर्दछ कि फर्स्ट बेसम्यान सेकेन्ड बेसम्यानभन्दा अग्लो हुन्छन्।

अझ औपचारिक रूपमा, हामीले समाधान गर्न खोजिरहेको समस्या भनेको **दुई सम्भाव्यता वितरणहरू समान छन् कि छैनन्**, वा कम्तीमा समान प्यारामिटरहरू छन्। वितरणको आधारमा, हामीले त्यसका लागि विभिन्न परीक्षणहरू प्रयोग गर्नुपर्छ। यदि हामीलाई थाहा छ कि हाम्रो वितरणहरू सामान्य छन्, हामी **[स्टुडेन्ट टि-टेस्ट](https://en.wikipedia.org/wiki/Student%27s_t-test)** लागू गर्न सक्छौं।

स्टुडेन्ट टि-टेस्टमा, हामी तथाकथित **t-value** गणना गर्छौं, जसले औसतहरू बीचको भिन्नता संकेत गर्दछ, विचलनलाई ध्यानमा राख्दै। यो देखाइएको छ कि t-value **स्टुडेन्ट वितरण** अनुसरण गर्दछ, जसले हामीलाई दिइएको विश्वास स्तर **p** को लागि थ्रेसहोल्ड मान प्राप्त गर्न अनुमति दिन्छ (यो गणना गर्न सकिन्छ, वा संख्यात्मक तालिकाहरूमा हेर्न सकिन्छ)। त्यसपछि हामी t-value लाई यो थ्रेसहोल्डसँग तुलना गर्छौं ताकि परिकल्पनालाई स्वीकृत वा अस्वीकृत गर्न सकिन्छ।

Python मा, हामी **SciPy** प्याकेज प्रयोग गर्न सक्छौं, जसमा `ttest_ind` फङ्सन समावेश छ (थुप्रै अन्य उपयोगी सांख्यिकीय फङ्सनहरू सहित!)। यसले हाम्रो लागि t-value गणना गर्छ, र विश्वास p-value को रिभर्स लुकअप पनि गर्छ, ताकि हामी केवल विश्वासलाई हेरेर निष्कर्ष निकाल्न सकौं।

उदाहरणका लागि, फर्स्ट र सेकेन्ड बेसम्यानको उचाइको तुलना गर्दा हामीलाई निम्न परिणाम प्राप्त हुन्छ:
```python
from scipy.stats import ttest_ind

tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Designated_Hitter',['Height']],equal_var=False)
print(f"T-value = {tval[0]:.2f}\nP-value: {pval[0]}")
```
```
T-value = 7.65
P-value: 9.137321189738925e-12
```
हाम्रो केसमा, p-value धेरै कम छ, जसको अर्थ फर्स्ट बेसम्यान अग्लो हुने बलियो प्रमाण छ।

त्यहाँ अन्य विभिन्न प्रकारका परिकल्पनाहरू पनि छन् जुन हामी परीक्षण गर्न चाहन सक्छौं, उदाहरणका लागि:
* कुनै नमूना कुनै वितरण अनुसरण गर्छ भन्ने प्रमाणित गर्न। हाम्रो केसमा हामीले मान्य गरेका छौं कि उचाइहरू सामान्य रूपमा वितरण गरिएका छन्, तर त्यसलाई औपचारिक सांख्यिकीय प्रमाण चाहिन्छ।
* नमूनाको औसत मान कुनै पूर्वनिर्धारित मानसँग मेल खान्छ भन्ने प्रमाणित गर्न
* विभिन्न नमूनाहरूको औसत तुलना गर्न (जस्तै, विभिन्न उमेर समूहहरू बीचको खुशी स्तरको भिन्नता के हो)

## ठूलो संख्याको नियम र केन्द्रीय सीमा प्रमेय

सामान्य वितरण किन महत्त्वपूर्ण छ भन्ने कारण मध्ये एक **केन्द्रीय सीमा प्रमेय** हो। मानौं हामीसँग स्वतन्त्र N मानहरूको ठूलो नमूना छ X<sub>1</sub>, ..., X<sub>N</sub>, जुन कुनै पनि वितरणबाट औसत μ र विचलन σ<sup>2</sup> संग नमूना गरिएको छ। त्यसपछि, पर्याप्त ठूलो N को लागि (अर्को शब्दमा, जब N→∞), औसत Σ<sub>i</sub>X<sub>i</sub> सामान्य रूपमा वितरण गरिनेछ, औसत μ र विचलन σ<sup>2</sup>/N संग।

> केन्द्रीय सीमा प्रमेयलाई व्याख्या गर्ने अर्को तरिका भनेको भन्नु हो कि वितरणको पर्वाह नगरी, जब तपाईं कुनै यादृच्छिक चर मानहरूको योगको औसत गणना गर्नुहुन्छ, तपाईं सामान्य वितरणमा पुग्नुहुन्छ।

केन्द्रीय सीमा प्रमेयबाट यो पनि निष्कर्ष निकाल्न सकिन्छ कि, जब N→∞, नमूनाको औसत μ बराबर हुने सम्भावना 1 हुन्छ। यसलाई **ठूलो संख्याको नियम** भनिन्छ।

## सहसंबंध र सहविचलन

डेटा विज्ञानले गर्ने कामहरू मध्ये एक भनेको डेटा बीचको सम्बन्ध पत्ता लगाउनु हो। हामी भन्छौं कि दुई क्रमहरू **सहसंबद्ध** छन् जब तिनीहरूले एकै समयमा समान व्यवहार देखाउँछन्, अर्थात् तिनीहरू एकसाथ बढ्छन्/घट्छन्, वा एउटा क्रम बढ्दा अर्को घट्छ र उल्टो। अर्को शब्दमा, दुई क्रमहरू बीच केही सम्बन्ध देखिन्छ।

> सहसंबंधले दुई क्रमहरू बीचको कारणात्मक सम्बन्धलाई अनिवार्य रूपमा संकेत गर्दैन; कहिलेकाहीं दुवै चरहरू केही बाह्य कारणमा निर्भर हुन सक्छन्, वा यो पूर्ण रूपमा संयोगले दुई क्रमहरू सहसंबद्ध हुन सक्छ। तर, बलियो गणितीय सहसंबंधले दुई चरहरू कुनै न कुनै रूपमा जडित छन् भन्ने राम्रो संकेत हो।

गणितीय रूपमा, दुई यादृच्छिक चरहरू बीचको सम्बन्ध देखाउने मुख्य अवधारणा भनेको **सहविचलन** हो, जुन यसरी गणना गरिन्छ: Cov(X,Y) = **E**\[(X-**E**(X))(Y-**E**(Y))\]। हामी दुवै चरहरूको औसत मानबाट विचलन गणना गर्छौं, र त्यस विचलनहरूको गुणनफल। यदि दुवै चरहरू सँगै विचलित हुन्छन्, गुणनफल सधैं सकारात्मक मान हुनेछ, जसले सकारात्मक सहविचलनमा थपिनेछ। यदि दुवै चरहरू असंगत रूपमा विचलित हुन्छन् (अर्थात् एउटा औसतभन्दा तल झर्दा अर्को औसतभन्दा माथि बढ्छ), हामी सधैं नकारात्मक संख्याहरू पाउँछौं, जसले नकारात्मक सहविचलनमा थपिनेछ। यदि विचलनहरू निर्भर छैनन्, तिनीहरू लगभग शून्यमा थपिनेछन्।

सहविचलनको पूर्ण मानले सहसंबंध कति ठूलो छ भन्ने कुरा धेरै बताउँदैन, किनभने यो वास्तविक मानहरूको परिमाणमा निर्भर गर्दछ। यसलाई सामान्य बनाउन, हामी दुवै चरहरूको मानक विचलनद्वारा सहविचलनलाई विभाजन गर्न सक्छौं, **सहसंबंध** प्राप्त गर्न। राम्रो कुरा यो हो कि सहसंबंध सधैं [-1,1] को दायरामा हुन्छ, जहाँ 1 ले मानहरू बीचको बलियो सकारात्मक सहसंबंध संकेत गर्दछ, -1 - बलियो नकारात्मक सहसंबंध, र 0 - कुनै सहसंबंध छैन (चरहरू स्वतन्त्र छन्)।

**उदाहरण**: हामी बेसबल खेलाडीहरूको डेटासेटबाट वजन र उचाइ बीचको सहसंबंध गणना गर्न सक्छौं:
```python
print(np.corrcoef(weights,heights))
```
नतिजाको रूपमा, हामी यस्तो **सहसंबंध म्याट्रिक्स** प्राप्त गर्छौं:
```
array([[1.        , 0.52959196],
       [0.52959196, 1.        ]])
```

> सहसंबंध म्याट्रिक्स C कुनै पनि संख्याको इनपुट क्रमहरू S<sub>1</sub>, ..., S<sub>n</sub> को लागि गणना गर्न सकिन्छ। C<sub>ij</sub> को मान S<sub>i</sub> र S<sub>j</sub> बीचको सहसंबंध हो, र कर्ण तत्वहरू सधैं 1 हुन्छन् (जसलाई S<sub>i</sub> को आत्म-सहसंबंध पनि भनिन्छ)।

हाम्रो केसमा, मान 0.53 ले संकेत गर्दछ कि व्यक्तिको वजन र उचाइ बीच केही सहसंबंध छ। हामी एक मानलाई अर्कोको विरुद्ध स्क्याटर प्लट पनि बनाउन सक्छौं ताकि सम्बन्धलाई दृश्य रूपमा देख्न सकिन्छ:

![वजन र उचाइ बीचको सम्बन्ध](../../../../1-Introduction/04-stats-and-probability/images/weight-height-relationship.png)

> सहसंबंध र सहविचलनका थप उदाहरणहरू [संग्लग्न नोटबुक](../../../../1-Introduction/04-stats-and-probability/notebook.ipynb) मा भेट्न सकिन्छ।

## निष्कर्ष

यस खण्डमा, हामीले सिक्यौं:

* डेटा को आधारभूत सांख्यिकीय गुणहरू, जस्तै औसत, विचलन, मोड र क्वार्टाइलहरू
* यादृच्छिक चरहरूको विभिन्न वितरणहरू, सामान्य वितरण सहित
* विभिन्न गुणहरू बीचको सहसंबंध कसरी पत्ता लगाउने
* केही परिकल्पनाहरू प्रमाणित गर्न गणित र सांख्यिकीको साउन्ड उपकरण कसरी प्रयोग गर्ने
* डेटा नमूनाको आधारमा यादृच्छिक चरको लागि विश्वास अन्तराल कसरी गणना गर्ने

यद्यपि यो सम्भाव्यता र सांख्यिकी भित्रका विषयहरूको पूर्ण सूची होइन, यो तपाईंलाई यस पाठ्यक्रममा राम्रो सुरुवात दिन पर्याप्त हुनुपर्छ।

## 🚀 चुनौती

नोटबुकमा रहेको नमूना कोड प्रयोग गरेर अन्य परिकल्पनाहरू परीक्षण गर्नुहोस्:
1. फर्स्ट बेसम्यान सेकेन्ड बेसम्यानभन्दा पुराना छन्
2. फर्स्ट बेसम्यान थर्ड बेसम्यानभन्दा अग्लो छन्
3. सर्टस्टप सेकेन्ड बेसम्यानभन्दा अग्लो छन्

## [पाठपश्चात क्विज](https://ff-quizzes.netlify.app/en/ds/quiz/7)

## समीक्षा र आत्म अध्ययन

संभाव्यता र सांख्यिकी यति व्यापक विषय हो कि यसले आफ्नै पाठ्यक्रमको हकदार छ। यदि तपाईं सिद्धान्तमा गहिरो जान इच्छुक हुनुहुन्छ भने, तपाईं निम्न पुस्तकहरू पढ्न जारी राख्न चाहनुहुन्छ:

1. [न्यूयोर्क विश्वविद्यालयका कार्लोस फर्नान्डेज-ग्रान्डा](https://cims.nyu.edu/~cfgranda/) का उत्कृष्ट व्याख्यान नोटहरू [Probability and Statistics for Data Science](https://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf) (अनलाइन उपलब्ध)
1. [पिटर र एन्ड्रु ब्रुस। Practical Statistics for Data Scientists.](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/) [[R मा नमूना कोड](https://github.com/andrewgbruce/statistics-for-data-scientists)]।
1. [जेम्स डी. मिलर। Statistics for Data Science](https://www.packtpub.com/product/statistics-for-data-science/9781788290678) [[R मा नमूना कोड](https://github.com/PacktPublishing/Statistics-for-Data-Science)]

## असाइनमेन्ट

[सानो मधुमेह अध्ययन](assignment.md)

## क्रेडिट

यो पाठ [दिमित्री सश्निकोभ](http://soshnikov.com) द्वारा ♥️ सहित लेखिएको हो।

---

**अस्वीकरण**:  
यो दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) प्रयोग गरेर अनुवाद गरिएको छ। हामी शुद्धताको लागि प्रयास गर्छौं, तर कृपया ध्यान दिनुहोस् कि स्वचालित अनुवादहरूमा त्रुटि वा अशुद्धता हुन सक्छ। यसको मूल भाषा मा रहेको मूल दस्तावेज़लाई आधिकारिक स्रोत मानिनुपर्छ। महत्वपूर्ण जानकारीको लागि, व्यावसायिक मानव अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न हुने कुनै पनि गलतफहमी वा गलत व्याख्याको लागि हामी जिम्मेवार हुने छैनौं।