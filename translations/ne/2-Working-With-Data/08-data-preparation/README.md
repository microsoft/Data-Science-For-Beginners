<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1b560955ff39a2bcf2a049fce474a951",
  "translation_date": "2025-09-06T07:44:34+00:00",
  "source_file": "2-Working-With-Data/08-data-preparation/README.md",
  "language_code": "ne"
}
-->
# डेटा संग काम गर्ने: डेटा तयारी

|![ Sketchnote by [(@sketchthedocs)](https://sketchthedocs.dev) ](../../sketchnotes/08-DataPreparation.png)|
|:---:|
|डेटा तयारी - _Sketchnote by [@nitya](https://twitter.com/nitya)_ |

## [पाठ अघि क्विज](https://ff-quizzes.netlify.app/en/ds/quiz/14)

डेटाको स्रोतको आधारमा, कच्चा डेटा केही असंगतिहरू समावेश गर्न सक्छ जसले विश्लेषण र मोडलिङमा चुनौतीहरू सिर्जना गर्दछ। अर्को शब्दमा, यस्तो डेटा "फोहोर" मानिन्छ र यसलाई सफा गर्न आवश्यक हुन्छ। यो पाठले हराएको, गलत, वा अपूर्ण डेटा सम्बोधन गर्न डेटा सफा गर्ने र परिवर्तन गर्ने प्रविधिहरूमा केन्द्रित छ। यस पाठमा समेटिएका विषयहरू Python र Pandas लाइब्रेरी प्रयोग गरेर [नोटबुकमा प्रदर्शन गरिनेछ](../../../../2-Working-With-Data/08-data-preparation/notebook.ipynb)।

## डेटा सफा गर्ने महत्त्व

- **प्रयोग र पुनःप्रयोगको सजिलो**: जब डेटा राम्रोसँग व्यवस्थित र सामान्यीकृत हुन्छ, यसलाई खोज्न, प्रयोग गर्न, र अरूसँग साझा गर्न सजिलो हुन्छ।

- **संगतता**: डेटा विज्ञानले प्रायः एकभन्दा बढी डेटासेटसँग काम गर्न आवश्यक हुन्छ, जहाँ विभिन्न स्रोतहरूबाट आएका डेटासेटहरूलाई एकसाथ जोड्नुपर्छ। प्रत्येक व्यक्तिगत डेटासेटमा समान मानकीकरण सुनिश्चित गर्दा सबै डेटासेटहरू एकसाथ मिल्दा पनि उपयोगी रहन्छ।

- **मोडलको शुद्धता**: सफा गरिएको डेटा मोडलहरूको शुद्धता सुधार गर्दछ, जुन यसमा निर्भर गर्दछ।

## सामान्य सफा गर्ने लक्ष्यहरू र रणनीतिहरू

- **डेटासेट अन्वेषण**: डेटा अन्वेषण, जुन [पछिल्लो पाठ](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/4-Data-Science-Lifecycle/15-analyzing) मा समेटिएको छ,ले सफा गर्न आवश्यक डेटा पत्ता लगाउन मद्दत गर्दछ। डेटासेटभित्रका मानहरू दृश्य रूपमा अवलोकन गर्दा बाँकी डेटा कस्तो देखिन्छ भन्ने अपेक्षा सेट गर्न सकिन्छ, वा समाधान गर्न सकिने समस्याहरूको विचार प्रदान गर्न सकिन्छ। अन्वेषणमा आधारभूत क्वेरी, भिजुअलाइजेसन, र नमूना समावेश हुन सक्छ।

- **फर्म्याटिङ**: स्रोतको आधारमा, डेटा प्रस्तुत गर्ने तरिकामा असंगतता हुन सक्छ। यसले डेटासेटमा मान देखिए पनि भिजुअलाइजेसन वा क्वेरी परिणामहरूमा सही रूपमा प्रतिनिधित्व नगरिएको अवस्थामा खोज्न र मान प्रस्तुत गर्न समस्या उत्पन्न गर्न सक्छ। सामान्य फर्म्याटिङ समस्याहरूमा ह्वाइटस्पेस, मिति, र डेटा प्रकार समाधान गर्न समावेश हुन्छ। फर्म्याटिङ मुद्दाहरू समाधान गर्ने जिम्मेवारी प्रायः डेटा प्रयोग गर्ने व्यक्तिहरूको हुन्छ। उदाहरणका लागि, मिति र संख्याहरू प्रस्तुत गर्ने मानक देश अनुसार फरक हुन सक्छ।

- **डुप्लिकेसन**: डेटा जसको एकभन्दा बढी घटना छ, गलत परिणाम उत्पादन गर्न सक्छ र सामान्यतया हटाउनुपर्छ। यो दुई वा बढी डेटासेटहरू जोड्दा सामान्य घटना हुन सक्छ। तर, त्यस्ता अवस्थामा डुप्लिकेसनले थप जानकारी प्रदान गर्न सक्छ र यसलाई सुरक्षित राख्न आवश्यक हुन सक्छ।

- **हराएको डेटा**: हराएको डेटा गलत परिणामहरू साथै कमजोर वा पक्षपाती परिणामहरू निम्त्याउन सक्छ। कहिलेकाहीँ यसलाई डेटा पुनःलोड गरेर, Python जस्ता कोड प्रयोग गरेर हराएको मानहरू भरेर, वा केवल मान र सम्बन्धित डेटा हटाएर समाधान गर्न सकिन्छ। डेटा किन र कसरी हरायो भन्ने आधारमा समाधानका कार्यहरू निर्भर हुन सक्छ।

## DataFrame जानकारी अन्वेषण गर्दै
> **सिक्ने लक्ष्य:** यो उपविभागको अन्त्यसम्ममा, तपाईं pandas DataFrames मा संग्रहित डेटा बारे सामान्य जानकारी पत्ता लगाउन सहज हुनुहुनेछ।

एकपटक तपाईंले pandas मा आफ्नो डेटा लोड गरेपछि, यो सम्भवतः DataFrame मा हुनेछ (पछिल्लो [पाठ](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/2-Working-With-Data/07-python#dataframe) मा विस्तृत अवलोकन हेर्नुहोस्)। तर, यदि तपाईंको DataFrame मा 60,000 पङ्क्ति र 400 स्तम्भहरू छन् भने, तपाईंले काम गर्न लागेको डेटा कस्तो छ भन्ने थाहा कसरी पाउनुहुन्छ? सौभाग्यवश, [pandas](https://pandas.pydata.org/) ले DataFrame को समग्र जानकारी छिटो हेर्नका लागि केही सुविधाजनक उपकरणहरू प्रदान गर्दछ।

यस कार्यक्षमता अन्वेषण गर्न, हामी Python scikit-learn लाइब्रेरी आयात गर्नेछौं र एक प्रसिद्ध डेटासेट प्रयोग गर्नेछौं: **Iris डेटा सेट**।

```python
import pandas as pd
from sklearn.datasets import load_iris

iris = load_iris()
iris_df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])
```
|                                        |sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|
|----------------------------------------|-----------------|----------------|-----------------|----------------|
|0                                       |5.1              |3.5             |1.4              |0.2             |
|1                                       |4.9              |3.0             |1.4              |0.2             |
|2                                       |4.7              |3.2             |1.3              |0.2             |
|3                                       |4.6              |3.1             |1.5              |0.2             |
|4                                       |5.0              |3.6             |1.4              |0.2             |

- **DataFrame.info**: सुरु गर्न, `info()` विधि `DataFrame` मा रहेको सामग्रीको सारांश प्रिन्ट गर्न प्रयोग गरिन्छ। यो डेटासेटमा के छ हेर्नुहोस्:
```python
iris_df.info()
```
```
RangeIndex: 150 entries, 0 to 149
Data columns (total 4 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   sepal length (cm)  150 non-null    float64
 1   sepal width (cm)   150 non-null    float64
 2   petal length (cm)  150 non-null    float64
 3   petal width (cm)   150 non-null    float64
dtypes: float64(4)
memory usage: 4.8 KB
```
यसबाट, हामीलाई थाहा हुन्छ कि *Iris* डेटासेटमा चार स्तम्भहरूमा 150 प्रविष्टिहरू छन् र कुनै पनि null प्रविष्टिहरू छैनन्। सबै डेटा 64-बिट फ्लोटिङ-पोइन्ट संख्याहरूको रूपमा संग्रहित छ।

- **DataFrame.head()**: त्यसपछि, `DataFrame` को वास्तविक सामग्री जाँच गर्न, हामी `head()` विधि प्रयोग गर्छौं। हाम्रो `iris_df` को पहिलो केही पङ्क्तिहरू कस्तो देखिन्छ हेर्नुहोस्:
```python
iris_df.head()
```
```
   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
0                5.1               3.5                1.4               0.2
1                4.9               3.0                1.4               0.2
2                4.7               3.2                1.3               0.2
3                4.6               3.1                1.5               0.2
4                5.0               3.6                1.4               0.2
```
- **DataFrame.tail()**: उल्टो, `DataFrame` को अन्तिम केही पङ्क्तिहरू जाँच गर्न, हामी `tail()` विधि प्रयोग गर्छौं:
```python
iris_df.tail()
```
```
     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)
145                6.7               3.0                5.2               2.3
146                6.3               2.5                5.0               1.9
147                6.5               3.0                5.2               2.0
148                6.2               3.4                5.4               2.3
149                5.9               3.0                5.1               1.8
```
> **टेकअवे:** DataFrame मा जानकारीको मेटाडेटा हेर्दा वा पहिलो र अन्तिम केही मानहरू हेर्दा मात्र, तपाईंले काम गरिरहेको डेटा आकार, प्रकार, र सामग्रीको तत्काल विचार प्राप्त गर्न सक्नुहुन्छ।

## हराएको डेटा सम्बोधन गर्दै
> **सिक्ने लक्ष्य:** यो उपविभागको अन्त्यसम्ममा, तपाईं DataFrames बाट null मानहरू प्रतिस्थापन वा हटाउन जान्नुहुनेछ।

प्रायः तपाईंले प्रयोग गर्न चाहेको (वा प्रयोग गर्नुपर्ने) डेटासेटहरूमा हराएको मानहरू हुन्छन्। हराएको डेटा कसरी सम्बोधन गरिन्छ भन्ने निर्णयले अन्तिम विश्लेषण र वास्तविक-विश्व परिणामहरूमा सूक्ष्म प्रभाव पार्न सक्छ।

Pandas ले हराएको मानहरू दुई तरिकामा सम्बोधन गर्छ। पहिलो, जुन तपाईंले पहिलेका खण्डहरूमा देख्नुभएको छ: `NaN`, वा Not a Number। यो वास्तवमा IEEE फ्लोटिङ-पोइन्ट निर्दिष्टीकरणको एक विशेष मान हो र यो केवल हराएको फ्लोटिङ-पोइन्ट मानहरू संकेत गर्न प्रयोग गरिन्छ।

फ्लोट बाहेकका हराएको मानहरूको लागि, pandas ले Python `None` वस्तु प्रयोग गर्छ। जबकि `None` र `NaN` ले समान कुरा संकेत गर्छन्, यी दुईको प्रयोगले प्रोग्रामिङमा केही प्रतिबन्धहरू ल्याउँछ। 

`NaN` र `None` को बारेमा थप जानकारी [नोटबुक](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/4-Data-Science-Lifecycle/15-analyzing/notebook.ipynb) बाट हेर्नुहोस्!

- **Null मानहरू पत्ता लगाउँदै**: `pandas` मा, `isnull()` र `notnull()` विधिहरू null डेटा पत्ता लगाउनका लागि मुख्य विधिहरू हुन्। दुवैले Boolean मास्कहरू फिर्ता गर्छन्। हामी `numpy` प्रयोग गरेर `NaN` मानहरू जाँच गर्नेछौं:
```python
import numpy as np

example1 = pd.Series([0, np.nan, '', None])
example1.isnull()
```
```
0    False
1     True
2    False
3     True
dtype: bool
```
आउटपुटलाई ध्यानपूर्वक हेर्नुहोस्। के यसले तपाईंलाई अचम्मित बनायो? उदाहरणका लागि, `0` एक अंकगणितीय null हो, तर pandas ले यसलाई पूर्णांकको रूपमा मान्छ। 

> **टेकअवे:** `isnull()` र `notnull()` विधिहरूले `DataFrame` मा समान परिणाम उत्पादन गर्छन्: तिनीहरूले परिणामहरू र ती परिणामहरूको सूचकांक देखाउँछन्, जसले तपाईंलाई डेटा व्यवस्थापनमा धेरै मद्दत गर्दछ।

- **Null मानहरू हटाउँदै**: हराएको मानहरू पहिचान गर्न बाहेक, pandas ले `Series` र `DataFrame` बाट null मानहरू हटाउन सुविधाजनक तरिका प्रदान गर्दछ। उदाहरणका लागि, `example1` मा फर्कौं:
```python
example1 = example1.dropna()
example1
```
```
0    0
2     
dtype: object
```
`DataFrame` मा दुई आयामहरू छन्, त्यसैले यसले डेटा हटाउनका लागि थप विकल्पहरू प्रदान गर्दछ।

```python
example2 = pd.DataFrame([[1,      np.nan, 7], 
                         [2,      5,      8], 
                         [np.nan, 6,      9]])
example2
```
|      | 0 | 1 | 2 |
|------|---|---|---|
|0     |1.0|NaN|7  |
|1     |2.0|5.0|8  |
|2     |NaN|6.0|9  |

तपाईं `DataFrame` बाट एकल मान हटाउन सक्नुहुन्न, त्यसैले तपाईंले पूर्ण पङ्क्ति वा स्तम्भहरू हटाउनुपर्छ। 

```python
example2.dropna()
```
```
	0	1	2
1	2.0	5.0	8
```
यदि आवश्यक छ भने, तपाईं स्तम्भहरूबाट NA मानहरू हटाउन सक्नुहुन्छ। `axis=1` प्रयोग गर्नुहोस्:
```python
example2.dropna(axis='columns')
```
```
	2
0	7
1	8
2	9
```
`dropna` मा `how` र `thresh` प्यारामिटरहरू प्रयोग गरेर, तपाईंले पङ्क्ति वा स्तम्भहरू हटाउन थप नियन्त्रण प्राप्त गर्न सक्नुहुन्छ।

```python
example2[3] = np.nan
example2
```
|      |0  |1  |2  |3  |
|------|---|---|---|---|
|0     |1.0|NaN|7  |NaN|
|1     |2.0|5.0|8  |NaN|
|2     |NaN|6.0|9  |NaN|

`thresh` प्यारामिटरले तपाईंलाई थप सूक्ष्म नियन्त्रण दिन्छ: तपाईंले पङ्क्ति वा स्तम्भहरूमा आवश्यक *non-null* मानहरूको संख्या सेट गर्न सक्नुहुन्छ:
```python
example2.dropna(axis='rows', thresh=3)
```
```
	0	1	2	3
1	2.0	5.0	8	NaN
```

- **Null मानहरू भर्दै**: कहिलेकाहीँ हराएको मानहरू हटाउनुभन्दा तिनीहरूलाई वैध मानहरूद्वारा प्रतिस्थापन गर्नु राम्रो हुन्छ। pandas ले `fillna` प्रदान गर्दछ, जसले हराएको मानहरू तपाईंको रोजाइको मानद्वारा प्रतिस्थापन गरेर `Series` वा `DataFrame` को प्रतिलिपि फिर्ता गर्छ। 

```python
example3 = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))
example3
```
```
a    1.0
b    NaN
c    2.0
d    NaN
e    3.0
dtype: float64
```
तपाईं सबै null प्रविष्टिहरूलाई एकल मान, जस्तै `0` द्वारा भर्न सक्नुहुन्छ:
```python
example3.fillna(0)
```
```
a    1.0
b    0.0
c    2.0
d    0.0
e    3.0
dtype: float64
```
तपाईं null मानहरूलाई **अगाडि-भर्ने** गर्न सक्नुहुन्छ:
```python
example3.fillna(method='ffill')
```
```
a    1.0
b    1.0
c    2.0
d    2.0
e    3.0
dtype: float64
```
तपाईं null मानहरूलाई **पछाडि-भर्ने** गर्न पनि सक्नुहुन्छ:
```python
example3.fillna(method='bfill')
```
```
a    1.0
b    2.0
c    2.0
d    3.0
e    3.0
dtype: float64
```
`DataFrame` मा पनि यो समान तरिकाले काम गर्छ। उदाहरणका लागि:
```python
example2.fillna(method='ffill', axis=1)
```
```
	0	1	2	3
0	1.0	1.0	7.0	7.0
1	2.0	5.0	8.0	8.0
2	NaN	6.0	9.0	9.0
```
जब अगाडि-भर्नेका लागि कुनै मान उपलब्ध छैन, null मान यथावत रहन्छ।
> **मुख्य कुरा:** तपाईंको डाटासेटहरूमा हराएका मानहरूलाई व्यवस्थापन गर्न धेरै तरिकाहरू छन्। तपाईंले प्रयोग गर्ने विशेष रणनीति (तिनीहरूलाई हटाउने, प्रतिस्थापन गर्ने, वा कसरी प्रतिस्थापन गर्ने) त्यो डाटाको विशेषताहरूले निर्धारण गर्नुपर्छ। तपाईंले डाटासेटहरूसँग जति धेरै काम गर्नुहुन्छ र अन्तरक्रिया गर्नुहुन्छ, हराएका मानहरूलाई कसरी व्यवस्थापन गर्ने भन्ने राम्रो समझ विकास हुनेछ।
## डुप्लिकेट डाटा हटाउने

> **शिक्षण लक्ष्य:** यो उपविभागको अन्त्यसम्ममा, तपाईंले DataFrames बाट डुप्लिकेट मानहरू पहिचान गर्न र हटाउन सहज महसुस गर्नुपर्छ।

हराएको डाटाका अतिरिक्त, तपाईंले वास्तविक संसारका डेटासेटहरूमा प्रायः डुप्लिकेट डाटा पनि भेट्नुहुनेछ। सौभाग्यवश, `pandas` ले डुप्लिकेट इन्ट्रीहरू पत्ता लगाउन र हटाउन सजिलो तरिका प्रदान गर्दछ।

- **डुप्लिकेट पहिचान: `duplicated`**: तपाईं `pandas` को `duplicated` मेथड प्रयोग गरेर सजिलै डुप्लिकेट मानहरू पत्ता लगाउन सक्नुहुन्छ। यसले Boolean मास्क फिर्ता गर्छ, जसले `DataFrame` मा कुनै इन्ट्री पहिलेको इन्ट्रीको डुप्लिकेट हो कि होइन भनेर देखाउँछ। यो कार्यमा हेर्नको लागि अर्को उदाहरण `DataFrame` बनाऔं।
```python
example4 = pd.DataFrame({'letters': ['A','B'] * 2 + ['B'],
                         'numbers': [1, 2, 1, 3, 3]})
example4
```
|      |letters|numbers|
|------|-------|-------|
|0     |A      |1      |
|1     |B      |2      |
|2     |A      |1      |
|3     |B      |3      |
|4     |B      |3      |

```python
example4.duplicated()
```
```
0    False
1    False
2     True
3    False
4     True
dtype: bool
```
- **डुप्लिकेट हटाउने: `drop_duplicates`:** यसले `duplicated` मानहरू `False` भएका डाटाको प्रतिलिपि फिर्ता गर्छ:
```python
example4.drop_duplicates()
```
```
	letters	numbers
0	A	1
1	B	2
3	B	3
```
`duplicated` र `drop_duplicates` दुबैले डिफल्ट रूपमा सबै स्तम्भहरूलाई विचार गर्छन्, तर तपाईं आफ्नो `DataFrame` मा केवल केही स्तम्भहरू जाँच्न निर्दिष्ट गर्न सक्नुहुन्छ:
```python
example4.drop_duplicates(['letters'])
```
```
letters	numbers
0	A	1
1	B	2
```

> **मुख्य कुरा:** डुप्लिकेट डाटा हटाउनु लगभग हरेक डाटा-साइन्स प्रोजेक्टको महत्त्वपूर्ण भाग हो। डुप्लिकेट डाटाले तपाईंको विश्लेषणको नतिजा परिवर्तन गर्न सक्छ र गलत नतिजा दिन सक्छ।


## 🚀 चुनौती

यहाँ छलफल गरिएका सबै सामग्रीहरू [Jupyter Notebook](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/2-Working-With-Data/08-data-preparation/notebook.ipynb) को रूपमा उपलब्ध छन्। साथै, प्रत्येक खण्डपछि अभ्यासहरू पनि छन्, तिनीहरूलाई प्रयास गर्नुहोस्!

## [पोस्ट-लेक्चर क्विज](https://ff-quizzes.netlify.app/en/ds/quiz/15)



## समीक्षा र आत्म-अध्ययन

तपाईंको डाटालाई विश्लेषण र मोडलिङको लागि तयार पार्नका लागि विभिन्न तरिकाहरू पत्ता लगाउन र अपनाउन सकिन्छ। डाटा सफा गर्ने चरण एक महत्त्वपूर्ण "हातको अनुभव" हो। Kaggle का यी चुनौतीहरू प्रयास गर्नुहोस् जसले यस पाठले समेट्न नसकेको प्रविधिहरू अन्वेषण गर्न मद्दत गर्दछ।

- [डाटा सफा गर्ने चुनौती: मिति पार्सिङ](https://www.kaggle.com/rtatman/data-cleaning-challenge-parsing-dates/)

- [डाटा सफा गर्ने चुनौती: डाटा स्केल र नर्मलाइज गर्नुहोस्](https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data)


## असाइनमेन्ट

[फारमबाट डाटा मूल्याङ्कन गर्नुहोस्](assignment.md)

---

**अस्वीकरण**:  
यो दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) प्रयोग गरेर अनुवाद गरिएको छ। हामी शुद्धताको लागि प्रयास गर्छौं, तर कृपया ध्यान दिनुहोस् कि स्वचालित अनुवादहरूमा त्रुटि वा अशुद्धता हुन सक्छ। यसको मूल भाषा मा रहेको मूल दस्तावेज़लाई आधिकारिक स्रोत मानिनुपर्छ। महत्वपूर्ण जानकारीको लागि, व्यावसायिक मानव अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न हुने कुनै पनि गलतफहमी वा गलत व्याख्याको लागि हामी जिम्मेवार हुने छैनौं।