{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability మరియు Statistics కు పరిచయం\n",
    "ఈ నోట్బుక్‌లో, మనం మునుపటి చర్చించిన కొన్ని భావాలను అన్వయించుకుంటాము. Probability మరియు Statistics నుండి అనేక భావనలు Python లోని ముఖ్యమైన డేటా ప్రాసెసింగ్ గ్రంధాలయాలలో, ఉదాహరణకు `numpy` మరియు `pandas` లో బాగా సూచించబడ్డాయి.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## రాండమ్ వేరియబుల్స్ మరియు పంపిణీలు\n",
    "0 నుండి 9 వరకు ఉన్న యూనిఫారం పంపిణితం నుండి 30 విలువల నమూనాను చూపడం ప్రారంభిద్దాం. మేము సగటు మరియు వ్యత్యాసాన్ని కూడా లెక్కించబోతున్నాం.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [ random.randint(0,10) for _ in range(30) ]\n",
    "print(f\"Sample: {sample}\")\n",
    "print(f\"Mean = {np.mean(sample)}\")\n",
    "print(f\"Variance = {np.var(sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "నమూనాలో ఎంతమేర విలువలు ఉన్నాయో దృష్టిగావ చూడటానికి, మనము **హిస్టోగ్రామ్**ని చిత్రించవచ్చు:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## నిజమైన డేటాను విశ్లేషించడం\n",
    "\n",
    "నిజమైన ప్రపంచ డేటాను విశ్లేషించేటప్పుడు సగటు మరియు వ్యత్యాసం చాలా ముఖ్యమైనవి. [SOCR MLB Height/Weight Data](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_MLB_HeightsWeights) నుండి బేస్‌బాల్ ప్లేయర్ల సంబంధిత డేటాను లోడ్ చేద్దాం\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/SOCR_MLB.tsv\",sep='\\t', header=None, names=['Name','Team','Role','Weight','Height','Age'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> మేము ఇక్కడ డేటా విశ్లేషణ కోసం [**Pandas**](https://pandas.pydata.org/) అనే ప్యాకేజ్‌ని ఉపయోగించుకుంటున్నాము. ఈ కోర్సులో తరువాత Pandas మరియు Pythonలో డేటాతో పని గురించి మరింత చర్చిస్తాము.\n",
    "\n",
    "వయస్సు, ఎత్తు మరియు బరువు కోసం సగటు విలువలను లెక్కించుదాం:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Age','Height','Weight']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ఇప్పుడు మనము ఎత్తుపై దృష్టి సారించి, ప్రామాణిక విచలనం మరియు వ్యత్యాసాన్ని లెక్కించుకుందాం:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df['Height'])[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df['Height'].mean()\n",
    "var = df['Height'].var()\n",
    "std = df['Height'].std()\n",
    "print(f\"Mean = {mean}\\nVariance = {var}\\nStandard Deviation = {std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "సగటు విలువ తప్ప ఇప్పటి మధ్య విలువ మరియు క్వార్టైళ్లను చూసుకోవడం కూడా అర్థవంతమైంది. వాటిని **బాక్స్ ప్లాట్** ఉపయోగించి దృశ్య రూపంలో చూపించవచ్చు:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2))\n",
    "plt.boxplot(df['Height'].ffill(), vert=False, showmeans=True)\n",
    "plt.grid(color='gray', linestyle='dotted')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "మనం మా డేటాసెట్ యొక్క ఉపసమూహాల బాక్స్ ప్లాట్లు కూడా తయారు చేయవచ్చు, ఉదాహరణకు, ప్లేయర్ పాత్ర ఆధారంగా గ్రూప్ చేయబడినవి.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='Height', by='Role', figsize=(10,8))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **గమనిక**: ఈ диаг్రామ్ సూచిస్తోంది, సగటున, ఫస్ట్ బేస్ మ్యాన్‌ల పొడవు సెకండ్ బేస్ మ్యాన్‌ల పొడవు కంటే ఎక్కువ ఉంటుందని. తరువాత మనం ఈ సార్ధకతను మరింత అధికారికంగా ఎలా పరీక్షించాలో, మరియు మన డేటా గణాంకపరంగా సార్ధకమైనదని ఎలా నిరూపించాలో నేర్చుకుంటాము.  \n",
    "\n",
    "వయసు, పొడవు మరియు బరువు అన్నీ నిరంతర రాండమ్ వేరియబుల్‌లు. అవి ఎలా పంపిణీ అవుతాయనుకుంటున్నారు? వాటి పంపిణీని గమ్యం చేసుకోవడానికి మంచి మార్గం విలువల హిస్టోగ్రామ్‌ను గీయడమటే: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weight'].hist(bins=15, figsize=(10,6))\n",
    "plt.suptitle('Weight distribution of MLB Players')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## సాధారణ విభజన\n",
    "\n",
    "మన నిజమైన డేటాతోనే సగటు మరియు వ్యత్యాసం కలిగిన సాధారణ విభజనను అనుసరించే బరువుల искусственном నమూనాను సృష్టించుకుందాం:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = np.random.normal(mean, std, 1000)\n",
    "generated[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(generated, bins=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(np.random.normal(0,1,50000), bins=300)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "వాస్తవ జీవితంలో ఎక్కువ విలువలు సాధారణంగా పంపిణీ అవుతాయి కనుక, నమూనా డేటాను సృష్టించడానికి ఒక సమాన రాండమ్ సంఖ్య జనరేటర్ ను ఉపయోగించకూడదు. సమాన పంపిణీతో బరువులను సృష్టించాలని ప్రయత్నిస్తే, ( `np.random.rand` ద్వారా సృష్టించబడిన):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_sample = np.random.rand(1000)*2*std+mean-std\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(wrong_sample)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## విశ్వాస మధ్యవర్తిత్వాలు\n",
    "\n",
    "ఇప్పుడు బేస్‌బాల్ ఆటగాళ్ల బరువులు మరియు ఎత్తుల కోసం విశ్వాస మధ్యవర్తిత్వాలను లెక్కిద్దాం. మేము కింద తెలిపిన కోడ్‌ను [ఈ stackoverflow చర్చ నుండి](https://stackoverflow.com/questions/15033511/compute-a-confidence-interval-from-sample-data) ఉపయోగిస్తాము:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, h\n",
    "\n",
    "for p in [0.85, 0.9, 0.95]:\n",
    "    m, h = mean_confidence_interval(df['Weight'].fillna(method='pad'),p)\n",
    "    print(f\"p={p:.2f}, mean = {m:.2f} ± {h:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ఊహ పరీక్ష\n",
    "\n",
    "మన బేస్‌బాల్ ప్లేయర్ల డేటాసెట్‌లో వివిధ పాత్రలను పరిశీలిద్దాం:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Role').agg({ 'Weight' : 'mean', 'Height' : 'mean', 'Age' : 'count'}).rename(columns={ 'Age' : 'Count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "మొదటి బేస్‌మెన్‌లు రెండవ బేస్‌మెన్‌ల కంటే ఎత్తైనవారంటే ఆ హైపోతీసిస్‌ను పరీక్షిద్దాం. దీనికి సరళమైన పద్ధతి కాంఫిడెన్స్ ఇంటర్వల్స్‌ను పరీక్షించడం:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [0.85,0.9,0.95]:\n",
    "    m1, h1 = mean_confidence_interval(df.loc[df['Role']=='First_Baseman',['Height']],p)\n",
    "    m2, h2 = mean_confidence_interval(df.loc[df['Role']=='Second_Baseman',['Height']],p)\n",
    "    print(f'Conf={p:.2f}, 1st basemen height: {m1-h1[0]:.2f}..{m1+h1[0]:.2f}, 2nd basemen height: {m2-h2[0]:.2f}..{m2+h2[0]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "మేము ఇంటర్వల్స్ ఒప్పుకోకపోవడం స్పష్టంగా చూడవచ్చు.\n",
    "\n",
    "సాంఖ్యికంగా మరింత సరైన హైపోథసిస్ నిరూపణ మార్గం **స్టూడెంట్ t-టెస్ట్** ఉపయోగించడమే:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "tval, pval = ttest_ind(df.loc[df['Role']=='First_Baseman',['Height']], df.loc[df['Role']=='Second_Baseman',['Height']],equal_var=False)\n",
    "print(f\"T-value = {tval[0]:.2f}\\nP-value: {pval[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ttest_ind` ఫังก్షన్ ఇచ్చే రెండు విలువలు ఏమిటంటే:\n",
    "* p-విలువను రెండు పంపిణీలకు ఒకే సగటు ఉందని భావించే అంద probability గా చూడవచ్చు. మన సందర్భంలో, ఇది చాలా తక్కువగా ఉంది, అంటే మొదటి బేస్‌మెన్‌లు పొడవైనవారని బలమైన సాక్ష్యం ఉంది.\n",
    "* t-విలువ అనేది t-పరీక్షలో ఉపయోగించే సాంద్రీకృత సగటు తేడా యొక్క మధ్యస్థ విలువ, మరియు ఇది ఇచ్చిన నమ్మక విలువ కోసం ఒక పరిమితి విలువతో పోల్చబడుతుంది.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## కేంద్రీయ పరిమితి సిద్ధాంతం సహితంగా సాధారణ పంపిణీ అనుకరణ\n",
    "\n",
    "Pythonలో ఉన్న దుష్టసంఖ్యాత్మక జన్యకము మనకు సమాన పంపిణీని అందించడానికి రూపొంది ఉంటుంది. మనం సాధారణ పంపిణీ కోసం ఒక జన్యకాన్ని సృష్టించాలనుకుంటే, కేంద్రీయ పరిమితి సిద్ధాంతం ఉపయోగించవచ్చు. సాధారణంగా పంపిణీచేసిన విలువను పొందడానికి, మనం సమానంగా ఉత్పత్తి చేసిన నమూనా యొక్క సగటును లెక్కించగలం.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_random(sample_size=100):\n",
    "    sample = [random.uniform(0,1) for _ in range(sample_size) ]\n",
    "    return sum(sample)/sample_size\n",
    "\n",
    "sample = [normal_random() for _ in range(100)]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(sample)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## అనుబంధం మరియు చెడ్డ బేస్‌బాల్ కార్పొరేషన్\n",
    "\n",
    "అనుబంధం మాకు డేటా క్రమాల మధ్య సంబంధాలను కనుగొనడానికి సహాయపడుతుంది. మన ఆట వేళ ఉదాహరణలో, ఒక చెడ్డ బేస్‌బాల్ సంస్థ ఉంది అని భావిద్దాం, అది తన ఆటగాళ్లను వారి ఎత్తు ప్రకారం పారితోషకం ఇస్తుంది - ఆటగాడు ఎత్తైనట్లయితే, అతను/ఆమె ఎక్కువ డబ్బు పొందుతాడు/ఉంటుంది. మూల వేతనం $1000 మరియు ఎత్తును ఆధారంగా $0 నుండి $100 వరకు అదనపు బోనస్ ఉంటుందని అనుకోండి. మనము MLB నుండి నిజమైన ఆటగాళ్లను తీసుకొని, వారి కల్పిత జీతాల‌ను లెక్కించబోతున్నాము:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = df['Height'].fillna(method='pad')\n",
    "salaries = 1000+(heights-heights.min())/(heights.max()-heights.mean())*100\n",
    "print(list(zip(heights, salaries))[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ఇప్పుడు ఆ సీక్వెన్సుల కోవేరియన్స్ మరియు కోరిలేషన్ లను లెక్కిద్దాం. `np.cov` మాకు కోవేరియన్స్ యొక్క విస్తరణ అయిన ఒక **కోవేరియన్స్ మ్యాట్రిక్స్** ను ఇస్తుంది, ఇది బహు చారాలను ఆక్రమిస్తుంది. కోవేరియన్స్ మ్యాట్రిక్స్ $M$ లోని మూలకం $M_{ij}$ ఇన్‌పుట్ చారాలు $X_i$ మరియు $X_j$ మధ్య కోవేరియన్స్, మరియు డయాగనల్ విలువలు $M_{ii}$ $X_{i}$ యొక్క వ్యత్యాసం. ఇది లాగే, `np.corrcoef` మాకు **కోరిలేషన్ మ్యాట్రిక్స్** ను ఇస్తుంది.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Covariance matrix:\\n{np.cov(heights, salaries)}\")\n",
    "print(f\"Covariance = {np.cov(heights, salaries)[0,1]}\")\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "సంబంధం 1 కు సమానం అంటే రెండు మేరలు మధ్య బలమైన **సరణి సంబంధం** ఉందని అర్థం. మనం ఒక విలువను మరొకదాన్ని వ్యతిరేకంగా గీసే ద్వారా సరణి సంబంధాన్ని దృశ్యరూపంలో చూడవచ్చు:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(heights,salaries)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "సంబంధం రేఖీయ కాకపోతే ఏమవుతుందో చూద్దాం. మన సంస్థ ఎత్తులు మరియు వేతనాల మధ్య స్పష్టమైన రేఖీయ ఆధారితాన్ని దాచిపెట్టాలని నిర్ణయించుకొని, సూత్రంలో కొంత రేఖీయతలేని భాగాన్ని, ఉదాహరణకు `sin`ని చేర్చిందని అనుకుందాం:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = 1000+np.sin((heights-heights.min())/(heights.max()-heights.mean()))*100\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ఈ సందర్భంలో, సహసంబంధం కొంచెం తక్కువగా ఉంది, కానీ అది ఇంకా చాలా ఎక్కువగా ఉంది. ఇప్పుడు, సంబంధాన్ని మరింత స్పష్టంగా కానివ్వడానికి, జీతానికి కొంత అదనపు రాండమ్ వేరియబుల్ జోడించడం ద్వారా కొన్ని అదనపు యాదృచ్ఛికతను చేర్చవచ్చు. ఏం జరుగుతుందో చూద్దాం:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = 1000+np.sin((heights-heights.min())/(heights.max()-heights.mean()))*100+np.random.random(size=len(heights))*20-10\n",
    "print(f\"Correlation = {np.corrcoef(heights, salaries)[0,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(heights, salaries)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> మీరు అంగీకరించగలరా ఎందుకు చిదులు ఈరూపంలో నిలబడతాయి?\n",
    "\n",
    "మనం జీతం వంటి కృత్రిమంగా రూపొందించిన భావన మరియు గమనించిన మార్పిడి *ఎత్తు* మధ్య సంబంధాన్ని గమనించాము.ఇప్పుడు, ఎత్తు మరియు బరువు వంటి రెండు గమనించిన మార్చులు కూడా సంబంధితమయ్యాయో లేదో చూద్దాము:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df['Height'].ffill(),df['Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "దుఃఖంగా, మనకి ఎలాంటి ఫలితాలు లభించలేదు - కేవలం కొన్ని అపరిచితమైన `nan` విలువలు మాత్రమే లభించాయి. ఇది మా సిరీస్‌లోని కొన్ని విలువలు నిర్వచించబడలేదు, వాటిని `nan`తో ప్రదర్శించబడుతుంది, తద్వారా ఆపరేషన్ ఫలితం కూడా నిర్వచించబడదు. మ్యాట్రిక్స్‌ను పరిశీలిస్తూ మనం చూస్తే `Weight` కాలమ్ సమస్యగా ఉంది, ఎందుకంటే `Height` విలువల మధ్య స్వీయ-సంబంధం లెక్కించబడింది.\n",
    "\n",
    "> ఈ ఉదాహరణ **డేటా తయారీ** మరియు **శుభ్రపరచడంల యొక్క ప్రాముఖ్యతను** చూపిస్తుంది. సరైన డేటా లేకుండా మనం ఎలాంటి లెక్కింపులు జరపలేము.\n",
    "\n",
    "మిస్ అయ్యిన విలువలను పూరించడానికి `fillna` మెథడ్‌ను ఉపయోగించి, సంబంధాన్ని లెక్కించుకుందాం:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df['Height'].fillna(method='pad'), df['Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "వాస్తవానికి ఒక సంబంధం ఉంది, కానీ మా కృత్రిమ ఉదాహరణలో ఉన్నంత కఠినమైనటి కాదు. నిజంగా, ఒక విలువను మరొక విలువకు వ్యతిరేకంగా స్ఫురణ చార్ట్‌లో చూస్తే, సంబంధం చాలా తక్కువ స్పష్టంగా ఉంటుంది:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(df['Weight'],df['Height'])\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Height')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ముగింపు\n",
    "\n",
    "ఈ నోట్బుక్‌లో మేము గణాంక ఫంక్షన్‌లను లెక్కించడానికి డేటాపై ప్రాథమిక కార్యకలాపాలను ఎలా నిర్వహించాలో నేర్చుకున్నాము. కొన్ని ఊహాగానాలను నిరూపించడానికి సబ్బంది గణితం మరియు గణాంకాల పరికరాన్ని ఎలా ఉపయోగించాలో, మరియు డేటా నమూనా ఇచ్చిన అల్ప విస్తరణ విలువలకు విశ్వాస అంతరాలను ఎలా లెక్కించాలో మాకు ఇప్పుడు తెలుసు.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**ముక్తాపత్రం**:  \nఈ పత్రాన్ని AI అనువాద సేవ [Co-op Translator](https://github.com/Azure/co-op-translator) ద్వారా అనువదించబడ్డది. మేము అత్యంత ఖచ్చితత్వానికి ప్రాముఖ్యత ఇస్తున్నప్పటికీ, ఆటోమేటెడ్ అనువాదాలలో పிழళ్లు లేదా అసమర్థతలు ఉండవచ్చు. మౌలిక పత్రం స్వదేశి భాషలోనే అధికారిక మూలంగా తీసుకోవాలి. కీలక సమాచారం కోసం, వ్యావసాయిక మానవ అనువాదం సిఫార్సు చేయబడుతుంది. ఈ అనువాదాన్ని ఉపయోగించడం వల్ల ఏర్పడే ఏవైనా అపార్థాలు లేదా തെറ്റుమాటలకు మేము బాధ్యత వహించటంలేదు.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86193a1ab0ba47eac1c69c1756090baa3b420b3eea7d4aafab8b85f8b312f0c5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "coopTranslator": {
   "original_hash": "0f899e3c5019f948e7c787b22f3b2304",
   "translation_date": "2026-01-16T23:08:10+00:00",
   "source_file": "1-Introduction/04-stats-and-probability/notebook.ipynb",
   "language_code": "te"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}